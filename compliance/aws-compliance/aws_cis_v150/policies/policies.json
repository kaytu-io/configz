[
    {
        "ID": "aws_cis_v150_1_1",
        "Title": "1.1 Maintain current contact details",
        "Description": "Ensure contact email and telephone details for AWS accounts are current and map to more than one individual in your organization.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v150_1_1.md",
        "ManualVerification": true,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# Control: Contact Email and Phone Details \n\nIn order to enhance the security and accessibility of your AWS accounts, it is crucial that the contact email and telephone details are up-to-date and link to more than one individual within your organization. \n\n## Purpose:\n\nThis control ensures that alerts or notifications sent by AWS, important account information or any incident response activities can be responded to promptly and efficiently, rather than being missed or delayed.\n\n## Steps for Compliance:\n\n1. **Check Account Information:** Log into your AWS account and go to the account settings to check the current contact email and phone numbers.\n\n2. **Update Contact Information:** If the contact details are outdated or not correct, update them as necessary. \n\n3. **Add Multiple Contacts:** To ensure reliability, it's recommended to map the contact information to more than one individual within your organization. This ensures that if the primary contact is unavailable, another responsible person can promptly respond to any alerts or notifications sent by AWS. Multiple contacts can be added in the AWS Management Console.\n\nHaving multiple points of contact increases redundancy, making sure that important notifications do not get overlooked.\n\n## Audit:\n\nPerform regular checks on the contact information of your AWS accounts, ensuring that they are correct and current. Make sure that the email addresses and telephone numbers listed are those of the appropriate contacts within your organization.\n\nConsider setting up a quarterly or semi-annual reminder to review and update the contact information. \n\n## Remediation:\n\nWhenever you find that the contact details are outdated or if a listed contact person is no longer appropriate (e.g., they left the company or changed positions), promptly update or change the relevant details in the AWS Management Console.\n\nRemember — communication is a key aspect of managing cloud resources efficiently and securely. By keeping your contact information current and having more than one contact person, you can improve both the security and performance of your AWS accounts."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the mentioned AWS control could lead to several consequences such as:\n\n1. **Communication Issue:** If an AWS account's contact details are not up-to-date or not associated with multiple individuals, important information may not reach the right people timely. This could include critical alerts, updates, security notifications, usage reports, billing information, and other key data.\n\n2. **Delayed Resolution:** In case of any technical issue or an emergency situation related to AWS services, the resolution process could be delayed as support from AWS will struggle to reach relevant personnel in the organization.\n\n3. **Security Risks:** It could pose a security risk if an AWS-related alert or issue cannot be promptly addressed because the email or phone number is not current or if the responsible person is not available. This delay can potentially allow a security issue to escalate, causing more damage.\n\n4. **Data Loss:** If the account is tied to only one individual who leaves the organization, it could potentially result in data loss, especially if no other person in the organization has access to that account.\n\n5. **Operational Disruption:** If the only account holder is absent or unavailable during a critical issue, it could disrupt ongoing operations using AWS services. \n\n6. **Regulatory Fines:** Depending on regulatory standards and guidelines in different jurisdictions, not having updated contact information and responsible individuals may lead to fines and penalties from regulatory bodies. \n\n```markdown\n- Communication Issue: Important information may not reach right people timely which includes critical alerts, updates, etc.\n- Delayed Resolution: Any technical or emergency situation related to AWS services might get delayed for resolution due to outdated contact info.\n- Security Risks: Increased risk of security threats if any AWS-related alert or issue is not addressed promptly. \n- Data Loss: Potential data loss if account is tied to only one individual who leaves the organization.\n- Operational Disruption: If the only account holder is absent during a critical issue, it can disrupt ongoing operations.\n- Regulatory Fines: Potential fines and penalties from regulatory bodies for not having updated contact information and responsible individuals.\n```\nRemember that non-compliance to this AWS control can result in higher monetary and operational costs than simply keeping the contact details current and mapped to more than one individual."
            ],
            "x-kaytu-usefulness-example": [
                "This AWS control is particularly useful in case of emergencies related to your AWS account. For instance, if a breach is detected on your AWS account, AWS will try to contact the owners of the account immediately. If the contact details are outdated or only linked to one individual who is unavailable at the time, this could delay the response rate and lead to further damage. Updating the contact email and telephonic details and mapping them to multiple individuals ensures quicker response, better communication, and more effective handling of the incident."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_2",
        "Title": "1.2 Ensure security contact information is registered",
        "Description": "AWS provides customers with the option of specifying the contact information for account's security team. It is recommended that this information be provided.",
        "QueryID": "aws_account_alternate_contact_security_registered",
        "DocumentURI": "policies/aws_cis_v150_1_2.md",
        "ManualVerification": false,
        "Severity": "Low",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Security Contact \n\nAWS, or Amazon Web Services, provides a security feature that allows customers to specify the contact information of an account's security team. This feature is important as it allows AWS to communicate readily with the account's security team when needed.\n\n## Why Should You Specify Security Contact Information? \n\nSpecifying the contact information for your AWS account's security team is a matter of best practice for several reasons: \n\n1. **Rapid Incident Response:** In case of any security incidents, AWS can rapidly reach out to the designated security personnel for prompt resolution. \n2. **Strategic Communication:** AWS can send important security advisories and recommendations targeted towards improving an account's security posture.\n3. **Account Recovery:** Should account access be lost or compromised, having designated security contacts can be crucial.\n\n## How To Define a Security Contact\n\nTo define a security contact in the AWS management console, perform the following steps:\n\n1. Go to your account settings in the AWS Management Console.\n2. Scroll down to the section labeled \"Safety and Security Details\".\n3. Fill in contact information, including email addresses and phone numbers for your security team.\n4. Click the update button to finalize and save your changes. \n\nRemember to update this information regularly, especially when there are changes in your security team.\n\n```markdown\n**Note:** AWS takes privacy seriously and assures that this information is used strictly for security purposes.\n```\n\nIn conclusion, providing a contact for your AWS account's security team plays a crucial role towards ensuring your account's overall security. AWS recommends all customers utilize this feature."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can have multiple costs:\n\n1. **Delayed Incident Response:** In cases of security incidents or breaches involving your AWS resources, AWS's ability to promptly contact and cooperate with your security team can significantly speed up incident response and investigation. If AWS can’t reach your security team immediately due to missing or outdated contact information, there are potential delays in resolving these incidents, which can lead to extended downtime or data exposure.\n\n2. **Increased Vulnerability:** If AWS cannot contact your security team about potential vulnerabilities or necessary patching and remediation steps, your resources might remain at risk for longer than necessary. This could potentially result in a security breach, loss of data, or other negative impacts.\n\n3. **Non-Compliance Penalties:** If your organization is subject to specific industry regulations or standards (like PCI DSS for payment card information or HIPAA for health-related data), not providing such mandatory contact can make your organization fall out of compliance, leading to penalties or fines.\n\n4. **Reputation Damage:** If a security incident were to occur and response was slowed due to inadequate contact information, it could result in reputational damage. This could impact customer trust and lead to loss of business.\n\n5. **Increased Operational Costs:** Time spent tracking down appropriate contacts in the event of an issue could have been spent on resolving the issue. This creates additional operational costs and inefficiencies. \n\nThese potential costs highlight the importance of complying with this AWS control by maintaining updated security contact information."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company named XYZ Corporation has an account on AWS for handling its cloud computing needs. They have a dedicated security team whose job it is to address any security-related issues that can potentially arise. \n\nBy specifying the contact information of their security team, AWS can directly get in touch with them in the event of any security incidents like unauthorized access, breaches or threats. This reduces the time taken to find the right contact, ensuring swift communication and quicker resolution of the issue. \n\nMoreover, it simplifies the process of conducting regular audits and reviews as AWS already has the necessary contact information. This ensures that communication regarding security matters is always directed to the right department in XYZ Corporation, making it a useful control tool. \n\n```\nExample:\n\u003caws-control\u003e\n    \u003ccontact-info\u003e\n        \u003csecurity-team\u003e\n            \u003cname\u003eXYZ Corporation Security Team\u003c/name\u003e\n            \u003cemail\u003esecurity@xyzcorporation.com\u003c/email\u003e\n            \u003cphone\u003e1234567890\u003c/phone\u003e\n        \u003c/security-team\u003e\n    \u003c/contact-info\u003e\n\u003c/aws-control\u003e\n```\n\nSpecifying the contact information in such a manner ensures that AWS always has the correct information to reach out to the security teams of their clients, ensuring smooth and efficient handling of security incidents."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_1",
        "Title": "3.1 Ensure CloudTrail is enabled in all regions",
        "Description": "AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services (such as CloudFormation).",
        "QueryID": "aws_cloudtrail_multi_region_read_write_enabled",
        "DocumentURI": "policies/aws_cis_v150_3_1.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "## AWS CloudTrail\n\n**AWS CloudTrail** is a web service that is designed to log and continuously monitor account activity related to actions across your AWS infrastructure. It captures a comprehensive record of every API (Application Programming Interface) call that occurs in your account, which includes all API calls made from the AWS Management Console, Command Line Tools, SDKs (Software Development Kits), and other AWS services. \n\n### What Does AWS CloudTrail Record?\n\nHere is a breakdown of the key information AWS CloudTrail records:\n\n- **Identity of the API Caller:** The identity or identification credentials of the individual or service who made the call to the API are recorded.\n\n- **Time of API Call:** Logs the exact time the API call was made. This timestamp provides a chronological context and helps track when specific changes were made.\n\n- **Source IP Address of the API Caller:** Records the IP address from which the API call was made - giving a geographical context to the API call.\n\n- **Request Parameters:** Logs the specifics of what could have been requested or modified via the API call.\n\n- **Response Elements:** This encompasses the output or outcomes delivered by the API call. In essence, this reveals what the API call achieved or modified in your AWS infrastructure.\n\n- **Other Information:** In addition to the above, CloudTrail logs other relevant data like the resources that the API call acted upon, the user-agent string of the API caller, etc.\n\n### Key Features of AWS CloudTrail\n\nIn general, AWS CloudTrail is leveraged for several crucial purposes by organizations, such as:\n\n- **Security Analysis:** Allows the detection of suspicious activity and the identification of trends related to API calls.\n\n- **Compliance Auditing:** Helps meet compliance requirements by recording and storing account activity.\n\n- **Operational Troubleshooting:** Allows the user to view, track, and understand actions that modify or impact their environment.\n\nFor more information about AWS CloudTrail, visit [AWS Official Documentation](https://aws.amazon.com/cloudtrail/)."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS control could manifest in several forms:\n\n1. **Potential for a Security Breach**: AWS CloudTrail is a crucial tool for security and governance. It logs all the activity within your AWS environment, making it easier for security teams to analyze any suspicious activity. If a breach occurs, the lack of CloudTrail logs would make it difficult to assess the extent of the breach or identify the weak points that the intruder exploited.\n\n2. **Trouble during Auditing**: If your business is subject to compliance standards like GDPR, HIPAA, or PCI DSS, auditors may require evidence of logging and monitoring. Non-compliance with AWS CloudTrail controls could lead to failed audits and potential penalties.\n\n3. **Loss of operational insight**: Aside from security, CloudTrail is also used for troubleshooting operational issues, understanding system activity patterns, and making optimization decisions. Without it, businesses could lose valuable insights that could help them in their decision-making process.\n\n4. **Costly forensic investigations**: In the case of security incidents, forensic investigations can be significantly more time-consuming and costly without AWS CloudTrail logs. This is because these logs can help narrow down the timeline, source, and the impact of the incident relatively easily.\n\n5. **Trouble in accountability**: CloudTrail also keeps track of which user made which changes in the environment. So without CloudTrail, it would be difficult to follow back and keep track of accountability if something goes wrong.\n\nIn conclusion, non-compliance with AWS CloudTrail controls could lead to information security risks, operational inefficiencies, potential regulatory penalties, and increased cost of operations."
            ],
            "x-kaytu-usefulness-example": [
                "Here are few instances where AWS CloudTrail can be useful:\n\n1. **Security Analysis:** With the detailed information provided by CloudTrail, security analysts can track changes to AWS resources and even determine if a security policy has been violated. This can help in identifying and mitigating potential security risks.\n\n   ```\n   For example, if a security analyst notices several failed attempts to access an S3 bucket, they could further investigate and then implement additional security measures, such as IP restrictions or MFA for higher risk AWS services to avert a potential data breach.\n   ```\n\n2. **Troubleshooting:** CloudTrail's detailed records of every API call, including the identities of callers and timestamps, can be invaluable when troubleshooting operational issues.\n\n   ```\n   For instance, if an EC2 instance were to suddenly stop working, a developer could use CloudTrail to review the recent API calls made to the instance. This can help in identifying what caused the issue, such as an accidental modification or termination of the instance.\n   ```\n\n3. **Compliance Auditing:** Organizations subject to regulatory standards can use CloudTrail to help maintain compliance by continuously monitoring the activity in their AWS environment.\n\n   ```\n   As an example, a healthcare provider could use CloudTrail to track access to their patient data stored in AWS, helping to ensure that they are in compliance with HIPAA regulations by demonstrating that only authorized personnel are accessing sensitive data.\n   ```\n\n4. **Resource Lifecycle Tracking:** CloudTrail can show when and where AWS resources were created or deleted, providing a detailed audit of resource lifecycles.\n\n   ```\n   For instance, when managing a complex application deployment using AWS CloudFormation, CloudTrail can be used to identify exactly when and why a specific resource was created or deleted during the deployment process."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_3",
        "Title": "1.3 Ensure security questions are registered in the AWS account",
        "Description": "The AWS support portal allows account owners to establish security questions that can be used to authenticate individuals calling AWS customer service for support. It is recommended that security questions be established.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v150_1_3.md",
        "ManualVerification": true,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "## AWS Control: Security Questions for Account Authentication\n\nAmazon Web Services (AWS) offers a series of controls to ensure the security and privacy of user accounts. One such control is the ability to set up security questions for account authentication. This feature is accessible via the AWS support portal and is recommended for all account owners.\n\n**Purpose of the Control:**\n\nThe purpose of this control is to add an extra layer of security to your AWS account. It is designed to verify the authenticity of individuals contacting AWS customer support with inquiries or issues related to your account.\n\n**How It Works:**\n\nWhen a call is made to AWS customer service, the caller is required to answer the security questions correctly to authenticate their identity. This is to ensure that only authorized individuals have access to information about the account or can issue instructions about its operation.\n\n**Recommendations:**\n\nIt is strongly recommended that account owners set up these security questions as a part of their security controls. These questions should be known only to the authorized individuals to prevent unauthorized access to the account information.\n\n**Benefits:**\n\n- Ensures that only authorized individuals can access your account information or make changes.\n- Provides an extra layer of security, reducing chances of a security breach.\n\n```markdown\n# AWS Control: Security Questions for Account Authentication \n\n## Purpose:\nThis control adds an added layer of security to your AWS account by requiring individuals contacting AWS customer support to authenticate their identity by correctly answering security questions.\n\n## How It Works:\nWhen a call is made to AWS customer service, authentication of the caller's identity is confirmed by correctly answering the security questions.\n\n## Recommendations:\nSet up security questions via the AWS support portal. These questions should be known only by authorized individuals for maintaining the security of account data.\n\n## Benefits:\n- Ensures authorized access to account information.\n- Prevents unauthorized changes to the account.\n- Enhances overall account security. \n```\nThis markdown document can be used as a template or guide for understanding this AWS control."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the above AWS control majorly leads to following potential costs:\n\n- **Security Cost:** If security questions are not established and someone impersonates as an account stakeholder to access sensitive account information, it may lead to serious security breaches. This could result in the loss of sensitive data or unauthorized manipulations of your AWS resources that could harm your business operations.\n\n- **Financial Cost:** Resulting from potential security breaches, there could be significant financial impact. This cost could be direct, such as financial loss from theft, or indirect, such as the costs involved in recovery, investigation, and setting up additional preventive measures post-breach.\n\n- **Reputational Cost:** In an era where data privacy is a major concern, a breach could lead to severe reputational damage. Trust is hard to gain in the digital world and easy to lose. Once your customers find out about a security breach, it could lead to a significant loss of clientele and hamper future business opportunities.\n\n- **Operational Cost:** In the absence of security questions, AWS customer service might take more time to verify the identity of the requesting person, leading to longer resolution times for the issues.\n\nTherefore, although it might seem inconsequential, NOT establishing security questions could lead to considerable costs in terms of financial losses, reputational damage and operational inefficiencies."
            ],
            "x-kaytu-usefulness-example": [
                "Example: \n\nJohn Smith is the IT in-charge of Alpha Company that uses AWS services for their cloud architecture. There are many instances when John encounters issues or needs assistance for managing these services. In such situations, he often needs to contact the AWS customer support for resolution. \n\nEarlier, there were instances when the customer support was unable to authenticate him, causing delays in resolving critical cases. To avoid such issues in future, he decides to establish security questions for the Alpha Company's AWS account through the AWS Support portal. \n\nNow, whenever he calls the AWS customer service for support, he’s asked to answer the security questions established by him for the purposes of authentication. With this, the authentication process is a lot smoother and also ensures stringent security standards as only authorized personnel knowing the answers to these security questions are able to obtain support assistance. \n\nTherefore, John has met the recommended guideline and found the AWS Support Portal's ability to establish security questions highly useful for a quick and secure customer service experience. \n\nThis instance displays the usefulness of having security questions in place, as it not only validates the authenticity of the account owner but also speeds up the process of customer service interaction.\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_2",
        "Title": "3.2 Ensure CloudTrail log file validation is enabled",
        "Description": "CloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails.",
        "QueryID": "aws_cloudtrail_trail_validation_enabled",
        "DocumentURI": "policies/aws_cis_v150_3_2.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.2"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: CloudTrail Log File Validation\n\n## Introduction\nAmazon Web Services (AWS) CloudTrail is a service that provides a record of actions taken by a user, role, or an AWS service in AWS CloudTrail. With CloudTrail, you can conduct security analysis, resource change tracking, and compliance auditing. A key feature of this service is the *log file validation* feature. \n\n## What is Log File Validation?\nCloudTrail log file validation generates a digitally signed digest file which contains a cryptographic hash of each log that CloudTrail creates and stores in an Amazon S3 bucket. The hash in the digest files serves as a unique identifier/tracker of each log.\n\n## Why Log File Validation?\nThese digest files can be used to track the history and changes of the logs. By comparing the current hash of a log file with the recorded hash in the digest file, users can easily determine whether a log file has been changed, deleted, or remains unchanged after it was delivered by CloudTrail.\n\n## Importance and Recommendation\nThe log file validation feature is critical for the security and integrity of your AWS logs. It is especially useful in forensic investigations to ensure your log data has not been tampered with. Therefore, it is recommended that file validation be enabled on all CloudTrails. This adds an additional layer of security and maintains the integrity of your log data.\n\n## How to Enable Log File Validation?\nIn order to enable log file validation, follow these steps:\n1. Open the CloudTrail Service in AWS Management Console.\n2. Tap on your trail in the dashboard.\n3. Scroll down to the section \"Advanced\".\n4. Select 'Yes' for the option 'Enable log file validation'.\n5. Save the changes.\n\nEssentially, the log file validation feature in CloudTrail ensures that your log files are securely tracked and any changes to them are recorded, enhancing the overall transparency, audit capability and security of your AWS operations."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the above AWS Control by not enabling file validation on all CloudTrails can be seen in multiple ways:\n\n**1. Increased Security Risks:** Without file validation, organizations increase their vulnerability to various security risks such as data tampering, unauthorized access to log files, and other cyber-attacks. If log files are altered maliciously, it can be difficult to trace back actions, identify breaches, or detect intrusions.\n\n**2. Regulatory Non-Compliance:** For businesses operating in regulated industries, non-compliance with this control could lead to violation of data protection and cybersecurity laws and regulations, leading to potential penalties, fines, or legal actions. \n\n**3. Business Continuity Issues:** Log files are often essential to troubleshoot issues, making sure systems are running optimally, and identifying areas of improvement in operations. Without file validation, the integrity of these log files might not be reliable when needed.\n\n**4. Forensics Difficulty:** The inability to verify log file integrity can complicate forensic efforts after a security incident, as logs often provide crucial details about the event in question. Manipulated or deleted logs could hinder investigation efforts.\n\n**5. Reputational Damage:** Given the potential for increased security breaches, potential regulatory issues, and operational deficiencies, there's a higher risk for reputational damage which might affect customer trust and future business.\n\n**6. Increased Costs:** If data tampering goes undetected, it could lead to inappropriate decision-making based on false data, which could have financial implications. Also, rectifying breaches or cyber-attacks could result in additional costs in security, system repairs, investigations, recovery operations, etc.\n\n```markdown \nCost of Non-compliance to AWS CloudTrail Log File Validation:\n\n- Increased Security Risks: Vulnerability to data tampering, unauthorized access, and cyber-attacks.\n- Regulatory Non-Compliance: Potential for regulatory penalties, fines, or legal actions for non-compliance to data protection and cybersecurity laws.\n- Business Continuity Issues: Reliability on log files for troubleshooting and operational improvements could be compromised.\n- Forensics Difficulty: Hindrance to investigation efforts due to unavailable or manipulated logs.\n- Reputational Damage: Potential loss in customer trust and future business opportunities due to increased security breaches and operational deficiencies.\n- Increased Costs: Potential financial implications resulting from decision-making based on false data, rectifying breaches or cyber-attacks, and increased security, recovery and repair costs.  \n```\n"
            ],
            "x-kaytu-usefulness-example": [
                "Example Instance:\n\nCompany ABC uses Amazon Web Services (AWS) for various computing needs, including storing vast amounts of data in S3 buckets. One of the critical priorities for the company is ensuring the data's integrity and confidentiality.\n\nConcerned about possible unauthorized alterations or deletions of their log files, ABC turned on CloudTrail log file validation. With this facility, ABC could easily verify whether any log file, once delivered by CloudTrail, has been changed, deleted, or remains unchanged. \n\nFor instance, during a routine audit, ABC found discrepancies with some of the data. With CloudTrail log file validation, they were quickly able to check the authenticity of the logs. ABC could compare the current hash of the log file with the hash recorded in the digest file at the time of log delivery. This way, ABC discovered unauthorized changes in the log files, pinpointed the problem, and applied swift remediation to it. \n\nOverall, the CloudTrail log file validation control proved highly useful in providing an added layer of security and maintaining the integrity of ABC's log files on AWS."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_4",
        "Title": "1.4 Ensure no 'root' user account access key exists",
        "Description": "The 'root' user account is the most privileged user in an AWS account. AWS Access Keys provide programmatic access to a given AWS account. It is recommended that all access keys associated with the 'root' user account be removed.",
        "QueryID": "aws_iam_root_user_no_access_keys",
        "DocumentURI": "policies/aws_cis_v150_1_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.4"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Remove Access Keys Associated with 'root' User Account\n\nThe 'root' user account in AWS is the most privileged user account. It holds complete and ultimate control over an AWS account and thus, has the power to perform all types of operations, including the ability to access and manage all AWS services and resources within the account.\n\nAWS Access Keys are long-term credentials for an IAM user or the AWS account root user. These keys provide programmatic access to a given AWS account, allowing the owner to make programmatic requests to AWS APIs (Application Programming Interfaces).\n\nSince the 'root' user has ultimate privileges, its security is crucial. Any compromise of this account's security could lead to unauthorized access or manipulation of your AWS resources.\n\n## Recommendation\n\nIt is recommended to **remove all access keys** associated with the 'root' user account. Without these keys, programmatic access is denied to the root account, thereby providing an additional layer of security. \n\nInstead, use AWS Identity and Access Management (IAM) for day-to-day interaction with AWS. Create individual IAM users with limited and necessary permissions for carrying out specific tasks. \n\nThis minimizes the risk associated with compromised credentials. If credentials of an individual IAM user are compromised, the damage is restricted based on what permissions that particular IAM user has, which is typically significantly less than the root account.\n\nHere is a sample code snippet to remove the access keys:\n\n```bash\naws iam delete-access-key --access-key-id AKIAIOSFODNN7EXAMPLE\n```\nNote: Replace \"AKIAIOSFODNN7EXAMPLE\" with your actual access key ID.\n \nRemember, this action does not delete the IAM user, it only deletes the access key ID that is associated with that user."
            ],
            "x-kaytu-noncompliance-cost": [
                "Not following this AWS control may lead to severe security risks and financial costs. Here are the details:\n\n1. **Security Risks**: The 'root' user has unrestricted access to all AWS resources, operations, and information. If an unauthorized person obtains root access keys, they can manipulate anything in the AWS account. Potential misuse ranges from changing security configurations and accessing sensitive information to completely deleting all resources, which might cause irreversible data loss.\n\n2. **Financial Impact**: Unauthorized access to root could also lead to financial losses. For example, an attacker could launch excessive or large instances resulting in sudden increase in your AWS costs. Additionally, they might place resources in regions where the cost is higher. Recovering from such an attack can be costly and time-consuming.\n\n3. **Compliance Violation Penalties**: Most compliance regulations require implementing the principle of least privilege and strong access controls to protect sensitive data. Keeping root access keys violates these principles, which may lead to failing audits and brings potential for heavy fines.\n\n4. **Business Reputation**: A security breach due to misuse of root access keys can damage a company's reputation. It might lead to loss of customer trust, negatively affecting future business prospects.\n\n5. **Operational Disruptions**: If misused, root access keys can lead to significant operational disruptions, impacting the flow of day-to-day business activities until the issue is resolved. This can lead to lowered productivity, missed opportunities, and additional operational cost for recovery.\n\nTherefore, it’s necessary to remove all access keys associated with the 'root' user account and use AWS IAM users and groups for daily interactions with your AWS resources for better granular control."
            ],
            "x-kaytu-usefulness-example": [
                "AWS Control and management policies recommend against using the 'root' user account for regular tasks that require programmatic or console login. Instead, one should create individual IAM (Identity and Access Management) users with the specific access required for their task.\n\nThe 'root' user access is powerful and opens the potential for irreversible actions on account resources, and if these credentials are compromised, the results could be catastrophic. As such, removing all Access Keys associated with the 'root' account helps to reduce the potential surface for malicious activities. \n\nFor instance, consider an example of a business that is leveraging AWS for important data storage, server hosting, and running their application. Using the 'root' user account regularly increases the risk of unintentional mistakes like deletion of critical data or shutting down crucial servers. Furthermore, if the access keys related to the 'root' user are lost or stolen, the attacker gets unrestricted access.\n\nDeleting the root access keys means there isn't a set of static credentials linked with root access that can be used to compromise the account. This is vital as it forces all access to go through IAM users, where permissions can be audited and controlled, providing an added layer of security. It helps in preventing rogue actions from internal users and makes it difficult for external entities to compromise an AWS account."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_1",
        "Title": "4.1 Ensure a log metric filter and alarm exist for unauthorized API calls",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for unauthorized API calls.",
        "QueryID": "aws_log_metric_filter_unauthorized_api",
        "DocumentURI": "policies/aws_cis_v150_4_1.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS Control provides several services to monitor your resources, systems and applications in real-time. Two of these services are CloudTrail and CloudWatch. Let's dive into understanding how these two services can help in monitoring API calls in real-time.\n\nAWS CloudTrail is a service that provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event history simplifies security analysis, resource change tracking, and troubleshooting.\n\nWhen you enable CloudTrail, AWS starts recording the API calls made in your AWS environment and delivers these logs to an S3 bucket that you specify. These are known as CloudTrail Logs.\n\nApart from storing CloudTrail Logs in S3, you can also direct these logs to AWS CloudWatch Logs. CloudWatch is a monitoring and observability service. It can collect data in the form of logs and metrics from more than 70 AWS services.\n\nYou can set up metric filters in CloudWatch to search for and match terms, phrases, or values in your CloudTrail Logs. When a metric filter finds one of the terms, phrases, or values in your log events, it counts it in a CloudWatch metric.\n\nAlarms are then used to automate actions based on thresholds you define in your metrics. For example, an alarm could watch for a specific number of unauthorized API calls in the CloudTrail Logs.\n\nYou can set alarms to notify you when there are abnormal amounts of API calls, failed API calls or unauthorized API calls. This helps ensure that you are quickly notified of any unexpected or undesired behavior, and can act promptly to mitigate any potential risks.\n\nHere is how you can present this in markup format:\n\n```markup\nAWS Control offers real-time monitoring of API calls using CloudTrail and CloudWatch Logs:\n\n1. **AWS CloudTrail:** Records API calls made in your AWS environment and delivers the logs to an S3 bucket.\n\n2. **AWS CloudWatch Logs:** CloudTrail Logs can be directed to CloudWatch. You can set up metric filters in CloudWatch to search for and match terms, phrases, or values in your log data.\n\n3. **Metric Filters and Alarms:** When a metric filter finds a term, phrase, or value in your logs, it counts it as a CloudWatch metric. You can set up alarms based on these metrics. For example, you can establish a metric filter and alarm for unauthorized API calls. When there's a specific number of unauthorized API calls, you receive a notification.\n\nThis ensures you are quickly notified of any unexpected or undesired API activity, helping you mitigate any potential risks promptly.\n```\nIn conclusion, directing CloudTrail Logs to CloudWatch and establishing corresponding metric filters and alarms enables a proactive approach to detect anomalies or unauthorized access, and swiftly take remedial action."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the aforementioned AWS Control could be detrimental to an individual or organization in a multitude of ways. The control, which calls for real-time monitoring of API calls, is crucial in identifying abnormal behavior or unauthorized access to an organization's resources. Enhanced further by the recommendation of establishing a metric filter and alarm for unauthorized API calls, this control forms a crucial part of the overall security posture of an AWS environment.\n\nNon-compliance can lead to:\n\n1. **Increased Security Vulnerabilities:** Not monitoring API calls in real time can make the system susceptible to breaches, exploitation of vulnerabilities, and unauthorized access. Without an alarm system for unauthorized API calls, malicious activity can go undetected, causing potential harm to your applications or theft of sensitive data.\n\n2. **Audit Failures:** For organizations that are subject to periodic audits for compliance to certain standards (like HIPAA, SOC, or ISO), non-compliance to these controls could lead to failure in audits, leading to reputational harm and potentially financial penalties.\n\n3. **Operational Disruptions:** Unauthorized API calls can disrupt service operations and cause system malfunctioning. This could impact system availability, leading to a poor user experience and potential financial loss.\n\n4. **Increased Financial Costs:** The aftermath of a security breach or operational disruption due to unauthorized API calls could lead to financial loss. These costs can exist in the form of remediation efforts, damage control, system recovery, potential regulatory fines, and increased insurance premiums.\n\nThus, ensuring compliance to this control helps reduce the potential risks and costs associated with data breaches, system disruptions, and regulatory non-compliance."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider a case where a company has a cloud-based application on AWS. They use various APIs to manage resources and carry out activities such as triggering code execution or accessing database. Any unauthorized API call could mean a potential security breach or misuse of resources.\n\nBy enabling real-time monitoring of API calls with CloudTrail Logs directed to CloudWatch Logs, the company can meticulously scrutinize each API call. If an Unauthorized API call metric filter and alarm is established, every time there is an unauthorized API call, the alarm goes off and instant notification is sent to the security team. The team can then immediately investigate the issue, securing the cloud environment in the process.\n\nThis real-time monitoring system ensures continuous security checks, keeps track of all activities within the AWS environment, and reduces the reaction time in case of a potential security threat, thereby demonstrating the usefulness of this AWS Control."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_5_1",
        "Title": "5.1 Ensure no Network ACLs allow ingress from 0.0.0.0/0 to remote server administration ports",
        "Description": "The Network Access Control List (NACL) function provide stateless filtering of ingress and egress network traffic to AWS resources. It is recommended that no NACL allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389.",
        "QueryID": "aws_vpc_network_acl_remote_administration",
        "DocumentURI": "policies/aws_cis_v150_5_1.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "The Network Access Control List (NACL) is a feature in AWS that filters both incoming (ingress) and outgoing (egress) network traffic to AWS resources. This is done in a stateless manner, meaning that the system does not keep track of the state of network connections.\n\nA recommended best practice for using NACLs is not to permit unrestricted ingress access to remote server administration ports. In other words, it is advisable not to allow unrestricted access to ports used for secure shell (SSH) connections (port 22) and remote desktop protocol (RDP) connections (port 3389). \n\n```markdown\n## Network Access Control List (NACL)\n\nThe **Network Access Control List (NACL)** is an important function provided by AWS that filters both incoming (ingress) and outgoing (egress) network traffic to AWS resources. This is a **stateless** process, implying that the system does not keep an account of the state of network connections.\n\nA critical best practice for using NACLs is to avoid permitting unrestricted ingress access to remote server administration ports. This means, you should not allow unrestricted access to ports used for:\n\n* Secure shell (SSH) connections - Port 22\n* Remote desktop protocol (RDP) connections - Port 3389\n```\nHere, unrestricted access implies the absence of any security measures that limit who could connect to these ports. Limiting access to these crucial admin ports could help in averting potential security breaches."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the Network Access Control List (NACL) recommendations can lead to a host of potential issues that have both financial and security consequences.\n\n1. **Security Compromise:**\nAllowing unrestricted ingress access to server administration ports, such as SSH (22) and RDP (3389), may expose your resources to potential malicious activities. An attacker could potentially gain unauthorized access to your network infrastructure which can result in data breaches, theft, and other types of security incidents.\n\n2. **Financial Impact:**\nReferring to security compromises; data breaches can lead to significant financial losses. This can be in the form of damage recovery costs, fines from regulatory bodies for violating data protection regulations, potential lawsuits from affected parties, and a decrease in business due to reputational damage.\n\n3. **Regulatory Noncompliance:**\nIf your organization is subject to guidelines like the GDPR, HIPAA, PCI DSS, or any other regulations that mandate particular data security measures, failing to comply with this control could result in non-compliance. This can lead to hefty fines and penalties. \n\n4. **Operational Disruption:**\nA successful attack on your system can lead to significant disruption in your operations. Depending on the intensity of the attack, your system could be brought down, resulting in service unavailability.\n\nIn conclusion, the cost of non-compliance with the AWS NACL control is multifaceted, comprising of potential financial loss, security issues, accountability-related problems, and operational disruptions. Ensuring compliance by implementing stateless filtering of ingress and egress network traffic is an advisable approach to prevent these potential issues."
            ],
            "x-kaytu-usefulness-example": [
                "An example of how the AWS Network Access Control List (NACL) function might be useful is to control the traffic to an organization's servers hosted on AWS.\n\nFor example, a company could have the following scenario: the company's web application is hosted on an AWS EC2 instance and needs to communicate with an AWS RDS instance hosting their database. However, they want to make sure that only specific network traffic (like HTTP, HTTPS, SSH) are allowed and they desire to specifically block other types of traffic. They also want to prevent any unrestricted access to their remote server administration ports like SSH to port 22 and RDP to port 3389 to secure their servers from any unauthorized remote access.\n\nIn such a scenario, the NACL function would come in handy. They could configure their NACL to allow only the specific types of network traffic required for their application to function properly and block everything else. They could also deny all unrestricted ingress access to ports 22 and 3389, thus enhancing the overall security of their servers on AWS.\n\n    ```\n    NACL Example:\n    \n    Inbound Rule\n    | Rule # | Type    | Protocol | Port Range | Source    | Allow/Deny |\n    |--------|---------|----------|------------|-----------|------------|\n    | 100    | HTTP    | TCP      | 80         | 0.0.0.0/0 | ALLOW      |\n    | 200    | HTTPS   | TCP      | 443        | 0.0.0.0/0 | ALLOW      |\n    | 300    | SSH     | TCP      | 22         | Trusted_IP_Adress/32 | ALLOW  |\n    | *      | ALL     | ALL      | ALL        | 0.0.0.0/0 | DENY       |\n\n    Outbound Rule\n    | Rule # | Type | Protocol | Port Range | Destination | Allow/Deny |\n    |--------|------|----------|------------|-------------|------------|\n    | 100    | ALL  | ALL      | ALL        | 0.0.0.0/0   | ALLOW      |\n    ```\nIn this configuration, only HTTP, HTTPS and SSH traffic from specific trusted IP addresses are allowed inbound, and all outbound traffic is allowed. All other inbound traffic is denied by default."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_5",
        "Title": "1.5 Ensure MFA is enabled for the 'root' user account",
        "Description": "The 'root' user account is the most privileged user in an AWS account. Multi-factor Authentication (MFA) adds an extra layer of protection on top of a username and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their username and password as well as for an authentication code from their AWS MFA device.",
        "QueryID": "aws_iam_root_user_mfa_enabled",
        "DocumentURI": "policies/aws_cis_v150_1_5.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.5"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: MFA (Multi-factor Authentication) for Enhanced Security\n\nThe `'root'` user account in an AWS (Amazon Web Services) account has the highest levels of access and permissions. Due to this, it is pivotal to put additional safeguards to protect this account from unauthorized access. One such safeguard is MFA or Multi-factor Authentication.\n\n## Multi-factor Authentication – An Extra Layer of Safety\n\nMFA gives an extra layer of protection to your AWS account. When you enable MFA, an additional step is included in the typical sign-in process. \n\n## What happens when you sign in with MFA?\n\nWhen a user signs in to an AWS site with MFA enabled, the following process ensues:\n\n1. **Step 1**: The user is prompted to provide their username and password.\n\n2. **Step 2**: The user is asked to enter an authentication code. \n\n    This code is not a fixed code. Instead, it is given by an AWS MFA device. The user has to input this code within a stated time-frame. After that, the code changes. This dynamic nature of the authentication code adds an extra layer of safety to the account.\n\nIn summary, the MFA feature reduces the risk of unauthorized access by necessitating something the user knows (username \u0026 password) with something the user has (temporary authentication code from their AWS MFA device).\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control can result in significant costs and consequences, including:\n\n1. **Security Breach**: The root user has complete access to all AWS services and resources. If an attacker gains unauthorized access to the root account without MFA, they could manipulate or delete resources, causing significant damage and loss of data.\n\n2. **Financial Impact**: An attacker with root access can create new instances, increase capacities, or use expensive services, leading to unexpected and high AWS bills. \n\n3. **Regulatory Fines**: Non-compliance with security best practices or specific regulations (such as GDPR or HIPAA) could result in substantial fines. MFA is a common requirement in many security standards and regulations.\n\n4. **Reputation Damage**: A security breach, particularly one involving data loss or unplanned downtime, can seriously damage a company's reputation, leading to loss of customers and business opportunities.\n\n5. **Loss of Productivity**: Recovery from a security breach often requires significant time and resources, distracting from normal business operations and reducing productivity.\n\nTherefore, enabling MFA for the root account is a critical measure for securing an AWS account and mitigating potential security risks."
            ],
            "x-kaytu-usefulness-example": [
                "For example, a global company named 'Tech Solutions Inc.' has multiple AWS root user accounts across different regions. They store sensitive customer data in their AWS resources and utilize various AWS services for their day-to-day operations.\n\nOne day, the credentials of one of their root user accounts were compromised due to a phishing attack. The attacker tried to log in using these stolen credentials from an unfamiliar location.\n\nHowever, 'Tech Solutions Inc.' had enabled Multi-factor Authentication (MFA) for all their AWS root user accounts. When the attacker tried to login, as the unfamiliar device did not have the MFA device, the login process halted at the MFA code request interface. The attacker couldn't proceed further without the MFA code, thereby protecting the company's AWS resources from unauthorized access.\n\nTherefore, this instance demonstrates the usefulness of enabling MFA for the AWS 'root' user account--- it added an extra layer of security that helped 'Tech Solutions Inc.' avoid a potential data breach and retain the trust of their customers."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_3",
        "Title": "3.3 Ensure the S3 bucket used to store CloudTrail logs is not publicly accessible",
        "Description": "CloudTrail logs a record of every API call made in your AWS account. These logs file are stored in an S3 bucket. It is recommended that the bucket policy or access control list (ACL) applied to the S3 bucket that CloudTrail logs to prevent public access to the CloudTrail logs.",
        "QueryID": "aws_cloudtrail_bucket_not_public",
        "DocumentURI": "policies/aws_cis_v150_3_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "Sure, here's a brief explanation of the statement in the context of IT audit control:\n\nAWS CloudTrail is a service that records all the activity in your AWS environment, specifically capturing all the API calls being made.\n\nThis information is stored in log files that are delivered to an Amazon S3 bucket, which you have specified during the setup of CloudTrail. \n\nAn Amazon S3 bucket is a public cloud storage resource available in Amazon Web Services' (AWS) Simple Storage Service (S3), which is used for storing data to power applications, websites, and backups.\n\nHowever, these log files contain very sensitive information, such as who made the call, from which IP address, at what time, etc. Hence, they should be strictly confidential. Therefore, it is highly recommended to configure your S3 bucket to prevent public access. You can configure this by modifying the bucket policy or access control list (ACL).\n\nHere's the markup format:\n\n```markdown\n# AWS Control\nAWS CloudTrail is a [service](https://aws.amazon.com/cloudtrail/) that provides a record of all API calls in an AWS account - these calls are stored in log files in an Amazon S3 bucket. \n\nDue to the sensitive nature of these logs, care should be taken to prevent public access. This can be achieved by implementing an appropriate bucket policy or access control list (ACL) on the S3 bucket.\n\n## Key Points\n- **AWS CloudTrail** logs all API calls in your AWS account.\n- The logs are stored in an **Amazon S3 bucket**.\n- Due to the potential sensitive nature of these logs, it is recommended to prevent public access.\n- This can be achieved by applying appropriate **bucket policies** or an **Access Control List (ACL)** on the S3 bucket.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control can have significant costs. Below are some potential scenarios that may occur due to non-compliance.\n\n* **Security Breaches:** If a S3 bucket containing CloudTrail logs is left publicly accessible, it could allow unauthorized individuals to view, download or even manipulate these logs. This could lead to an abundance of serious security problems including data theft or the introduction of malicious software. \n\n* **Financial Impact:** It may result in direct financial costs to the organization, not only in terms of regulatory fines or penalties but also the costs associated with the investigation, remediation, and communication around the breach.\n\n* **Regulatory Risks:** Non-compliance can possibly lead to legal actions from various regulatory bodies depending on the severity and the kind of data exposed. Legal penalties and fines can have significant financial impacts on a company.\n\n* **Reputational Damage:** Data breaches can cause significant damage to a company's reputation, the loss in consumer trust may lead to a decline in business.\n\nIn markup format:\n```\n1. **Security Breaches**: Non-compliance could invite unauthorized access to these logs, compromising data integrity and inviting various security problems such as data theft or introduction of malicious software.\n\n2. **Financial Impact**: The resultant security breach may lead to significant financial costs related to investigation, remediation, and communication apart from potential regulatory penalties.\n\n3. **Regulatory Risks**: Depending upon the severity and nature of data that was exposed, non-compliance may also invite legal action from various regulatory bodies which can lead to substantial financial losses from fines.\n\n4. **Reputational Damage**: Data breaches can cause significant damage to a company's reputation. The loss in consumer trust may lead to a decline in business.\n```\nRemember, the actual cost of non-compliance will depend on the nature and severity of the non-compliance. Therefore, it is crucial to maintain a high level of security and privacy by adhering to recommended AWS Controls."
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a scenario where you have multiple users, with various permission levels, accessing and performing actions on your AWS resources. In such a situation, having CloudTrail enabled is extremely beneficial as it helps track every single API call made within your account. \n\nLet's imagine one of your resources, say a data warehouse on Amazon Redshift, unexpectedly experiences loss of certain data. The first thing you may want to investigate is who accessed that resource and what actions they performed. \n\nWithout CloudTrail logs, such investigations would be difficult. But, with CloudTrail logging all API calls along with related data such as requester's identity, time of request, source IP address, parameters passed in, and responses returned by AWS, you can directly trace the action. You will have the needed information about the user who performed the operation.\n\nBut, these logs could become a source of sensitive information leak if they fall in wrong hands, as they contain all the sequences of actions carried out. That’s why it’s crucial to secure the S3 bucket where these logs are stored and restrict public access. These bucket policies or ACLs ensure your logs stay confidential, are tamper-proof, and available for your review whenever required. \n\nIn general, the CloudTrail with secure S3 bucket provides both accountability through traceability of actions and security by maintaining the confidentiality of action details, making it an essential control within AWS environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_2",
        "Title": "4.2 Ensure a log metric filter and alarm exist for Management Console sign-in without MFA",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for console logins that are not protected by multi-factor authentication (MFA).",
        "QueryID": "aws_log_metric_filter_console_login_mfa",
        "DocumentURI": "policies/aws_cis_v150_4_2.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Real-time API Monitoring\n\nAWS CloudTrail and CloudWatch are two AWS services that provide the ability to monitor API calls in real-time. By directing CloudTrail Logs to CloudWatch Logs, you can keep track of all API calls within your AWS environment. You can also establish metric filters and alarms that trigger notifications or actions based on specific conditions. \n\nOne recommendation is to establish a metric filter and alarm for console logins that are not protected by Multi-factor Authentication (MFA). This measure would enhance the security of your AWS environment by alerting you of any unauthorized access attempts.\n\nHere are the steps to implement it:\n\n## Step 1: Enable AWS CloudTrail\n\nFirstly, AWS CloudTrail must be enabled to track and log user activity. This service records AWS API calls for your account and delivers the logged information to a specified S3 bucket.\n\n## Step 2: Direct CloudTrail Logs to CloudWatch Logs\n\nDirect the collected logs to CloudWatch Logs. By integrating CloudTrail with CloudWatch, you can monitor real-time activity and receive reports on log data.\n\n## Step 3: Establish Metric Filters and Alarms\n\nUnder CloudWatch, establish metric filters and alarms for specific events. A metric filter extracts data from your log data and converts it into a numeric CloudWatch metric that you can graph or set an alarm on.\n\nTo enhance security, a metric filter and alarm can be established for console logins that are not protected by MFA. \n\nFor example, the following metric filter pattern will match successful console sign-in events without MFA:\n\n```\n{ $.eventName = \"ConsoleLogin\" \u0026\u0026 $.additionalEventData.MFAUsed = \"No\" }\n```\n\nAfter the metric filter is created, configure an alarm to notify when such event occurs. \n\nThis AWS control ensures you can react promptly to unauthorized access attempts, enhancing overall security posture."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this specific AWS control can result in several potential costs that include:\n\n1. **Security breaches:** If console logins aren't protected by MFA and there's inadequate real-time monitoring of API calls, it can make unauthorized access easier which can lead to security breaches. The financial implications of breaches can be substantial; they can include loss of critical data, recovery costs, and in some cases, regulatory fines.\n\n2. **Compliance Violations:** Many industries have strict regulations requiring user activity monitoring and MFA as a part of their security compliance. Violation of these regulations may result in hefty fines.\n\n3. **Investigation and Remediation Costs:** In the event of anomalous activities or security incidences, substantial time and resources may need to be allocated to investigate and remedy the situation.\n\n4. **Reputation Damage:** A security breach can harm a business's reputation, which may lead to the loss of customers and revenue. The cost to rebuild a brand's reputation can be significant.\n\n5. **Loss of Business:** If the breach leads to application downtime, it could result in loss of business, which can directly impact an organization's bottom line.\n\nTo avoid these potential costs, it's essential that organizations comply with the recommended AWS control; by doing so, they can secure their console login processes and regularly monitor API call activities through real-time monitoring, thus maintaining a highly secure and reliable AWS environment.\n"
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a software company uses AWS for their web application operations. They have several APIs that allow them to interact with various AWS services. Because of the critical nature of these services, they need to continuously monitor various parameters such as the number of API calls, the response times, error rates, etc.\n\nFor this, they can leverage CloudTrail, which will log all the API calls happening. However, merely recording these logs isn't sufficient; they need to evaluate these logs in real-time. Hence, they can direct these CloudTrail logs to CloudWatch, which will help them in real-time monitoring.\n\nFurthermore, a part of their security best practices involves the use of multi-factor authentication (MFA) for console logins. However, due to varying reasons, some of the console logins might lack this MFA. Hence, as an added security measure, they can set up a metric filter and alarm to alert them whenever such a console login occurs.\n\nThis way, the company can immediately react to potential security risks, maintaining the integrity of their services and sensitive data. This is a practical example of how real-time monitoring of API calls using AWS CloudTrail and CloudWatch can benefit a business."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_6",
        "Title": "1.6 Ensure hardware MFA is enabled for the 'root' user account",
        "Description": "The 'root' user account is the most privileged user in an AWS account. MFA adds an extra layer of protection on top of a user name and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their user name and password as well as for an authentication code from their AWS MFA device. For Level 2, it is recommended that the root user account be protected with a hardware MFA.",
        "QueryID": "aws_iam_root_user_hardware_mfa_enabled",
        "DocumentURI": "policies/aws_cis_v150_1_6.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.6"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: MFA for Root User Account\n\nThe **root user account** is the most privileged user in an AWS account. It has unrestricted access and permissions on all resources in an AWS account. As such, it's vital to maintain its security.\n\n**Multi-Factor Authentication (MFA)** adds an extra layer of protection on top of a user's name and password. It demands an additional form of authentication to verify the user's identity, making it harder for unauthorized individuals to access your data. \n\nWhen MFA is enabled, a user signing in to an AWS website is prompted for their username and password, as well as an authentication code from their AWS MFA device. \n\nFor a **Level 2** security control, it is recommended that the root user account be protected with a **hardware MFA**. Unlike virtual or software-based MFA, hardware MFA involves a physical device that generates authentication codes. This adds yet another barrier for potential intruders, as they would need both the physical MFA device and your login credentials to access the account.\n\nIn summary, protecting the root user with a hardware MFA enhances the security of your AWS account by requiring multiple forms of authentication to validate user identity.\n\n```\n\u003caws\u003e\n    \u003ccontrol\u003e\n        \u003cname\u003eMFA for Root User Account\u003c/name\u003e\n        \u003cdescription\u003e\n            The root user account is the most privileged user in an AWS account.\n            For optimal security, protect this account with a hardware MFA device.\n        \u003c/description\u003e\n    \u003c/control\u003e\n\u003c/aws\u003e\n```\n\nHere's how this information could be formatted in markup language. The above markup layout delineates the control's name (\"MFA for Root User Account\") and provides a description to summarize what it does."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS control, which recommends the protection of the root user account using a hardware Multi-Factor Authentication (MFA), can be significant.\n\n1. **Data Breaches:** If the root user account is compromised, attackers can have complete control over your AWS environment. They can access and steal sensitive data, leading to breaches that can result in large fines and loss of customer trust.\n\n2. **Financial Loss:** AWS root user has access to each and every service within AWS account. Malicious users, upon gaining access, can launch instances or use services leading to huge unexpected charges.\n\n3. **Service Disruption:** Attackers can alter configurations that can disrupt the service or even delete critical data. This can lead to loss of business continuity causing customer dissatisfaction, potential financial loss and damages your company's reputation.\n\n4. **Non-compliance fines:** Not complying with MFA for root account can also lead to failing compliances such as GDPR, HIPAA, and others, which can result in legal penalties and fines. \n\n5. **Cost of Recovery:** If a breach or service disruption happens caused by non-compliance, the cost of recovering lost data, fixing altered configurations, and restoring services can be high.\n\nIn summary, beyond potentially high financial costs, non-compliance can lead to reputational damage and detrimental operational consequences. Therefore, it is always recommendable to follow AWS best practices and secure root user accounts with hardware MFA for added security."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, suppose you are the owner of a rapidly growing startup that uses AWS for its infrastructure. As the root user, you have ultimate power over all AWS resources. Given the sensitive nature of your data and large scale of operations, it becomes absolutely critical to ensure that your root user account is secure.\n\nOne day, you inadvertently click on a malicious email link, that allows hackers to obtain your AWS root user credentials. If you did not have Multi-Factor Authentication (MFA) enabled, these hackers would now have full control over your AWS resources.\n\nHowever, because you followed AWS best practices and have a hardware MFA associated with your root account, there is an additional layer of security. Even if the hackers have your password, they are prompted to input a code generated by your hardware MFA device. Without this device, they cannot gain access to your resources, thus saving your organization from potential disaster.\n\nIn this scenario, the hardware MFA acts as a robust and critical safety net, ensuring that even in the event of password theft, your AWS resources remain secure."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_4",
        "Title": "3.4 Ensure CloudTrail trails are integrated with CloudWatch Logs",
        "Description": "AWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch Logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch Logs log group. It is recommended that CloudTrail logs be sent to CloudWatch Logs.",
        "QueryID": "aws_cloudtrail_trail_integrated_with_logs",
        "DocumentURI": "policies/aws_cis_v150_3_4.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.4"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "# AWS CloudTrail\n[AWS CloudTrail](https://aws.amazon.com/cloudtrail/) is a web service which records API calls made in your AWS account. This helps in checking compliance, auditing and operational auditing. \n\n## Key Features\n- Records information about the **API caller**, the **time** of the API call, the **source IP** address of the API caller, the **request parameters**, and the **response elements** returned by the AWS service.\n- Uses Amazon S3 for **log file storage** and delivery, ensuring the log files are stored securely.\n- Supports **real-time analysis** where CloudTrail sends logs to CloudWatch Logs.\n\n### Log Files\nCloudTrail captures logs within a specified S3 bucket for long-term analysis. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch Logs log group. It is recommended that CloudTrail logs be sent to [CloudWatch Logs](https://aws.amazon.com/cloudwatch/).\n\nBy continuously monitoring and storing events related to your AWS account, AWS CloudTrail enhances security and simplifies compliance auditing."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control (CloudTrail logs being sent to CloudWatch Logs) could result in the following costs:\n\n1. **Security Costs**: Without the proper setup of CloudTrail and CloudWatch, you could be vulnerable to undetected security breaches. If logs are not correctly sent to CloudWatch Logs, real-time review of logs for security anomalies may not be possible, endangering the security posture of the AWS environment. Non-compliance might cause significant security implications including data leakage, uncontrolled access, and undetected malicious activities within the AWS account.\n\n2. **Operational Costs**: Besides security concerns, non-compliance could lead to operational complications. Without proper logging, troubleshooting and debugging operational issues could be difficult as critical event data may not be readily accessible or may not be available at all. This could lead to longer outage durations, revenue loss, and a degraded customer experience.\n\n3. **Regulatory and Compliance Costs**: Certain industries require comprehensive auditing and logging practices to be in place to comply with laws and regulations. Non-compliance to these standards, including inadequate setup of CloudTrail and CloudWatch, could result in fines, penalties, and damage to the organization's reputation.\n\n4. **Forensic Costs**: CloudTrail logs provide critical information during forensic investigations. If logs are not sent to CloudWatch Logs for real-time and long-term analysis, it may lead to unsuccessful or inefficient incident investigations. This could increase costs related to forensic activities or could result in an inability to accurately understand the root cause and impact of security incidents.\n\nThus, it is crucial for organizations to ensure that CloudTrail logs are sent to CloudWatch Logs in adherence to this AWS Control."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nA financial services company wants to maintain a high standard of security and compliance in their AWS environments. They have many users and roles making a large number of API calls daily. However, they need a method to audit and monitor these for potential security issues or misconfigurations that could lead to data breaches or compliance issues. \n\nBy using AWS CloudTrail, the company can effectively track who made what type of call, when they made it, from where the call was made, and the responses sent by AWS services. These detailed records (log files) are securely stored in their Amazon S3 bucket. This allows them to keep track of all actions taking place in their AWS account for audit purposes.\n\nFurther, they configure CloudTrail to also send logs in real time to CloudWatch Logs. This real-time analysis helps them proactively scan for suspicious activity and set up alarms for unusual API activity. If an anomaly is detected, immediate action can be taken, mitigating any potential security threats.\n\nThrough this, the company is able to maintain rigorous audit trails of their AWS resource usage, thereby fulfilling compliance requirements and maintaining a high security posture. AWS CloudTrail proves to be a fundamental tool in their security and compliance toolkit."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_5_2",
        "Title": "5.2 Ensure no security groups allow ingress from 0.0.0.0/0 to remote server administration ports",
        "Description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389.",
        "QueryID": "aws_vpc_security_group_remote_administration_ipv4",
        "DocumentURI": "policies/aws_cis_v150_5_2.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "AWS provides a feature called \"security groups\" which are essentially virtual firewalls for your AWS resources. These security groups control both inbound (ingress) and outbound (egress) network traffic. \n\nIngress filtering determines which types of incoming traffic will be allowed into your resource, while egress filtering controls what type of outgoing traffic will be allowed. Both ingress and egress traffic can be customized according to different rules and protocols such as IP, PORT, and protocol (TCP/UDP). \n\nA vital part of maintaining proper security in your AWS environment is managing these security groups effectively. AWS recommends that remote server administration ports, such as SSH (port 22) and RDP (port 3389), should not have unrestricted inbound access. This practice limits the potential attack surface as exposure to the open internet could make these ports ideal targets for hackers seeking unauthorized access.\n\n```markup\n# Security Groups in AWS\n\nSecurity groups in AWS play a crucial role in protecting your resources by acting as a virtual firewall. They provide stateful filtering of both incoming (**ingress**) and outgoing (**egress**) network traffic. \n\n## Best Practice\n\nIt's a recommended practice not to allow unrestricted ingress access to specific ports associated with remote server administration. These ports include; \n\n- **SSH (Port 22)**: Used for secure, encrypted communication between two untrusted hosts over an insecure network.\n- **RDP (Port 3389)**: Stands for Remote Desktop Protocol. It's a proprietary protocol developed by Microsoft to perform remote desktop services.\n\n\u003e Note: Unrestricted access to these ports can make your AWS resources vulnerable to security risks and hack attempts.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control could result in several costs including:\n\n1. **Security Vulnerabilities:** Allowing unrestricted access to remote server administration ports such as SSH and RDP can expose the AWS resources to potential threats and attacks. This could lead to situations where confidential data is stolen or the integrity of the server is compromised.\n\n2. **Financial Loss:** In case of a cyberattack, not only will the company have to pay for the recovery of data and systems, but there can also be severe financial penalties in case of regulatory non-compliance.\n\n3. **Reputation Damage:** A security breach, resulting from the non-compliance, could damage the reputation of the organization leading to loss of costs as users might lose trust.\n\n4. **Operational Disruption:** A successful attack due to non-compliance could disrupt business operations, this could cause downtime and could affect the company's productivity and revenue. \n\n5. **Regulatory Fines:** Certain industries have strict network security regulations, and non-compliance could result in significant fines. \n\nHere's a markup format example:\n\n```\n- **Security Vulnerabilities:** Allowing _unrestricted access_ to server administration ports can expose the AWS resources to potential attacks.\n- **Financial Loss:** There can be severe financial penalties in case of _non-compliance_ which could be due to recovery of data or regulatory penalties. \n- **Reputation Damage:** A _security breach_ could damage the reputation of the organization leading to loss of trust.\n- **Operational Disruption:** _Non-compliance_ could disrupt business operations, causing _downtime_ and could affect productivity and revenue.\n- **Regulatory Fines:** Non-compliance could result in _significant fines_ due to strict network security regulations in certain industries.\n\n```"
            ],
            "x-kaytu-usefulness-example": [
                "Access to AWS resources must be closely controlled to prevent malicious activity like data theft, server attacks, or unintended configurations that might disrupt operations. In this respect, Security groups play a useful role in securing your AWS resources. \n\nFor example, consider an organization that is operating important services on EC2 instances. There are two main types of user interaction with these EC2 instances:\n\n1. Administrators accessing the instances for management and maintenance purposes using SSH or RDP.\n2. Customers or internal users accessing services hosted on the instances (like a web application on port 80 or 443).\n\nUnrestricted access to administrative ports (like SSH 22 and RDP 3389) would be a major security risk. An attacker could potentially brute force these ports for access or exploit any open vulnerabilities.\n\nIn this scenario, using security groups effectively restricts access to these admins-only ports, creating a secure environment. A security group can be configured to allow SSH (port 22) and RDP (port 3389) connections only from specific IP ranges (such as the company's IP range), which greatly reduces the danger of unauthorized access.\n\nThis configuration would look something like this:\n\n```markup\n[ \n   {\n      \"IpProtocol\": \"tcp\",\n      \"FromPort\": 22,\n      \"ToPort\": 22,\n      \"IpRanges\": [ { \"CidrIp\": \"203.0.113.0/24\" } ]\n   },\n   {\n      \"IpProtocol\": \"tcp\",\n      \"FromPort\": 3389,\n      \"ToPort\": 3389,\n      \"IpRanges\": [ { \"CidrIp\": \"203.0.113.0/24\" } ]\n   }\n]\n```\n\nIn this example, only IPs within the range \"203.0.113.0/24\" would be allowed to initiate SSH or RDP connections to EC2 instances associated with this security group. Consequently, the potential attack surface would be significantly reduced."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_3",
        "Title": "4.3 Ensure a log metric filter and alarm exist for usage of 'root' account",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for root login attempts.",
        "QueryID": "aws_log_metric_filter_root_login",
        "DocumentURI": "policies/aws_cis_v150_4_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "In Amazon Web Services (AWS), CloudTrail Logs and CloudWatch Logs can be used to monitor API calls in real-time. By directing your CloudTrail Logs to CloudWatch Logs, you can gain visibility into your actions and resource behaviors to understand how they are affecting your system. \n\nTo ensure greater security, it is advisable to establish a metric filter and alarm for root login attempts. This means that whenever someone tries to login to your AWS root account, an alarm will trigger and notify you. Root login attempts are serious security risks as the root account has full access to all resources in your AWS account.\n\nHere is this same information presented in a mock-up of its possible markup structure:\n\n```markdown\n# Real-time Monitoring of API Calls with AWS \n\nReal-time monitoring of API calls can be realized by using **AWS CloudTrail Logs** and **AWS CloudWatch Logs**. By directing your CloudTrail Logs to CloudWatch Logs, you can analyze your actions and resource behaviors in your system.\n\n## Establish a Metric Filter and Alarm for Root Login Attempts\n\nTo ensure optimum security, it is highly recommended to establish a metric filter and alarm for root login attempts. This action will trigger an alarm and notify you whenever someone attempts to login to your AWS root account - a serious security risk as the root account has full accessibility to all resources in your account.\n\n```\nThe above format is in markdown language which is widely used for formatting readme files and documentation. This will make the text easy to read and understand on platforms that understand markdown(like Github)."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS control would primarily be an increased risk of unauthorized access or activities. It could potentially lead to:\n\n1. **Security Incidents:** Non-compliance to the control may leave you blind to unauthorized login attempts and might result in an undetected security breach. An attacker might gain control over the root account which has full access to all resources in the AWS account. This could potentially lead to data breaches or disruption of services, depending on what resources the account has access to.\n\n2. **Increased Costs:** Any unauthorized activity may also lead to financial cost. For instance, an attacker with root access might start instances for bitcoin mining, transfer large amounts of data leading to hefty data transfer bills, or make other costly API calls.\n\n3. **Non-Compliance Penalties:** If your organization must adhere to certain laws, regulations, or standards (such as PCI-DSS, HIPAA, GDPR, etc.) and you fail to properly monitor API calls, this could result in non-compliance findings during audits, security assessments, or in case of a security incident. This could result in financial penalties, reputational damage, or even withdrawal of a license to operate in some cases.\n\n4. **Loss of Data Integrity:** Unauthorized accesses might also lead to the manipulation of sensitive data which would affect the integrity of data.\n\n5. **Loss of Customer Trust:** Any of the above scenarios can result in loss of customer trust which can have a long-term negative effect on your business. \n\nSo, compliance with this control not only protects the root account but also aids in detecting potential unauthorized access or unusual activities. It's a good security practice to establish a metric filter and alarm for root login attempts to ensure proper monitoring and quick detection of any suspicious activity."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company ABC runs its entire web application on AWS. It makes extensive use of various services provided by AWS. On a daily basis, there could be thousands of API calls interacting with various AWS services like EC2, S3, DynamoDB, etc., including potentially harmful attempts of unauthorized access through root login. \n\nABC needs to have a strict monitoring and alert system to quickly recognize and respond to the root login attempts, which are often not recommended due to privileged level of information and control they have. \n\nBy enabling CloudTrail Logs and directing them to CloudWatch Logs, ABC can keep record of all sorts of API calls, along with details like IP address, time stamp and user identity, which help in auditing and carrying out incident readiness. \n\nMoreover, by establishing corresponding metric filters and generating alarms, the company can trigger notifications in real-time whenever there is a root login attempt. These notifications will alert their security team to look into and act quickly, and hence, potentially avoiding security breaches. \n\nFor instance, using this AWS control might look like this:\n\n```markup\n{\n    \"logs\": {\n        \"metric_filters\": [\n            {\n                \"filter_name\": \"root-login-attempts\",\n                \"filter_pattern\": \"{ $.userIdentity.type = Root \u0026\u0026 $.eventName = AccessDenied }\",\n                \"metric_transformations\": [\n                    {\n                        \"metric_name\": \"RootLoginAttempts\",\n                        \"metric_namespace\": \"CompanyABC/SecurityMetrics\",\n                        \"metric_value\": \"1\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"alarms\": [\n        {\n            \"alarm_name\": \"RootLoginAttemptsAlarm\",\n            \"comparison_operator\": \"GreaterThanOrEqualToThreshold\",\n            \"evaluation_periods\": \"1\",\n            \"metric_name\": \"RootLoginAttempts\",\n            \"namespace\": \"CompanyABC/SecurityMetrics\",\n            \"period\": \"300\",\n            \"statistic\": \"SampleCount\",\n            \"threshold\": \"1\",\n            \"alarm_actions\": [\n                \"arn:aws:sns:us-east-1:1234567890:security-alerts\"\n            ],\n        }\n    ]\n}\n``` \n\nThis code basically creates a metric filter that matches log events when a root user login attempt is detected and adds the count to a CloudWatch metric. If an alarming situation occurs, a notification would be sent to the specified SNS topic."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_4",
        "Title": "4.4 Ensure a log metric filter and alarm exist for IAM policy changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established changes made to Identity and Access Management (IAM) policies.",
        "QueryID": "aws_log_metric_filter_iam_policy",
        "DocumentURI": "policies/aws_cis_v150_4_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.4"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS (Amazon Web Services) suggests a control that enables real-time monitoring of API calls. It's accomplished by directing AWS CloudTrail Logs to Amazon CloudWatch Logs and then creating related metric filters and alarms.\n\nAWS CloudTrail is a service that provides event history of AWS account activity, including actions made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event history aids in security analysis, resource change tracking, and troubleshooting. \n\nAmazon CloudWatch Logs helps to monitor, store and access log files from Amazon EC2 instances, AWS CloudTrail, and others. \n\nCloudWatch alarms can be set up to send notifications or automatically make changes to the resources monitored based on rules set.\n\nCombined together, CloudTrail Logs and CloudWatch Logs help in monitoring API calls in real-time. \n\nIt is recommended to establish a metric filter and alarm for changes made to Identity and Access Management (IAM) policies. IAM is a web service that helps securely control access to AWS resources. \n\nChanges to IAM policies could potentially grant unintended permissions or remove necessary permissions, hence having a metric filter and alarm helps to alert in such cases, ensuring security and access control. \n\nHere's an outline in the markup format:\n\n```markdown\n# AWS Real-time Monitoring of API Calls  \n  \n## CloudTrail Logs  \nCloudTrail Logs provide an event history of AWS account activities for security analysis, resource change tracking, and troubleshooting.\n  \n## CloudWatch Logs  \nCloudWatch Logs help to monitor, store and access log files from AWS resources. Alarms can be set to send notifications or make automatic changes when metrics reach thresholds.  \n\n## Metric Filter and Alarms for IAM Policies  \nAMS recommends setting up a metric filter and alarm for changes to IAM policies. IAM helps securely control access to AWS resources. Notifications for changes can prevent unintended access or removal of necessary permissions.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control can lead to several potential costs:\n\n1. **Security Risks \u0026 Data Breach**: Without real-time monitoring of API calls, malicious activities could go unnoticed, leading to security threats and potential data breaches. The cost of a data breach can be substantial, including recovery costs, fines, and reputational damage.\n\n2. **Regulatory Fines \u0026 Penalties**: Certain industries and data types have strict compliance and auditing requirements regarding access and change management (e.g. GDPR, HIPAA for healthcare data). Non-compliance with such regulations can lead to hefty fines and legal penalties.\n\n3. **Operational Disruption**: Unscheduled changes to IAM policies can potentially disrupt services and applications that rely on specified permissions. Such disruption can lead to operational costs, lost productivity and negative business impact.\n\n4. **Loss of Trackability**: If changes made in IAM policies are not logged, the traceability is lost which could make troubleshooting future issues difficult and time-consuming.\n\n_Note_: It's important to understand these costs can vary greatly from one organization to another, depending on their size, the industry they operate in, the type of data they manage, etc. It's recommended to perform a risk assessment to evaluate specific potential costs relevant to the specific organization and their use case."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider a large-scale internet company that manages multiple AWS services and hence, relies heavily on IAM policies for assigning different access permissions to its users. Simultaneously, its user base is constantly changing - new users are onboarded, existing ones' responsibilities shift, and old ones are offboarded. \n\nIn such a scenario, using real-time monitoring of API calls becomes essential to keep track of any changes made to IAM policies to ensure that only authorized individuals are granted certain privileges. When a change is detected, immediate alerts or 'alarms' can be triggered to send notifications to the security administrators. \n\nFor example, let's assume an unauthorized user tries to change an IAM policy in an attempt to grant themselves additional permissions, such as write-access to certain important documents or access to confidential data. This API call to modify IAM policies will get logged by CloudTrail and sent to CloudWatch Logs. The corresponding metric filter then scans this log data and triggers an alarm because it was set to monitor changes in IAM policies. The security team receives this alert and immediately reinspects the alterations, identifies the unauthorized user, and reverts the changes before any significant damage can be done. \n\nHence, it is an effective way of maintaining the security posture of their AWS infrastructure and ensuring that IAM policies have not been tempered with unexpectedly."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_7",
        "Title": "1.7 Eliminate use of the 'root' user for administrative and daily tasks",
        "Description": "With the creation of an AWS account, a 'root user' is created that cannot be disabled or deleted. That user has unrestricted access to and control over all resources in the AWS account. It is highly recommended that the use of this account be avoided for everyday tasks.",
        "QueryID": "aws_iam_root_last_used",
        "DocumentURI": "policies/aws_cis_v150_1_7.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.7"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "---\ntitle: AWS Root User Control\ntags: AWS, security, root user\n---\n\nThe AWS (Amazon Web Service) Control stipulates the creation of a 'root user' every time an AWS account is created. The root user has the ultimate authority within the AWS account as it is granted unrestricted access and control over every resource in the AWS account. \n\nGiven the potential security implications of this power, it is recommended that the root user account is not used for routine tasks. This barrier to everyday use can minimize any potential damage that could be triggered by human error or intentional misuse of the root user privileges.\n\n```markdown\n## AWS Root User Control\n\nUpon creation of an AWS account, a **root user** emerges by default. Equipped with unrestricted access and complete control over all resources within the AWS account, the root user is a powerful entity. \n\n**Recommendation:** Avoid using this account for day-to-day tasks due to its overarching power. Recommended instead is the regular use of an IAM (Identity Access Management) account, which allows for better security control measures including role-based access. \n\n### Root User Features:\n  - Cannot be disabled or deleted.\n  - Full access and control of every AWS resource\n  - Not recommended for regular use due to potential security risks\n```\nRemember, a well-managed AWS account will use the root user sparingly to maintain optimal security and operational measures."
            ],
            "x-kaytu-noncompliance-cost": [
                "The non-compliance with this AWS control can pose various risks to your organization, including the following:\n\n1. **Security Breach**: The 'root user' in AWS has unrestricted access to all services and resources. If these credentials are misused, lost, or stolen, it could open up the possibility for a major security breach, potentially compromising the confidentiality, integrity, and availability of your organization's data and systems.\n\n2. **Regulatory Non-Compliance**: Many regulatory standards, such as PCI-DSS, GDPR, or HIPAA, require evidence of strong access controls, including limiting privileged access. If auditors find that the 'root user' account is misused, your organization may fail compliance audits, which can cause hefty penalties and loss of customer trust.\n\n3. **Operational Risks**: Frequent use of 'root user' account can lead to inadvertent changes or even deletion of critical resources, as it bypasses the least privilege principle. This can disrupt services and ultimately result in financial loss due to downtime or the cost of recovery.\n\n4. **Cost Escalation**: With unrestricted access, there's a risk- if the root account is compromised, of provisioning unnecessary resources leading to unintended cost escalation.\n\nCost of non-compliance can be direct (like penalties and recovery costs) or indirect (like reputational damage or loss of business). Hence, it is important to secure your 'root user' account by using it sparingly and following best security principles like using strong passwords, enabling multi-factor authentication (MFA), and regularly monitoring its activity."
            ],
            "x-kaytu-usefulness-example": [
                "For example, let's say that you run a software company and have chosen to host your application on AWS. You have a team of developers working on different aspects of the application and they need access to various AWS resources. However, giving them the root user credentials would be risky as they would have unrestricted access to all resources, which might lead to unintentional alterations or worse, security breaches.\n\nSo, you create IAM (Identity and Access Management) users for each developer under the root user account. You assign specific privileges and access controls to these IAM users based on their role in the team. This way they can only access the resources they need for their work, and the overall security and management of the AWS resources remain intact.\n\nHowever, let's assume there occurs an emergency situation such as a significant security threat or the need to modify the organization-wide access policy. In these scenarios, you, as the owner or the head of the company, can use the root user to make necessary changes instantly. The root user authentication would allow you full control over all AWS resources to manage such special situations.\n\nThis exemplifies the usefulness of the AWS root user. It acts as the ultimate gatekeeper and emergency-access point for an AWS account, allowing full control while also advocating for best practice of minimum necessary access for daily use."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_5",
        "Title": "3.5 Ensure AWS Config is enabled in all regions",
        "Description": "AWS Config is a web service that performs configuration management of supported AWS resources within your account and delivers log files to you. The recorded information includes the configuration item (AWS resource), relationships between configuration items (AWS resources), any configuration changes between resources. It is recommended AWS Config be enabled in all regions.",
        "QueryID": "aws_config_enabled_all_regions",
        "DocumentURI": "policies/aws_cis_v150_3_5.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.5"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/Config"
            ],
            "x-kaytu-explanation": [
                "# AWS Config\n\nAWS Config is a robust web service provided by Amazon Web Services, designed with the key purpose of managing the configuration of supported AWS resources within your account. It ensures you have an overview and control of your AWS resources and all related configuration profiles.\n\n## Key Features\n\n1. **Configuration Management:** AWS Config records and maintains the configuration profiles of all your AWS resources within your account, thus enabling you to audit and review changes and updates over time.\n\n2. **Resource Relationship:** The service monitors and documents relationships between different AWS resources. This feature is especially beneficial for debugging or identifying dependency chains.\n\n3. **Configuration Changes:** AWS Config records any changes in the configuration of the resources. This log allows for easy tracing of changes, identification of patterns, or detection of anomalies.\n\n4. **All-Region Enablement:** For maintaining a comprehensive and all-encompassing management strategy, it is recommended that AWS Config is enabled across all regions. \n\nAWS Config provides you with visibility into the resource inventory, configuration history, and configuration change notifications. It helps in identifying and understanding the AWS resource configurations and the relationships between them.\n\nConsider AWS Config as your logistics team that provides you the necessary information and handles the internal functioning, while you can focus on your key business responsibilities."
            ],
            "x-kaytu-noncompliance-cost": [
                "- **Financial Implications:** If non-compliance occurs, you may face direct financial repercussions due to resource misconfiguration. For example, you may unwittingly provision more expensive resources or deploy unnecessary ones due to lack of visibility into your resource configurations and dependencies. Without AWS Config, you might miss changes that lead to increased costs.\n\n- **Security Risks:** Without AWS Config, you lose a layer of security as you won't be alerted about configuration changes that may weaken your security posture or even violate compliance mandates. If a security breach happens due to this overlooked configuration change, the cost would be significant in terms of financial loss, reputational damage, and potential legal consequences.\n\n- **Operational Efficiency:** AWS Config keeps you informed about your AWS resource configurations and interdependencies, enabling you to manage resources effectively. Non-compliance with this configuration control could lead to operational inefficiencies, like longer troubleshooting time because you would lack the readily available data about resource changes and history.\n\n- **Compliance Violations:** Some compliance standards require configuration management and monitoring. So, if AWS Config is not enabled, you risk failing to meet such regulatory requirements and may face penalties or fines. For instance, regulatory bodies like PCI DSS, HIPAA, and GDPR, require businesses to monitor changes to their systems. \n\nIn summary, the cost of non-compliance to AWS Config being enabled can lead to higher financial costs, potential security risks, operational inefficiencies, and violations of compliance standards. Being unaware of changes in configurations and relationships among resources can lead to uncontrolled environments, which can create vulnerabilities and inefficiencies."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nA company, XYZ Enterprises, hosts its infrastructure and services on AWS and has instances running in multiple regions. The services include several interconnected AWS resources such as EC2, RDS, and S3. At the enterprise level, there can be hundreds of such resources, making manual tracking of changes in configurations and relationships between these resources quite challenging.\n\nTo overcome this, XYZ Enterprises use AWS Config. It monitors all their AWS resources and records their current and historical configurations. This enables them to audit any configuration changes made to their resources, greatly assisting with security and governance.\n\nSuppose they experience an issue with their application. With AWS Config, they can quickly view the relationships between their resources, which greatly aids in diagnosing the problem. If a resource was accidentally or maliciously deleted, AWS Config can provide information about its configuration at the time leading up to deletion, potentially helping with its recovery.\n\nFurthermore, they have their AWS Config set up to run continuously across all regions. This ensures that they have full visibility into resource configuration changes as they occur, proactively enabling them to detect non-compliant configurations or potential security risks and take appropriate action to rectify those issues. \n\nIn doing so, AWS Config proves invaluable to XYZ Enterprises by providing enhanced visibility, robust compliance reporting, and helping manage security and governance within their AWS setup across all regions."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_5_3",
        "Title": "5.3 Ensure no security groups allow ingress from ::/0 to remote server administration ports",
        "Description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389.",
        "QueryID": "aws_vpc_security_group_remote_administration_ipv6",
        "DocumentURI": "policies/aws_cis_v150_5_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "## AWS Control: Security Groups\n\nSecurity groups are virtual firewalls that control inbound and outbound traffic for resources run on Amazon Web Services (AWS). They act as a primary method of network security, allowing you to specify permissible traffic based on protocol, port, and source or destination IP address.\n\nThe security groups in AWS are _stateful_, which means any changes in inbound rules will automatically reflect in outbound rules. This type of filtering ensures that if you send a request from your instance, the response to that request will be allowed to return, even if the inbound security rules do not allow it.\n\n### Restrictions on Ingress Access\nFor enhanced security, it is recommended not to enable unrestricted ingress access on remote server administration ports. These include:\n\n- __SSH (Secure Shell):__ Port 22. SSH is a networking protocol used for secure connections between a client and a server over an unsecured network.\n\n- __RDP (Remote Desktop Protocol):__ Port 3389. RDP is a Microsoft protocol used in Windows Server to remotely administer a desktop.\n\nUnrestricted access to these ports can open avenues for cyber attacks like Brute Force or Denial of Service (DoS). The recommendation is to limit the source IP addresses that can connect to these ports, or better, to use a VPN or a bastion host.\n\nThus, implementing the best practices for security groups will help improve the overall security posture of your AWS environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can result in several costs ranging from financial to reputational damage:\n\n1. **Financial Costs**: Non-compliance can lead to financial losses due to a successful cyberattack. For instance, in case of an attack resulting in data breach can incur substantial costs related to breach notification, potential fines or lawsuits, and even loss of business.\n\n2. **Damage to Reputation**: If unrestricted ingress access to remote server administration ports results in a security breach, the damage done to the company's reputation can be severe. This can cause loss of trust with existing customers and deter potential customers, which can eventually lead to loss in business.\n\n3. **Operational Disruption**: Cyberattacks, made possible by non-compliance, may result in system downtime or service disruptions, leading to lost productivity and potential loss of business. Depending on the extent of the attack, this could also result in loss of critical data.\n\n4. **Regulatory Fines and Sanctions**: Non-compliance can also lead to penalties from regulatory bodies. Depending on the regulations a company is subject to (GDPR, CCPA, HIPAA, etc.), these fines can be very substantial.\n\nThe costs mentioned above emphasize the necessity to comply with this AWS control - securing the remote server administration ports like SSH to port-22 and RDP to port 3389. By restricting unrestricted ingress access, a crucial layer of security is added, preventing unauthorized access to sensitive information usually needed for server administration."
            ],
            "x-kaytu-usefulness-example": [
                "The following example is a scenario showcasing the usefulness of AWS Security Groups:\n\nA mid-sized company, XYZ Inc., has their web application hosted on AWS EC2 instances. The web application is built in such a way that it has multiple layers, such as UI, API, Database etc., and each layer is hosted on different sets of EC2 instances.\n\nIn this scenario, AWS Security Groups can be effectively used to manage and control both incoming (ingress) and outgoing (egress) network traffic to these EC2 instances.\n\nFor example, the traffic flow between UI layer and API layer can be strictly restricted to only necessary ports and specific source IP addresses (in this case, IP addresses of EC2 instances hosting UI layer). This prevents unwanted network traffic reaching the API layer, thereby enhancing its security.\n\n```markdown\n- Security Group for UI layer EC2 instances\n    - Ingress: Allows HTTP and HTTPS traffic from any IP.\n    - Egress: Restricts traffic to API layer EC2 instances IP addresses only over specific ports.\n    \n- Security Group for API layer EC2 instances\n    - Ingress: Allows traffic from UI layer EC2 instances IP addresses only over specific ports.\n    - Egress: Allows traffic only to Database layer EC2 instances IP addresses.\n```\n\nAlso, administrative access like SSH (port 22) or RDP (port 3389) can be strictly limited to specific IP addresses, which belong to the company's secure VPN. This closes any potential security loophole that might allow unauthorised access to the EC2 instances.\n\nThis way, AWS Security Groups provide a robust way to manage network traffic to AWS resources, enhancing the overall security of the application."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_8",
        "Title": "1.8 Ensure IAM password policy requires minimum length of 14 or greater",
        "Description": "Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure password are at least a given length. It is recommended that the password policy require a minimum password length 14.",
        "QueryID": "aws_iam_account_password_policy_min_length_14",
        "DocumentURI": "policies/aws_cis_v150_1_8.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.8"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "This is a rule within AWS (Amazon Web Service) Identity and Access Management (IAM) that sets the requirements for password complexity. Specifically, it's advising that your password policies should require a minimum of 14 characters for each password. \n\nIn a markdown format, it might look something like this:\n\n```\n# AWS Control: Password Policies \n\n## Overview:\nPassword policies enforce password complexity requirements in AWS. IAM password policies allow for specific password requirements to be set and adapted as needed for security purposes.\n\n## Recommendation:\nFor optimal security, it's advised to require a minimum password length of 14 characters. \n\nTo implement, go to your IAM dashboard on AWS, navigate to Account Settings, and set the password policy to require at least 14 characters.\n```\n\nThis includes a brief explanation of the control, why it's important, and how to implement it."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the mentioned AWS control regarding IAM password lengths can be multi-layered. Here are a few potential impacts:\n\n1. **Security Risks**: Not enforcing a password length of at least 14 characters could lead to weak passwords. This could make it easier for unauthorized individuals to compromise your AWS resources. This could lead to data breaches, service interruptions, and data corruption or loss.\n\n2. **Financial Costs**: Data breaches and service interruptions could have direct financial costs, such as downtime leading to lost revenue, or regulatory fines in case of exposure of sensitive or personal data.\n\n3. **Reputation Damage**: The exposure of customer data or a high-profile service interruption could harm a company's reputation, leading to the loss of customer trust and future business opportunities.\n\n4. **Regulatory Violations**: If your organization is under industry regulations that require certain security measures, non-compliance with those could result in heavy fines or sanctions.\n\nHere is an example of the cost of non-compliance in markup format:\n\n```markdown\n- **Security Risks**: Lowering the password complexity and length could lead to unauthorized access to your AWS resources. This may result in data breaches, service interruptions, and data corruption or loss, compromising the security of your organization.\n- **Financial Impact**: Data breaches or service interruptions could cause significant financial losses. These might be due to downtime leading to loss in revenue, cost of incident response, or potentially heavy regulatory fines in case of exposure of sensitive or personal data.\n- **Reputation Damage**: Any form of data breach or service interruption can lead to a significant damage to a company's reputation. Losing customer trust could drastically affect future business opportunities and overall company's market position.\n- **Regulatory Violations**: Non-compliance to industry standards and regulations could result in heavy fines or sanctions. Depending on the industry you operate in, this might include regulations such as GDPR, HIPAA, PCI DSS, and more.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a company that manages sensitive health data. This organization heavily relies on AWS services to store and process data, and has dozens of employees who are granted access to these resources. To protect against potential breaches, a strong password policy needs to be in place. Therefore, the Security Team at the organization sets an IAM password policy that enforces all passwords to be at least 14 characters long. \n\n```\n{\n    \"PasswordPolicy\": {\n        \"MinimumPasswordLength\": 14,\n        \"RequireSymbols\": true,\n        \"RequireNumbers\": true,\n        \"RequireUppercaseCharacters\": true,\n        \"RequireLowercaseCharacters\": true,\n        \"AllowUsersToChangePassword\": true\n    }\n}\n```\nIn this example, the AWS IAM password policy ensures that every password has a minimum length of 14, including requirements for symbols, numbers, and both uppercase and lowercase characters. This significantly lowers the risk of unauthorized access due to weak passwords, effectively protecting the organization's sensitive data."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_5_4",
        "Title": "5.4 Ensure the default security group of every VPC restricts all traffic",
        "Description": "A VPC comes with a default security group whose initial settings deny all inbound traffic, allow all outbound traffic, and allow all traffic between instances assigned to the security group. If you don't specify a security group when you launch an instance, the instance is automatically assigned to this default security group. Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that the default security group restrict all traffic.",
        "QueryID": "aws_vpc_default_security_group_restricts_all_traffic",
        "DocumentURI": "policies/aws_cis_v150_5_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.4"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "# Explaining AWS Control - Default Security Group\n\nAmazon Web Services (AWS) provides a component named AWS Virtual Private Cloud (VPC), which is used to secure your resources and manage networking functionalities. \n\nOne important component of a VPC is the 'security group'. Each VPC has a 'default security group' that comes with initial settings. These settings are geared towards the essential security of your computing resources.\n\n- **Inbound Traffic** - Initially, the default security group denies all types of inbound network traffic. This means, any attempt to connect to your instances (AWS resources) from any external resource is blocked.\n\n- **Outbound Traffic** - At the beginning, the default security group allows all outbound traffic. This indicates that any resource inside this group can connect to an external resource (Internet or other AWS services).\n\n- **Inter-Instance Traffic** - The instances assigned to the security group can communicate with each other freely as the group allows all traffic between these instances.\n\nImportantly, if you do not specify a security group when launching a new resource (like EC2 instance), AWS automatically assigns this instance to the default security group.\n\nThese security groups in AWS provide stateful filtering of ingress (incoming) and egress (outgoing) network traffic for AWS resources. 'Stateful Filtering' ensures that the response to any request is allowed back into the network, even if it is not explicitly permitted by security rules.\n\nTo enhance the security of your AWS resources, it is recommended that you modify the default security group to restrict all traffic (both inbound and outbound). This way, you only allow the necessary and secured traffic to and from your AWS resources.\n\nNote: It's important to customize your specific requirements for network traffic to maintain a secure and effective network environment. You can do this by modifying the rules of the security group, creating new security groups, or assigning instances to different security groups as per your needs."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS Control can lead to the following risks and costs:\n\n1. **Security Risks** - The most apparent cost of not adhering to this AWS control is the potential security risks. If you do not restrict all traffic in the default security group, malicious actors may gain access to your instances which could lead to data theft, service disruption, or even remote code execution.\n\n2. **Data Breach Costs** - If a breach occurs because of this, there could be financial implications ranging from fines due to non-compliance with data protection laws, to costs involved in investigating the breach, restoring data, or rectifying the damage. In some cases, this could cost millions of dollars.\n\n3. **Reputation Damage** - A compromise of your AWS resources could result in significant damage to your company's reputation. A loss of trust from your customers could lead to loss of business, which could ultimately cost revenue.\n\n4. **Loss of Availability** - Without proper restrictions, your resources can be susceptible to Denial-of-service (DoS) or Distributed Denial-of-service (DDoS) attacks, affecting the availability of your service, which can result in financial losses and damage to customer relationships.\n\nTherefore, it is essential to abide by this AWS control to effectively manage your security groups and restrict all unnecessary traffic to protect your network and system."
            ],
            "x-kaytu-usefulness-example": [
                "A common use case for this AWS control would be to help a company maintain strict control over the network traffic in and out of its AWS resources with enhanced security protection. \n\n```markdown\nFor instance, suppose a software company, ABC Tech, is developing a new web application in AWS. The development environment is set up within a VPC. For added security, they want to ensure that only their approved IP addresses have access to this environment.\n\nWhen setting up their VCP, ABC Tech can use the default security group and modify it to their needs. They can deny all unknown inbound traffic, restricting access only to their approved IP addresses. They can also allow all outbound traffic from their resources, enabling their team to work efficiently. \n\nThe feature also helps ABC Tech to connect instances securely. For instance, if they have different instances for application servers and database servers, the default security group will automatically allow traffic between these instances, facilitating secure communication within the VPC.\n\nBy leveraging this AWS control, ABC Tech can effectively manage their network traffic and protect their AWS resources, reducing the risk of security breaches and data loss.\n```\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_5",
        "Title": "4.5 Ensure a log metric filter and alarm exist for CloudTrail configuration changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for detecting changes to CloudTrail's configurations.",
        "QueryID": "aws_log_metric_filter_cloudtrail_configuration",
        "DocumentURI": "policies/aws_cis_v150_4_5.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.5"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "This AWS control suggests setting up a system that allows for real-time monitoring of API calls. This can be done utilizing two AWS Services – CloudTrail and CloudWatch.\n\n1. **CloudTrail**: An AWS service that records and stores event logs, including API calls, for your AWS account. If you or someone on your team makes a change to a resource, that action is documented in a CloudTrail event.\n\n2. **CloudWatch**: A service that lets you monitor and analyze your AWS resources' performance and operational health. \n\nYou can direct your CloudTrail Logs, which include the API calls, to CloudWatch Logs. Once the logs are sent to CloudWatch, you can analyze the data, discover patterns, and find potential issues.\n\nThis control suggests setting up metric filters and alarms for real-time monitoring. A metric filter extracts the data from your CloudWatch Logs and converts it into a CloudWatch metric. An alarm, on the other hand, watches a single metric over a time period you specify. It performs one or more actions based on the value of the metric relative to a threshold.\n\nThis control particularly emphasizes on monitoring changes to CloudTrail's configurations. Any amendments to your CloudTrail configurations could potentially impact your ability to audit and monitor activity within your AWS account, hence it's crucial to establish metric filters and alarms for such changes. Thus, you're alerted when such changes occur, which could signify unauthorized activity or points of concern."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS (Amazon Web Services) control can be seen from different aspects:\n\n1. **Security Costs**: If changes to CloudTrail configurations are not monitored, unauthorized modifications might go unnoticed. This could lead to potential security breaches such as unauthorized access to data or resources. By not having a metric filter and alarm, an organization could be vulnerable to cyber attacks.\n\n2. **Financial Costs**: Without real-time monitoring, you could miss instances where resources are maliciously or erroneously provisioned, which could lead to high AWS charges. Timely detection of these changes can help in maintaining budget control over AWS resources.\n\n3. **Operational Costs**: Unmonitored changes in configurations could lead to system failures or service disruptions. This could affect the continuity of business operations, affecting the reputation of the business and causing potential loss of customer trust and revenue.\n\n4. **Compliance Costs**: Many regulatory standards require real-time monitoring and timely detection of changes in system configuration. Non-compliance might lead to penalties, sanctions, or legal action from regulatory bodies.\n\n5. **Investigative Costs**: In the event of a security incident, undetected changes in CloudTrail's configurations could add complexity to the forensic investigation, prolonging the incident response time and potentially increasing the cost of the investigation.\n\nIn conclusion, not complying with this AWS control—real-time monitoring of API calls by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms for detecting changes to CloudTrail's configurations—could significantly increase security and financial risks, operational interruptions, compliance consequences, and investigation challenges."
            ],
            "x-kaytu-usefulness-example": [
                "Suppose you are a developer working for a large corporation with a complex cloud infrastructure on AWS. As part of your company's security policy and due to the sensitive nature of the data your company handles, all changes to its AWS infrastructure are strictly monitored and any changes must be approved by the security team. \n\nOne day, you realize that there are a large number of unauthorized API calls being made, and some CloudTrail configurations have been modified without authorization. This could potentially mean that a malicious entity has gained access to your AWS and is trying to manipulate your infrastructure. \n\nIf a metric filter and alarm had been established for detecting changes to CloudTrail's configurations, it would have sent a real-time alert as soon as these unauthorized changes were detected. Therefore, critical steps could have been taken immediately to prevent the potential security breach, demonstrating the usefulness of real-time monitoring.\n\nIf this measure was not in place, this potential breach could remain undetected for a substantial amount of time, leaving your company at risk for data corruption, data leaks, or worse. By directing CloudTrail Logs to CloudWatch Logs and establishing the metric filters and alarms, your company enhances its security measures by enabling real-time detection of harmful activity on your AWS infrastructure."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_6",
        "Title": "3.6 Ensure S3 bucket access logging is enabled on the CloudTrail S3 bucket",
        "Description": "S3 Bucket Access Logging generates a log that contains access records for each request made to your S3 bucket. An access log record contains details about the request, such as the request type, the resources specified in the request worked, and the time and date the request was processed. It is recommended that bucket access logging be enabled on the CloudTrail S3 bucket.",
        "QueryID": "aws_cloudtrail_s3_logging_enabled",
        "DocumentURI": "policies/aws_cis_v150_3_6.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.6"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "```markdown\n# S3 Bucket Access Logging Control\n\n**Amazon Web Services (AWS)** offers a feature called S3 Bucket Access Logging which is a reliable tool for monitoring and ensuring secure access to your stored data.\n\n## What is S3 Bucket Access Logging?\n\nThis is a feature that provides detailed records of the requests made to your AWS S3 (Simple Storage Service) bucket. This feature tracks and logs multiple types of request information like:\n\n- Type of request made\n- Resources specified in the request\n- Time and date of request processing\n\n## Why should we enable it?\n\nThe key benefits are:\n\n1. **Improved security** - It provides critical information about any unauthorized access or anomaly in the bucket access pattern which can be used for security analysis.\n2. **Better auditing** - Auditors can use the bucket access logs to verify that security policies in place are actually being followed.\n3. **Efficient troubleshooting** - If any issue arises relating to the accessibility of the S3 bucket, having access logs can help to quickly identify and resolve the issue.\n\nIt is highly recommended to enable the Bucket Access Logging on the CloudTrail S3 bucket. This service records the API calls for your AWS account, providing a history of changes made to the AWS resources. Consequently, integrating it will deliver a more detailed scope for analysis and ensure better security of your AWS environment.\n```\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this control can result in:\n\n1. **Increased Security Risks**: Without the access log, it would be difficult to track who accessed the bucket, when it was accessed, and what operations were performed. This could help malicious users infiltrate and manipulate your system without alerting you.\n\n2. **Reduced Auditability**: Access logs are a primary source of information for internal or external audits. Without them, it would be challenging to validate compliance with various regulations and best practices.\n\n3. **Difficulties in debugging and troubleshooting**: Logs help in understanding anomalies and events leading up to an incident. Without access logs, tracing back incidents and issues could become a nightmare.\n\n4. **Legal implications**: Many regulations require organizations to log access to data, particularly sensitive information. Non-compliance to this could result in significant penalties.\n\n5. **Data Loss**: In the scenario where the bucket was accessed and information was accidentally or maliciously deleted, it would be virtually impossible to identify the perpetrator or the action leading to the data loss without access logs."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, imagine you are running a popular e-commerce company, which mainly operates on AWS infrastructure. You store wide variety of data in your S3 buckets including user data, transaction details, product listings, etc. \n\nOne day, some of your users report unauthorized activities in their accounts. As part of an immediate security response, you need to investigate who accessed the S3 bucket with your customer's personal data. After all, you have not just the user's report, but also legal and compliance reasons to identify and correct any potential data breach as fast as possible.\n\nThis is where S3 Bucket Access Logging comes into play. Since you have this feature enabled, you now have the ability to look through the log records for any suspicious activities. You can see all the requests made on the bucket along with timeline, the requester, the type of request and whether the request was successful or not. Using this data, you can identify the activities that lead up to the security incident and take appropriate actions to mitigate it effectively.\n\nThus, enabling S3 Bucket Access Logging in this case allows you to track any attempts to access your data, identify any unauthorized or suspicious activity and respond to security incidents with immediate effect."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_5_5",
        "Title": "5.5 Ensure routing tables for VPC peering are \"least access\"",
        "Description": "Once a VPC peering connection is established, routing tables must be updated to establish any connections between the peered VPCs. These routes can be as specific as desired - even peering a VPC to only a single host on the other side of the connection.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v150_5_5.md",
        "ManualVerification": true,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.5"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "VPC (Virtual Private Cloud) peering in AWS (Amazon Web Services) allows you to connect two VPCs as if they're on the same network. To ensure the successful communication between the peered VPCs, the routing tables must be updated.\n\nRouting tables dictate where traffic is sent in a network. When a VPC peering connection is established, you need to add a route to the VPC's routing table that points to the IP address range (CIDR block) of the other VPC.\n\nFor example, you have two peered VPCs, VPC A (10.1.0.0/16) and VPC B (10.2.0.0/16). In VPC A's routing table, you should add a route where any destination traffic to 10.2.0.0/16 is targeted to the peering connection, and vice versa in VPC B.\n\nThis ensures that any traffic destined for the other VPC is sent through the peering connection. The exact configuration can vary, allowing for highly custom routes - even setting up the VPC peering in such a way that the VPC is connected to only a single host on the other side of the connection. \n\nThis level of flexibility is important in meeting different networking requirements for different use cases, and can significantly improve the security and efficiency of communication between VPCs.\n```markdown\n## AWS VPC Peering and Routing\n\n*AWS VPC Peering* allows you to connect two VPCs as if they were on the same network. \nTo make this happen:\n\n1. A VPC peering connection must be established.\n2. Routing tables must be updated to handle traffic between the connected VPCs.\n\n### Updating Routing Tables\n\nThese are the high-level steps to update routing tables:\n\n1. Identify the IP address range (CIDR block) of the other VPC.\n2. Add a route to the VPC's routing table that points to the above CIDR block and targets the VPC peering connection.\n\n**Example:**\n\n- VPC A: 10.1.0.0/16\n- VPC B: 10.2.0.0/16\n\nIn the routing table of VPC A, add a route that targets all traffic destined to 10.2.0.0/16 to the peering connection.\n\nDo the same for VPC B, but with VPC A's CIDR block.\n\n### Custom Routes\n\nRoutes can be as specific or as broad as needed. For example, you can set up a VPC to be connected to only a single host on the other VPC side of the connection. This can enhance security and communication efficiency between VPCs.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control can lead to various issues including:\n\n1. **Security Risks**: If routing tables are not updated properly after establishing a VPC peering connection, unauthorized or unintended traffic may be allowed to pass between VPCs, potentially exposing sensitive data and creating security vulnerabilities.\n\n2. **Network Connectivity Issues**: Without correctly updated routing tables, desired network connections between peered VPCs may not be established. This could lead to system downtime, inefficiencies, or failures in data transmission.\n\n3. **Inefficient Resource Usage**: If the routing tables are not finely tuned to route only to necessary hosts, there might be redundant data flow between unnecessary hosts. This can lead to inefficient usage of network resources and increased costs.\n\n4. **Compliance Violations**: Many industries require adhering to specific IT governance and security protocols. Not updating your routing tables adequately can lead to violations of these compliance requirements.  \n\nAs a result of these issues, non-compliance with this AWS control could lead to significant financial and operational costs. These could include, but are not limited to, the cost of lost business due to network downtime, the cost of wasted resources due to inefficient routing, potential fines or legal repercussions due to compliance violations, and the cost of potential data breaches and associated reputational damage."
            ],
            "x-kaytu-usefulness-example": [
                "An ecommerce company runs two different AWS accounts, account A which runs the management services and account B that runs the customer services. They want to ensure that only the management services in account A can access specific services like database backups in account B. In order to achieve this, a VPC Peering connection is established between the two accounts. \n\nHowever, for security reasons, they need to restrict access to only a specific host (management server) in account A. With AWS VPC Peering, the company can go as granular as needed in its connection settings. \n\nThey can modify the routing tables of the peered VPCs such that only the management server in account A can connect to the database in account B. \n\nThis way, they limit exposure of sensitive data and resources, preventing other hosts in account A from accessing the database in account B. This control in AWS can help in preventing data leaks, unwanted access while also aiding in smoother system operation, by reducing unnecessary data traffic between non-essential services.\n\n```\nResources:\n  DBPeeringConnection:\n    Type: 'AWS::EC2::VPCPeeringConnection'\n    Properties: \n      VpcId: vpc-0abcdef1234567890 \n      PeerVpcId: vpc-1abcdef1234567890\n      PeerOwnerId: 123456789012\n``` \n\nIn the routing tables, they can specify the route target as the VPC peering connection for routes that should be routed to the management server's VPC. \n\n```\nResources:\n  DBRoute:\n    Type: 'AWS::EC2::Route'\n    Properties: \n      RouteTableId: 'rtb-abcdef1234567890'\n      DestinationCidrBlock: 10.0.0.0/20\n      VpcPeeringConnectionId: pcx-abcdef1234567890\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_6",
        "Title": "4.6 Ensure a log metric filter and alarm exist for AWS Management Console authentication failures",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for failed console authentication attempts.",
        "QueryID": "aws_log_metric_filter_console_authentication_failure",
        "DocumentURI": "policies/aws_cis_v150_4_6.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.6"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "```\n# Real-Time Monitoring of API Calls Using AWS \n\nThis AWS control involves using two services - **AWS CloudTrail** and **Amazon CloudWatch** to achieve real-time monitoring of API calls. \n\n## Using CloudTrail Logs with CloudWatch \n\nAWS CloudTrail is a service that provides you with logs of all API calls for your account, including API calls made through the AWS Management Console, SDKs, and CLI. By directing these logs to Amazon CloudWatch Logs, you can perform real-time monitoring of your API activity. \n\n## Metric Filters and Alarms \n\nIn addition, by establishing metric filters and alarms in CloudWatch, you can set up specific conditions to monitor for in your logs, such as failed authentication attempts. If one of these alarm conditions is met, you receive notifications, allowing you to respond immediately. \n\nIt's recommended to establish a metric filter and alarm for failed console authentication attempts. This can help you detect and respond to unauthorized activity in your AWS account.\n\n```\n## Markup format \n\nBelow is an example of how this control might look in a markup format:\n\n```\n## AWS Real-Time API Monitoring Control\n\n1. **CloudTrail:** Utilize AWS CloudTrail to monitor API calls in your account. \n    - Direct CloudTrail logs to CloudWatch Logs. \n2. **CloudWatch Logs:** Perform real-time monitoring of API activity.\n3. **Metric Filters \u0026 Alarms:** Set up metric filters and alarms in CloudWatch for specific log conditions.\n    - Example: Create a metric filter for failed console login attempts. \n    - If this condition is met, an alarm triggers a notification. \n\nRecommendation: Establish a metric filter and alarm for **Failed Console Authentication Attempts**.\n\n```\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS control can be categorized into two main types: financial costs and security costs.\n\n1. Financial Costs:\n\nIf the recommended monitoring is not implemented, unusual or unexpected API call usage patterns may go unnoticed. This can potentially result in unexpected charges due to increased or unpredictable AWS usage. Identifying this immediately can stop the service and prevent further charges. The financial cost is subject to the usage and scale of the resources being used in AWS. \n\n2. Security Costs:\n\nThe more significant cost of non-compliance, however, is likely to be in terms of security. If failed console authentication attempts are not monitored, it makes it harder to detect and respond to potential security threats and breaches. Unauthorized access attempts often go hand in hand with failed console logins. Without this monitoring, breaches might go unnoticed, potentially resulting in data theft, loss, or manipulation.\n\nA single data breach could cost a company millions depending on the extent and nature of the data accessed. Moreover, it may result in a loss of business due to reputational damage, and there could be potential legal repercussions as well, especially if customer data is involved.\n\nIn summary, the cost of non-compliance with this AWS control is not just financial but can also lead to significantly increased security risks. It is strongly recommended to follow the AWS controls in place for monitoring API calls and failed console authentication attempts."
            ],
            "x-kaytu-usefulness-example": [
                "For example, let's imagine a situation where you're running a business which operates on AWS and you have multiple employees with access to the AWS console. For the security of your business operations, it's very important to track all the activity happening in your AWS account.\n\nHere comes the importance of monitoring failed console authentication attempts. It's a common practice for attackers to guess passwords in order to gain unauthorized access to consoles. By monitoring these failed attempts, you can be alerted about any potential security breach attempts. If the alarms for failed console attempts are continuously triggering, it might mean that your console is under brute force attack. \n\nSo, establishing a metric filter and alarm for failed console authentication attempts in AWS increases the security of your systems. The moment there are one or more failed attempts, CloudWatch will trigger an alarm and send notifications through SNS or any other configured notification channel, alerting you in real time. You can take immediate action to secure your account, such as identifying the source of failed attempts, blocking certain IPs, increasing the security level of your password policies, or even disabling the user account, if necessary.\n\nSo, this real-time monitoring ability to track failed console authentication attempts plays a vital role in maintaining the security and integrity of your AWS services, and thus, your business operations on the whole."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_7",
        "Title": "3.7 Ensure CloudTrail logs are encrypted at rest using KMS CMKs",
        "Description": "AWS CloudTrail is a web service that records AWS API calls for an account and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data, and uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. It is recommended that CloudTrail be configured to use SSE-KMS.",
        "QueryID": "aws_cloudtrail_trail_logs_encrypted_with_kms_cmk",
        "DocumentURI": "policies/aws_cis_v150_3_7.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.7"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "`AWS CloudTrail` is a web service that records AWS API calls for an account and makes those logs available to users and resources in accordance with `IAM policies`. `AWS Key Management Service (KMS)` is a managed service that helps create and control the encryption keys used to encrypt account data. It uses Hardware Security Modules (`HSMs`) to protect the security of encryption keys. \n\nCloudTrail logs can be configured to leverage server side encryption (`SSE`) and KMS customer created master keys (`CMK`) to further secure CloudTrail logs. It is **recommended** that CloudTrail be configured to use `SSE-KMS`. \n\nHere's why:\n\nLeveraging KMS via SSE provides an additional layer of security to CloudTrail. The encryption of your logs helps to ensure the integrity of that data. It can provide valuable evidence in the event of a cyber security incident or even for routine audits, so the logs themselves can become a target for threats. By encrypting the logs using `AWS KMS`, you provide an additional layer of protection to the logs. \n\nAlso, having KMS keys providing encryption allows better key management such as automated key rotation and centralized control of keys which ensures better governance, risk and compliance (GRC) management. \n\nIn conclusion, by configuring `CloudTrail` to use `SSE-KMS` adds more security to your logs and improves your overall GRC management."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS control that advises use of CloudTrail configured with SSE-KMS could result in the following potential costs:\n\n1. **Security Risk**: Without SSE-KMS, your CloudTrail logs, which may contain sensitive details like IP addresses and API activity, could come under attack by cyber-criminals. This can result in data breaches which may expose sensitive data, thus compromising the security and integrity of your organization's AWS infrastructure.\n\n2. **Revenue Loss**: In the event of security breaches, organizations could suffer significant financial losses. This could come from system downtime, loss of business due to reputational damage, possible lawsuits from affected parties or punitive fines by regulatory bodies.\n\n3. **Regulatory Fines**: Many industries have strict rules for how data should be handled. Failing to encrypt sensitive logs could result in non-compliance with such regulations and invite hefty fines and penalties. \n\n4. **Loss of Customer Trust**: Customers may lose faith in your organization’s ability to protect their data which can result in loss of clients and potential future business.\n\n5. **Forensic Costs**: If a breach occurs, organizations may have to hire cyber forensics experts to investigate the breach, identify the compromised areas, and implement measures to avoid future security incidents.\n\nHence, it is critical that AWS CloudTrail be configured with Server Side Encryption-KMS to protect the organization from significant potential negative impacts."
            ],
            "x-kaytu-usefulness-example": [
                "```\nExample:\nCompany XYZ is a software as a service provider that handles sensitive data from its customers. To ensure the security and integrity of this data, the company uses various AWS services. They have implemented AWS CloudTrail to monitor their account's API calls, which provides an audit log of all activities in their AWS environment.\n\nHowever, the logs generated by CloudTrail contain sensitive information, such as user actions and access patterns, which could be exploited if they fall into the wrong hands. To fortify the security of these logs, Company XYZ decided to configure CloudTrail to use Server Side Encryption (SSE) enabled with AWS Key Management Service (KMS).\n\nThrough AWS KMS, they created a Customer Master Key (CMK) to be used specifically for encrypting and decrypting their CloudTrail logs. With the combination of SSE-KMS, their logs are now encrypted with a key that is stored and managed separately, offering an additional layer of security.\n\nThe company also has the flexibility to manage and rotate these keys as required, giving them control over who can access the encrypted data. AWS handles the durability and physical security of these keys, while Company XYZ controls their use.\n\nThus, through the use of SSE-KMS, Company XYZ has significantly enhanced the protection of their CloudTrail logs, maintaining the confidentiality and integrity of their sensitive data.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_9",
        "Title": "1.9 Ensure IAM password policy prevents password reuse",
        "Description": "IAM password policies can prevent the reuse of a given password by the same user. It is recommended that the password policy prevent the reuse of passwords.",
        "QueryID": "aws_iam_account_password_policy_reuse_24",
        "DocumentURI": "policies/aws_cis_v150_1_9.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.9"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS Identity and Access Management (IAM) is the AWS tool that offers a way to manage access to AWS services and resources securely. \n\nOne of the ways in which it does this is through password policies for IAM users. It is a powerful feature that allows an administrator to define and enforce password rules and requirements for all IAM users in an AWS account. \n\nThis strategy is useful in mitigating certain types of security risks. For instance, if a password was previously compromised or weak, preventing reuse inhibits a potential attacker from just trying old passwords.\n\nHere's how it can be written in markup format:\n\n```markdown\n# IAM Password Policies\n**AWS Identity and Access Management (IAM)** offers a secure way to manage access to AWS services and resources. It includes enforcing password rules and requirements through **password policies**.\n\nThese policies help mitigate security risks, such as password compromise or weak password usage. For example, an administrator can prevent the reuse of previously used passwords, thereby limiting the chances an attacker has to access the system simply by trying old passwords.\n\nTo implement, just adjust and apply the password policy settings in the AWS Management Console, AWS CLI, or AWS API.\n```\nFor illustrative purposes, here is how it can be set in the AWS Management Console:\n\n1. In the AWS Management Console, navigate to the IAM console.\n2. In the navigation pane, choose \"Account Settings\".\n3. On the Account Settings page, choose \"Change Password Policy\".\n4. In the \"Prevent password reuse\" section, specify the number of passwords to remember.\n5. Choose \"Apply Password Policy\". \n\nThe policy will then effectively prevent IAM users from reusing a given number of previous passwords."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the IAM password policy control that prevents password reuse is risky and can lead to several costs for your organization:\n\n1. **Security Breach**: If an old password is compromised, it could be reused to gain unauthorized access to your systems, leading to potential data loss, alteration, or damage.\n\n2. **Financial Loss**: A security breach can result in financial loss if data related to financial operations or customer's financial information is compromised. Also, dealing with cyber-attacks may require a significant investment in terms of time and resources.\n\n3. **Regulatory fines**: Non-compliance could result in penalties if your organization needs to comply with certain security standards (like PCI DSS, HIPAA, ISO 27001, GDPR, etc.) that mandate secure password policies.\n\n4. **Loss of Trust**: Users' (or customers') trust could be lost if they become aware of insecure password practices. This could result in loss of customer base and reputation.\n\n5. **Interruption to Business Operations**: Successful cyber attacks could result in serious downtime, disrupting the routine business operations.\n\n6. **Cost of Incident Response**: Resources (both personnel and financial) will need to be dedicated to investigating the breach, mitigating the damage, and implementing stronger security measures to prevent future attacks.\n\nIn summary, non-compliance to this control can have far-reaching implications not limited to security breaches and loss of data. It can result in significant financial costs, regulatory penalties, and damage to company reputation."
            ],
            "x-kaytu-usefulness-example": [
                "```markdown\nFor example, a software company ABC Inc. uses AWS services and has a large team of developers who frequently require access to the AWS Management Console. The company has experienced security breaches in the past due to passwords being reused and easily guessed by malicious parties.\n\nTo enhance the security of their AWS account, ABC Inc. decides to implement IAM password policies to prevent the reuse of a given password by the same user. They do this by using AWS Management Console and navigates to IAM dashboard \u003e Account settings \u003e Password policy settings, and check two options: \"Prevent password reuse\" and the number of passwords to remember is set to 24 to ensure a password can't be reused until after 24 rotations.\n\nThis enforcement ensures that once a developer changes their password, they cannot change it back to the same password they used before. This adds an extra layer of security to ABC Inc.’s AWS accounts and significantly reduces the risk of their accounts being compromised due to password reuse. The practice also ensures that developers come up with new and stronger passwords every time they are prompted to change it, enhancing the entire system's security.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_7",
        "Title": "4.7 Ensure a log metric filter and alarm exist for disabling or scheduled deletion of customer created CMKs",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for customer created CMKs which have changed state to disabled or scheduled deletion.",
        "QueryID": "aws_log_metric_filter_disable_or_delete_cmk",
        "DocumentURI": "policies/aws_cis_v150_4_7.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.7"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS (Amazon Web Services) provides several services for monitoring and managing resources and applications that run on AWS. These include Amazon CloudTrail, which records AWS API calls for an account and delivers log files for audit and review, and Amazon CloudWatch, which provides data and insights to monitor applications, understand and respond to system-wide performance changes, and optimize resource utilization.\n\nIn the stated control, AWS recommends real-time monitoring of API calls through a combination of CloudTrail and CloudWatch. Here's how it works:\n\n- API Calls are logged by AWS CloudTrail.\n- These logs are then pushed to Amazon CloudWatch. \n- Within CloudWatch, you define metric filters to inspect the incoming logs for specific phrases or patterns. \n- If a pattern is identified, it can then trigger a CloudWatch alarm to alert you of the event.\n\nThe control specifically recommends setting up a filter and alarm for events where a customer created CMK (Customer Master Key) changes its state to either 'disabled' or 'scheduled for deletion'. A CMK is a logical representation of a master key which can be used within AWS Key Management Service (KMS) to control the use of encrypted data.\n\nBy implementing this, you can ensure data security and integrity by being alerted when a CMK is modified in a potentially harmful way. \n\nHighlights in Markdown Format: \n\n- Real-time monitoring of **API calls** can be done via **CloudTrail Logs** to **CloudWatch Logs**\n- **Metric filters** and **alarms** are established in CloudWatch Logs to trigger certain actions or notifications based on log patterns\n- Recommendation for monitoring any changes in status to 'disabled' or 'scheduled for deletion' for **customer created Customer Master Keys (CMKs)** \n- This is useful for organizations to keep **track of changes** and maintain high **data security** standards"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control could potentially result in significant financial and operational costs for your organization. Here's a breakdown of the specific cost implications:\n\n1. **Security Breaches**: If Customer Master Keys (CMKs) are disabled or scheduled for deletion without proper monitoring, it would be possible for unauthorized parties to unauthorized decrypt or misuse sensitive data. This could result in financial losses due to data breaches, stolen data, or compliance fines.\n\n2. **Operational Disruption**: Disabling or deleting keys could disrupt applications or services that depend on them for functionality. This could lead to loss of business, reputation damage, and reduced customer satisfaction.\n\n3. **Compliance Costs**: Many industries have regulations requiring monitoring and logging of access to sensitive data. If these logs are not maintained, it could result in non-compliance, leading to heavy fines and penalties. In extreme circumstances, non-compliance could also lead to suspension of business license.\n\n4. **Investigation costs**: In the absence of monitoring, identifying the origin of a security issue or understanding the sequence of events leading to a problem could be challenging. This could translate into increased time and cost in detective work.\n\n5. **Remediation Costs**: If keys are disabled or deleted without proper oversight, costly resources may be required to recreate or reactivate keys, update systems that utilized these keys, and remediate any damage done.\n\nTo avoid these potential costs, it is crucial to establish real-time monitoring of API calls by directing CloudTrail Logs to CloudWatch Logs and creating a metric filter and alarm for customer created CMKs which have changed state to disabled or scheduled deletion."
            ],
            "x-kaytu-usefulness-example": [
                "Instance:\n\nA fintech company uses AWS Key Management Service (KMS) to create and manage cryptographic keys and control their use across a wide range of AWS services and in their applications. They have hundreds of customer created CMKs (Customer Managed Keys) in their AWS account.\n\nOne day, an unauthorized user gained access to their AWS account and disabled some of the CMKs which affected the operation of their fintech applications, and it took them several hours to resolve this issue.\n\nFollowing this event, the fintech company used AWS CloudTrail to capture all API calls for AWS KMS, which delivered the log files to an Amazon S3 bucket in near real-time. They set up CloudWatch Logs to monitor the CloudTrail Logs and established a metric filter which matches events on the status change of their CMKs. Also, they set an alarm to notify the right personnel via email whenever the state of any customer created CMK changes to disabled or scheduled deletion.\n\nNow, they put real-time monitoring in place and can take immediate action if any unauthorized person tries to disable or schedule deletion of their CMKs, thus preventing any potential disturbance or halt in their services. This is a clear instance example of establishing an alarm and metric filter for CloudTrail Logs and CloudWatch Logs."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_8",
        "Title": "3.8 Ensure rotation for customer created symmetric CMKs is enabled",
        "Description": "AWS Key Management Service (KMS) allows customers to rotate the backing key which is key material stored within the KMS which is tied to the key ID of the Customer Created customer master key (CMK). It is the backing key that is used to perform cryptographic operations such as encryption and decryption. Automated key rotation currently retains all prior backing keys so that decryption of encrypted data can take place transparently. It is recommended that CMK key rotation be enabled for symmetric keys. Key rotation can not be enabled for any asymmetric CMK.",
        "QueryID": "aws_kms_cmk_rotation_enabled",
        "DocumentURI": "policies/aws_cis_v150_3_8.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.8"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/KMS"
            ],
            "x-kaytu-explanation": [
                "AWS Key Management Service (KMS) is a managed service that allows you to easily create and manage cryptographic keys and control their use across a wide range of AWS services and in your applications. A key aspect of the AWS KMS is the ability to rotate the backing keys which are tied to the Customer Created customer master key (CMK).\n\nThe backing key, also known as the key material, is used to perform cryptographic operations such as encryption and decryption of data. It is stored within the KMS and is associated with the CMK's key ID.\n\nOne crucial feature of AWS KMS is automated key rotation, which means AWS KMS can automatically generate a new backing key annually. This feature enhances your security posture by reducing the potential impact of a compromised key as AWS KMS retains all previous backing keys, allowing for the decryption of any data encrypted under those keys.\n\nAWS recommends enabling key rotation for symmetric keys, which use the same key for both encryption and decryption. However, it's important to note that key rotation cannot be enabled for asymmetric CMKs, where the key used for encryption is different from the key used for decryption."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS KMS Control can be described as follows:\n\n1. **Security Risk:** The primary cost of non-compliance is an increased risk to data security. Not rotating keys periodically can increase the vulnerability of data to unauthorized access, especially if a key is compromised. It can lead to unauthorized access to sensitive data, resulting in loss of confidentiality, integrity, and availability.\n\n2. **Regulatory Compliance Penalties:** In some industries, regulatory standards require key rotation for certain types of data. Non-compliance with these requirements can result in costly fines and sanctions, including potential loss of the ability to operate within that industry.\n\n3. **Reputation Damage:** Suffering a security breach due to non-compliance with good security practices can result in significant harm to a company's reputation. It can lead to loss of customer trust and consequent loss of business.\n\n4. **Loss of Data:** In a situation where the keys are compromised and misused, companies may lose valuable data. The cost of re-acquiring or rebuilding this data can be substantial.\n\n5. **System Interruptions:** Unauthorized access or alterations to encrypted data can result in significant system interruptions, which can lead to loss of productivity and revenue.\n\n6. **Costly Remediation:** If a breach occurs, investigations and remediation can be costly. These costs can include internal time and resources, as well as potential fees for third-party security firms to assist in incident response and forensic analysis.\n\nTo avoid these potential costs, it is highly recommended to comply with the AWS KMS Control by enabling CMK key rotation for symmetric keys."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nABC corporation, a multinational company, stores a large amount of sensitive customer and sales data in AWS S3 buckets. Because the data is highly sensitive, it is encrypted before being stored. To encrypt and decrypt this data, they created their own Customer Master Key (CMK) in the AWS Key Management Service (KMS).\n\nHowever, ABC corporation's compliance policies require them to change their encryption keys every year to mitigate the risk related to key exposer or leakage over time. They could manually rotate the keys, but it is a resource-intensive and error-prone task, especially considering the amount of data they manage.\n\nThankfully, AWS KMS allows automatic rotation of the backing key tied to the CMK every year, without their intervention. This automated process provides the ABC corporation with an efficient way to align with their key rotation policy, and ensure that the encryption and decryption of their data continue to happen seamlessly. \n\nThe usefulness of AWS KMS here is twofold:\n\n1. It automates a critical, tedious process (CMK rotation), reducing the scope for human error and freeing up resources.\n2. It allows the corporation to adhere to its internal security policies and regulations, helping maintain the safety of its precious data. \n\nSo, by using AWS KMS for rotating their symmetric CMK, the ABC corporation can continue to keep their sensitive data secure without needing to focus on manual key management."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_9",
        "Title": "3.9 Ensure VPC flow logging is enabled in all VPCs",
        "Description": "VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. After you've created a flow log, you can view and retrieve its data in Amazon CloudWatch Logs. It is recommended that VPC Flow Logs be enabled for packet \"Rejects\" for VPCs.",
        "QueryID": "aws_vpc_flow_logs_enabled",
        "DocumentURI": "policies/aws_cis_v150_3_9.md",
        "ManualVerification": false,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.9"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "Sure, here's an overview of how you might explain VPC Flow Logs feature using a markup (typically markdown) format for readability:\n\n# VPC Flow Logs in AWS\n\n**VPC Flow Logs** is a valuable feature provided by AWS that allows you to collect, track, and monitor the IP traffic that enters and exits the network interfaces within your **Virtual Private Cloud (VPC)**.\n\n## Amazon CloudWatch Logs Integration \n\nYou can retrieve and view the created flow logs data through **Amazon CloudWatch Logs**. This powerful integration provides a central location to track, manage, and analyze the flow log data, allowing for efficient troubleshooting and operational tasks.\n\n## Recommended Use\n\nFor optimal use and security, it is recommended that **VPC Flow Logs should be enabled for packet \"Rejects\"** within your VPCs. This will offer more extensive monitoring and can help identify traffic patterns or issues that may impact security or performance.\n\nIn summary, VPC Flow Logs serves as a crucial diagnostic tool in *network troubleshooting*, *performance optimization*, and *security auditing*."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the mentioned AWS Control, \"VPC Flow Logs should be enabled for packet 'Rejects' for VPCs\" , can result in:\n\n1. **Security Risks**: Disabling flow logs for packet \"rejects\" may leave network security threats unnoticed. Attackers might attempt to send harmful or unapproved traffic, and if these packets are not logged as \"rejects\", their activities may go undetected. This can potentially increase the risk of a successful cyber attack or a data breach which can have severe financial and reputational consequences for the business.\n\n2. **Compliance Violations**: Depending on the organization's industry, there might be compliance standards in place (like SOC, PCI DSS, HIPAA, etc.) that require logging and monitoring of network traffic. Not having flow logs for packet \"rejects\" enabled could lead to non-compliance with these standards resulting in substantial fines and penalties.\n\n3. **Operational Inefficiencies**: Without VPC Flow Logs for packet \"rejects\" enabled, troubleshooting network issues can be challenging and time-consuming. It might slow down the resolution of system errors and lead to extended system downtime impacting the business operation and potentially leading to revenue loss.\n\n4. **Loss of Visibility**: It will reduce the visibility of traffic patterns and network operations in your VPCs. This lack of visibility can lead to inefficient resource utilization and poor decision making in security and operational matters.\n\n5. **Forensics Difficulty**: In the event of a security incident, the absence of detailed logging information can hamper the forensic investigation process, making it harder to understand the event's impact and prevent future incidents. \n\nIn summary, the cost of non-compliance to this control can be quite significant, potentially exposing the organization to unforeseen security, financial, and operational risks."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, imagine you are working as a cloud architect for a certain company. Lately, there have been unusual traffic patterns within your company's Virtual Private Cloud (VPC), which raises concerns of a potential security breach. \n\nTo specifically track and continuously monitor all traffic within your VPC, you decide to use VPC Flow Logs. This will provide a granular view of every IP traffic going in and out of all network interfaces in the network. \n\n```markdown\nBy enabling VPC Flow logs, you effortlessly identify and troubleshoot security and network issues. More so,\n\n- It aids in meeting compliances, e.g., checking if the 'deny' rules are correctly implemented and optimized for your VPC Security Groups and Network Access Control Lists (ACLs).\n- It provides valuable insights for bandwidth optimization, spotting traffic trends, and traffic engineering decisions. \n\nAnd when you set it to log packet \"Rejects\" for the VPCs, any suspicious or denied entry attempts are logged. For instance, \n\n- If a sudden surge of rejected traffic is found from a specific IP, it could indicate a potential security risk.\n- It can also provide evidence of compliance with specific security policies for audits purposes.\n\nIn a nutshell, VPC flow logs help you to better understand, optimize, and troubleshoot your applications' network activity. \n```\nHaving these logs in Amazon CloudWatch Logs allows you easy storage, access, and analysis of your network's data making VPC Flow Logs a valuable tool for your cloud networking and security infrastructure."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_8",
        "Title": "4.8 Ensure a log metric filter and alarm exist for S3 bucket policy changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for changes to S3 bucket policies.",
        "QueryID": "aws_log_metric_filter_bucket_policy",
        "DocumentURI": "policies/aws_cis_v150_4_8.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.8"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "This AWS control refers to monitoring changes to Amazon Simple Storage Service (S3) bucket policies in real-time. Here's a simple breakdown:\n\nAmazon Web Services (AWS) provides a service called CloudTrail, which records AWS API calls for your account and delivers log files to you. These logs can be directed to another AWS service, CloudWatch, which allows for easy monitoring and alarming based on metrics identified in the logs.\n\nThe control put forward is a recommendation to use these services in tandem to establish real-time monitoring of changes to S3 bucket policies. This would potentially include changes such as granting or removing access rights to S3 buckets.\n\nA metric filter is a CloudWatch component that scans incoming data and transforms it into a numeric CloudWatch metric that you can chart or set an alarm on. \n\nSetting an alarm refers to creating a CloudWatch Alarm, a feature that sends a message (to your AWS SNS Topic) when the metrics meet a condition you set.\n\nIn markup format, it would look like:\n\n```\n**Real-time API Call Monitoring in AWS**\n\n1. Direct *CloudTrail Logs* to *CloudWatch Logs*.\n2. Establish *metric filters* and *alarms* in CloudWatch Logs.\n3. Set the above for monitoring changes to *S3 bucket policies*.\n\nThis setup is recommended for constant and real-time supervision of your S3 bucket policies.\n```\n\nThis configuration will alert the appropriate personnel when changes to S3 bucket policies occur, allowing for prompt investigation and response."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the AWS control that recommends the establishment of a metric filter and alarm for changes to S3 bucket policies can have various costs associated with it, including:\n\n1. **Security Costs:** Without real-time monitoring, any unauthorized or malicious changes to S3 bucket policies will not be detected or reported immediately, leaving your data at increased risk. If your data is compromised, you might face huge losses and damage to your reputation.\n\n2. **Financial Impact:** If a data breach occurs due to unauthorized changes in S3 bucket policies, potential financial losses might occur due to penalties or fines from regulatory authorities, potential lawsuits, or losing business due to trust issues. \n\n3. **Operational Disruption:** Untracked changes to S3 bucket policies might lead to operational disruptions. For instance, unexpected changes can result in service disruptions or connectivity issues, causing inefficiencies and productivity losses.\n\n4. **Compliance Issues:** Many industries are subject to regulations which require logging and monitoring of data access. Non-compliance with this control could result in failing an audit, leading to fines or other punitive actions.\n\n```\nThus, non-compliance with this AWS control could result in severe financial, operational, and reputational damage. It is crucial to ensure real-time monitoring of API calls and changes to S3 bucket policies to maintain the security and integrity of your data.\n```\n\nPlease note that the exact costs of non-compliance can vary based on the size and nature of your operations and how much you rely on AWS for your business needs."
            ],
            "x-kaytu-usefulness-example": [
                "In AWS, S3 buckets are used for storing important data including business and customer information. However, if a configuration change occurs to these S3 buckets, it might result in data theft, data loss or unexpected charges. \n\nFor example, suppose we have an e-commerce company, \"BuyItAll\", that relies heavily on data housed in S3 buckets - information like customer shopping behaviour, inventory, sales and financial statistics. An unintended or malicious change in bucket policies might give unauthorized people access to this sensitive information, which could lead to data theft. Moreover, it might also lead to an unexpected increase in costs if the altered policy allows everyone to list or download the content.\n\nHere's where real-time monitoring of API calls comes in. If \"BuyItall\" directs its CloudTrail logs to CloudWatch and sets up metric filters and alarms, any changes to their S3 bucket policies would trigger an alarm. This immediate notification allows the security administration team of \"BuyItAll\" to act swiftly and ensure the policies changes are intentional and authorized, hence preventing potential data exposure or costly operations. \n\nThis way, using AWS CloudWatch and CloudTrail for real-time monitoring of API calls particularly for changes in S3 bucket policies, helps maintain data security and integrity."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_9",
        "Title": "4.9 Ensure a log metric filter and alarm exist for AWS Config configuration changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for detecting changes to CloudTrail's configurations.",
        "QueryID": "aws_log_metric_filter_config_configuration",
        "DocumentURI": "policies/aws_cis_v150_4_9.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.9"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "This AWS Control refers to the practice of setting up continual, real-time monitoring of all API calls made within an AWS environment. This can be achieved by directing CloudTrail Logs to CloudWatch Logs. \n\nCloudTrail is an AWS service that records API calls made on your account and delivers log files to you. CloudWatch Logs provide an interface to centralize, monitor and retain your log files.\n\nMetric Filters and Alarms are AWS CloudWatch features to monitor specific phrases, values or patterns that appear in CloudTrail logs. When a pattern (a specific API event) matches the metric filter, it will increment a CloudWatch metric.\n\nThe control recommends that a metric filter and alarm be set up specifically for changes to CloudTrail's configurations. This means that whenever a change is made to the configurations, the activity is logged in CloudTrail, and the change fires off a CloudWatch alarm. This helps in maintaining the security and integrity of your AWS services by alerting you of any changes, preventing any undesired modifications.\n\nFor example, if someone changes the configurations of CloudTrail (like turning off the logging), an alarm will be triggered in CloudWatch, notifying you of the same. This will allow you to quickly acknowledge and take action on any unauthorized or undesired changes."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control can lead to several risks and costs:\n\n1. **Loss of Visibility and Transparency**: If you don't monitor API calls in real time, you will lack visibility into your operational and security status. Any suspicious or unauthorized activities can go unnoticed, potentially leading to security breaches.\n\n2. **No Early Warning System**: Without real-time monitoring of API calls, you lose the ability to detect and address potential issues early. This could result in larger problems down the line that could disrupt your business operations and customer experience.\n\n3. **Non-compliance with Regulations**: Depending on your organization's industry, you may be subject to certain regulations that require real-time monitoring of API calls. Non-compliance could lead to legal actions, fines, and a damaged reputation.\n\n4. **Data Breaches**: Failing to monitor API calls in real-time could give attackers more time to maneuver and harm your systems, steal sensitive data, or perform other malicious activities. The cost of a data breach can be significantly high, involving financial penalties, loss of customer trust, and damage to your brand.\n\nTherefore, it's essential to establish a metric filter and alarm for detecting changes to CloudTrail's configurations. The cost of non-compliance can be quite hefty, considering both the direct financial impact and long-term reputational damage."
            ],
            "x-kaytu-usefulness-example": [
                "Instance:\n\nAn example where such a setup could be useful is in a business scenario where you need to ensure the integrity and security of your AWS services. \n\nLet's say that you have a critical application running on an EC2 instance and relies heavily on AWS S3 bucket for data storage. Unauthorized or unexpected changes to this S3 bucket's configurations through API calls may have a drastic effect on your application's performance or even worse cause data loss. This is where real-time monitoring of API calls comes in.\n\nBy directing AWS CloudTrail Logs to CloudWatch Logs and setting up corresponding metric filters and alarms, you can immediately detect any changes to the S3 bucket's configurations. \n\nWhen a coinciding metric filter is established and triggers an alarm due to detected changes, CloudWatch can send notifications via SNS or even trigger a Lambda function to auto-correct the configuration change. \n\nThis real-time monitoring and alarming give you more visibility over who is changing what in your environment and enables fast response to possibly critical configuration changes. Therefore, securing your application's performance and your business's data."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_10",
        "Title": "1.10 Ensure multi-factor authentication (MFA) is enabled for all IAM users that have a console password",
        "Description": "Multi-Factor Authentication (MFA) adds an extra layer of authentication assurance beyond traditional credentials. With MFA enabled, when a user signs in to the AWS Console, they will be prompted for their user name and password as well as for an authentication code from their physical or virtual MFA token. It is recommended that MFA be enabled for all accounts that have a console password.",
        "QueryID": "aws_iam_user_console_access_mfa_enabled",
        "DocumentURI": "policies/aws_cis_v150_1_10.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.10"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Multi-Factor Authentication (MFA)\n\nAWS Multi-Factor Authentication (MFA) is a security feature that provides an additional layer of protection for your AWS resources. In addition to your usual user name and password, MFA requires an authentication code from a physical or virtual MFA device when you sign in to the AWS Console.\n\n## How It Works\n\nWhen you sign in to the AWS Console with MFA enabled, you'll be prompted for:\n\n1. Your user name and password.\n2. An authentication code from your physical or virtual MFA token.\n\nTo get this code, you'll typically need to use a smartphone app or a special hardware device, like an RSA key fob. This code is randomly generated each time, which makes it nearly impossible for attackers to guess.\n\n## MFA for Console Password\n\nFor additional security, it's recommended that MFA be enabled for all accounts that have a console password. This ensures that even if your password is compromised, an attacker still can't access your account without your MFA device. This practice significantly increases the security of your AWS environment.\n\nSo, not only does MFA prevent unauthorized users from signing into your accounts, it also helps protect your applications and data and helps ensure compliance with relevant regulatory requirements for data security.\n\n**Note:** This security control would be applicable to privileged users (like root users) and IAM users who have console access permissions. If MFA is enabled, these users would be presented with an MFA challenge whenever they attempt to log into their AWS Console."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance with the Multi-Factor Authentication (MFA) control can be significant, both in direct financial terms and in terms of reputation. It can also lead to further security complications. Here are a few key aspects:\n\n1. **Data Breaches**: Without MFA, unauthorized users can potentially gain access to the AWS console by merely guessing or stealing user names and passwords. They could then access sensitive information, modify important configurations, or launch instances for their use, leading to data breaches.\n\n2. **Increased Financial Cost**: If unauthorized users gain access to the AWS console, they could launch instances or services and leave them running, leading to unexpected charges on the AWS bill.\n\n3. **Reputational Damage**: Data breaches can result in significant reputational damage, leading to a loss of customer trust and potential legal implications.\n\n4. **Regulatory Non-Compliance Penalties**: If your organization falls under an industry that requires regulatory compliance (like GDPR, HIPAA etc.), a lack of MFA can lead to non-compliance, resulting in fines and sanctions.\n\nTherefore, these costs associated with the absence of MFA highlight its need to fortify the security of AWS console access.\n\nHere's how this can be expressed in markup (e.g., for a Markdown-based document):\n\n```\n# Cost of Non-Compliance with Multi-Factor Authentication in AWS\n\nNon-compliance with the Multi-Factor Authentication (MFA) control can lead to several complications for businesses, ranging from financial implications to reputational damage. \n\n## Data Breaches\n\nWithout MFA, there's a higher risk of unauthorized access to your AWS console. This can potentially lead to severe **data breaches** where sensitive information may be accessed or stolen.\n\n## Financial Costs\n\nOnce unauthorized users gain access to the AWS console, they may launch instances/services that remain running and lead to unexpected **increases in your AWS bills**.\n\n## Reputational Damage\n\nData breaches can significantly harm your business's reputation, leading to decreased **customer trust** and tending towards long term financial losses. \n\n## Regulatory Non-Compliance\n\nAbsence of MFA could lead to **non-compliance with regulations** such as GDPR or HIPAA, which can result in financial penalties and sanctions.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a medium-size e-commerce company using AWS services to manage its business operations. Its systems may contain sensitive data like customer personal information, credit card details, and other important financial information. Unauthorized access to this information can lead to serious security breaches which can do irreversible damage both financially and in terms of customer trust.\n\nWith Multi-Factor Authentication (MFA), the company can further secure the access to their AWS environment. When a company’s system administrator or any other person with access to the AWS Console tries to sign in, they will not only need to provide their username and password, but also a unique code that they get from their physical or virtual MFA token.\n\nThis way, even if somebody gets hold of their username and password through any means, they won’t be able to access the console without also having access to the unique one-time use authentication code that's generated on the authorized user's MFA device. Thus, MFA provides a significantly higher level of security for the company's AWS account and its sensitive data.\n\nWe can demonstrate this in the following sample markup:\n\n```markdown\n# Enable Multi-Factor Authentication for Enhanced Security on AWS \n\nOur e-commerce company's operations rely heavily on AWS services. With the sensitive and crucial financial data we deal with, ensuring optimal security is our priority. \n\n## How do we do this? \n\nBy implementing **Multi-Factor Authentication (MFA)**.\n\n## How Does MFA Work?\n\nA user signs into the AWS console with their username and password. AWS then prompts them for an authentication code. But where does this code come from?\n\nThe code comes from an MFA device that the AWS account owner possesses. So for a security breach to happen, an unauthorized individual would need both the users' credentials *and* the physical MFA device. \n\nBy enabling MFA, we ensure that our AWS console is doubly protected and drastically reduce the chances of a security breach.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_11",
        "Title": "1.11 Do not setup access keys during initial user setup for all IAM users that have a console password",
        "Description": "AWS console defaults to no check boxes selected when creating a new IAM user. When creating the IAM User credentials you have to determine what type of access they require.",
        "QueryID": "aws_iam_user_access_keys_and_password_at_setup",
        "DocumentURI": "policies/aws_cis_v150_1_11.md",
        "ManualVerification": false,
        "Severity": "Low",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.11"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS, or Amazon Web Services, provides different controls for managing access to resources within its cloud environment. One of these controls is the Identity and Access Management (IAM) service, which allows administrators to create and manage AWS users and groups and use permissions to allow and deny their access to AWS resources.\n\nWhen creating a new IAM user through the AWS console, it defaults to no boxes selected. This is a security measure to prevent unintentionally granting excess permissions.\n\nHere is how you might describe this process in markup format:\n\n```markdown\n## Creating a New IAM User in AWS Console\n\n1. Sign in to the AWS Management Console.\n2. Navigate to the IAM Dashboard.\n3. Click on **Users** in the navigation pane.\n4. Click **Add User**.\n5. Provide a **User Name**.\n6. Under **Access Type**, you'll see two checkboxes:\n    - **Programmatic access** - Grants an Access Key ID and Secret Access Key for the AWS API, CLI, SDK, and other development tools.\n    - **AWS Management Console access** - Grants a password for signing in to the AWS Management Console.\n7. By default, these boxes are unchecked. Determine what type of access the user needs and check the appropriate box(es).\n8. Follow the remaining steps to set a password (if granting console access), set permissions, and create the user.\n```\n\nRemember, it is crucial to only grant the necessary permissions to each user as per the principle of least privilege to ensure the security of your resources."
            ],
            "x-kaytu-noncompliance-cost": [
                "If this AWS Control is not complied with, it can lead to the following costs:\n\n1. **Unauthorized access:** If access types are not carefully determined, it might lead to undesirable unauthorized access. This could potentially lead to data breaches or inappropriate manipulation of data which can cause irreparable damage to businesses.\n\n2. **Operational Failures:** Improperly granted access can lead to operational failures, as users might gain access to functions they are not trained for or supposed to interact with. This could potentially bring systems down or cause faulty operations.\n\n3. **Non-compliance penalties:** If the oversight leads to regulatory non-compliance (like GDPR, HIPPA, etc.), it can lead to hefty fines.\n\n4. **Damage to reputation:** Incidents related to unauthorized access or data breaches can cause significant damage to a company's trustworthiness, potentially leading to loss of clients or stakeholders.\n\n5. **Increased Costs:** The costs of remediating unauthorized access, system failures, or reputational damage can be significant. These might include investigation costs, system restoration, improved security measures, PR recovery initiatives, etc.\n\nTherefore, ensuring proper adherence to IAM user access control is crucial in mitigating such risks."
            ],
            "x-kaytu-usefulness-example": [
                "This particular feature of AWS is useful in many situations. One instance could be in a large organization with a significant number of employees, each having varying levels and types of access to AWS services based on their roles.\n\n**Scenario:**\n\nFor example, consider an organization that has hired a new Data Analyst. As a Data Analyst, the employee would need access to AWS services like S3 buckets for storage, Athena for running SQL queries, or Quicksight for visualization, but they shouldn't be given access to more sensitive services like IAM for user management or EC2 instances which are more related to DevOps activities.\n\n```markdown\nIn this case, the AWS Admin of the organization would:\n  \n1. Go to AWS IAM console.\n2. Click on \"Add user.\"\n3. Provide an appropriate \"User name.\"\n4. Under \"Access type,\" select \"Programmatic access\" or \"AWS Management Console access\" according to the need.\n5. Unclick any pre-selected checkboxes (with this feature, none would be pre-selected anyway).\n6. Then, in the \"Set permissions\" section, set the relevant permissions. For example, they might grant access to S3, Athena, and Quicksight, but not  to IAM or EC2 instances.\n7. Complete the process to create the new user.\n\n**Benefits:**\n\nWith the console defaulting to no checkboxes selected, this process is more secure because it reduces the risk of accidentally granting access to services the new user doesn't need for their role. It ensures that the admin only gives specific access to what the new employee requires, providing a \"least privilege\" model of security.\n```\nThis policy helps large organization to maintain a better AWS security posture by reducing the likelihood of unnecessary access privileges being granted during new user set up."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_20",
        "Title": "1.20 Ensure that IAM Access analyzer is enabled for all regions",
        "Description": "Enable IAM Access analyzer for IAM policies about all resources in each region. IAM Access Analyzer is a technology introduced at AWS reinvent 2019. After the Analyzer is enabled in IAM, scan results are displayed on the console showing the accessible resources. Scans show resources that other accounts and federated users can access, such as KMS keys and IAM roles. So the results allow you to determine if an unintended user is allowed, making it easier for administrators to monitor least privileges access. Access Analyzer analyzes only policies that are applied to resources in the same AWS Region.",
        "QueryID": "aws_iam_access_analyzer_enabled",
        "DocumentURI": "policies/aws_cis_v150_1_20.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.20"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "## AWS Control - Enable IAM Access Analyzer for IAM Policies\n\nAWS Identity and Access Management (IAM) Access Analyzer is a feature that helps you identify the resources in your organization and accounts, such as AWS KMS keys and IAM roles, that are shared with an entity outside of your account. This critical functionality assists in ensuring that you adhere to the security best practices of providing least privilege access to your AWS resources.\n\nWhen IAM Access Analyzer is enabled, it scans your existing IAM policies and provides detailed insights, all viewable on the AWS console. Essentially, it helps you identify which resources can be accessed by accounts outside of your own, including federated users.\n\nIn other words, IAM Access Analyzer enables a more thorough and streamlined monitoring of your AWS security setup and resource access.\n\n### Key Features\n\n- **Access Overview**: IAM Access Analyzer displays the resources which can be accessed by external accounts or federated users, providing an easy way to monitor and rectify any unauthorized or unintended access permissions. \n\n- **Regional Specific**: The Access Analyzer is only capable of analyzing those entity-based policies that are applied to resources in the same AWS region in which it is enabled. \n\n### Enabling IAM Access Analyzer\n\nFollow the steps below to enable IAM Access Analyzer:\n\n1. Open the IAM console, navigate to the Access Analyzer section.\n2. Click on 'Create Analyzer'.\n3. Choose the account or organization for the analyzer, and then select the region.\n4. Click 'Create'.\n\nRemember that you should enable this feature separately for each region in your AWS account to ensure all your AWS resources are analyzed effectively."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the IAM Access Analyzer control can pose significant risks and potential costs for an organization. Here are some of the main impacts:\n\n1. **Security Risks**: If you fail to enable IAM Access Analyzer, you might not be aware of the potential security vulnerabilities in your IAM policies. Potentially unintended users may have access to sensitive resources, which can lead to data leaks or misuse of your AWS services. This could expose your organization to both financial and reputational damage.\n\n2. **Regulatory Compliance**: Depending on your organization's industry and the data it handles, you might be subject to certain regulations or standards that require specific security controls to be in place. Non-compliance with these regulations can result in heavy fines and penalties.\n\n3. **Operational Efficiency**: Without the insights provided by IAM Access Analyzer, your IT and Security teams might need to spend additional resources and time manually auditing and reviewing IAM policies and access rights. This effort could be better spent on other important tasks.\n\n4. **Incident Response and Recovery Costs**: If a security incident occurs due to lack of awareness of access privileges, the cost of response and recovery can be high. This can include costs related to forensic investigations, system repairs, data recovery, and legal services.\n\n5. **Lost Business**: In case of a significant breach, customers may lose trust in the organization and switch to competitors, leading to a loss in revenue."
            ],
            "x-kaytu-usefulness-example": [
                "An example use-case for AWS IAM Access Analyzer can be an organization maintaining numerous AWS resources across different regions. Suppose a corporation has a complex IAM policy setup due to multiple different projects and teams working on various AWS resources. Monitoring these policies and permissions manually for each resource would be a daunting task. \n\nIn such scenarios, an accidental allowance or over-permission can pose a serious security risk. Therefore, using IAM Access Analyzer will help the corporation's AWS administrators to identify resources that are shared with external entities, thus enabling them to review these access permissions. \n\nSuppose AWS Access Analyzer identifies an S3 bucket that is shared with an external account. This bucket may contain sensitive information and the sharing was done unintentionally or without proper review. The AWS administrators can take immediate action to revoke the access and secure the data, effectively resolving serious security risk before any damage is done.\n\n```markdown\nExample Instance:\nCompany ABC has a substantial AWS environment that spans multiple regions. Due to the complexity and volume of their operations, manually monitoring each resource and IAM policy becomes highly challenging and time-consuming. The accidental allowance of external access to an S3 bucket containing sensitive customer data could have potentially catastrophic consequences.\n\nBy implementing AWS IAM Access Analyzer, ABC's AWS administrators were alerted to the configuration error. The S3 bucket was shared unintentionally with an external account due to a deployment error. Upon receiving the alert, the team was able to swiftly revoke access, securing the sensitive customer data and preventing any potential data breach.\n```\nThis example clearly demonstrates the importance and utility of AWS IAM Access Analyzer in maintaining secure and efficient operations in a complex AWS environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_12",
        "Title": "1.12 Ensure credentials unused for 45 days or greater are disabled",
        "Description": "AWS IAM users can access AWS resources using different types of credentials, such as passwords or access keys. It is recommended that all credentials that have been unused in 45 or greater days be deactivated or removed.",
        "QueryID": "aws_iam_user_unused_credentials_45",
        "DocumentURI": "policies/aws_cis_v150_1_12.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.12"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS Identity and Access Management (IAM) is a service offered by Amazon Web Services to manage access to its services and resources securely. IAM users are entities created in AWS to represent the people or services that use them. \n\n## IAM User Credentials\n\nDifferent types of credentials are used depending on how the user interacts with AWS:\n\n- *Passwords* are used to sign in to AWS Management Console.\n\n- *Access keys* consist of an access key ID and a secret access key, used to make programmatic calls to AWS through API, command line interface, or SDKs.\n\n## Unused Credentials\n\nCredentials that are not in use pose a potential security risk if they fall into the wrong hands, making your AWS account vulnerable to unauthorized access. \n\n## Remediation Steps \n\nTo mitigate any security risks, it is recommended to deactivate or remove unused credentials. According to AWS best practices, any credentials that have not been used for 45 or more days should be considered unused and therefore eligible for deactivation or removal.\n\n1. Open the IAM console.\n2. In the navigation pane, choose Users.\n3. Choose the name of the user whose access keys you want to deactivate, and then choose the `Security credentials` tab.\n4. Next to the access key that you want to deactivate, choose `Make inactive`.\n\nThis helps to keep your AWS environment secure by limiting the number of active credentials that can access resources, reducing the risk of unwanted access. It also helps in maintaining the efficiency of your systems by lessening the load of unused credentials. \n\nRemember, only activate the credentials when you need them, and always follow the principle of least privilege (PoLP). The more inactive or deactivated credentials, the better the security. \n\n---\nThis is not an official AWS documentation. Please refer to the official AWS website and documentation for authoritative information."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can result in significant negative implications. Here's what it could involve:\n\n1. **Increased Security Risks**: If old, unused credentials are not deactivated or removed, there may be an increased possibility of unauthorized access in case these credentials have been compromised unknowingly. This can potentially lead to breaches of sensitive data which could be costly, both financially and reputation-wise.\n\n2. **Audit Failures**: If your organization needs to comply with certain industry standards like SOC, ISO, or PCI, you may fail audits for not managing outdated credentials, which might result in penalties.\n\n3. **Operational Inefficiencies**: A large number of unused credentials makes it harder to manage IAM properly. This can lead to confusion, errors, and inefficiencies in access management.\n\n4. **Inconsistent Access Management**: Without a standard protocol for deactivating or removing old credentials, control over access to resources can become inconsistent, possibly leading to unauthorized changes.\n\n5. **Potential Financial Impact**: In the worst-case scenario, if these dormant accounts are used maliciously, you may find unexpected charges for resources or services used by these accounts.\n\nFor these reasons, it is essential to adequately manage AWS IAM users-access and regularly deactivate or remove credentials that have been unused for a substantial period."
            ],
            "x-kaytu-usefulness-example": [
                "For Instance:\nLet's assume we have a big tech company that uses AWS for all its cloud computing needs. This company has a large number of users who were given access keys and passwords to access different resources. This access is associated with various roles like admins, developers, and data analysts, etc. With time, some of these users don't engage with these resources anymore, perhaps because they have shifted roles, left the company, or simply due to the conclusion of the projects they were handling. \n\nThis unused access becomes a potential security risk, as it can be exploited to gain unauthorized access to the company's resources. By applying the AWS IAM controls to deactivate or remove credentials that have been inactive for 45 days or more, we significantly reduce the risk of unwarranted access. This ensures that only the relevant current users possess active credentials, enhancing the overall security of the company's AWS resources.\n\nThis method is not just beneficial in terms of security. It also helps in better managing resources and user access, as it provides a clear view of who actively uses which resources. It makes auditing easier and policy application more streamlined."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_21",
        "Title": "1.21 Ensure IAM users are managed centrally via identity federation or AWS Organizations for multi-account environments",
        "Description": "In multi-account environments, IAM user centralization facilitates greater user control. User access beyond the initial account is then provide via role assumption. Centralization of users can be accomplished through federation with an external identity provider or through the use of AWS Organizations.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v150_1_21.md",
        "ManualVerification": true,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.21"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control in Multi-Account Environments\n\nIAM (Identity and Access Management) user centralization is a key concept in AWS which allows for superior control over users in multi-account environments. This is achieved through role assumption, whereby user access beyond the initial account is given.\n\n## User Centralization\nUser centralization can be accomplished in two ways:\n\n1. **Federation with an External Identity Provider:** This involves creating a secure connection between your directory and AWS (also known as federation). It involves integrating an external identity provider, like Microsoft Active Directory or other SAML 2.0 provider, with AWS. This allows you to manage access to AWS resources across all your accounts centrally.\n\n2. **Use of AWS Organizations:** AWS Organizations helps centralize management of multiple AWS accounts. You can fully manage all of your accounts from a master account, allowing you to define granular control over the AWS services that can be accessed.\n\nThis model provides many benefits including simplified billing, improved security via centralized controls, and more.\n\nIn both cases, the IAM user's roles can be assumed to grant them certain access permissions across different AWS accounts.\n\n## Role Assumption\nUnder this model, a single IAM user can have its role assumed by another, receiving permissions assigned to the assumed role. This is particularly useful in scenarios where central AWS account manages access to resources that reside in other accounts. \n\nBy creating IAM roles that can be assumed by users in your account, you can provide the necessary access to resources across accounts, while at the same time maintain control and visibility into their activities.\n\nOverall, in a multi-account environment, centralizing IAM users and using role assumption facilitates greater access control, visibility, and ultimately, enhanced security."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with AWS Control about IAM user centralization in multi-account environments can result in several significant costs and these can be summed in up in several categories:\n\n1. **Security Costs:** Non-centralization of IAM users may lead to users being able to access services and data they shouldn't. This increases the potential for data leaks, unauthorized access or changes to critical systems, and overall diminished security posture. The cost of a security breach can be immense, in terms of fines, damaged reputation, loss customer trust, and even potential legal action.\n\n2. **Operational Costs:** Without centralization, managing users and their access individually across multiple accounts can be time-consuming and creates additional operational overhead. This can lead to inefficiency and increased administrative cost due to the complexity of managing multiple access levels across various accounts.\n\n3. **Compliance Costs:** If your organization is subject to regulatory compliance rules (such as GDPR, HIPAA, etc.), discrepancies in IAM user control across accounts can result in non-compliance. Non-compliance could lead to investigations, audits, penalties, and fines.\n\n4. **Maintenance Costs:** Decentralization can make it harder to maintain and manage user access policies, which can mean higher costs for routine maintenance. It can also make it more complicated to troubleshoot access issues, leading to increased support costs.\n\n5. **Risk Management Costs:** Consistent access management across multiple accounts can make risk assessment, mitigation, and management more complicated. If unauthorized access occurs, it may be more difficult to investigate, resulting in potential increased costs for risk management. \n\nTherefore, sticking to AWS Control's recommendations about IAM user centralization is crucial to avoid these costly implications."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider a companyXYZ that uses AWS across multiple departments - Marketing, HR, Sales, and Engineering. Each department has its own AWS account and services they use. Instead of creating IAM users in each of those accounts and managing them separately, companyXYZ decides to centralize IAM user management.\n\nThey decide to federate with an external identity provider (IdP), Google's G Suite. This means the IAM users are created and managed in Google's G Suite and are synced with AWS. This simplifies the user and access management for the company administrator - they no longer need to deal with user creation/deletion, password resets, and other related tasks in AWS.\n\nWhen a new employee joins companyXYZ, the admin simply creates a new user in G Suite. AWS will automatically recognize and authorize this new user, granting them the necessary permissions via role assumption. Role assumption allows the employees to have different roles when they shift between departments. For example, a Marketing employee has limited permissions compared to an Engineering employee.\n\nIn conclusion, by centralizing IAM users and using role assumption, companyXYZ can control user access more effectively and efficiently. It saves time and resources for managing IAM users across multiple AWS accounts while enhancing the security."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_10",
        "Title": "3.10 Ensure that Object-level logging for write events is enabled for S3 bucket",
        "Description": "S3 object-level API operations such as GetObject, DeleteObject, and PutObject are called data events. By default, CloudTrail trails don't log data events and so it is recommended to enable Object-level logging for S3 buckets.",
        "QueryID": "aws_cloudtrail_s3_object_write_events_audit_enabled",
        "DocumentURI": "policies/aws_cis_v150_3_10.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.10"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "AWS S3 object-level API operations refers to actions that are done on objects in your S3 bucket such as retrieving an object (GetObject), deleting an object (DeleteObject), or adding an object (PutObject). These operations are termed as data events in AWS terminology. \n\nBy default, AWS CloudTrail, a service that provides a record of actions taken by a user, a role, or an AWS service, doesn't log these data events, meaning that it doesn't keep a record of these operations. Thus, if you want to track the operations on each object in your S3 bucket for auditing, troubleshooting, or compliance purposes, you need to specifically enable object-level logging for your S3 buckets.\n\nThe explanation in the markup format is as follows:\n\n```markdown\nAWS `S3 object-level API operations` are the actions carried out on objects inside your S3 bucket such as `GetObject`, `DeleteObject`, or `PutObject`. These operations are referred to as `data events` in AWS. \n\nBy default, `AWS CloudTrail` does not log these data events, so it does not keep a record of these operations. Therefore, if you wish to monitor the operations performed on each object in your S3 bucket for audit, troubleshooting, or compliance purposes, you must explicitly enable `object-level logging` for your S3 buckets.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "# Cost of Non-Compliance to S3 object-level API operations Logging \n\nIf you do not comply with the AWS Control that recommends enabling Object-level logging for S3 buckets, the following can be the potential cost:\n\n1. **Loss of Traceability and Accountability:** Without logging these data events, you lose the ability to track who accessed, modified or deleted your data. This can lead to accountability issues in case of a data breach or unauthorized access.\n\n2. **Barrier to Auditing and Compliance:** In many industry sectors like healthcare, finance or govt. services, regulations require you to track and keep a record of all data access and modifications. Not having these logs can lead to regulatory non-compliance and potential penalties.\n\n3. **Difficulty in Troubleshooting:** Without the logs, tracing the root cause of a problem related to data becomes difficult. It will be challenging to identify whether an issue is due to a data change or because of some other component of your application.\n\n4. **Increased Security Risk:** Unlogged data events might allow potential security threats to go undetected. By tracking data events, you can spot anomalous behavior and take proactive steps to prevent potential cyber threats. \n\n5. **Lack of Insights for Performance Optimization:** Analyzing data event logs can provide useful insights regarding how frequently data is accessed/updated, allowing for performance optimizations like data caching. Not having these logs will lead to a loss of such optimization opportunities. \n\nIn conclusion, not enabling object-level logging for S3 buckets can lead to decreased accountability, increased security risks, potential non-compliance to auditing and difficulty in troubleshooting and performance optimization. So, it's recommended to comply with AWS control to avoid these costs."
            ],
            "x-kaytu-usefulness-example": [
                "Consider an organization that stores sensitive customer information in an S3 bucket. Recently, they detected some inconsistencies in their data and suspected unauthorized access or manipulation.\n\nBy enabling object-level logging for their S3 bucket, they would receive detailed logs for all data events like GetObject, DeleteObject, and PutObject. This means they can trace the activities on all their S3 objects. This will help them pin-point if there were any unauthorized actions on their S3 objects, who performed them and when.\n\nHere is an instance recorded in the logs: \n\n```\n{\n    \"eventVersion\": \"1.07\",\n    \"userIdentity\": {\n        \"type\": \"IAMUser\",\n        \"principalId\": \"EXAMPLE\",\n        \"arn\": \"arn:aws:iam::account-id:user/Alice\",\n        \"accountId\": \"account-id\",\n        \"accessKeyId\": \"EXAMPLE_KEY_ID\",\n    },\n    \"eventTime\": \"2019-10-17T17:05:27Z\",\n    \"eventSource\": \"s3.amazonaws.com\",\n    \"eventName\": \"GetObject\",\n    \"awsRegion\": \"us-east-1\",\n    \"sourceIPAddress\": \"sourceIPAddress\",\n    \"userAgent\": \"[aws-sdk-java/1.11.603 Linux/4.14.133-113.105.amzn2.x86_64 OpenJDK_64-Bit_Server_VM/25.222-b10 java/1.8.0_222 vendor/Oracle_Corporation]\",\n    \"requestParameters\": {\n        \"bucketName\": \"example-bucket\",\n        \"Host\": \"example-bucket.s3.us-east-1.amazonaws.com\",\n        \"key\": \"example-key\"\n    },\n    \"responseElements\": null,\n    \"additionalEventData\": {\n        \"x-amz-id-2\": \"EXAMPLE\"\n    },\n    \"eventID\": \"EXAMPLE\",\n    \"readOnly\": true,\n    \"resources\": [\n        {\n            \"type\": \"AWS::S3::Object\",\n            \"ARN\": \"arn:aws:s3:::example-bucket/example-key\"\n        },\n        {\n            \"accountId\": \"account-id\",\n            \"type\": \"AWS::S3::Bucket\",\n            \"ARN\": \"arn:aws:s3:::example-bucket\"\n        }\n    ],\n    \"eventType\": \"AwsApiCall\",\n    \"managementEvent\": false,\n    \"recipientAccountId\": \"account-id\"\n}\n```\n\nFrom this data, they can determine that the user `Alice` accessed (used GetObject operation) file `example-key` in S3 bucket `example-bucket` at the specific timestamp `2019-10-17T17:05:27Z` from the IP address `sourceIPAddress`. Such detailed logging would allow the organization to monitor and investigate data anomalies efficiently."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_13",
        "Title": "1.13 Ensure there is only one active access key available for any single IAM user",
        "Description": "Access keys are long-term credentials for an IAM user or the AWS account root user. You can use access keys to sign programmatic requests to the AWS CLI or AWS API (directly or using the AWS SDK).",
        "QueryID": "aws_iam_user_one_active_key",
        "DocumentURI": "policies/aws_cis_v150_1_13.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.13"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "Sure, here you go:\n\n# AWS Control - Access Keys\n\n**Access keys** are important components of AWS security. They are long-term credentials that help to authenticate users when they want to access and utilize AWS services.\n\n## IAM User Access Keys\n\nAccess keys for **IAM users** are similar to the username/password you use to log in to your AWS Management Console. They allow your applications to make requests to AWS programmatically, through the `AWS Command Line Interface (CLI)`, `AWS Query API`, and `AWS SDKs`.\n\n## AWS Account Root User Access Keys\n\nAccess keys for the **AWS account root user** give full access to all resources in the account. AWS recommends that we do not use the root user for daily interactions and we should not be shared.\n\n## Use of Access Keys\n\nAccess keys are for programmatic (i.e., code-level) access to AWS services. This means that you can use them to:\n\n- Sign requests that you make to AWS API to ensure they are secure.\n- Incorporate into code to authenticate with AWS Services using AWS SDKs.\n- Use with AWS CLI to securely interact with AWS services from command line.\n\n## Format\n\nEach access key consists of two parts:\n\n- Access key ID (e.g., `AKIAIOSFODNN7EXAMPLE`): This is used to identify the key when you need to use it.\n- Secret access key (e.g., `wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY`): This is a secret and should never be shared or transmitted in plaintext.\n\n## Security\n\nFor security:\n\n- We should not embed or hardcode Access Keys directly into our code.\n- We should use `IAM roles` for Amazon EC2 instances.\n- We should regularly rotate and replace keys.\n- We must be aware that anyone who has the Access Keys will have the same permissions as the IAM user or root user to whom the keys are associated."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS Control regarding access keys can be significant and multi-faceted. It can lead to unauthorized access, data breaches, service disruption and financial loss. Below are some of the potential costs:\n\n1. **Security breaches:** Improper management or usage of access keys can lead to sensitive data exposure. AWS access keys have significant privileges and can be exploited by malicious actors if not adequately secured. Such a security breach may cause reputation and credibility damage for the business.\n\n2. **Legal repercussions \u0026 penalties:** Data breaches that occur due to improperly secured access keys can lead to legal consequences and hefty penalties, particularly for businesses operating in highly regulated industries or dealing with sensitive data like healthcare or financial data.\n\n3. **Unwanted Resource Usage:** If access keys fall into the wrong hands, attackers can use them to spin up resources for their own use (e.g., for cryptocurrency mining), causing a significant increase in AWS costs.\n\n4. **Data Loss and Service Disruption:** In the event of a malicious attack, data could be destroyed, leading to permanent data loss. Or the attackers might disrupt the services, causing operational inefficiencies and downtimes, which hamper business continuity and customer trust.\n\n5. **Remediation Costs:** In case of a security incident due to misused access keys, businesses will need to spend valuable resources to investigate the incident, conduct a security audit, rectify the issue, and possibly construct additional security measures to prevent such incidents in the future.\n\nBy ensuring proper compliance with AWS Control, businesses can prevent these undesirable consequences. It's always advisable to frequently rotate access keys, never share them, avoid embedding them in unencrypted files or code, and use roles for giving permissions whenever possible."
            ],
            "x-kaytu-usefulness-example": [
                "```markdown\nExample Instance:\n\nImagine that you are a developer working on a new web application. The application collects user data and stores it into an AWS RDS instance. \n\nFor the web application to interact with the AWS RDS instance, you need a way to authenticate your application's access to AWS resources. This is where access keys come into play. An IAM user will be set up specifically for your application with access rights to the necessary AWS resources.\n\n1. First, you login to the AWS Management Console, navigate to IAM Dashboard and create a new IAM user. You assign a policy to the IAM user that authorically allows access to interact with your AWS RDS resources.\n\n2. Generating access keys for this IAM user, you obtain two pieces of data - an Access Key ID and a Secret Access Key. \n\n3. These access keys are then embedded into your application code (or securely stored in your application’s environment variables or configuration files for better security practices).\n\nWhen your web application needs to interact with your AWS RDS instance (e.g., to store data from the new user sign-ups), it sends a request to the AWS API. This request is signed with the IAM access keys. AWS validates these access keys and, if they are valid, allows the interaction with the AWS RDS instance to proceed. Without these access keys, AWS would deny your application's API requests.\n\nHence, the access keys serve as a crucial tool in ensuring the secure and authorized interaction of your application with AWS resources.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_3_11",
        "Title": "3.11 Ensure that Object-level logging for read events is enabled for S3 bucket",
        "Description": "S3 object-level API operations such as GetObject, DeleteObject, and PutObject are called data events. By default, CloudTrail trails don't log data events and so it is recommended to enable Object-level logging for S3 buckets.",
        "QueryID": "aws_cloudtrail_s3_object_read_events_audit_enabled",
        "DocumentURI": "policies/aws_cis_v150_3_11.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.11"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "AWS (Amazon Web Services) provides different types of controls for managing and logging its operations. One such control is Amazon S3 data events or object-level logging. S3 data events refer to the API operations performed at the object-level in an Amazon S3 bucket, which include:\n\n- `GetObject`: Retrieves objects stored in Amazon S3.\n- `DeleteObject`: Deletes a single object in an Amazon S3 bucket.\n- `PutObject`: Adds an object to a bucket.\n\nIn AWS CloudTrail, by default, these data events are not logged. CloudTrail is a feature offered by AWS that helps track user activity and API usage. The events it tracks include management events such as creating and modifying S3 buckets.\n\nHowever, if you want more granular visibility into the operations within an S3 bucket such as read or write requests, you can enable object-level logging. It will allow you to monitor and identify individual actions in your S3 bucket, providing an added level of security and auditing capability.\n\nThis could be useful in scenarios where you need to:\n\n- Track access to sensitive documents stored in S3 buckets.\n- Auditing purposes, where a record of all operations is required.\n- Diagnosing problems related to specific operations on objects in S3. \n\nIt's worth noting that enabling object-level logging might incur additional charges, as CloudTrail charges a fee for logging data events.\n\nHere's an example of how it can be configured in markup (JSON) format for a bucket policy:\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EnableObjectLevelLogging\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"cloudtrail.amazonaws.com\"\n      },\n      \"Action\": \"s3:GetBucketAcl\",\n      \"Resource\": \"arn:aws:s3:::myBucket\"\n    },\n    {\n      \"Sid\": \"EnableObjectLevelLogging\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"cloudtrail.amazonaws.com\"\n      },\n      \"Action\": \"s3:PutObject\",\n      \"Resource\": \"arn:aws:s3:::myBucket/prefix/AWSLogs/Your-aws-account-id/*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"s3:x-amz-acl\": \"bucket-owner-full-control\"\n        }\n      }\n    }\n  ]\n}\n```\nIn this example, replace `myBucket`, `prefix`, and `Your-aws-account-id` with your own bucket name, prefix, and AWS Account ID. This bucket policy will enable object-level logging to the specified bucket."
            ],
            "x-kaytu-noncompliance-cost": [
                "## Cost of Non-Compliance\n\nIf S3 object-level API data events are not logged, there could be several consequences that might end up incurring costs:\n\n- **Loss of Auditability:** Logging data events are essential for audit purposes. It keeps track of who accessed which data and when. This becomes critical in forensic investigation in the event of a data breach. If logging is not enabled, there is no way to track who accessed the data. The cost of a data breach could be huge, including the potential financial loss, loss in customer trust and consequences of non-compliance to data protection regulations.\n\n- **Non-Compliance to Regulations:** Depending on the industry and nature of data stored, various regulations make it mandatory to log access to certain data. For instance, GDPR, HIPAA, and other similar regulations require that any access to sensitive information must be logged. Non-Compliance to these regulations could cause penalties which can be as high as 4% of global turnover or 20 million Euros, whichever is higher for GDPR, for example.\n\n- **Limited Operational Visibility:** Without logging, you have limited visibility into S3 bucket operations which hampers operational monitoring, troubleshooting, and security incident response. \n\n- **Difficulty in Detecting Unusual Activities:** Logging is also useful for detecting any unusual activity in the bucket. If there’s a sudden increase in 'GET' requests, it could mean someone is trying to download all the data. Without logging, early detection of such activities can be difficult.\n\nIn conclusion, not enabling object-level logging could increase the total cost of operation by exposing the organization to breaches, penalties from non-compliance to regulations, and operational inefficiencies."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a healthcare research organization uses AWS S3 buckets to store sensitive patient data for data analysis. Due to the sensitive nature of the data, the organization needs to track who is accessing, modifying, or deleting data from the S3 buckets. \n\nHence, the organization enables object-level logging for their S3 buckets. This setup allows them to audit GetObject, PutObject, and DeleteObject operations, getting detailed information about each API call, including the IP address from which requests came, the identities of the requestors, and the time of each request. \n\nThus, if any unauthorized operation is carried out such as deletion or modification of data, the organization can track it back to the source and take appropriate action swiftly. So, in this case, enabling S3 object level logging increases the security of their sensitive data."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_10",
        "Title": "4.10 Ensure a log metric filter and alarm exist for security group changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. Security Groups are a stateful packet filter that controls ingress and egress traffic within a VPC. It is recommended that a metric filter and alarm be established for detecting changes to Security Groups.",
        "QueryID": "aws_log_metric_filter_security_group",
        "DocumentURI": "policies/aws_cis_v150_4_10.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.10"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "# Real-time Monitoring of API Calls\nAmazon Web Services (AWS) provides users with the ability to monitor their API calls in real-time. This is achieved using CloudTrail Logs and CloudWatch Logs. \n\n## **CloudTrail Logs**\nCloudTrail is a service that records AWS API calls and delivers log files. These records provide detailed information about the request, including who made the request, the services used, the actions performed, parameters for the actions, and the response elements returned by the AWS service.\n\n## **CloudWatch Logs**\nCloudWatch Logs can consume these CloudTrail logs and provide a platform for real-time monitoring. Users can create metric filters to search for and match terms, phrases or values in your log events.\n\n# **Security Groups**\nSecurity Groups act as a virtual firewall for your instance to control incoming and outgoing traffic. They are stateful - if you send a request from your instance, the response traffic for that request is allowed to flow in regardless of inbound security group rules.\n\n# **Alerts for Security Group Changes**\nDue to their critical role in managing network traffic, monitoring changes to Security Groups can help identify potential security risks or misconfigurations. Users can create a metric filter and alarm in CloudWatch for changes made to security groups. The alarm will trigger whenever the specified event (like changes to a security group) occurs, informing the user of the change and allowing them to react accordingly.\n\n```markup\n{\n    \"source\": [\n        \"aws.ec2\"\n      ],\n    \"detail-type\": [\n        \"AWS API Call via CloudTrail\"\n      ],\n    \"detail\": {\n          \"eventSource\": [\n              \"ec2.amazonaws.com\"\n            ],\n          \"eventName\": [\n              \"AuthorizeSecurityGroupIngress\",\n              \"RevokeSecurityGroupIngress\",\n              \"AuthorizeSecurityGroupEgress\",\n              \"RevokeSecurityGroupEgress\"\n            ]\n      }\n}\n```\nThe above CloudWatch Logs syntax will monitor for changes to AWS Security Group settings."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the mentioned AWS control can lead to several potential costs. \n\n1. **Security Costs**: Not having a real-time monitoring system for API calls can result in unauthorized access, causing security breaches. Similarly, without a metric filter and alarm for Security Groups changes, unauthorized changes to Security Groups may cause potential security risks without detection.\n\n2. **Financial Costs**: These security breaches can lead to financial losses if hackers access private data and use it for malicious activities.\n\n3. **Operational Efficiency Costs**: Failure to continuously monitor API calls or changes in Security Groups might also lead to unnoticed performance issues or faults, leading to downtime and loss of operational efficiency.\n\n4. **Reputation Costs**: If the data breach is severe, it might lead to damage in your company's reputation. This could also lead to loss of customers and might require significant resources to recover.\n\n5. **Regulatory Compliance Costs**: Many industries are regulated and require businesses to maintain certain security standards, including logging and monitoring data access. Non-compliance to these regulations can result in hefty fines. \n\nIn summary, non-compliance to the AWS control could incur significant potential costs in security, operational efficiency, reputation, regulatory penalties, and financially. It is always recommended to adhere to these controls and safeguard the resources and reputation of your organization."
            ],
            "x-kaytu-usefulness-example": [
                "An example of this AWS Control could be:\n\nYour company has a critical production environment in AWS with various security measures in place - including security groups that control traffic to your EC2 instances. These Security Groups are adjusted according to business needs and any changes should be monitored and alerted on to minimize risks.\n\nWithout monitoring, a malicious or unintentionally harmful alteration might lead to a security breach or a disruption in application services. Therefore, to keep your infrastructure secure, you implement real-time monitoring of API calls for changes to Security Groups.\n\nYou configure AWS CloudTrail to capture all API calls with a trail that logs data to an S3 bucket. Furthermore, you also direct these CloudTrail logs to Amazon CloudWatch Logs. Then, you establish a CloudWatch metric filter that matches patterns for Security Group modification events - such as `AuthorizeSecurityGroupIngress`, `RevokeSecurityGroupEgress`, etc. \n\nFinally you create a CloudWatch alarm that triggers an SNS (Simple Notification Service) topic when the metric filter captures an event. This will send immediate notifications to the appropriate personnel in your team, alerting them of changes to Security Groups that may need to be reviewed. \n\nThis AWS control helps maintain the security integrity of your AWS environment by providing real-time monitoring and alerting of changes to critical security components."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_14",
        "Title": "1.14 Ensure access keys are rotated every 90 days or less",
        "Description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated.",
        "QueryID": "aws_iam_user_access_key_age_90",
        "DocumentURI": "policies/aws_cis_v150_1_14.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.14"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Access Keys\n\nAWS `access keys` are comprised of `two main elements: Access key ID and secret access key` which are employed to authenticate programmatic requests made to AWS.\n\n## Use cases\n\nAccess keys are required by AWS users to make calls programmatically to AWS in different ways:\n\n1. **AWS Command Line Interface (CLI)**: A tool by AWS to manage your AWS services and resources.\n2. **Tools for Windows PowerShell**: It is a task automation and configuration management framework from Microsoft, consisting of a command-line shell and the associated scripting language.\n3. **AWS SDKs (Software Development Kits)**: A collection of software tools and libraries that are used to create applications for specific platforms.\n4. **Direct HTTP calls using APIs for individual AWS Services**: Sometimes, you may need to interact with AWS services using API calls.\n\n## Security Measure\n\nFor sustained security, it's `advised that all access keys are regularly rotated` - changing them periodically as an added security measure. This helps reduce the likelihood of an access key that is used unintentionally or maliciously."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS Control can result in several risks and potential costs, such as:\n\n1. **Security breaches**: If access keys are not regularly rotated, they become more vulnerable to theft or misuse. A malicious actor could potentially gain access to your AWS resources and data.\n\n2. **Financial loss**: With the stolen keys, an attacker can perform activities that result in additional charges on your AWS bill.\n\n3. **Data loss or corruption**: An attacker with access to your keys could also damage or delete important data, which can be a significant cost if that data is not recoverable. \n\n4. **Regulatory violations**: Depending on your jurisdiction and industry, allowing security breaches due to poor key rotation policies can result in fines or other regulatory penalties.\n\n5. **Loss of reputation**: Finally, a security breach caused by non-compliance can compromise your company's image, potentially leading to loss of business.\n\nIn markup format:\n\n* **Security breaches**: If access keys are not regularly rotated, they become more vulnerable to theft or misuse.\n* **Financial loss**: With the stolen keys, an attacker can perform activities that result in additional charges on your AWS bill.\n* **Data loss or corruption**: An attacker with access to your keys could also damage or delete important data.\n* **Regulatory violations**: Non-compliance can result in fines or other penalties.\n* **Loss of reputation**: A security breach caused by non-compliance can compromise your company's image, potentially leading to loss of business."
            ],
            "x-kaytu-usefulness-example": [
                "For example, let's say an organization has developed a web application hosted on an AWS EC2 instance. They wish to make it possible for the app to programmatically interact with the data stored in a specific S3 bucket. The application uses the AWS SDK for Python (Boto3) to connect and perform actions like list, create or delete buckets.\n\nIn order to authorize these requests, the use of access keys is required. These keys consist of an access key ID and secret access key, which are affiliated with a specific IAM user. The keys are set in the environment variables of AWS CLI or in a configuration file, and they are used to authenticate the calls made from the SDK to AWS services.\n\nFor security reason, if these keys are lost, leaked, or believed to be compromised, they should be replaced with a new set. That's why it is also recommended to regularly rotate these keys to minimize potential security risks, even if there is no obvious threat. \n\nThis is an exemplary instance that shows how useful access keys are when a secured programmatic interaction with AWS services is needed."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_11",
        "Title": "4.11 Ensure a log metric filter and alarm exist for changes to Network Access Control Lists (NACL)",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. NACLs are used as a stateless packet filter to control ingress and egress traffic for subnets within a VPC. It is recommended that a metric filter and alarm be established for changes made to NACLs.",
        "QueryID": "aws_log_metric_filter_network_acl",
        "DocumentURI": "policies/aws_cis_v150_4_11.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.11"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "The `AWS` control explained here involves several services - `CloudTrail`, `CloudWatch`, `NACLs` (Network Access Control Lists) and `VPC` (Virtual Private Cloud).\n\n`CloudTrail` logs record all API calls made within the AWS environment, including who made the call, when it was made, and other details. These logs can be directed to `CloudWatch Logs`, a service which facilitates the real-time monitoring of log data.\n\nOnce these logs are in `CloudWatch Logs`, you can establish metric filters and alarms. A metric filter extracts data from the incoming logs and converts it into a numerical format, which can be graphed or alerted upon. Alarms can be set up to send notifications or automatically make changes to the resources you're monitoring when a certain threshold is breached.\n\n`NACLs` are an optional layer of security for the subnets within your `VPC`, allowing or denying traffic to them based on the source or destination IP address, port, or protocol. They are stateless, meaning that they evaluate each incoming or outgoing packet individually, without taking into account any previous traffic.\n\nIt is recommended to establish a metric filter and alarm for changes made to `NACLs`, as it is crucial to be aware and informed in real-time about any modifications to the security rules. These changes could impact the network's security or functionality. \n\nThis `AWS` control helps to maintain a robust monitoring and alerting system for potential security risks and operational issues in the environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS Control mentioned above can lead to several costs - both monetary and non-monetary. \n\n**1. Security Risks:** If API calls are not monitored in real-time and NACL changes are not alarmed, it could potentially create security vulnerabilities. Unauthorized changes to API or NACL configuration can lead to data breaches, which can cost the company, both monetarily and reputation-wise.\n\n**2. Regulatory Penalties:** Many industries, like Healthcare, Financial Services, etc., are required to follow certain regulations that call for constant monitoring and alerting of access controls. The absence of such controls can lead to regulatory penalties.\n\n**3. Increased Operational Cost:** With the absence of real-time monitoring and alerts, IT teams may experience higher operational overhead with the requirement to manually monitor and investigate potential issues.\n\n**4. Loss of Business Continuity:** Unauthorized or malicious changes to API configurations could impact business services and processes leading to potential revenue loss.\n\n**5. System Downtime:** If some harmful API calls are made which are not detected on time. System outage could cost money and potential loss of customers.\n\nHence, it is highly crucial to establish metric filters and alarms for changes made to NACLs and ensure real-time monitoring of API calls by directing CloudTrail Logs to CloudWatch Logs."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nA company has a highly secure AWS environment where they store sensitive customer data. It is crucial for them to monitor every activity, especially changes to their Network Access Control Lists (NACLs) that control traffic to their environment.\n\nThey establish a metric filter and alarm for NACL changes by utilizing CloudTrail, CloudWatch Logs, and APIs. By monitoring API calls in real-time, they are instantly alerted if unexpected modifications occur.\n\nIn a specific scenario, an unauthorized user gains access to the console and makes changes to the NACLs to extract data from the company's VPC. As this change in NACL is captured by CloudTrail logs, the information is passed on to CloudWatch Logs. The previously set metric filter detects this change and triggers an alarm, instantly notifying the security team. The security team can then quickly resolve the security breach, minimizing potential damage and data loss.\n\nBy using real-time monitoring of API calls through CloudTrail Logs and CloudWatch Logs, the company can take immediate action when threats like unauthorized changes to NACLs arise. This mechanism provides a robust and proactive defense mechanism, increasing the overall security of the AWS environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_15",
        "Title": "1.15 Ensure IAM Users Receive Permissions Only Through Groups",
        "Description": "IAM users are granted access to services, functions, and data through IAM policies. There are three ways to define policies for a user: 1) Edit the user policy directly, aka an inline, or user, policy; 2) attach a policy directly to a user; 3) add the user to an IAM group that has an attached policy. Only the third implementation is recommended.",
        "QueryID": "aws_iam_user_no_inline_attached_policies",
        "DocumentURI": "policies/aws_cis_v150_1_15.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.15"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "Sure. \n\nAWS Identity and Access Management (IAM) is a service that lets you control permissions for different users by managing access to AWS services and resources. This control is managed through IAM policies attached to the users. \n\nThere are three ways to assign policies to a user:\n\n1. **Inline, or user policies:** This approach involves editing the user policy directly. Inline policies are JSON or XML documents that define permissions for a user. These policies are created in the IAM console and are directly attached to a single IAM user. \n\n```markdown\nExample Code:\n\n```json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"s3:ListBucket\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:s3:::example_bucket\"\n        }\n    ]\n}\n```\n```\n  \n2. **Attach a policy directly to a user:** In this approach, predefined policies can be attached directly to a user. The policies are not embedded within the user, but instead hold a relationship with the user. This way, the same policy can be attached to multiple users.\n\n```markdown\nExample Code:\n\n```bash\naws iam attach-user-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess --user-name exampleuser\n```\n```\n\n3. **Add the user to an IAM group with an attached policy:** This is the recommended approach. Here, instead of attaching policies to each user, you categorize users into IAM groups and attach the policies to those groups. This method eases administration, especially for a large number of users.\n\n```markdown\nExample Code:\n\n```bash\naws iam add-user-to-group --group-name examplegroup --user-name exampleuser\n```\n```\n\nRemember, it’s recommended to use the IAM group to manage policies for users rather than inline or direct user policies. This approach is easier to manage and scales well as the number of users increases."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can result in multiple costs ranging from financial losses to reputational damage. The detailed implications are as follows:\n\n1. **Unmanaged User Access:** If individual or inline policies are utilized, tracking user permissions becomes challenging which could potentially lead to unauthorized access. This unauthorized access could compromise the data stored within AWS resources, leading to data breaches.\n\n2. **Increased Overhead:** Managing permissions at an individual level increases the administrative overhead due to the constant need to monitor and update individual policies. This could lead to ramping up of operational costs.\n\n3. **Compliance Issues:** It could lead to non-compliance with regulatory standards and internal security policies, which can eventually lead to penalties or fines imposed by regulatory bodies as well as lower trust from customers and partners.\n\n4. **Security Risks:** By not following a central policy management approach, you increase your security risks by making it difficult to keep track of who has what access. This could potentially pave the way for internal and external security threats, causing financial and reputational harm.\n\nHence, it is suggested to utilize an IAM group for granting access wherever possible, it helps in easier management, improved security and ensures better compliance."
            ],
            "x-kaytu-usefulness-example": [
                "Consider a scenario where a company, named ABC Corp., uses AWS for their cloud computing and storage needs. They have an expanding team, with new members who require different levels of access to different services based on their roles. For example, data analysts need to access S3 buckets while developers need to access EC2 instances.\n\nTo manage these effectively, they use AWS Identity and Access Management (IAM). They create IAM groups each corresponding to a specific role like 'Data_Analysts' and 'Developers' and attach specific policies to these groups. For instance, the 'S3_Full_Access' policy is attached to 'Data_Analysts' group and 'EC2_Full_Access' is attached to 'Developers' group.\n\nWhen a new data analyst, Katie, joins ABC Corp., rather than creating an inline policy or attaching an individual policy to Katie, they just add her to the 'Data_Analysts' IAM group. This procedure has several benefits:\n\n1) It reduces manual work. They don't have to configure access for each user individually.\n2) If changes are needed, they don't have to edit each user’s policy, instead, they change the group’s policy and it applies to all users in the group.\n3) If a user changes role within the organization, they simply remove the user from the previous IAM and add to the new one reflecting their role.\n\nHence, the third implementation of IAM policies via IAM groups is the most effective and scalable, particularly for larger organizations. It provides convenience and promotes better access control management."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_12",
        "Title": "4.12 Ensure a log metric filter and alarm exist for changes to network gateways",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. Network gateways are required to send/receive traffic to a destination outside of a VPC. It is recommended that a metric filter and alarm be established for changes to network gateways.",
        "QueryID": "aws_log_metric_filter_network_gateway",
        "DocumentURI": "policies/aws_cis_v150_4_12.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.12"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "Unfortunately, I can't provide an explanation in markup format. However, here's a plain English explanation:\n\nThe control mentioned in the question talks about two essential aspects:\n\n1. **Real-time monitoring of API calls:** \n\nAPI calls made within your AWS environment can be logged through AWS CloudTrail, a web service that records AWS API calls for your account and delivers log files to you. These logs can then be directed to AWS CloudWatch, which is a monitoring and management service. In CloudWatch, you can set up metric filters and alarms that can help you react in real-time to changes in your AWS resources. \n\nFor example, you can set a metric to monitor the number of times a particular API is called and if it crosses a certain threshold, an alarm can be triggered, notifying you of potentially anomalous behaviour.\n\n2. **Establishing metrics and alarms for changes to network gateways:**\n\nA network gateway in AWS is a component that enables communication between your VPC (Virtual Private Cloud) and a network outside of the VPC (such as the internet or another AWS service). Changes to this could pose a significant security risk, therefore, it's recommended to set up metric filters and alarms in CloudWatch for these changes too. If an unexpected change occurs, such as a new gateway being established or an existing one being changed, the alarm will notify you immediately so appropriate action can be taken.\n  \nPlease note, this interpretation is more focused on interpreting AWS services and how they are used in API monitoring and network security rather than focusing on markup languages such as HTML or XML. If you meant something else by \"markup format\", please provide more information for a clearer explanation."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS Control could lead to several risks and potential costs for a business. \n\n1. **Security Risk:** Without real-time monitoring of API calls, the company might not be able to detect suspicious or malicious behavior. Changes to network gateways without proper alerts could possibly indicate unauthorized access or changes in the system, leading to potential data breaches.\n\n2. **Operational Risk:** Undetected changes in API calls or network gateways could lead to operational issues like system downtime, disruptions in data flow, or even complete service outage. \n\n3. **Compliance Violations:** If the company is subject to certain regulatory standards (such as HIPAA, SOX, or GDPR), failure to monitor and control changes could lead to non-compliance, resulting in hefty fines and penalties.\n\n4. **Reputation Damage:** Any security breach or service outage can seriously harm the company reputation, leading to loss of customer trust and potentially causing a decline in business. \n\n5. **Financial Impact:** All of the above risks could have direct and indirect implications on the financial health of the company-- from cleaning up post data breaches, restoring services, paying non-compliance fines, to losing business due to damaged reputation.\n\nImplementing real-time monitoring and alerts, therefore, not only satisfies this AWS Control but also mitigates these potential risks, making it an essential part of secure and efficient system operations."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company, XYZ Corp, has a complex network setup on AWS with multiple VPCs and network gateways across different regions and environments (production, development, etc). They have several teams making changes to these configurations daily and they need to keep track of these changes to maintain their security posture and troubleshooting issues.\n\nBy directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms, they can have real-time monitoring of changes made to their network gateways. \n\nFor example, suppose an unauthorized change is made to their network gateway which results in a security risk. The metric filter they've set up triggers an alarm as it detects the change made in the configuration. This type of setup can also be useful for catching unexpected changes that can potentially disrupt their services.\n\nUsing this setup, XYZ Corp will be immediately alerted of the changes and they can take prompt actions to review, and if necessary, revert these changes. This helps them to reinforce their network security and maintain the integrity of their AWS environment. \n\nWithout this metric filter and alarm setup, XYZ Corp would potentially have to manually sift through logs, which is not only tedious but also may result in delayed or missed detection of critical changes."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_13",
        "Title": "4.13 Ensure a log metric filter and alarm exist for route table changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. Routing tables are used to route network traffic between subnets and to network gateways. It is recommended that a metric filter and alarm be established for changes to route tables.",
        "QueryID": "aws_log_metric_filter_route_table",
        "DocumentURI": "policies/aws_cis_v150_4_13.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.13"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS Control, also known as AWS Identity and Access Management (IAM), is a service that allows you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.\n\nThe paragraph you've shared details two specific controls within AWS.\n\n1. **CloudTrail \u0026 CloudWatch:** This segment of the passage speaks to monitoring API calls in real time. This is done by sending CloudTrail Logs (which track user activity and API usage) to CloudWatch Logs (a monitoring service that allows you to collect and analyze logs). Here, by creating metric filters and alarms, users can be alerted when certain parameters are met or breached.\n\n2. **Routing Tables:** The second part of the passage discusses the use of routing tables, which direct traffic between subnets and network gateways. Subnets, short for subnetworks, are a way of dividing an IP network, while network gateways provide access to another network. The passage suggests setting up a metric filter and alarm for changes to route tables. This can be useful in tracking any unplanned or potentially malicious changes in traffic flow.\n\nIn summary, the passage recommends employing active monitoring and alert systems to both API usage and network traffic direction in order to ensure the secure and smooth operation of AWS services.\n\nIn markup format:\n\n```\n1. **CloudTrail \u0026 CloudWatch:**\n   * Monitor API calls in real time by sending [CloudTrail Logs](https://aws.amazon.com/cloudtrail/) to [CloudWatch Logs](https://aws.amazon.com/cloudwatch/).\n   * Create metric filters and alarms to be alerted when certain parameters are met or breached.\n\n2. **Routing Tables:**\n   * Use routing tables to direct traffic between subnets and network gateways.\n   * Set up a metric filter and alarm for changes to route tables to track any unplanned or potentially malicious changes in traffic flow.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this mentioned AWS control has several potential costs to your organization:\n\n1. **Security Risks**: Not monitoring API calls in real-time can lead to undetected unauthorized access, data loss, or malicious actions carried out on your AWS resources. If unauthorized changes are made to your route tables, it could lead to unauthorized routing of network traffic, potentially exposing your resources to unwanted audiences.\n\n2. **Operational Risks**: Changes to route tables can affect how traffic is routed within your network. Unmonitored, these changes could lead to downtime or slow response times by directing traffic inefficiently, or worse, routing to an incorrect destination. \n\n3. **Compliance Risks**: For organizations subject to industry regulations, failure to monitor essential actions might be a violation of compliance obligations. It could result in heavy fines and reparative actions, besides damaging your company's reputation. \n\n4. **Financial Costs**: Operational inefficiencies, downtime, regulatory penalties, and potential security breaches all bring significant financial costs which could be significantly greater than the cost of implementing the recommended controls. \n\nTo summarise, the cost of non-compliance will include potential security and operational risks, possible violation of regulatory compliances, and potential significant financial loss. Hence, it's strongly recommended to adhere to AWS controls which involve real-time monitoring of API calls and establishing a metric filter and alarms for changes to route tables."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company XYZ Corp. has a complex AWS environment, and they're managing a significant number of EC2 instances, VPCs, and several route tables. These route tables are controlling the traffic flow in their network infrastructure.\n\nSometime, due to accidental changes or unwanted intrusion, a route table can get modified leading to significant problems such as disrupted network communication, misdirected traffic, or potentially expose of secure servers to the public internet. \n\nConsequently, XYZ Corp. can take advantage of AWS CloudTrail and CloudWatch Logs service to set up real-time monitoring on API calls for changes in route tables. Every change made to the route tables, such as adding, deleting, or modifying routes, will trigger log events captured by CloudTrail, which will then get directed to CloudWatch Logs. \n\nWith appropriate metric filters set on these logs, XYZ Corp. can filter out the log events specifically associated with Route Table changes. They can then set alarms on these metric filter, so that every time a route table changes, an alarm is triggered indicating an unexpected modification has occurred. This alarm could very well be the difference between catching an unauthorized change in the early stages, thereby preventing any negative consequences, and letting it go unnoticed, which could potentially cause significant damage to XYZ Corp’s AWS environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_16",
        "Title": "1.16 Ensure IAM policies that allow full \"*:*\" administrative privileges are not attached",
        "Description": "IAM policies are the means by which privileges are granted to users, groups, or roles. It is recommended and considered a standard security advice to grant least privilege -that is, granting only the permissions required to perform a task. Determine what users need to do and then craft policies for them that let the users perform only those tasks, instead of allowing full administrative privileges.",
        "QueryID": "aws_iam_policy_all_attached_no_star_star",
        "DocumentURI": "policies/aws_cis_v150_1_16.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.16"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS IAM Policies: Granting Least Privilege \n\nAWS Identity and Access Management (IAM) policies provide a powerful mechanism to grant privileges to users, roles, and groups. Following the principle of least privilege, it is strongly recommended to only grant the minimum permissions necessary to complete specific tasks. This provides a general safeguard against potential abuse or unauthorized access.\n\n## Understanding Least Privilege\n\nWhen granting privileges, the principle of least privilege suggests that only the minimal permissions necessary should be granted. Full administrative privileges may unnecessarily expose areas of your AWS environment to potential risks or security breaches.\n\n## Practical Application\n\nTo effectively utilize IAM policies with the principle of least privilege, you should first identify what tasks a user or group needs to perform. Based on these tasks, you construct specific policies that grant only the necessary access. \n\nFor example, if a user needs to manage EC2 instances, you create a policy that grants access to EC2 services instead of granting full administrative access to all AWS services.\n\n## Benefits\n\nBy applying the principle of least privilege, the potential attack surface exposed to malicious threats is greatly reduced. It can also minimize the risk of unintended changes or actions within your environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the AWS control that recommends granting least privilege can result in the following potential costs:\n\n1. Increased Security Risk: Unnecessarily elevated privileges can lead to security breaches if these credentials are compromised. This increases the likelihood of unauthorized access to sensitive data and systems, data breaches, and other potential security incidents.\n\n2. Compliance Failure: Non-compliance can lead to failure in meeting regulatory requirements and national/international security standards, which could result in penalties, fines, and legal actions against the organization. This also risks loss of customer trust.\n\n3. Increased Operational Costs: If an incident occurs due to non-compliance with the principle of least privilege, the costs of resolving the problem (including incident response, data recovery, system repair, and communication with stakeholders) can be substantial.\n\n4. Business Continuity Impact: Any potential downtime or disruption caused by a security breach can affect business operations, potentially leading to loss of revenue and additional recovery costs.\n\nIn summary, non-compliance to the IAM policies control could potentially lead to financial losses, reputational damage, operational disruptions, and regulatory penalties.\n"
            ],
            "x-kaytu-usefulness-example": [
                "For example, suppose you have an AWS infrastructure wherein you have a team of developers in your organization who need to access your EC2 instances for application deployment and troubleshooting, but they should not be able to terminate the instances. This can be achieved using IAM policies.\n\nFirstly, you can create a user group called \"Developers\" in IAM. Once the group has been created, you would attach policies to this group that allow the necessary privileges. A policy can be created with access to EC2 instances that allows all EC2 actions like start, stop, and reboot but does not include the terminate action. Once the policy is created, it can be attached to the \"Developers\" group. In this way, developers would have the necessary access to do their tasks but avoid any unwanted instance termination.\n\nHere is a snippet of AWS policy in markup JSON format that denies EC2 terminate action:\n\n```json\n{\n   \"Version\": \"2012-10-17\",\n   \"Statement\":[\n      {\n         \"Effect\": \"Deny\",\n         \"Action\": \"ec2:TerminateInstances\",\n         \"Resource\": \"*\"\n      }\n   ]\n}\n```\n\nThis kind of fine-grained access control ensures that users perform only the tasks they need to, preventing potential accidents or misuse of resources."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_17",
        "Title": "1.17 Ensure a support role has been created to manage incidents with AWS Support",
        "Description": "AWS provides a support center that can be used for incident notification and response, as well as technical support and customer services. Create an IAM Role to allow authorized users to manage incidents with AWS Support.",
        "QueryID": "aws_iam_support_role",
        "DocumentURI": "policies/aws_cis_v150_1_17.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.17"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "## AWS Support Center\n\nThe AWS Support Center is a platform provided by Amazon Web Services that allows users to manage incidents, technical support, and customer services. It's an all-inclusive hub where you can create and manage your support cases, and communicate with AWS Support.\n\nTo effectively manage incidents within the AWS Support Center, specific permissions to the necessary users should be granted. This can be accomplished by creating IAM roles.\n\n## Identity Access Management (IAM) Role\n\nIdentity Access Management (IAM) is a feature of your AWS account offered at no additional charge. You can create and manage AWS users and groups and use permissions to allow and deny their access to AWS resources.\n\nCreating an IAM Role for AWS Support Center allows you to grant other people or AWS services permissions to manage incidents without having to share your AWS security credentials. \n\n```markdown\n## Steps to create an IAM Role:\n1. Open the IAM console.\n2. In the navigation pane, choose **Roles**.\n3. Choose **Create Role**.\n4. Choose **AWS service**, and then choose **Support**.\n5. Choose the use case for your role and select **Permissions**.\n   * Here, you can choose the existing policies that AWS has created for Support Center.\n6. Add tags (optional), review the role and create the role.\n   * You can give the role any name and description.\n7. Provide the role ARN to the AWS Support Center, and the users who would use the credentials in their AWS CLI, AWS SDK, and API calls will be able to manage incidents with AWS Support.\n\n**Note:** The user should only give these permissions to the users who can be trusted because giving this access might allow them to manage incidents which could alter the AWS resources. Always follow the principle of least privilege.\n```\nRemember, the user who is associated with this IAM role should have enough permissions and rights to handle such cases in AWS Support Center."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can have several costs and consequences:\n\n1. **Risk of Unresolved Incidents**: If users are not authorized properly through IAM roles, there could be delays or obstacles in resolving incidents, leading to extended outages or system downtime. This could in turn cause a loss in business and damage customer trust.\n\n2. **Security Issues**: Without proper authorization, it's hard to track who has access to sensitive data and control over critical systems. This can pose a severe risk to the security and integrity of data and systems.\n\n3. **Operational Inefficiencies**: IAM roles help in implementing least privilege access – where individuals are given only the permissions they need to perform their tasks. Without specific roles, users could be over-privileged, leading to misconfigurations or mistakes that can cause system issues, leading to waste in labor and potential costs to fix the issues.\n\n4. **Potential Regulatory Fines**: If you are in an industry that's subject to regulations like GDPR, HIPAA, or others that require certain security controls around identity and access to systems, non-compliance with these controls could result in hefty regulatory fines.\n\n5. **Damage to Reputation**: If lack of appropriate access controls leads to a security incident or data breach, this could damage the reputation of the organization, resulting in loss of business and trust.\n\nIn summary, the cost of non-compliance could be significant in terms of business continuity, data security, regulatory fines, and reputation, so ensuring that IAM roles are properly configured to give authorized users access to manage incidents with AWS support is crucial to managing a secure and efficient AWS environment."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider a technology company named \"TechVerto\". They have multiple tech teams who handle and maintain different services deployed on AWS. The company uses AWS Support for technical assistance, incident notifications, and response. \n\nHowever, not everyone in TechVerto is allowed to interact with AWS Support due to security protocols in place. Only team leads and the DevOps team have the permission to interact with AWS Support and manage incident responses. \n\nTo accomplish this, TechVerto uses an IAM role that is specifically designed to provide these privileges. An IAM role is created and named \"AWS Support Manager\". This role is configured to allow interaction with AWS Support including opening and managing support tickets. \n\nThis role is then assigned to the respective team leads and DevOps team members via their IAM User Accounts. Each user, when required, can then assume this role to interact with AWS Support and handle incidents. This setup provides TechVerto with the ability to efficiently manage their support process while maintaining a high level of security as not everyone has access to critical incident information."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_14",
        "Title": "4.14 Ensure a log metric filter and alarm exist for VPC changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is possible to have more than 1 VPC within an account, in addition it is also possible to create a peer connection between 2 VPCs enabling network traffic to route between VPCs. It is recommended that a metric filter and alarm be established for changes made to VPCs.",
        "QueryID": "aws_log_metric_filter_vpc",
        "DocumentURI": "policies/aws_cis_v150_4_14.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.14"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "The AWS control explained here outlines a process for real-time surveillance of API calls, communication between VPCs, and tracking of changes made to VPCs. This is achieved through applying AWS CloudTrail, CloudWatch Logs, and setting up specific metric filters and alarms.\n\nHere is the same principle explained using Markup Language format:\n\n```markdown\n- **AWS CloudTrail and CloudWatch Logs** are used for **real-time monitoring of API calls**. \n\n- **CloudTrail Logs** are directed to **CloudWatch Logs**, where corresponding **metric filters and alarms** are set up for identified API patterns and anomalies. \n\n- An AWS account can hold **more than one Virtual Private Cloud (VPC)**, and it is possible to establish a **peer connection between two VPCs**. This allows for routing of network traffic between the two VPCs. \n\n- It is recommendable to **set up a metric filter and alarm specifically for tracking changes in VPCs**. This allows the user to promptly respond to any unexpected changes or potentially malicious activities.\n```\nIt's crucial to set alerts and monitors on these services to maintain the integrity and security of your AWS infrastructure. Any changes to your VPCs could potentially expose your systems to significant risk, hence why it's essential to keep track of these changes."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the said AWS Control mainly centers around the potential security risks and unexpected costs.\n\n1. **Security Risks:** Not monitoring API calls in real-time can potentially lead to undetected security breaches. Attackers might exploit your APIs to gain unauthorized entry or carry out malicious activities within your AWS environment. Without real-time monitoring and alert systems, these breaches may go unnoticed until they have caused significant damage.\n\n    Moreover, changes made to Virtual Private Clouds (VPCs) can also pose security threats. Without a metric filter and alarm for changes applied to VPCs, alterations that pose security vulnerabilities might not be identified promptly. For instance, if a VPC peering connection is made without compliance to the security procedures, it could expose your network to threats.\n\n2. **Unexpected Costs:** Both unauthorized API usage and unsanctioned changes to VPCs can result in unexpected costs. For example, if an attacker uses your APIs excessively or if services are unnecessarily running due to changes in VPC settings, it will lead to a spike in your AWS costs. Without alerts, these cost anomalies could get overlooked.\n\n    Also, in case of a security breach, the costs for incident response, investigations, and remediations can also be considerable.\n\nIn addition, non-compliance with this control might also violate certain regulatory compliance standards that your enterprise is obliged to maintain, which might result in hefty penalties.\n\nTherefore, it is crucial to carry out real-time monitoring of API calls and set up metric filters and alarms for changes applied to VPCs. These steps will aid in identifying potential security threats and preventing unnecessary costs."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company is running a complex multi-tier web application in AWS. The application is hosted across several Virtual Private Clouds (VPCs) to ensure secure and scalable operation of different components like web servers, application servers, and databases in isolated networks. \n\nThey have set up a peer connection between the VPCs to enable seamless network communication. This setup is pretty dynamic, and changes are often made to the VPCs, such as modifying their security groups, adding or removing subnets, changing route tables, etc. Such changes, if not properly monitored and controlled, can have significant impacts on the application's availability, security, and performance. \n\nTo manage this, they have directed CloudTrail logs to CloudWatch logs with a setup for real-time monitoring of API calls associated with the changes made to VPCs. They have created a metric filter and corresponding alarm that triggers notifications when there are changes like a new subnet added or a security group modified. \n\nThis setup is advantageous because in the event of an unintended change or malicious activity, the alerted team can quickly investigate and remediate potential issues. For example, if there's an alert about unusual changes in a Security Group that expose the servers to the internet. A swift response can close the hole before it can be exploited, avoiding potential security breaches. \n\nThus, having a metric filter and alarm for changes made to VPCs in CloudWatch, greatly boosts their ability to maintain the integrity, security, and performance of their web application on AWS."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_15",
        "Title": "4.15 Ensure a log metric filter and alarm exists for AWS Organizations changes",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for AWS Organizations changes made in the master AWS Account.",
        "QueryID": "aws_log_metric_filter_organization",
        "DocumentURI": "policies/aws_cis_v150_4_15.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.15"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "## AWS Control - Real-time Monitoring of API calls\n\nAmazon Web Services (AWS) provides various tools for real-time monitoring of API calls, giving you in-depth understanding and greater visibility into your AWS accounts.\n\nOne way to achieve real-time monitoring is by directing CloudTrail logs to CloudWatch logs.\n\n#### AWS CloudTrail:\nAWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. It provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command-line tools, and other AWS services.\n\n#### AWS CloudWatch:\nAWS CloudWatch provides you with data and actionable insights to monitor your applications, respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health.\n\nBy using a combination of both, you can monitor and track your API usage in real time.\n\n### Steps:\n\n1. **Direct CloudTrail Logs to CloudWatch Logs:** Firstly configure CloudTrail to send event logs to CloudWatch logs. These event logs contain details about every API call made in your AWS account.\n\n2. **Establish Metric filters:** After directing logs to CloudWatch, you can set up metric filters in CloudWatch. Metric filters define the terms for which CloudWatch searches the log data, and turns that data into a numeric metric that you can graph or put an alarm on.\n\n3. **Establish alarms:** Finally establish alarms in CloudWatch. Alarms automatically initiate actions on your behalf, based on criteria that you specify. For example, if the number of instances in any Availability Zone differs by a specified amount from the other Availability Zones in the region, CloudWatch can send notifications or automatically change system status.\n\nIt is recommended that a metric filter and alarm be established specifically for AWS Organizations changes made in the master AWS Account. This helps in tracking any changes made at the organizational level and can help prevent unwanted actions being performed unknowingly.\n\nBy implementing this AWS control, you can achieve real-time monitoring of API calls, track changes, and secure your AWS environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the suggested AWS Control may result in several potential costs:\n\n1. **Security Risk**: AWS API calls could possibly include sensitive operations (e.g., modifying security group, creating/deleting users, changing user permission) which are crucial to monitor in real time. If any unintended or malicious activity happens, early detection and fast response can mitigate potential harm. Without real-time monitoring, these activities could go unnoticed, increasing security risks to your AWS resources and data.\n\n2. **Loss of Visibility and Traceability**: Without proper monitoring, organizations lose visibility over their operations in the AWS environment. When an issue arises, tracing back the actions that led to it can be difficult, if not impossible, without appropriate logging and monitoring.\n\n3. **Compliance Violations**: Many industry standards and regulations require companies to have a certain level of security monitoring. Not complying with this AWS control can lead to violations of such standards, potentially resulting in hefty fines and detrimental effects on the company's reputation.\n\n4. **Increased Operational Costs**: When a security breach occurs, the cost of handling it can be high – that includes the cost of downtime, investigating what happened, recovery costs, and any resulting fines or lawsuits. Regular monitoring and alarming can prevent many of these incidents or at least minimize their impact, thereby saving the associated costs.\n\n```markdown\nOverall, non-compliance costs can include:\n\n- Increased security risks.\n- Potential compliance violation fines.\n- Increased operational costs from security breaches.\n- Loss of visibility and traceability in your AWS environment.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "Using the real-time monitoring of API calls, we can establish an auditing and regulatory compliance for our organization. For example, in a scenario where we have a multi-account AWS environment managed centrally via AWS Organizations, it is important to monitor any changes made, especially in the master AWS Account. This could include creating, deleting or modifying an AWS account, enabling or disabling a service control policy, making changes to organizational units, etc.\n\nThis is how it'd work:\n\n```\n# 1. Enable CloudTrail to Log Events:\nAWS CloudTrail allows you to monitor the API calls in your AWS environment, capturing detailed information about each API call.\n\n# 2. Direct CloudTrail Logs to CloudWatch Logs:\nOnce CloudTrail is enabled, direct the logs to AWS CloudWatch Logs. This allows you to monitor, store and access your log files from Amazon EC2 instances, AWS CloudTrail, and other sources.\n\n# 3. Establish CloudWatch Metric Filters and Alarms:\nOn these directed logs, establish metric filters and alarms on CloudWatch for any API calls that change, create or delete items in AWS Organizations.\n\nHere is an example in AWS CLI:\n\n```bash\naws cloudwatch put-metric-filter --region us-west-1 --filter-name AWSOrganizations-Changes --log-group-name CloudTrail/DefaultLogGroup --filter-pattern '{ ($.eventName = CreateAccount) || ($.eventName = InviteAccountToOrganization) || ($.eventName = RemoveAccountFromOrganization) || ($.eventName = DeleteOrganizationalUnit) || ($.eventName = DetachPolicy) || ($.eventName = DisableAWSServiceAccess) || ($.eventName = DisablePolicyType) || ($.eventName = EnableAWSServiceAccess) || ($.eventName = EnablePolicyType) }'\n```\n\nOnce a metric filter is set, you can create an alarm to alert when a certain threshold is crossed.\n\n```\nThis real-time monitoring and alerting mechanism can help detect unauthorized or accidental changes, ensuring the overall security and governance of your AWS environment. It also simplifies the task of compliance with industry or internal regulatory policies."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_18",
        "Title": "1.18 Ensure IAM instance roles are used for AWS resource access from instances",
        "Description": "AWS access from within AWS instances can be done by either encoding AWS keys into AWS API calls or by assigning the instance to a role which has an appropriate permissions policy for the required access. \"AWS Access\" means accessing the APIs of AWS in order to access AWS resources or manage AWS account resources.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v150_1_18.md",
        "ManualVerification": true,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.18"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "When you work with AWS services, there are two general ways for your AWS instances (like EC2 instances), to interact or communicate with other AWS services:\n\n1. **AWS Keys**: You can include AWS keys in your API calls. These keys - also known as Access Key ID and Secret Access Key - are like a username and password that allows your AWS instance to interact with other AWS services. This is not recommended as it can lead to security risks if compromised.\n\n2. **Roles**: AWS also allows assigning roles to AWS instances. A role does not have standard long-term credentials (password or access keys) associated with it. Instead, it uses temporary security tokens that AWS Security Token Service (STS) provides. A role includes a set of permissions that determine what the identity (user, application, or service) can and cannot do in AWS. It provides a secured way to grant permissions to your AWS service without sharing Access Key ID and Secret Access Key.\n\n\"AWS Access\" refers to the ability to use AWS APIs to interact with AWS resources or manage resources in your AWS account. This interaction could be anything from launching an EC2 instance, reading a file from an S3 bucket, or making changes to your AWS account settings. These operations require certain permissions, which is governed by AWS Identity and Access Management (IAM) policies. If an AWS service doesn't have required permissions, it cannot interact with other services or resources."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this control can lead to several financial, securicial, and reputational costs:\n\n1. **Security Breach Costs**: If AWS access isn't securely managed according to these principles, it could lead to unauthorized access to your AWS resources. This can result in the theft, damage, or unauthorized modification of data, which can lead to considerable financial loss.\n\n2. **Non-Compliance Penalties**: Depending on the specific industry or jurisdiction that your business operates in, not following appropriate access management principles for cloud resources could violate regulations or laws, resulting in fines or penalties.\n\n3. **Operational Downtime**: In the event of a security breach or mishandling of access keys, you may have to halt operations to do damage control, fix the issue, or investigate the breach. This operational downtime can be costly.\n\n4. **Reputational Damage**: If your AWS resources are breached due to poor access control, it could result in significant reputational damage, impacting your relationships with customers and partners, and potentially resulting in lost business.\n\n5. **Remediation Costs**: If your AWS access management is found to be deficient, you may need to invest in remediation, including identifying and implementing more secure management practices, potentially hiring consultants or more experienced personnel, and conducting thorough testing and audits.\n\n6. **Increased Audit Costs**: Failure to comply with this control could lead to more frequent and intrusive audits, which can be costly both in terms of time and money.\n\nTherefore, it's important to adhere to secure AWS access principles, such as encoding AWS keys into API calls and assigning instances to roles with appropriate permission policies. This not only enhances security but also avoids non-compliance costs."
            ],
            "x-kaytu-usefulness-example": [
                "An example worth considering would be deploying a web application in an AWS environment. This web application might require read and write access to an Amazon DynamoDB table. Without role-based access control, you would have to hard-code the AWS access keys into the application code, risking potential security issues. \n\nHowever, with the AWS role-based system, you wouldn't have to explicitly provide your AWS credentials within the instances to make requests to other AWS services. Instead, you would create an IAM role with the necessary permissions to access the DynamoDB table, and then you can assign this role to the EC2 instance running the web application. This provides a more secure and scalable method of managing AWS access within the AWS instances. \n\nHere's a break down in markup format:\n\n```\n1. Create an IAM Role:\n  a. Navigate to IAM console on AWS.\n  b. Choose 'Roles' and then 'Create role'.\n  c. Select 'AWS service' as the type of trusted entity and 'EC2' as the service that will use this role. Proceed with 'Next: Permissions'.\n  d. In permissions, choose the policy that grants required permissions to the DynamoDB table. Proceed with 'Next: Tags'.\n  e. You can optionally add tags. Proceed with 'Next: Review'.\n  f. Name the role appropriately and describe its purpose. Confirm creation with 'Create role'.\n\n2. Assign the Role to an EC2 Instance:\n  a. Navigate to EC2 dashboard.\n  b. Choose 'Instances' and select the instance that will run the web application.\n  c. Under 'Actions', navigate to 'Security' then 'Modify IAM role'.\n  d. Select the role that was just created from the drop-down menu. Save changes with 'Apply'.\n```\nNow, the web application can securely access the necessary DynamoDB resources without embedding AWS keys directly in the code."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_1_19",
        "Title": "1.19 Ensure that all the expired SSL/TLS certificates stored in AWS IAM are removed",
        "Description": "To enable HTTPS connections to your website or application in AWS, you need an SSL/TLS server certificate. You can use ACM or IAM to store and deploy server certificates. Use IAM as a certificate manager only when you must support HTTPS connections in a region that is not supported by ACM. IAM securely encrypts your private keys and stores the encrypted version in IAM SSL certificate storage. IAM supports deploying server certificates in all regions, but you must obtain your certificate from an external provider for use with AWS. You cannot upload an ACM certificate to IAM. Additionally, you cannot manage your certificates from the IAM Console.",
        "QueryID": "aws_iam_server_certificate_not_expired",
        "DocumentURI": "policies/aws_cis_v150_1_19.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.19"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "```markdown\n# AWS Control - HTTPS Connections and SSL/TLS Server Certificates \n\nTo enable HTTPS connections in AWS, you need to use an SSL/TLS server certificate. AWS offers two services to help you store and deploy these certificates - AWS Certificate Manager (ACM) and Identity and Access Management (IAM).\n\n## AWS Certificate Manager\n\nThis is the recommended service for most users. However, it's important to note that ACM is not supported in all regions.\n\n## Identity and Access Management (IAM)\n\nIAM is an alternative to ACM that allows you to deploy server certificates in all regions. You would primarily use it when you need to support HTTPS connections in a region that doesn't support ACM.\n\n### Key Features of IAM\n\n1. **Secure Encryption:** IAM securely encrypts your private keys and then stores the encrypted version in the IAM SSL certificate storage.\n\n2. **External Provider Compatibility:** Unlike ACM, IAM requires that you obtain your certificate from an external provider in order to use it with AWS.\n\n### Limitations of IAM\n\n1. **Cannot Upload ACM Certificates:** You can't upload an ACM certificate to IAM.\n\n2. **No Console Management:** You can't manage your certificates from the IAM Console.\n\n\nTo summarize, while both IAM and ACM have their benefits, the choice between the two will depend on your specific needs and the regions you need to support.\n\nRemember, always consider security and the impact on your workflow in your decision-making process.\n```\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the specified AWS control can lead to the following costs/disadvantages:\n\n1. **Security Risks**: Non-compliance can increase the risk of data breaches and other security threats. Without a SSL/TLS server certificate, your data isn't encrypted when transmitted between your site/app and users. Hackers could potentially intercept this data and misuse it for illegal activities.\n\n2. **Lack of Trust**: Websites without HTTPS are marked as 'not secure' by most browsers, which can deter users from visiting your site. This could lead to reduced traffic and lower client trust in your application or website. \n\n3. **Compliance Violations**: If your organization must adhere to certain regulations that require data to be transmitted securely (like HIPAA or PCI DSS), then non-compliance may lead to violations and penalties.\n\n4. **Loss of Business Reputation**: A data breach or non-compliance issue can significantly harm your business' reputation, leading to decreased customer confidence. Recovering from such a setback can be very costly and time consuming.\n\n5. **Potential Fines**: Non-compliance could also lead to fines from regulatory bodies or lawsuits from affected stakeholders. In some industries, these costs can be significant.\n\n6. **Reduced SEO Ranking**: Search engines like Google prioritize secure (HTTPS enabled) websites in their rankings. Without HTTPS, your site's SEO ranking could drop, resulting in fewer visitor traffic and potential business loss.\n\nIn summary, the cost of non-compliance would be a mixture of potential financial penalties, loss of reputation, and security vulnerabilities, all of which could significantly impact both the operational and financial aspects of a business."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nLet's suppose you're running a web application on AWS in a region that doesn't have ACM (AWS Certificate Manager) support, say for example 'ap-northeast-3' (Osaka) or 'af-south-1' (Africa).  This region might be critical for providing low latency responses to your clients or users who are predominantly based in and around this geographical location. The web application processes sensitive information like user personal data that requires secure HTTPS connections.\n\nIn this context, the IAM service can be used as a certificate manager to enable HTTPS connections. You would first request a server certificate from a third-party provider, acquire the private key, public key and certificate chain from the acquired certificate, then you upload and store them in the IAM SSL certificate storage. AWS IAM would handle the encryption of the private key and securely store the certificate for deployment on Elastic Load Balancing or Amazon CloudFront.\n\nEven though managing certificate directly through IAM is not as friendly as with ACM, this process enables you to secure your web application's data transmission in an AWS region that doesn't provide ACM support; hence ensuring data privacy and integrity for your users."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_4_16",
        "Title": "4.16 Ensure AWS Security Hub is enabled",
        "Description": "Security Hub collects security data from across AWS accounts, services, and supported third-party partner products and helps you analyze your security trends and identify the highest priority security issues. When you enable Security Hub, it begins to consume, aggregate, organize, and prioritize findings from AWS services that you have enabled, such as Amazon GuardDuty, Amazon Inspector, and Amazon Macie. You can also enable integrations with AWS partner security products.",
        "QueryID": "aws_securityhub_enabled",
        "DocumentURI": "policies/aws_cis_v150_4_16.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.16"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/SecurityHub"
            ],
            "x-kaytu-explanation": [
                "# AWS Security Hub\n\nAWS Security Hub is an excellent security service that aggregates, analyzes and prioritizes security findings from across various AWS accounts, services, and even approved third-party partner products. \n\n## Features\n\n### Aggregated View\n\nUsing AWS Security Hub, you can get a comprehensive view of your high-priority security alerts and security status across various AWS accounts. \n\n### High Priority Alerts\n\nAWS Security Hub can help you identify the most crucial issues first by organizing and categorizing findings based on their priority.\n\n### Automated Security Checks\n\nOnce enabled, it automatically runs continuous, account-level configuration and compliance scans, including compliance standards checks.\n\n### Data Analysis\n\nSecurity Hub collects and analyzes findings from various services such as Amazon GuardDuty, Amazon Inspector, Amazon Macie, and others, for a thorough and detailed understanding of the security position.\n\n### Integrations\n\nIt integrates with several AWS partner security products, providing a more robust and replete security analysis. \n\n## Working\n\nTo leverage AWS Security Hub, you need to enable it first. Post-enabling, it will start consuming, aggregating, organizing, and prioritizing findings from the enabled AWS services like Amazon GuardDuty, Amazon Inspector, and Amazon Macie amongst others. You can also enable integrations with AWS partner security products to extend its capabilities."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS Security Hub service primarily comes with significant risks and costs to an organization. \n\n1. **Increased Security Risks**: AWS Security Hub is designed to provide a comprehensive view of your high-priority security alerts and compliance status across AWS accounts. By not complying with this control, you run the risk of missing critical security threats which could lead to data breaches, unauthorized access to sensitive data, or damage to your company's reputation.\n\n2. **Increased Operational Costs**: Security Hub simplifies security management and reduces the effort of managing individual service-level security notifications. Without it, you might have to spend more time and resources manually analyzing and consolidating data from different services.\n\n3. **Non-compliance penalties**: If your organization falls under regulations such as GDPR, HIPAA, or PCI-DSS, not complying with this control could lead to failing to meet your regulatory compliance requirements. This could result in hefty fines and penalties. \n\n4. **Delayed Incident Response**: Swift incident response is crucial in mitigating security threats. Without the consolidated view provided by Security Hub, there could be delays in detecting and responding to security incidents which can potentially increase damage.\n\n5. **Impeded Decision Making**: The prioritized view of your security alerts can allow quicker decisions to be made based on the most critical threats. Non-compliance could impede this quick decision-making, possibly leading to security vulnerabilities being addressed slower.\n\nTo avoid these costs, maintaining compliance with AWS Security Hub is recommended. It offers centralized security incident data, prioritized threats, quick visibility of compliance status, and facilitates faster incident response."
            ],
            "x-kaytu-usefulness-example": [
                "```\nAWS Control: AWS Security Hub\n\nExample Instance of Usefulness:\n\nA retail company with a significant online presence is using multiple AWS services and third-party security tools to manage their infrastructure. As their online service grows, the number of security events and alerts are increasing proportionally, and it is becoming quite challenging for their security team to manually go through all these alerts.\n\nIn this scenario, AWS Security Hub would come to their rescue. Once enabled, the Security Hub would start aggregating and prioritizing security findings from across their AWS services like GuardDuty, Inspector, and Macie, as well as from any third-party security tools they are using.\n\nNow, with the help of AWS Security Hub, the company's security team gets a centralized and comprehensive view of their security alerts. With a few clicks, they can identify security trends, pinpoint high-priority security issues, and quickly respond to them before they become significant threats to their infrastructure.\n\nIn addition to reducing the burden on their security team, AWS Security Hub also provides insights and helps them improve their overall security posture, thus increasing their confidence in the safety and security of their online services.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_1_1",
        "Title": "2.1.1 Ensure all S3 buckets employ encryption-at-rest",
        "Description": "Amazon S3 provides a variety of no, or low, cost encryption options to protect data at rest.",
        "QueryID": "aws_s3_bucket_default_encryption_enabled",
        "DocumentURI": "policies/aws_cis_v150_2_1_1.md",
        "ManualVerification": false,
        "Severity": "Low",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.1"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "# AWS Control - Amazon S3 Encryption\n\n**Amazon S3** is a scalable object storage service provided by AWS. It allows users to store and retrieve data of any amount and at any time. One of its key features is offering encryption for data at rest, enhancing security and reducing risks associated with unauthorized access.\n\n## The Variety of No, or Low, Cost Encryption Options\n\nAmazon S3 provides several encryption options to help you protect your data at a reasonable cost. These encryption options are integrated into the service, and they're either low cost or free, providing affordability while maintaining security.\n\n1. **S3 Managed Keys (SSE-S3)**: Each object is encrypted with a unique key. As an additional safeguard, it encrypts the key itself with a master key that it regularly rotates.\n\n2. **AWS Key Management Service (SSE-KMS)**: This provides you with an additional layer of security over SSE-S3 by giving you control over the cryptographic keys.\n\n3. **Server-Side Encryption with Customer-Provided Keys (SSE-C)**: You can decide to manage the encryption keys yourself. With SSE-C, Amazon S3 handles the encryption and decryption of the data while maintaining the security and durability characteristics of SSE-S3.\n\n4. **Client-Side Encryption**: Alternatively, you can encrypt data client-side and upload the encrypted data to Amazon S3. Managing encryption and keys on client side provides you with the highest level of control.\n\nIn summary, Amazon S3 offers a variety of no, or low, cost encryption options for users to safeguard their data. With these options, businesses can achieve security and compliance objectives, without breaking the bank.\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control can have financial, legal, and reputational implications.\n\n1. **Data Breach Costs**: If your data is not encrypted and a data breach occurs, your organization will lose sensitive data which can be exploited by cybercriminals. This can include costs associated with fighting and recovering from the breach, potential ransom payments, and the cost of preventative measures to avoid future breaches.\n\n2. **Regulatory Fines**: Regulatory bodies like the GDPR, HIPAA, or CCPA have strict rules around data protection. If your data is found to be unprotected due to non-compliance with encryption controls, your organization may be subject to heavy fines.\n\n3. **Reputation Damage**: Data breaches due to non-compliance can harm your brand's reputation, resulting in loss of customers or negative impacts on your market position. This can lead to loss of revenue, business opportunities and require investment in PR and damage control efforts.\n\n4. **Loss of Trust**: If customer data is compromised due to non-encryption, it can lead to loss of trust, making it harder to retain existing customers or attract new ones.\n\n5. **Legal Costs**: Non-compliance can result in lawsuits from clients whose data has been breached. This will include legal fees as well the cost of any potential settlements or penalties. \n\nTherefore, it's crucial to comply with the controls provided by Amazon S3 to ensure data is encrypted at rest, as the costs of non-compliance can be significant."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nA company named XYZ Corp stores sensitive customer data such as home addresses, financial information, health records, etc. in their Amazon S3 buckets. To ensure that this data is secure and maintain customer trust, they use Amazon S3's encryption options to protect this data at rest. Not only does this provide them with strong security measures, but due to S3's low cost encryption options, they're also able to save on costs related to data protection. \n\nFurthermore, in the event of an audit or compliance check, XYZ Corp can demonstrate that they have taken robust measures to secure their customer data, thereby complying with industry standards and regulations such as GDPR or HIPAA."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_2_1",
        "Title": "2.2.1 Ensure EBS Volume Encryption is Enabled in all Regions",
        "Description": "Elastic Compute Cloud (EC2) supports encryption at rest when using the Elastic Block Store (EBS) service. While disabled by default, forcing encryption at EBS volume creation is supported.",
        "QueryID": "aws_ebs_volume_encryption_at_rest_enabled",
        "DocumentURI": "policies/aws_cis_v150_2_2_1.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.2.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.2"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/EBS"
            ],
            "x-kaytu-explanation": [
                "The Elastic Compute Cloud (EC2) is a service provided by Amazon Web Services (AWS) that offers scalable computing capacity in the cloud. One of its features is Elastic Block Store (EBS), a block storage system used to store persistent data.\n\nEncrypting EBS volumes is a crucial security practice. It helps prevent unauthorized access to the information stored in the volumes. By default, EBS volumes created in EC2 are not encrypted.\n\nHere is the AWS control in markup format:\n\n```\n# AWS Control - EC2 Encryption at Rest\n\n**AWS Service:** Elastic Compute Cloud (EC2)\n\n**Control Description:** EC2 supports encryption at rest when using the Elastic Block Store (EBS) service. This control ensures that the data stored in EBS is safe and secure, avoiding unauthorized access.\n\n**Enabled/Disabled by Default:** This control is disabled by default. AWS does not automatically encrypt data in EBS during volume creation.\n\n**Enable Encryption at EBS Volume Creation:** When creating an EBS volume, you have the option to enable encryption. Enforcing encryption during volume creation ensures that all data stored on the volume is encrypted at rest.\n\n- To enforce encryption at volume creation, use the [AWS Management Console](https://aws.amazon.com/console/), the [AWS Command-Line Interface (CLI)](https://aws.amazon.com/cli/), or the [AWS SDKs](https://aws.amazon.com/tools/)\n- When encryption is enabled, all I/O operations from/to the volume are encrypted, as are all snapshots created from the volume.\n\n**Benefits of Encryption at Rest:** Prevent unauthorized access to information, comply with regulatory requirements, and ensure data privacy and security.\n```\nPlease note that specifics of how to enable the encryption could vary slightly based on the actual AWS interface and updates. Always refer to the current AWS documentation for the most accurate information."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS control that supports encryption at rest when using the Elastic Block Store (EBS) service can have multiple costly impacts, including:\n\n1. **Data Breach Costs**: If data is breached and it had not been encrypted, the sensitive information could be accessed by unauthorized parties. This could result in hefty fines from regulatory authorities, potential lawsuits from customers, and more.\n\n2. **Regulatory Fines**: Many industry standards and government regulations (like GDPR, HIPAA, PCI DSS) require data encryption. Non-compliance to these can result in heavy penalties and fines.\n\n3. **Reputational Damage**: A data breach and failure to comply with required data protection standards like encryption can lead to loss of client trust, which can indirectly cause significant financial losses.\n\n4. **Loss of Intellectual Property**: If sensitive business information or intellectual property is stored on these EBS volumes, non-compliance could lead to loss of that data, potentially giving competitors an advantage.\n\n5. **Potential downtime**: In event of a breach, services may need to be taken down for audit, investigation or cleanup, resulting in operation losses.\n\nThus, the cost of non-compliance to the AWS EC2 EBS volume encryption is not just about paying fines or penalties, but the overall impact on the business, including potential revenue losses, ripple effect on customer trust and the company's image."
            ],
            "x-kaytu-usefulness-example": [
                "```markdown\nExample:\n\nConsider a healthcare company, HealthCorp, using AWS to store patient data and other sensitive materials. HealthCorp is bound by various compliance standards such as HIPAA (Health Insurance Portability and Accountability Act), which require strict data protection measures.\n\nHealthCorp uses AWS Elastic Compute Cloud (EC2) instances to run their applications and store patient data. They decide to use Elastic Block Store (EBS) for persistent, block-level storage for their EC2 instances, due to its durability and tightly integrated backups.\n\nHowever, due to the sensitive nature of the data, HealthCorp must ensure that this data is stored securely and is encrypted at rest to prevent unauthorized access. \n\nTo fulfill this requirement, they enable EBS encryption while creating the EBS volume for EC2 instances. This ensures that the data at rest is always encrypted, providing an additional layer of security for HealthCorp's sensitive patient data. Data is encrypted under keys managed by AWS Key Management Service (KMS), which secures keys with strong administrative and operational controls.\n\nEnforcing encryption of EBS volumes, even when they are in the idle state, is a crucial control, especially when HealthCorp is dealing with sensitive health-related information. Using AWS EC2 and EBS with enforced encryption, HealthCorp can ensure the security and confidentiality of its patient data while complying with HIPAA regulations.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_1_2",
        "Title": "2.1.2 Ensure S3 Bucket Policy is set to deny HTTP requests",
        "Description": "At the Amazon S3 bucket level, you can configure permissions through a bucket policy making the objects accessible only through HTTPS.",
        "QueryID": "aws_s3_bucket_enforces_ssl",
        "DocumentURI": "policies/aws_cis_v150_2_1_2.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.2"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "In Markdown format, this AWS control explanation would appear as follows:\n\n```markdown\nAmazon S3 provides the ability to control access to objects in a bucket using **buckets policies**. These policies specify what actions are allowed or denied for which principals on the bucket. \n\nOne of the configurations you can apply is to make the objects in the bucket accessible **only through HTTPS**. This means that the data can only be accessed when transferred over a secure connection (HTTPS), thereby providing an additional layer of security to your data.\n\nThis configuration can be particularly useful if you want to ensure that all interactions with the objects in your bucket occur securely. With this setting enabled, any attempts to access the data over an insecure connection (HTTP) will not be allowed.\n```\n\nThis demonstrates how you can use Markdown to format the explanation of the AWS control - using emphasis on key points such as \"buckets policies\" and \"only through HTTPS\" for easier understanding."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS Control could have several impacts including financial, reputational, and operational risks. If Amazon S3 buckets are not properly configured to only allow access via HTTPS, this could potentially result in unauthorized access, making sensitive data susceptible to interception. The associated costs could include:\n\n1. **Data Breach**: Non-compliance can open doors for data leakages/breaches, where sensitive data is compromised, leading to potential fines and lawsuits. Financial loss can be significant, depending on the nature of the lost data and the subsequent impact.\n\n2. **Fines and Penalties**: Regulations like GDPR, CCPA etc. mandate encryption of personal data during transmission. If breached, companies can face monetary penalties which can be a percent of their global turn-over. \n\n3. **Reputational Damage**: Data breaches can have a long-lasting impact on a company's reputation, resulting in loss of customer trust and business.\n\n4. **Legal and Remediation Cost**: Following a data breach, companies may need to conduct an investigation to understand what occurred, potentially involving legal advice and technical experts, contributing to overall cost.\n\nIn light of these risks, ensuring secure data transmission by enabling access over HTTPS only for Amazon S3 bucket is critical."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, an e-commerce company houses all their product images and details on their Amazon S3 buckets. It is crucial that this sensitive data is protected from unauthorized access or cyber attacks, so they apply a bucket policy that requires access to the objects through HTTPS only. With this policy, the objects can be accessed securely and the risk of data theft or attacks is significantly minimized.\n\nThis AWS control would look like this:\n\n```json\n{\n\"Version\": \"2012-10-17\",\n\"Id\": \"MyBucketPolicy\",\n\"Statement\": [\n  {\n    \"Sid\": \"SecureTransport\",\n    \"Effect\": \"Deny\",\n    \"Principal\": \"*\",\n    \"Action\": \"s3:*\",\n    \"Resource\": \"arn:aws:s3:::your-bucket-name/*\",\n    \"Condition\": {\n      \"Bool\": {\n        \"aws:SecureTransport\": \"false\"\n      }\n    }\n  }\n]\n}\n```\n\nIn the above policy, all s3 operations (`\"Action\": \"s3:*\"`) for any user (`\"Principal\": \"*\"`) on the bucket (`\"Resource\": \"arn:aws:s3:::your-bucket-name/*\"`) are denied if the request is not made through SSL/TLS (`\"aws:SecureTransport\": \"false\"` condition is `false`). This will ensure that all interactions with the S3 bucket are made securely with HTTPS."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_1_3",
        "Title": "2.1.3 Ensure MFA Delete is enabled on S3 buckets",
        "Description": "Once MFA Delete is enabled on your sensitive and classified S3 bucket it requires the user to have two forms of authentication.",
        "QueryID": "aws_s3_bucket_mfa_delete_enabled",
        "DocumentURI": "policies/aws_cis_v150_2_1_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "`MFA Delete` is a feature provided by Amazon Web Services (AWS) under its S3 service. MFA stands for `Multi Factor Authentication` which simply means that the system asks for more than one way to confirm the identity of the user. \n\nIn the context of AWS S3 bucket, once MFA Delete is enabled, it requires additional authentication for either of the following actions:\n\n1. Permanent deletion of an object version.\n2. Suspension of versioning on the bucket.\n\nBy enabling this feature, a user with AWS `Access Key` and `Secret Key` will not be able to delete an object or suspend versioning without an additional form of authentication. \n\nThis second form of verification, which is MFA, improves the security of the bucket as it requires additional confirmation before deletion. It can be particularly useful for protecting sensitive and classified data from accidental deletion or malicious activities.\n\n```markdown\n**Steps to Enable MFA Delete**\n\n1. Login to AWS Console.\n2. Go to S3 Service.\n3. Select the Bucket you want to secure with MFA Delete.\n4. In the `Permissions` tab, go to `bucket policy`.\n5. Enable `Versioning` and `MFA Delete`.\n6. For enabling MFA delete, AWS console will ask for the MFA code.\n\n```\nNote: Only the bucket owner (root account), who is logged in using MFA, can enable or suspend MFA Delete feature. \n\nAlso, this feature is not enabled by default and is also not available in all instances, especially if you are tacking operations programmatically.\n\nRemember, enabling MFA delete might incur additional costs as it involves versioning. So, please review the pricing details related to S3 storage, MFA, and data transfer before enabling MFA delete."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS control of enabling Multi-Factor Authentication (MFA) Delete on sensitive and classified S3 buckets can be significant. There are several potential costs associated with non-compliance:\n\n1. **Loss of Data**: The most direct risk of non-compliance is the potential loss of data. If MFA Delete is not enabled, unauthorized persons might gain access and delete critical data.\n\n2. **Financial Loss**: Loss of critical data can also lead to significant financial cost, which can range from loss of business due to service disruption, expenses necessary to recover the data (if possible), or in the worst case, going out of business.\n\n3. **Reputation Damage**: Data breaches or loss can lead to reputational damage, loss of customers, and a drop in share prices in case of public companies. It might be difficult to regain the trust of customers after a significant data loss or breach.\n\n4. **Legal Penalty**: Depending on the nature of the data like personal, financial, or health-related data, non-compliance can trigger lawsuits, heavy fines, or other penalties. Different regions have different laws - like GDP in Europe, CCPA in California, etc.\n\n5. **Loss of Productivity**: Data loss can cause outages or disruptions to operations, leading to loss of man-hours and productivity.\n\nTherefore, it is highly recommended to follow AWS controls and enable MFA Delete for sensitive and classified S3 buckets not only to avoid potential data loss but also protect against financial, reputational, and legal costs."
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider an organization called XYZ that stores a large amount of sensitive customer data in an S3 bucket. This data includes personal identifiers like addresses and social security numbers, so it's crucial that only authorized users can access, edit or delete it.\n\nRecently, the organization experienced a security incident where a team member’s access credentials got compromised. The unauthorized user used these credentials to log in and tried to access and delete the confidential data in the S3 bucket.\n\nLuckily, this bucket had MFA Delete enabled. When the user tried to delete the files, he was asked for a second form of authentication. Since he did not have access to the second authentication factor, he was unable to delete the data.\n\nIn this case, using MFA Delete was crucial. It added an additional layer of security by requiring two forms of authentication, and thus prevented the potential data breach. \n\nThis instance clearly highlights the usefulness of MFA Delete on S3 buckets that store sensitive and classified data. The cost of a potential data breach can go far beyond financial loss, possibly leading to loss of customer trust and damage to reputation."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_3_1",
        "Title": "2.3.1 Ensure that encryption is enabled for RDS Instances",
        "Description": "Amazon RDS encrypted DB instances use the industry standard AES-256 encryption algorithm to encrypt your data on the server that hosts your Amazon RDS DB instances. After your data is encrypted, Amazon RDS handles authentication of access and decryption of your data transparently with a minimal impact on performance.",
        "QueryID": "aws_rds_db_instance_encryption_at_rest_enabled",
        "DocumentURI": "policies/aws_cis_v150_2_3_1.md",
        "ManualVerification": false,
        "Severity": "Low",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.3.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/RDS"
            ],
            "x-kaytu-explanation": [
                "# Amazon RDS Encrypted DB Instances \n\nAmazon RDS encrypted DB instances provide an efficient and secure way to protect your data. The encryption method employed is the highly secure industry standard AES-256 encryption algorithm. \n\nThis encryption is done at the server level, specifically at the server that hosts your Amazon RDS DB instances. \n\n## AES-256 Encryption\n\nAES-256 is a symmetric encryption algorithm widely recognized for its robustness and security. Because it is applied at the server hosting your DB instances, the protection is both deep and extensive.\n\n## Automated Decryption \n\nWith Amazon RDS encryption, data is automatically decrypted just before it is utilized. This occurs at the RDS service end, which means you do not personally handle the decryption process. \n\n## Authentication \n\nAmazon RDS oversees the authentication of access so that only authorized access to the encrypted data is allowed. This management of access significantly reduces potential risks of intrusion.\n\n## Minimal Performance Impact \n\nIn spite of its rigorous encryption and decryption processes, Amazon RDS encryption has a minimal impact on performance. This means users do not have to trade-off performance for data security. \n\nIn essence, Amazon RDS encrypted DB instances offer security, efficiency and a user-friendly experience."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control might result in several potential costs:\n\n1. **Data Breach Costs**: Unencrypted databases are more vulnerable to data breaches. If your unencrypted Amazon RDS DB instances get compromised, the cost can be significant. This includes direct expenses such as incident response, customer notification, customer support, and potential fines. There are also indirect costs, like loss of customer trust and reputation damage, which could lead to lost business.\n\n   _Example: Based on the Ponemon Institute's 2020 Cost of a Data Breach Report, the average total cost of a data breach is $3.86 million._\n\n2. **Regulatory Fines and Penalties**: Many industries and regions have strict regulations regarding data protection, including requirements for data encryption. Non-compliance with these regulations could result in hefty fines or penalties.\n\n   _Example: Under the EU's General Data Protection Regulation (GDPR), non-compliance can result in fines up to €20 million, or 4% of the worldwide annual revenue of the prior financial year, whichever is higher._\n\n3. **Contractual and Legal Liabilities**: If you have contractual obligations or service level agreements with your customers to protect their data, which includes encryption, any breach could lead to lawsuits and legal liabilities.\n\n4. **Loss of Competitive Advantage**: If competitors are seen as having more secure data practices (such as data encryption), customers may choose to migrate to their services, leading to a loss of competitive advantage.\n\n5. **Cost of Remediation**: If a lack of encryption is identified in an audit or after a security incident, the cost of resolving these issues and implementing encryption can be significant.\n\nThese costs can vary based on the nature of the data, the size of the company, the region in which it operates, and the specific circumstances of any data breach. Hence, it's crucial to comply with AWS controls for encrypted DB instances to avoid these potential costs."
            ],
            "x-kaytu-usefulness-example": [
                "Consider a scenario where you are running an online retail business. When customers purchase products from your online platform, they submit sensitive information such as their names, addresses, and credit card numbers. To protect this sensitive data and abide by data protection regulations, you need to ensure that all data is encrypted, both in transit and at rest.\n\nThis is where Amazon RDS encrypted DB instances come in. By employing AES-256 encryption algorithm - an industry-standard - your customers' sensitive data stored on server hosting the Amazon RDS DB instances will be encrypted. This adds an extra layer of protection, making it challenging for unauthorized persons to access or misuse the data. \n\nAdditionally, Amazon RDS handles the authentication of access and decryption of your data, so you don't need to worry about implementing these processes manually. This ensures the secure handling of your data with minimal impact on the performance of your RDS instances. Hence, the use of Amazon RDS encrypted DB instances eliminates the complexities related to data encryption and gives you peace of mind over your data security - a vital aspect of any business operating online."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_3_2",
        "Title": "2.3.2 Ensure Auto Minor Version Upgrade feature is Enabled for RDS Instances",
        "Description": "Ensure that RDS database instances have the Auto Minor Version Upgrade flag enabled in order to receive automatically minor engine upgrades during the specified maintenance window. So, RDS instances can get the new features, bug fixes, and security patches for their database engines.",
        "QueryID": "aws_rds_db_instance_automatic_minor_version_upgrade_enabled",
        "DocumentURI": "policies/aws_cis_v150_2_3_2.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.3.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/RDS"
            ],
            "x-kaytu-explanation": [
                "# AWS Control - Auto Minor Version Upgrade for RDS Instances\n\nThe **Auto Minor Version Upgrade** is a flag feature provided by Amazon Web Services (AWS) for RDS database instances. When this flag is enabled, your RDS instances will automatically receive minor engine upgrades during the specified maintenance window. \n\n```markdown\n## Benefits\n- **New Features:** Your RDS instances can benefit from new features rolled out in minor updates.\n- **Bug Fixes:** Minor upgrades also often fix bugs, ensuring smooth operation of your services.\n- **Security Patches:** Keeping your database engine updated with the latest security patches is vital to prevent potential security vulnerabilities.\n\n## How to Enable Auto Minor Version Upgrade\n1. Open the Amazon RDS console.\n2. In the navigation pane, choose **Databases**, and then choose the database instance that you want to modify.\n3. For **Maintenance**, choose **Edit**.\n4. For **Auto minor version upgrade**, choose **Yes**.\n5. Choose **Save changes**.\n\nBy enabling the Auto Minor Version Upgrade feature, you are ensuring that your database engines are always up-to-date, eliminating the need for manual intervention to apply these minor upgrades.\n```\n\nRemember, **Minor Version Upgrades** are usually safe. They are meant to rectify bugs and enhance features rather than changing the fundamental workings of the database engine. However, for critical systems, it is usually recommended to conduct proper testing in a separate environment before upgrading the production environments."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can result in several potential costs:\n\n1. **Security Vulnerabilities:** If the Auto Minor Version Upgrade flag is not enabled, your RDS instances may not receive prompt updates, exposing them to various types of security risks. This could potentially lead to breaches, data loss, and reputational harm, all of which have their own significant costs.\n\n2. **Outdated Features and Bug Fixes:** Newer versions of RDS not only have improved security features, but also improvements in functionality, performance, and bug fixes. Not upgrading could lead to missed opportunities for better performance and stability. This can lead to productivity loss in terms of troubleshooting and latency.\n\n3. **Increased Operational Costs:** Running outdated software versions could necessitate added efforts in terms of backward compatibility and maintaining older systems. These could lead to a rise in operational costs in terms of both time and resources.\n\n4. **Compliance Violations:** If you’re operating in an industry where regulations mandate running up-to-date software, non-compliance with this AWS control could lead to significant penalties and fines. For instance, industries such as healthcare, finance, and government often have strict compliance requirements about system and software updates.\n\n5. **Potential Downtime:** Occasionally, AWS may forcefully update a severely outdated RDS instance, which may result in unexpected downtime if not properly planned.\n\nTo avoid these costs, it's important to enable the Auto Minor Version Upgrade feature. This feature ensures that your RDS instances are updated, reducing security risks, improving functionality, and reducing maintenance efforts."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider a company called ABC Corp. which uses Amazon RDS database instances for storing their production data. They have a dedicated team of database administrators for managing these instances. However, manually keeping up with the latest minor engine upgrades and implementing them can be a time-consuming process.\n\nBy enabling the Auto Minor Version Upgrade flag, their RDS database instances would automatically receive the updates during the specified maintenance window. This way, ABC Corp. can be assured of getting the latest features, bug fixes, and most importantly, security patches without requiring manual intervention.\n\nHence, they can focus more on their core business operations while AWS takes care of maintaining the engine versions of their RDS instances up-to-date. This results in minimizing potential vulnerabilities, improving database performance, and saving time for the ABC Corp. team."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_4_1",
        "Title": "2.4.1 Ensure that encryption is enabled for EFS file systems",
        "Description": "EFS data should be encrypted at rest using AWS KMS (Key Management Service).",
        "QueryID": "aws_efs_file_system_encrypt_data_at_rest",
        "DocumentURI": "policies/aws_cis_v150_2_4_1.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.4.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/EFS"
            ],
            "x-kaytu-explanation": [
                "AWS Elastic File System (EFS) provides a simple, scalable, and fully managed elastic NFS file system for use with AWS cloud services and on-premises resources. Data stored within EFS should be encrypted at rest to add another layer of data protection. Encrypting data at rest provides an additional security barrier in case unauthorized users gain access to storage.\n\nAWS Key Management Service (KMS) is the tool that can be used within AWS services to create and manage cryptographic keys, referred to as Customer Master Keys (CMKs), and control their use across a wide range of AWS services and in your applications. \n\nYou can use AWS KMS to encrypt EFS data at rest. When data at rest is encrypted, even if someone unauthorized gains access to the storage, they would not be able to make sense of the data without the key.\n\nSo, the control here is saying: For security and compliances purpose, configure EFS data to be encrypted at rest using AWS KMS.\n\n```html\n\u003cp\u003eAWS Elastic File System (EFS) should be configured to encrypt data at rest using AWS Key Management Service (KMS). This helps add an additional layer of security to protect against unauthorized access to your data. With encryption, even if an unauthorized entity gains access to the storage, they cannot comprehend the data without the encryption key provided by KMS.\u003c/p\u003e \n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS control that \"EFS data should be encrypted at rest using AWS KMS\" can lead to several costs:\n\n1. **Security Breach Costs**: If data is not encrypted at rest, it increases the susceptibility of your AWS data to security breaches. The cost of such breaches can be massive, involving sensitive data loss, financial implications, and harm to the organization's reputation. \n\n2. **Regulatory Compliance Fines**: Various regulations (like GDPR, HIPAA, PCI DSS) require data to be encrypted at rest. Non-compliance could lead to substantial fines and penalties. \n\n3. **Loss of Trust**: Clients or customers who discover that their data is not being stored securely may lose trust in your business, leading to potential business losses.\n\n4. **Recovery Costs**: If a breach occurs, there may be significant expenses related to recovering lost data, restoring systems, forensic analysis, and remediation efforts.\n\n```markdown\n### Cost of Non-Compliance to the AWS Control: EFS data should be encrypted at rest using AWS KMS ###\n1. **Security Breach Costs**: Not encrypting data at rest can lead to potential security breaches which can lead to data loss or exposure, resulting in financial losses alongside harm to the company brand and reputation.\n2. **Regulatory Compliance Fines**: Several regulations (like GDPR, HIPAA, PCI DSS) mandate that data be encrypted at rest. Non-adherence to these requirements could result in severe penalties or fines.\n3. **Loss of Trust**: Customers who discover that their data is not being stored securely may lose faith in the business, potentially leading to business losses.\n4. **Recovery Costs**: In case of a security breach, the expenses related to data recovery, system restoration, forensic analysis, and other rectification efforts can be significant.\n```\nNote that the actual costs will depend on the specific nature of the non-compliance, the sensitivity of the data involved, the regulatory environment, and the effectiveness of the organization's response to the issue."
            ],
            "x-kaytu-usefulness-example": [
                "AWS Elastic File System (EFS) is a cloud storage service provided by AWS. However, any data at rest in the EFS can be a potential vulnerability. Therefore, it's recommended to encrypt the data at rest in EFS using AWS Key Management Service (KMS). This mechanism ensures that your data is safe and only users with the decryption key can access the data.\n\nExample:\n\nSuppose a company is storing sensitive user information, like financial details or private user data, in the AWS EFS. It's paramount that this information is kept secure and confidential to avoid any potential malicious attacks or data breaches. By using AWS KMS to encrypt this data at rest, the company adds an extra layer of security. Furthermore, KMS allows the company to fully control the keys, including establishing policies and auditing key usage to ensure the appropriate use of encryption keys.\n\n```\nEnsure all data in Amazon EFS is encrypted at rest:\n    \n    Step 1:\n    aws efs describe-file-systems --query 'FileSystems[*].[FileSystemId,Name]' --output text \u003e EFS_fileSystems.txt\n\n    Step 2:\n    for filesystem in (cat EFS_fileSystems.txt); do  aws efs describe-file-systems --file-system-id $filesystem | grep KmsKeyId; done\n\nIf KmsKeyId is 'null', then the file system is unencrypted, and the company would be at risk of exposing user sensitive data. Hence, it's useful to encrypt at rest using AWS KMS.\n```\nThis example illustrates protecting user sensitive data by encrypting at rest using AWS KMS and highlights the importance of EFS data encryption in maintaining data security and confidentiality."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_1_4",
        "Title": "2.1.4 Ensure all data in Amazon S3 has been discovered, classified and secured when required",
        "Description": "Amazon S3 buckets can contain sensitive data, that for security purposes should be discovered, monitored, classified and protected. Macie along with other 3rd party tools can automatically provide an inventory of Amazon S3 buckets.",
        "QueryID": "aws_s3_bucket_protected_by_macie",
        "DocumentURI": "policies/aws_cis_v150_2_1_4.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.4"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "### AWS S3 Buckets and Macie \n\n**Amazon S3 (Simple Storage Service) buckets** are storage units where you can dump data in the form of objects. These buckets might contain sensitive data, such as Personally Identifiable Information (PII), financial data, health records, etc. It's crucial to ensure the security and privacy of this data to mitigate risks and comply with regulations.\n\nTo help with this, AWS introduced **Macie**, a fully managed data security and data privacy service that uses machine learning and pattern matching to discover and protect your sensitive data in AWS.\n\n**Amazon Macie** automatically provides an inventory of your Amazon S3 buckets and evaluates them. This involves identifying, monitoring and categorizing data stored in the buckets. It detects S3 buckets with potentially sensitive data, monitors and provides alerts of any unauthorised access or potential data leaks. \n\nIn addition to Macie, there are many **3rd party tools** available in the market that can provide the similar functionality. These tools can be integrated with your AWS infrastructure to enhance security. These solutions may also provide additional features, capabilities, or specializations depending on your specific needs. \n\nFor example, they might offer features like:\n\n- Inventory and classification of your data across multiple cloud platforms, not just AWS.\n- Advanced data loss prevention features.\n- More customizable policies and alerts.\n- Integration with other security solutions or platforms you're already using.\n  \nRemember that no single tool is a panacea, and that your data security strategy should take a multi-layered approach that includes regular audits, access controls, encryption, and other security best practices. \n\nIn combination, AWS Macie and 3rd party tools can provide a comprehensive solution to manage your S3 buckets, maintain security and adhere to compliance norms."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the said AWS control, which pertains to monitoring S3 buckets' sensitive data using Macie and other 3rd party tools, is multifaceted and can impact an organization in several ways:\n\n1. **Financial Loss** - If sensitive data in S3 buckets is breached, there could be substantial financial implications. This could be through direct theft of financially-sensitive data like credit card information or indirect through the impact of a data breach on company's reputation, leading to lost business.\n\n2. **Regulatory Fines** - Non-compliance can lead to substantial fines and penalties from regulatory bodies, such as the GDPR or HIPAA, which might have rules about data protection and privacy.\n\n3. **Reputation Damage** - Failure to protect sensitive data can erode trust from customers and partners, harming the organization's reputation, which can have long-term impacts on the business.\n\n4. **Legal Consequences** - Non-compliance can also lead to legal consequences, such as lawsuits from individuals or entities whose data was compromised. \n\n5. **Operational Disruption** - Data breaches can cause major operational disruptions while response teams take action to patch security issues and recover lost data.\n\n6. **Loss of Competitive Advantage** - If the data is intellectual property or represents a competitive advantage, data breaches can provide a competitive edge to rivals if it lands in the wrong hands.\n\nTherefore, ensuring compliance by protecting sensitive data in S3 buckets is crucial to avoiding these non-compliance costs. \n\nHowever, it is important to note that while tools like Macie can help automatically identify and classify sensitive data in S3 buckets, the ultimate responsibility for compliance lies with the organization itself. It should maintain appropriate security measures and validate its compliance status regularly."
            ],
            "x-kaytu-usefulness-example": [
                "An example instance highlighting the usefulness of Amazon Macie for S3 bucket security could be:\n\nJohn is the IT administrator of a company that has recently migrated to the Cloud. As part of this process, their whole data storage plan has changed and now they're utilizing Amazon S3 buckets, storing both regular and sensitive data. Over time, with increasing data, it becomes difficult for John to manually keep track of all S3 buckets and certify their security.\n\nWhen he learns about Amazon Macie, he immediately implements it. The tool automatically offers him an inventory of their existing Amazon S3 buckets, clearly showing him where sensitive data is stored. This automated process frees up significant time for John that he previously spent manually keeping track of and protecting all S3 buckets. Given the volume of their data, Macie’s ability to automatically discover, monitor, and classify data proves to be valuable feature for continuous security."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_1_5",
        "Title": "2.1.5 Ensure that S3 Buckets are configured with 'Block public access (bucket settings)'",
        "Description": "Amazon S3 provides Block public access (bucket settings) and Block public access (account settings) to help you manage public access to Amazon S3 resources. By default, S3 buckets and objects are created with public access disabled. However, an IAM principle with sufficient S3 permissions can enable public access at the bucket and/or object level. While enabled, Block public access (bucket settings) prevents an individual bucket, and its contained objects, from becoming publicly accessible. Similarly, Block public access (account settings) prevents all buckets, and contained objects, from becoming publicly accessible across the entire account.",
        "QueryID": "aws_s3_public_access_block_bucket_account",
        "DocumentURI": "policies/aws_cis_v150_2_1_5.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.5"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Block Public Access to Amazon S3 Resources\n\n## Overview\n\nAmazon S3 provides two settings that help you manage public access to your S3 resources: \n\n- Block public access (bucket settings)\n\n- Block public access (account settings)\n\nWhile public access is disabled by default for S3 buckets and objects, you may wish to add an extra layer of security to prevent public access under certain circumstances. \n\n## Definitions\n\n### Block public access (bucket settings)\n\nThis setting prevents an individual bucket and its contained objects from receiving public access. This is ideal for when you have individual buckets that contain sensitive data or data that does not need to be accessed publicly. \n\n### Block public access (account settings)\n\nThis setting prevents all buckets and contained objects from receiving public access across the entire AWS account. It is useful when none of the S3 resources in the account need to be accessible to the public, and to enforce this policy uniformly across all buckets in the account.\n\n## Default Settings\n\nWhen a new S3 bucket or object is created, it is automatically set to have public access disabled. This is a safety measure to ensure that new resources are not unintentionally exposed to the public.\n\nHowever, an IAM user with sufficient S3 permissions is able to enable public access at the bucket level or object level. This flexibility enables you to decide which resources need to be publicly accessible and which do not.\n\n## Conclusion\n\nBlock public access settings are an important tool for maintaining security and privacy of your S3 resources. By understanding how these settings work, you can more effectively manage access to your Amazon S3 resources."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the aforementioned AWS control could potentially lead to several risks and costs:\n\n1. **Data Breaches**: If public access is not blocked, there is a high probability that sensitive data could be exposed to unauthorized users, leading to data breaches. The cost of these breaches could range from regulatory fines, legal fees, and reputational damage.\n\n2. **Unexpected Cost Increase**: When data is publicly accessible, it can be accessed an unlimited number of times. This could lead to an increase in data transfer costs which can spike the monthly AWS bill.\n\n3. **Compliance Violations**: If your company needs to comply with strict regulatory standards (like GDPR, HIPAA, etc.), allowing public access to S3 buckets might violate these compliance requirements, leading to hefty fines and penalties.\n\n4. **Business Disruption**: Non-compliance could lead to business disruption, especially if a breach results in the loss or corruption of important data.\n\nTo summarize, not adhering to the AWS Block public access control (in both bucket and account settings) may pose serious security threats, lead to regulatory issues, and result in unexpected costs. It's crucial to implement these controls to minimize the risk of such issues.\n"
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider the following scenario: A tech company named 'TechCorp' uses AWS S3 for storing their codebase, project files, financial data, and customer information. These resources in their S3 buckets are highly confidential and should not, under any circumstances be accessible to anyone outside the organization.\n\nDespite having permission controls in place, there's always a chance that someone mistakenly changes the access settings making a certain S3 bucket or object publicly accessible. This can lead to severe data leak and financial losses to the organization.\n\nTo safeguard against such scenarios, TechCorp can use the 'Block public access (bucket settings)' for individual buckets containing sensitive information and 'Block public access (account settings)' for the entire S3 resource in their account. This will ensure that even if someone changes the access controls accidentally or intentionally, the buckets and objects in their account will always remain private and not publicly accessible. This additional layer of security provides a robust solution to prevent unintended public exposure of sensitive data."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v150_2_3_3",
        "Title": "2.3.3 Ensure that public access is not given to RDS Instance",
        "Description": "Ensure and verify that RDS database instances provisioned in your AWS account do restrict unauthorized access in order to minimize security risks. To restrict access to any publicly accessible RDS database instance, you must disable the database Publicly Accessible flag and update the VPC security group associated with the instance.",
        "QueryID": "aws_rds_db_instance_prohibit_public_access",
        "DocumentURI": "policies/aws_cis_v150_2_3_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.3.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v1.5.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/RDS"
            ],
            "x-kaytu-explanation": [
                "# AWS RDS Security Control\n\nIn an AWS environment, Restricting unauthorized access to RDS database instances is a crucial security measure that can help to minimize potential risks.\n\n## Restricting Access\n\nTo restrict access to any publicly accessible RDS database instance, you need to configure its accessibility settings. Particularly, you will need to disable the `Publicly Accessible` flag of the database instance.\n\nHere's how you can disable this setting:\n\n1. Sign in to your AWS account and navigate to the RDS Dashboard.\n2. From the list of databases, select the instance that you want to modify.\n3. On the instance details page, select `Modify`.\n4. In the `Network \u0026 Security` section, look for the `Publicly Accessible` option. Be sure to set this option to `No`.\n5. Review the changes and select `Apply Immediately` for the changes to take effect immediately.\n6. Click `Modify DB Instance` to save your changes.\n\nRemember, altering this setting will not interrupt your database connectivity.\n\n## Updating VPC Security Group\n\nIn addition to the above step, you also need to update the VPC security group associated with the database instance. Update the security rules in a way that they allow access only from trusted IP addresses or IP ranges.\n\nEnsure that your security groups are correctly configured following the rules of least privilege; only necessary ports and IP ranges should be granted access to your RDS instances.\n\nThis combined approach of disabling public accessibility and tightening security group rules will significantly enhance your AWS RDS instances' security posture. It will effectively block any unauthorized access attempts, thus minimizing your overall security risks in your AWS account."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control can lead to significant costs for an organization, such as:\n\n1. **Financial Costs**: Failure to properly restrict access to your RDS instances can expose sensitive data to potential breaches, triggering financial penalties due to compliance violations and data protection laws (like GDPR). Additionally, public access to your databases means increased usage, leading to larger AWS bills.\n\n2. **Reputational Damage**: If data is compromised, it can significantly harm an organization's reputation. Customers may lose trust and choose to take their business elsewhere which can impact an organization's bottom line and its market position.\n\n3. **Operational Costs**: A data breach or unauthorized access can also lead to operational issues. It may interrupt normal business operations and require substantial time and resources to investigate, respond, and recover from these incidents.\n\n4. **Legal and Regulatory Repercussions**: Various laws, regulations, and standards govern the protection of sensitive data. If a breach occurs due to unrestricted access to your databases, your organization could face lawsuits and hefty fines.\n\nHere’s the markup explanation for further understanding:\n\n```\n- **Financial Costs**: Unauthorized access can lead to data breaches and higher resource usage, incurring penalties and increasing AWS costs.\n- **Reputational Damage**: Data breaches can lead to a loss of trust among customers, causing them to take their business elsewhere, impacting the organization's market position.\n- **Operational Costs**: Unauthorized access and data breaches can interrupt normal business operations and require significant resources to rectify.\n- **Legal and Regulatory Repercussions**: Non-compliance can result in lawsuits and fines from regulatory bodies due to the violation of data protection laws and standards.\n```\n\nTherefore, it's very important to ensure your RDS database instances are not publicly accessible and restrict unauthorized access."
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a scenario where a business has a customer-facing application that utilizes an RDS database instance to store user credentials and personal data. This data is sensitive and should not be accessible by unauthorized users. \n\nIf the RDS instance is publicly accessible, malicious actors may potentially be able to discover and exploit the database, which could result in a serious data breach. \n\nTo mitigate this, the business can disable public access to the RDS instance by updating the database instance settings under AWS Management Console. Specifically, they set the Publicly Accessible flag to 'No' and associates the instance with a security group that only allows inbound traffic from approved IP addresses.\n\nThis way, the RDS instance is not exposed to the public, dramatically reducing the risk of unauthorized access and potential data breaches. This is a clear example of why it is essential to restrict public access to RDS database instances in AWS. \n\nThe control rule will look like in markup format:\n\n```markdown\n**Control:** \nEnsure and verify that RDS database instances provisioned in your AWS account do restrict unauthorized access in order to minimize security risks.\n\n**Action:** \n1. Navigate to the 'RDS' service in the AWS Management Console.\n2. Select the individual RDS instance.\n3. In 'Instance Actions', select 'Modify'.\n4. Under the 'Public accessibility' section, select 'No'.\n5. Save the changes. \n6. In the VPC security group settings, only allow inbound traffic from approved IPs.\n```\n \nImplementation of the above control will help in securing the RDS databases from external threats."
            ]
        },
        "Managed": true
    }
]