[
    {
        "ID": "aws_cis_v200_1_1",
        "Title": "1.1 Maintain current contact details",
        "Description": "Ensure contact email and telephone details for AWS accounts are current and map to more than one individual in your organization.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v200_1_1.md",
        "ManualVerification": true,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS accounts are crucial for managing and operating the applications in Amazon Web Services. It is essential to maintain up-to-date contact information on these accounts to ensure smooth communication, troubleshooting, and incident management.\n\nThe control mentioned infers that you must keep the contact email and telephone details for these AWS accounts current and up-to-date. This ensures that AWS can reach out to you in case of any account-related alerts, such as security notifications, service updates, or other imperative details.\n\nMoreover, these contact details should not just be linked to a single individual. Instead, they should map to more than one individual in your organization. This is important for redundancy â€” if one person is unavailable or leaves the organization, AWS can still contact another person to ensure uninterrupted account management.\n\nHere's an example of how you could represent this control in markup format:\n\n```Markdown\n## AWS Account Management Control\n\n**Objective:** Ensure smooth communication and uninterrupted account management with AWS\n\n- **Control 1:** Keep contact email and telephone details for AWS accounts up-to-date\n- **Control 2:** The contact details must be linked to more than one individual in the organization\n\nThis ensures that AWS can reach out for account-related alerts, service updates, and ensure seamless management even if one individual is unavailable.\n```\nRemember, these controls are put in place to prevent potential communication disruptions with AWS, thus aiding in efficient account administration. \n\nThese practices could be part of your organization's governance, risk management, and compliance (GRC) strategy. Implementing them could help mitigate risks associated with account management and improve overall operational efficiency."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the control of ensuring contact email and telephone details for AWS accounts are current and map to more than one individual in an organization can result in significant costs including operational, financial, and reputational. The details are as follows:\n\n* **Operational Cost:** \n    - If the primary contact is unavailable or leaves the organization without updating the information, it can delay in-case of procurement of support from AWS or in any situation implying immediate action (e.g., security threats, downtime issues, etc.). This delay can cause operational inefficiency and can lead to system downtime.\n\n* **Financial Cost:**\n    - In an emergency, a delay in communication could lead to system failures or a security breach, which may result in significant financial loss. A breach could lead to penalties or fees if compliance regulations are not met.\n    - AWS provides service-related notifications and billing updates on these contact details. Non-availability of the right information could lead to missing out on important payment deadlines resulting in late payment fees or, at worse, losing control over the resources due to non-payment.\n\n* **Reputational Cost:**\n    - Missed AWS account alerts due to non-compliance may lead to serious security breaches exposing customer data, leading to a potential loss of reputation. It could take years for the company to regain customer trust.\n    - Failure in meeting compliance requirements can also lead to decertification which greatly damages the company's reputation.\n\nTherefore, non-compliance to this control is not advisable as it can lead to significant costs. AWS recommends maintaining up to date contact details associated with the account and ensuring that more than one person in the organization receives communication to avoid any negative impact."
            ],
            "x-kaytu-usefulness-example": [
                "**Example:**\n\nABC Corporation is a large enterprise with multiple AWS accounts utilized across various departments and projects. They have a strict policy to ensure up-to-date contact information and proper mapping of email and telephone details for these AWS accounts to more than one individual. \n\nDuring one instance, their primary AWS account experiences a security breach. AWS security frameworks immediately detected the breach and emailed the respective alert to the registered contact emails. \n\n```markup\n- Alert from AWS: \n    Subject: Unauthorized Access Alert\n```\n\nThanks to the corporation's policy, these alerts were not only sent to the account manager but also to the alternate contact person. The account manager was traveling overseas and had limited access to emails. However, upon receiving the alert, the alternate contact person was able to take immediate actions.\n\n```markup\n- To: johndoe@abccorp.com, janedoe@abccorp.com \n    Subject: Unauthorized Access Alert\n```\n\nHe reported the breach to the security team who then worked with Amazon's incident response to mitigate the security risk. \n\nHaving current and mapped contact details for AWS accounts was crucial in quickly responding and managing the security incident. It potentially saved ABC Corporation from severe data loss and maintained their business continuity."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_2",
        "Title": "1.2 Ensure security contact information is registered",
        "Description": "AWS provides customers with the option of specifying the contact information for account's security team. It is recommended that this information be provided.",
        "QueryID": "aws_account_alternate_contact_security_registered",
        "DocumentURI": "policies/aws_cis_v200_1_2.md",
        "ManualVerification": false,
        "Severity": "Low",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "This AWS control refers to an account setting where customers can specify the contact information of their security team. This is particularly useful in case of a security event or if AWS needs to contact the team for any security concern.\n\nMarkdown version:\n```Markdown\nAWS provides users with the capability to set the contact information for their account's security team. Users are encouraged to take advantage of this feature and provide the necessary details. This could prove invaluable in case of a security incident or if AWS needs to reach out to the team regarding any security issues.\n```\n\nThis settings for providing contact information can typically include the name, email address, and phone number of the security team or person responsible for security. AWS can then use this information to alert users about any security concerns with their account such as attempted breaches or detected vulnerabilities."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can have several costs:\n\n1. **Lack of Rapid Response:** If AWS detects a security issue with an account, they need to alert someone immediately. Without proper contact information, they cannot do this, and the problem may worsen before it is discovered and rectified.\n\n2. **Potential Data Breaches**: A security issue, if not promptly addressed, can escalate to a full-fledged data breach. This might lead to unauthorized access to sensitive information.\n\n3. **Regulatory Penalties**: Depending on the jurisdiction and industry, failure to respond promptly to security incidents because AWS could not reach the right contact could also breach regulatory requirements, potentially leading to financial penalties.\n\n4. **Reputation Damage**: Security incidents and data breaches can significantly damage a company's reputation, both with its customers and within its industry.\n\n5. **Loss of Business**: In the worst-case scenario, a major data breach could lead to the loss of customers, clients, or the entire business.\n\nConsequently, it is very important that the specified contact information is accurate, up-to-date, and checked regularly. Also, it is recommended that the specified contact should have sufficient technical understanding to understand and respond to any potential issues."
            ],
            "x-kaytu-usefulness-example": [
                "For example, in a scenario where suspicious activities or potential security threats are detected in your AWS account, AWS can use the contact information provided to immediately alert your security team. This way, your team can quickly respond to mitigate the risk and prevent any potential data breaches. \n\nAdditionally, having the security team contact information also allows AWS to provide important account notifications, such as if your account is nearing its service limit or has outstanding billing issues. Overall, this AWS control enhances communication, responsiveness and management of your account security."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_3",
        "Title": "1.3 Ensure security questions are registered in the AWS account",
        "Description": "The AWS support portal allows account owners to establish security questions that can be used to authenticate individuals calling AWS customer service for support. It is recommended that security questions be established.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v200_1_3.md",
        "ManualVerification": true,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Security Questions\n\nThe AWS support portal has a feature wherein the account owners can set security questions to further validate the identity of the individual during customer service interactions and support. This provides another layer of security, ensuring that the person calling for support is authenticated and has authorized access to the account.\n\nWhen individuals call AWS customer service for support, they may be asked these security questions to confirm their identity before account information or assistance is provided. This is similar to security questions used by many other online services for password recovery or account verification.\n\nAWS highly recommends setting up these security questions for added security. \n\nWhen choosing the security questions and answers, consider the following:\n\n- Choose questions and answers that are hard for others to guess\n- Avoid using easily available or personal information\n- Make sure the answers are memorable to you\n- Keep your answers secure, don't share them\n\nImplementing this AWS control will help protect your AWS account from unauthorized access via customer support interactions, enhancing your overall cloud security.\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control could potentially lead to various costs and risks, including:\n\n1. **Security Risks:** The absence of security questions makes an AWS account more prone to unauthorized access and potential misuse. For example, if a malicious party tries to gain access to your AWS account through customer service, the absence of security questions makes it easier for them to succeed. This could then lead to data breaches or unauthorized changes to your AWS environment.\n\n2. **Financial Losses:** Unauthorized access or changes to your AWS environment can result in unintentional usage and consequently higher costs. In unfortunate instances, the attackers might even misuse the resources for illegal activities like crypto mining or organizing DDoS attacks, which could drive your AWS bills sky-high.\n\n3. **Reputational Damage:** If a security breach leads to a loss of customer data, it could tarnish your organization's reputation. Restoring brand reputation requires significant time and effort, and sometimes even that might not be enough to regain customer trust fully.\n\n4. **Operational Disruptions:** Unauthorized changes can impact system functionalities and cause business disruptions or system downtime. This may not only hamper business productivity but also result in financial losses.\n\n5. **Legal and Compliance Consequences:** Depending on the nature of your business and the data stored in AWS, you could potentially be in violation of data protection laws or industry regulations. This could lead to legal repercussions, such as fines and sanctions.\n\nTo summarize, not establishing security questions can make your AWS account less secure. The risks of unauthorized access, data breaches, and operational disruptions underline the importance of setting up appropriate security measures, such as security questions, for AWS customer service support."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company called `XYZ Inc.` uses AWS for their cloud services; they have a designated technical team to manage these services. One day while working on their cloud environment, something unexpected happens and they are unable to resolve it themselves. This issue is causing disruptions in their workflow and needs immediate AWS customer support intervention.\n\nThey call AWS customer service, but AWS needs to authentically identify the caller to ensure that they are actually from `XYZ Inc.` and authorized to make changes or receive sensitive information. Here is where the security questions come into play. In advance, `XYZ Inc.` had established security questions via AWS support portal. \n\nThe AWS customer service representative now asks these security questions to the caller. Only if the responses match with what was set up by `XYZ Inc.`, AWS support proceeds with providing help to the technical team of `XYZ Inc.`. This maintains the security and privacy of the AWS account held by `XYZ Inc.`, by preventing unauthorized individuals from accessing proprietary information or making unauthorized changes to their AWS services."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_1",
        "Title": "3.1 Ensure CloudTrail is enabled in all regions",
        "Description": "AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail provides a history of AWS API calls for an account, including API calls made via the Management Console, SDKs, command line tools, and higher-level AWS services (such as CloudFormation).",
        "QueryID": "aws_cloudtrail_multi_region_read_write_enabled",
        "DocumentURI": "policies/aws_cis_v200_3_1.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "# AWS CloudTrail\n\nAWS CloudTrail is a web service that tracks and logs AWS API calls for your account. The log files containing records of these API calls are then delivered to you.\n\n## API Call Logs \n\nEach API call log includes :\n\n- The identity of API caller\n- The timestamp of when the API call was made\n- The IP address from which the API call was made\n- The request parameters of the API call\n- The response elements returned by the AWS service the API call was made to\n\n## History of AWS API Calls\n\nCloudTrail provides a history of all AWS API calls made for an account. These API calls could be made from :\n\n- The AWS Management Console\n- AWS Software Development Kits (SDKs)\n- Command line tools\n- Higher-level AWS services such as AWS CloudFormation.\n\nBy providing a detailed record of all API activity, CloudTrail allows for timely security analysis, resource change tracking, compliance auditing, and troubleshooting."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the use of AWS CloudTrail can lead to the following potential costs:\n\n1. **Security Risk:** Without CloudTrail, an organization cannot monitor and identify potentially harmful or suspicious activity in their AWS environment. Unauthorized AWS API calls, including those made via the AWS Management Console, SDKs, command line tools, and higher-level AWS services such as AWS CloudFormation can go undetected. This poses a significant security risk and could lead to breaches or data leakage. The cost of a potential security incident exceeds the fee for using AWS CloudTrail.\n\n2. **Compliance Costs:** If an organization needs to adhere to regulatory standards such as HIPAA, PCI DSS, and GDPR, they are required to have audit logs that shows who did what in the system at any given time. Failure to do so could lead to hefty fines and penalties. Without using AWS CloudTrail, fulfilling these compliance requirements becomes difficult if not impossible.\n\n3. **Operational Costs:** Errors or issues in the AWS environment can be harder to diagnose without the AWS API call history that CloudTrail provides. This can potentially increase operational costs due to increased time spent debugging and troubleshooting, and lower overall service quality.\n\n4. **Financial Costs:** If there is malicious activity like creating unnecessary resources, without AWS CloudTrail, organizations may not be able to identify such calls leading to increased and unexpected AWS bills.\n\n5. **Reputation Costs:** In the event of data being compromised because you're not using AWS CloudTrail, it can lead to substantial harm to the company's reputation, which can often result in client or revenue loss.\n\nFor these reasons, it's important to use AWS CloudTrail as it offers an additional layer of security to AWS resources, makes troubleshooting easier, helps with compliance requirements, and assists in optimizing costs."
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a multinational company that utilizes various AWS services across different departments, including S3 for data storage, EC2 for hosting web applications, and RDS for managing databases. Unauthorized or malicious activities within these services could significantly impact the company's operations or data privacy.\n\nBy implementing AWS CloudTrail, the company can have a detailed record of all API calls made within their account. Suppose one day, there was an unusual deletion of some important files in their S3 buckets. AWS CloudTrail logs can be used to identify who made the API call, from which IP address, at what time, as well as the specific parameters of the call. This provides valuable information for investigation and helps the company efficiently detect and respond to the security incident.\n\nCloudTrail's integration with CloudWatch and SNS also allows the company to set up real-time alerts to notify them of certain types of activities, enhancing the overall security monitoring and incident response capabilities."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_2",
        "Title": "3.2 Ensure CloudTrail log file validation is enabled",
        "Description": "CloudTrail log file validation creates a digitally signed digest file containing a hash of each log that CloudTrail writes to S3. These digest files can be used to determine whether a log file was changed, deleted, or unchanged after CloudTrail delivered the log. It is recommended that file validation be enabled on all CloudTrails.",
        "QueryID": "aws_cloudtrail_trail_validation_enabled",
        "DocumentURI": "policies/aws_cis_v200_3_2.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.2"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "AWS CloudTrail is a service that records all actions taken in an AWS account and delivers log files to an Amazon S3 bucket. CloudTrail log file validation is a feature of this service which enhances the integrity of the logs provided by CloudTrail.\n\nThis feature generates a 'digest' file, a form of digital fingerprint that contains a cryptographic hash of each log file, created whenever CloudTrail writes to an Amazon S3 bucket. The hashes in the digest files are then digitally signed by CloudTrail using the private key of a key-pair that CloudTrail owns. This allows customers to validate the integrity of the log files and confirm that the log files have not been tampered with.\n\nThe aim of enabling log file validation is to confirm if a log file was altered, deleted, or remained unchanged after CloudTrail delivered it to the S3 bucket. If the contents of the delivered log file don't match the hash value stored in the signed digest file, it means the log may have been tampered with.\n\nHere is an example of how this might look in markup:\n\n```markdown\n# AWS CloudTrail Log File Validation\n\nAWS CloudTrail is a service that provides log files of actions taken in an AWS account. An additional feature, log file validation, creates a digital 'digest' of each log file:\n\n```\n- For each log file, a hash value is created. \n- These hash values are stored and digitally signed in a digest file by CloudTrail. \n```\n\nYou can use these digest files to verify the integrity of the log files, see if they were changed, deleted, or if they remained unchanged after CloudTrail sent them to the S3 bucket.\n\n**Recommendation: Enable Log File Validation**\nEnable this feature on all CloudTrails in your AWS account to ensure the integrity of your logs.\n```\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS Control of enabling CloudTrail log file validation can result in several potential costs:\n\n**1. Security Breach Costs:** If file validation isn't enabled, unauthorized changes to the log files could go undetected. These could potentially hide data breaches or open up vulnerabilities for future attacks.\n\n**2. Compliance Costs:** Many industry standards and regulations require activity logging and the ability to detect changes to those logs. Non-compliance could result in fines and penalties, and potentially loss of certification or accreditation.\n\n**3. Audit Costs:** If logs have been altered and this cannot be detected, it can lead to failed IT audits. This can result in a need for re-auditing and associated costs.\n\n**4. Operational Costs:** If log files are changed or deleted without detection, there may be incorrect business decisions made based on that data, potentially leading to operational inefficiencies and costs.\n\n**5. Reputational Costs:** Failure to provide sufficient security measures, such as the ability to detect log file changes, can lead to loss in customer and stakeholder trust.\n\nLife-cycle management of logs and their validation are critical controls for identifying and investigating suspected malicious activity. Non-compliance not only increases the risk of not detecting security incidents but the costs mentioned above as well. Thus, it's recommended to have CloudTrail log file validation enabled on all CloudTrails."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a Security administrator in a company has noticed an unexpected change in the system logs. Without CloudTrail log file validation, the administrator would have to manually review each log to identify if the logs were altered or tampered with. This process could be tedious, time-consuming, and prone to human errors.\n\nHowever, by using AWS CloudTrail log file validation, the administrator creates a digitally signed digest file containing a hash for each log that CloudTrail writes to S3. If there is any tampering or deletion in the logs, the hash value in the digest would differ from the hash value calculated from the altered log file. \n\nThis feature allows the administrator to quickly determine if the logs were tampered with, thus saving time and enhancing the security of the system. Therefore, it is useful for maintaining the integrity of logs, aiding in forensic investigations, and complying with regulatory standards."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_4",
        "Title": "1.4 Ensure no 'root' user account access key exists",
        "Description": "The 'root' user account is the most privileged user in an AWS account. AWS Access Keys provide programmatic access to a given AWS account. It is recommended that all access keys associated with the 'root' user account be deleted.",
        "QueryID": "aws_iam_root_user_no_access_keys",
        "DocumentURI": "policies/aws_cis_v200_1_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.4"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# Delete Access Keys Associated with Root User Account\n\n## Overview\nThe 'root' user account in an AWS account holds the highest level of privileges. AWS Access Keys provide a way to programmatically access the AWS account. However, it's recommended to delete any access keys linked with the 'root' user to enhance security.\n\n## Rationale\nThe 'root' user has extensive permissions and unrestricted access to all resources in the AWS account. If its access keys fall into the wrong hands, it could lead to unauthorized actions on your AWS resources or potential security breaches. Therefore, removing the access keys associated with the 'root' user minimizes risks.\n\n## Instructions\n\n1. **Sign in to the AWS Management Console:** Firstly, sign in to your AWS account as a 'root' user.\n\n2. **Navigate to IAM:** On the AWS Management Console main page, navigate to the Identity and Access Management (IAM) service.\n\n3. **Go to security credentials:** Click on your account name at the top-right corner of the console. From the drop-down, select 'My Security Credentials'.\n\n4. **Delete Root Access Key:** If any access keys are present, you will see them listed here. You can select an access key and delete it.\n\nRemember, it's better to create IAM users with specific permissions for everyday tasks and keep your 'root' user credentials secure and seldom used.\n\n## Conclusion\nRegularly rotating and carefully handling access keys strengthens your AWS security posture. Built on the principle of 'least privilege', the best practice recommends using the 'root' user only for necessary tasks. Deleting access keys associated with 'root' is a step towards achieving AWS security best practices."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the mentioned AWS control can be categorized into security risks and potential financial implications. \n\n1. Security Risks: The 'root' user account in AWS has unlimited privileges. If the access keys linked to this account fall into the wrong hands, they could use these privileges to manipulate all aspects of the AWS account. This could include accessing or deleting data, modifying running resources, or even creating new resources. \n\n```markdown\n    * Data Loss or Corruption: Unauthorized access to the AWS 'root' account may result in data loss if the user maliciously deletes or modifies data stored in the account. This could severely disrupt business operations, especially if there are no backup measures in place.\n    \n    * Unauthorized Access to Confidential Data: The 'root' user has access to all data stored on the platform. Thus, an unauthorized user could access sensitive or confidential data, leading to potential breaches of privacy and security regulations.\n```\n\n2. Financial Implications: \n\n```markdown\n    * Additional AWS Charges: If the 'root' access keys are misused, there could be unwarranted costs to your AWS account. For instance, an unauthorized user could spin up instances or use services that lead to extra charges.\n\n    * Regulatory Fines: If a data breach occurs due to misuse of the 'root' access keys, there can be serious regulatory repercussions, including hefty fines. This would be particularly relevant if the AWS account contains sensitive data (like customer information, health records, etc.). Regulations like the GDPR in Europe can impose fines of up to 4% of the annual global turnover, and they take data\n\n    * Repercussions with Customers: If customer data is compromised, it could lead not only to lost business but also compensations or lawsuits filed by customers.\n\nFor these reasons, it is recommended that access keys associated with the 'root' user be deleted and that tasks be performed using AWS IAM users, groups, and roles with the necessary permissions.\n```\n\nIt's worth noting that this doesn't mean the cost is completely avoidable. Regular audits, security practices adoption, employee training, and more are required to ensure this doesn't occur, which also comes with cost implications. However, these costs are much less than the potential cost of non-compliance with the control."
            ],
            "x-kaytu-usefulness-example": [
                "Multinational Corporation Example:\n\nABC Corp is a multinational company that has recently migrated to AWS Cloud. They have multiple regional offices spread across the globe, each having its own team of engineers working on various AWS Services. To maintain security, they have different IAM (Identity and Access Management) users for each individual so that everyone has specific roles and responsibilities.\n\nOne day, an audit revealed that they still have active root access keys. Considering this as a potential security threat, the IT manager at ABC Corp decided to delete the root access keys. The benefits include:\n\n1. Reduced Risk: Deleting the root access keys eliminates the risk of a security breach that could give unauthorized users access to all AWS services and resources.\n2. Regulatory Compliance: Compliance requirements often dictate that root user access keys should not be used and should be deleted.\n3. Principle of Least Privilege: Deleting the keys ensures that all users operate under the principle of least privilege, meaning they only have the permissions necessary to perform their jobs.\n4. Improved Access Control: With the root access keys deleted, all access is through IAM users, which makes it easier to manage and control who has access to the AWS account."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_1",
        "Title": "4.1 Ensure unauthorized API calls are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms.",
        "QueryID": "aws_log_metric_filter_unauthorized_api",
        "DocumentURI": "policies/aws_cis_v200_4_1.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.1"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS provides a service called CloudTrail that captures all the API calls made in your AWS environment. This can include calls made from the AWS Management console, SDKs, CLI (Command Line Interface), and other AWS services. \n\nCloudTrail logs are delivered to an S3 bucket and can also be directed to CloudWatch Logs or an external SIEM environment. This makes it very easy to centrally manage, search, and analyze all API activity. \n\nIf you direct CloudTrail logs to CloudWatch Logs, you can also create metric filters and alarms. A metric filter extracts data from the logs and creates a metric that you can graph or alert on. Alarms are used to notify you when a particular event occurs or when the value of a metric meets a certain condition. \n\nHere's what the AWS control may look like in markup:\n\n```\n# Real-Time Monitoring of API Calls with AWS \n\nAWS CloudTrail service records all API calls in your AWS environment, capturing key information such as the user who made the call, the return values, and more.\n\n## Directing CloudTrail Logs \n\nCloudTrail logs can be directed to an AWS S3 bucket, CloudWatch Logs, or an external SIEM environment. This provides central management of all API activity, making it easy to search and analyze data.\n\n```markdown\naws cloudtrail create-trail --name MyTrail --s3-bucket-name myBucket --is-multi-region-trail\n```\n\n## Creating Metric Filters and Alarms \n\nOnce logs are directed to CloudWatch Logs, metric filters and alarms can be established. Metric filters extract data from logs and create a corresponding metric. \n\n```markdown\naws logs put-metric-filter --log-group-name MyLogGroup --filter-name MyFilter --filter-pattern ERROR --metric-transformations metricsName=MyErrorMetric,metricNamespace=MyNamespace,metricValue=1\n```\n\nAlarms can be created to notify when a particular event occurs or the value of a metric meets a certain condition.\n\n```markdown\naws cloudwatch put-metric-alarm --alarm-name MyAlarm --metric-name MyErrorMetric --namespace MyNamespace --statistic SampleCount --period 300 --threshold 1 --comparison-operator GreaterThanOrEqualToThreshold --evaluation-periods 1 --actions-enabled --alarm-actions arn:aws:sns:us-east-1:012345678912:MyNotificationTopic\n```\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the AWS control about real-time monitoring of API calls can have several potential costs. Here's a breakdown in markup format:\n\n1. **Security Breaches:** Without real-time monitoring, suspicious activities may not be identified promptly. This could lead to security breaches. Such breaches can lead to unintended data leakage which might result in financial losses or harm a company's reputation.\n\n2. **Financial Costs:** Security breaches, as mentioned above, may result in significant direct financial loss. Additionally, a lack of API call monitoring could lead to wasteful consumption of resources (e.g., if a malicious actor is abusing your APIs). \n\n3. **Regulatory Fines:** Depending on the companyâ€™s market, there could be legal and regulatory implications for failing to implement appropriate security controls. This could result in hefty fines and penalties from regulatory bodies.\n\n4. **Operational disruption:** If real-time monitoring of API calls is not implemented and a breach or any unexpected activity occurs, it can cause immense operational disruption to sort out the issue and restore normalcy, during which the service might not be usable leading to potential loss of business.\n\n5. **Reputation Damage:** Any security breach can damage a company's reputation leading to a loss of business, reduction in client trust and disruption to important partnerships.\n\nHere's an example of how the above points could be represented in markup:\n\n```markdown\n- **Security Breaches:** Increased risk of unnoticed suspicious activities leading to security breaches, resulting in potential unauthorized data access, financial losses, and irreparable reputational damage.\n- **Financial Costs:** Increased financial implications due to potential security breaches and wasteful consumption of resources.\n- **Regulatory Fines:** Potential legal and regulatory implications, leading to fines and penalties based on the non-compliance to necessary security controls.\n- **Operational Disruption:** Potential service disruption and increased overhead in case of unexpected activities or breach situations.\n- **Reputation Damage:** Negative impact on company reputation and trustworthiness with clients and partners can lead to a direct and indirect loss of business.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "An e-commerce company uses a variety of AWS services for its operations, like EC2 instances for hosting its website, S3 Buckets for storing product images, and DynamoDB for storing user data. They also use custom APIs for various functionalities like user registration, order placement, and payment processing, all of which are of critical importance to their business operations. \n\nThey have recently experienced some suspicious activities that led to slower performance of these APIs, affecting their website's overall performance. To investigate this further and to instantly detect any abnormal activities in the future, they decide to use AWS CloudTrail for tracking all API calls.\n\nBy directing their CloudTrail Logs to CloudWatch Logs, they can monitor these activities in real-time. This strategy allows them to create metric filters and alarms for specific actions like unusually high numbers of API calls, calls from strange locations, or calls at odd hours, which could potentially suggest nefarious behavior.\n\nMoreover, they can also send these logs to an external SIEM environment, enabling them to conduct a more thorough analysis of their security events and improve their security posture.\n\nHere, the usefulness of this AWS control is quite evident, as it not only aids in detecting potentially harmful activity in real-time but also helps in maintaining overall system health and business continuity.\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_5_1",
        "Title": "5.1 Ensure no Network ACLs allow ingress from 0.0.0.0/0 to remote server administration ports",
        "Description": "The Network Access Control List (NACL) function provide stateless filtering of ingress and egress network traffic to AWS resources. It is recommended that no NACL allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389, using either the TDP (6), UDP (17) or ALL (-1) protocols.",
        "QueryID": "aws_vpc_network_acl_remote_administration",
        "DocumentURI": "policies/aws_cis_v200_5_1.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Network Access Control List (NACL)\n\nThe **Network Access Control List (NACL)** is a function provided by **Amazon Web Services (AWS)**. It's main role is to provide stateless filtering of both incoming (ingress) and outgoing (egress) network traffic to AWS resources. This control adds a layer of security by controlling who can access your AWS resources.\n\nAccess control is done based on the port number and the protocol type (like TCP, UDP or ALL).\n\n## Security Recommendation\n\nFor best security practices, it's recommended that no Network Access Control List (NACL) should permit unrestricted ingress access to remote server administration ports. Ports such as the Secure Shell (SSH) on port 22 and Remote Desktop Protocol (RDP) on port 3389 should be handled with caution.\n\n## Protocols and Port Numbers\n\n- TCP (Transmission Control Protocol, protocol number 6)\n- UDP (User Datagram Protocol, protocol number 17)\n- ALL (includes all protocols, representative number -1)\n\nThe unrestricted inbound access can lead to unauthorized access to your resources, which may pose significant security risks. Therefore, you should use NACLs to restrict access to only trusted entities.\n\nRestricting the access to these ports to specific IP addresses or ranges can greatly reduce the threat of harmful activities like data breaches or other malicious cyber activities targeted at your AWS resources."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS Control mentioned above is critical and can result in significant security risks and potential financial losses. To understand this better, let's break it down: \n\n1. **Security Risk:** Non-compliance means allowing unrestricted ingress access to remote server administration ports, like SSH (port 22) or RDP (port 3389). These ports are often targeted by hackers for initiating cyber attacks as gaining access to these could lead to unauthorized access to sensitive data, potentially leading to data breaches.\n\n2. **Potential Data Breach:** If a hacker manages to exploit these open ports, they could potentially gain access to sensitive data stored on your AWS resources. This could cause a data breach which could lead to massive fines if it is found that compliance regulations were not met along with loss of customer trust and potential lawsuits.\n\n3. **Financial Loss:** In addition to regulatory fines and potential legal action, recovery from a data breach can be extremely costly. This can include cost of additional security measures, damage control, informing customers, compensation for lost data, and more.\n\n4. **Damage to Reputation:** Beyond the immediate security and financial implications, allowing such lax security can severely damage the reputation of a company. Once customer trust is lost due to carelessness with their data, it could take a long time to regain it, if itâ€™s ever regained at all.\n\n5. **Loss of Business Continuity:** Post breach, the affected company may need to shut down certain operations to deal with the breach, resulting in further potential financial loss.\n\nTherefore, complying with recommended AWS control like the one mentioned above is crucial, as the risks associated with non-compliance far outweigh any potential short-term benefits or conveniences."
            ],
            "x-kaytu-usefulness-example": [
                "An example instance where the Network Access Control List (NACL) proves its usefulness is when setting up an AWS environment for a new web application. The team is dispersed across different geographies and requires access to the instances through SSH (Secure Shell) for administration.\n\nTo secure the environment, instead of allowing anyone to access, only specific IP addresses should be allowed to perform SSH. This could be achieved via AWS NACL. \n\nFor this, a NACL can be created, allowing SSH traffic (port 22) only from those specific IP addresses. Thus, even if there are attempts from other IP addresses trying to connect via SSH, the NACL blocks them, thereby maintaining the security of the AWS resources.\n\nThis is further useful, if, in future any of the team members leave or the specific IP addresses are no longer safe to be allowed SSH access, the NACL could be easily updated, helping to manage the security of the AWS resources effectively.\n\n```\nExample:\n\n# NACL configuration in AWS NACL \n```json\n{\n    \"egress\": [\n        {\n            \"protocol\": \"6\", \n            \"ruleAction\": \"allow\", \n            \"egressRuleNumber\": 100, \n            \"cidrBlock\": \"0.0.0.0/0\", \n            \"portRange\": {\n                \"from\": 0, \n                \"to\": 65535\n            }\n        },\n        {\n            \"protocol\": \"17\",\n            \"ruleAction\": \"allow\",\n            \"egressRuleNumber\": 200,\n            \"cidrBlock\": \"0.0.0.0/0\",\n            \"portRange\": {\n                \"from\": 0,\n                \"to\": 65535\n            }\n        }\n    ],\n    \"ingress\": [\n        {\n            \"protocol\": \"6\", \n            \"ruleNo\": 100, \n            \"ruleAction\": \"allow\", \n            \"cidrBlock\": \"\u003cspecific-ip-address\u003e/32\", \n            \"portRange\": {\n                \"from\": 22, \n                \"to\": 22\n            }\n        },\n        {\n            \"protocol\": \"17\",\n            \"ruleNo\": 200,\n            \"ruleAction\": \"allow\",\n            \"cidrBlock\": \"\u003cspecific-ip-address\u003e/32\",\n            \"portRange\": {\n                \"from\": 22,\n                \"to\": 22\n            }\n        }\n    ]\n}\n```\nIn the above JSON, the `ingress` section manages the incoming traffic and the `egress` section manages the outgoing traffic. The `cidrBlock` in the `ingress` section is set to the specific IP addresses from which SSH access is allowed. This IP address should be replaced with the actual IP details.\n```\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_5",
        "Title": "1.5 Ensure MFA is enabled for the 'root' user account",
        "Description": "The 'root' user account is the most privileged user in an AWS account. Multi-factor Authentication (MFA) adds an extra layer of protection on top of a username and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their username and password as well as for an authentication code from their AWS MFA device.",
        "QueryID": "aws_iam_root_user_mfa_enabled",
        "DocumentURI": "policies/aws_cis_v200_1_5.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.5"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control - Root User and Multi-Factor Authentication (MFA) \n\n## Root User Account\n\nThe **root user** account is the most privileged user in an AWS account. This user has permission to access all resources in the account. It is often the first account created when setting up AWS and has unrestricted access to all AWS services and resources in the account. \n\n## Multi-Factor Authentication (MFA)\n\nTo enhance the security measures, AWS recommends the use of **Multi-factor Authentication (MFA)**. MFA adds an additional layer of protection to the sign-in process of the AWS account. \n\nWith MFA enabled, the sign-in process consists of two distinct stages:\n\n1. **Username and Password:** Initially, when a user attempts to sign in to an AWS website, they are prompted to enter their username and password.\n\n2. **Authentication Code:** After this, they are asked to provide an authentication code that's generated from their AWS MFA device. \n\nThese two-factor authentication process ensures that even if a hacker steals your password, they won't be able to access your account without also having your MFA device. \n\nBy enforcing MFA, organizations can drastically reduce the likelihood of unauthorized access to their AWS accounts.\n\n## Summary\n\nBy utilizing the root user account and enabling MFA, you can effectively manage access and enhance the security of your AWS account. It's important to understand the significance of these features and use them appropriately to ensure maximum security."
            ],
            "x-kaytu-noncompliance-cost": [
                "The failure to comply with the AWS control of enabling Multi-factor Authentication (MFA) for the 'root' user account can result in several potential costs or consequences:\n\n1. **Security Breaches**: The 'root' user account has the most privileges in an AWS account, including access to all resources and the ability to change the security configuration settings. If this account is compromised, it can result in unauthorized access, data breaches, alteration, or deletion of data. The subsequent reputational damage and loss of client trust could even lead to loss of business. \n\n2. **Financial Loss**: If an unauthorized individual gains access to your AWS account's 'root' account without MFA, they can potentially run up large costs by using extensive AWS resources. The cost of unauthorized usage of these resources will be billed directly to your AWS account.\n\n3. **Non-Compliance Penalties**: If your organization is subject to any regulatory requirements such as GDPR, HIPAA, or PCI DSS, failure to comply with these mandatory secure access controls can result in severe penalties, fines, and legal repercussions.\n\n4. **Interruption of Service**: In the event of a security breach, AWS may need to suspend or limit services to mitigate the potential damage. This down-time can negatively impact your business operations, resulting in potential loss of revenue and customer satisfaction.\n\nTherefore, it is vitally important to always enforce MFA for the 'root' user account in your AWS console to mitigate these risks and costs."
            ],
            "x-kaytu-usefulness-example": [
                "AWS Root account refers to the account which has complete access to all AWS services and resources in the account. By enabling Multi-factor Authentication (MFA) for this 'root' account, companies can add an extra layer of security to prevent unauthorized entries. \n\nConsider a 'tailored news services' company that manages dozens of popular news services around the world. The company uses AWS services for hosting and to store millions of metadata for genuine news articles. AWS 'root' account is only used by a few top engineers in the company.\n\nUnfortunately, a phishing attempt tricked one of the engineers and attackers acquired the 'root' account's username and password. However, as the company had MFA enabled for the 'root' account, attackers were unable to access the AWS services as they didn't have the authentication code generated by the engineer's AWS MFA device. Thus, the MFA requirement in this scenario saved the company from a potential threat and demonstrated the usefulness of enabling MFA for 'root' account in AWS Control."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_3",
        "Title": "3.3 Ensure the S3 bucket used to store CloudTrail logs is not publicly accessible",
        "Description": "CloudTrail logs a record of every API call made in your AWS account. These logs file are stored in an S3 bucket. It is recommended that the bucket policy or access control list (ACL) applied to the S3 bucket that CloudTrail logs to prevent public access to the CloudTrail logs.",
        "QueryID": "aws_cloudtrail_bucket_not_public",
        "DocumentURI": "policies/aws_cis_v200_3_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "CloudTrail is a service provided by AWS (Amazon Web Services) that keeps track of API calls made within your AWS account. It logs each one, creating a record that can be reviewed later if needed. This can be useful for keeping an eye on your account's activity, for debugging, and for auditing purposes.\n\nThis data is stored in an S3 bucket. S3, short for Simple Storage Service, is AWS's scalable storage platform. Each bucket is a container for data that is stored in S3. \n\nIt is advised that the S3 bucket where CloudTrail logs are stored should have a bucket policy or an access control list (ACL) in place to block public access to the logs. This is to ensure that data within the bucket remains secure and isn't accessible to anyone who doesn't have the necessary permissions. \n\nBelow is the explanation in markup format:\n\n```markdown\n# AWS CloudTrail and S3 Bucket\n\n**CloudTrail** is a service by Amazon Web Services (AWS) that records every API call made in your AWS account.\n\nThese log files are stored in an AWS **S3 bucket**. S3 is AWS's scalable storage platform, where each bucket serves as a container for data storage. \n\nIt's highly recommended to set a bucket policy or an access control list (ACL) on the S3 bucket that stores CloudTrail logs, to **prevent public access** to these logs. This measure helps ensure data security by restricting access only to individuals with the necessary permissions.\n```\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control can result in significant costs, both direct and indirect, to your organization. These costs may include:\n\n1. **Security Breaches**: The most significant cost of non-compliance is the potential for a security breach. If the CloudTrail logs, which contain detailed records of all the API calls within your AWS account, are accessible by unauthorized entities, this can potentially lead to exposure of sensitive data and information to it being misused. This can include these actors potentially manipulating your resources or gaining unauthorized access.\n\n2. **Regulatory fines**: If your organization must comply with certain regulations or standards (e.g., GDPR, HIPAA, PCI-DSS), non-compliance with these controls can lead to substantial fines and penalties.\n\n3. **Loss of customer trust and business reputation**: A breach of security or data privacy can lead to a significant loss of trust among your customers or users, potentially leading to loss of business and damage to your organization's reputation.\n\n4. **Incident Response and Remediation Costs**: If a security breach occurs due to non-compliance, the costs associated with investigating the breach, remediating the issue, and restoring services can be substantial.\n\n5. **Potential Legal Costs**: Depending on the nature of the data leaked or the consequences of the security breach, your organization could also face legal repercussions, including lawsuits or other legal actions, leading to potential legal costs.\n\nIt is essential to ensure the S3 bucket which stores the CloudTrail logs is protected to prevent these potential risks and associated costs. This is best practice to maintain security and compliance within your AWS environment."
            ],
            "x-kaytu-usefulness-example": [
                "For example, a large ecommerce website might utilize several AWS resources, involving many API calls occurring within their AWS account. The CloudTrail service would log all these API calls, providing a record that includes not only the API call details but also the user who made the action, the time of the call, and the source IP address. This information can be invaluable for auditing, debug problems or detecting misuse of the system. \n\nHowever, these logs can contain sensitive information that, if made public, could compromise the security of the ecommerce site. Therefore, by applying a bucket policy or ACL that prevents public access to the CloudTrail logs stored in an S3 bucket, the ecommerce site can retain the benefits of logging API calls while protecting itself from potential security breaches. \n\nThis could be particularly useful in cases where suspicious activity is detected, as the company would have a record of all API calls to help investigate the issue. At the same time, the security measures applied to the S3 bucket would ensure that this information cannot be accessed by unauthorized users."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_2",
        "Title": "4.2 Ensure management console sign-in without MFA is monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms.",
        "QueryID": "aws_log_metric_filter_console_login_mfa",
        "DocumentURI": "policies/aws_cis_v200_4_2.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS provides several services that can help you monitor API calls in real-time. These include Amazon CloudTrail, CloudWatch Logs, and external Security Information and Event Management (SIEM) environments. \n\nAWS CloudTrail is a service that logs all API calls for your AWS account. This includes calls made through the AWS Management Console, AWS SDKs, command line tools, and higher-level AWS services. The logs generated by CloudTrail provide valuable information for security analysis and compliance audits.\n\nTo monitor these API calls in real-time, you can direct CloudTrail Logs to Amazon CloudWatch Logs. Amazon CloudWatch Logs is a service that monitors, stores, and accesses log files from AWS services and applications in near real-time. You can then use CloudWatch to create metric filters and alarms based on the contents of these logs. \n\nMetric filters define the terms and patterns to look for in log data as it is sent to CloudWatch Logs. You can think of a metric filter as a way to identify specific events, patterns, or behaviors in your logs. Once you've defined these metric filters, you can then set alarms on them. Alarms in CloudWatch Logs send notifications or automatically change the resources you are monitoring based on rules that you define.\n\nApart from CloudWatch Logs, you can also direct CloudTrail Logs to an external SIEM environment for real-time monitoring. SIEM systems provide real-time analysis of security alerts generated by applications and network hardware. They are typically used to log security data and generate reports for compliance purposes.\n\nThus, real-time monitoring of API calls can be achieved in AWS by integrating CloudTrail, CloudWatch Logs, and potentially, an external SIEM system. Corresponding metric filters and alarms can then be established to notify you of specific events or incidents."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the control that requires real-time monitoring of API calls through directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment can result in costly consequences, and they include:\n\n1. **Increased Security Risks**: Without real-time monitoring of API calls, your infrastructure is exposed to an increased risk of security threats and data breaches. This may lead to costly remediation processes, potential penalties for non-compliance, and reputational damage. \n\n2. **Reactive Rather Than Proactive Problem Resolution**: Non-compliance to this control can change your strategy from proactive to reactive. In case of an issue or a system anomaly, there would be a delay in detecting it, which further increases the time needed for resolution. This can result in downtime, interrupting important operations, which may lead to potential loss in revenue and customer satisfaction.\n\n3. **Absence of Audit Trails**: Non-compliance to this measure also means you won't have the necessary logs available for auditing purposes. This could be a breach of regulatory compliance in some sectors, leading to hefty fines.\n\n4. **Reduced Troubleshooting Capabilities**: The absence of CloudTrail Logs also means less data and insights for troubleshooting. Addressing application and server errors can potentially take much more time, reducing overall service availability and quality.\n\n5. **Potential Compliance Failures**: Especially for industries like Healthcare or Finance, not having real-time monitoring of API calls can lead to non-compliance with industry regulations and standards such as HIPAA, PCI-DSS, and GDPR, which can result in huge fines and penalties. \n\nOverall, non-compliance to this control of real-time monitoring of API calls may result in both direct costs (like fines for regulatory non-compliance, remediation costs for addressing breaches or vulnerabilities) and indirect costs (like damage to brand reputation, loss of customer trust, and potential loss of business)."
            ],
            "x-kaytu-usefulness-example": [
                "Suppose you have an e-commerce application running on AWS that relies heavily on various API calls for functionality like adding items to the cart, deleting items, checking out etc. Recently, you have noticed some irregularities and suspect that unauthorized API calls are being made, which could potentially lead to data leakage or breach.\n\nBy directing CloudTrail Logs to CloudWatch Logs, you can monitor these API calls in real time. You can set up metric filters to watch for specific API calls that should not be used. If such a call is detected, an alarm can be triggered which immediately notifies your security team to investigate the incident. Besides, you can also set up anomaly detection, which uses machine learning to recognize the normal pattern of API usage and alerts when the pattern changes due to irregular API calls.\n\nAdditionally, integration with an external SIEM environment can help in deeper analysis of the detected discrepancies, correlating events across different sources and better protection against potential threats.\n\nSo, in this instance, the real-time monitoring of API calls using AWS Control helps in early detection and prevention of potential security threats, thereby maintaining the integrity and security of your e-commerce application."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_6",
        "Title": "1.6 Ensure hardware MFA is enabled for the 'root' user account",
        "Description": "The 'root' user account is the most privileged user in an AWS account. MFA adds an extra layer of protection on top of a user name and password. With MFA enabled, when a user signs in to an AWS website, they will be prompted for their user name and password as well as for an authentication code from their AWS MFA device. For Level 2, it is recommended that the root user account be protected with a hardware MFA.",
        "QueryID": "aws_iam_root_user_hardware_mfa_enabled",
        "DocumentURI": "policies/aws_cis_v200_1_6.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.6"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "## AWS Control: MFA for Root User\n\nAWS (Amazon Web Services) recommends enabling Multi-Factor Authentication (MFA) for the 'root' user account for an additional layer of security. The root user account is the highest privilege user in an AWS account, with unrestricted access to all resources in the account.\n\n### What is MFA?\n\nMulti-Factor Authentication (MFA) is a security measure that requires multiple forms of verification to authenticate a user's identity. This helps safeguard access to data and applications, making it harder for potential attackers to gain access.\n\nWith MFA, users sign in to AWS services will be prompted for their username and password, along with an authentication code from their MFA device.\n\n### Level 2: Using Hardware MFA for Root User\n\nWhile software MFA devices are acceptable, AWS recommends using a hardware MFA device to protect the root user account at level 2. This offers the highest level of security for your AWS resources.\n\n```markdown\n**Recommendation:**\n\nTo protect your AWS resources, enable MFA for your root user account. For the best security, consider using a hardware MFA device. This way, even if your password is compromised, an attacker cannot access your AWS resources without your MFA device.\n```\n\n### Enabling MFA:\n\nFollow these steps to enable MFA for your root user account:\n\n1. **Sign in** to the AWS Management Console as the root user.\n2. In the navigation pane, choose **Your Account**.\n3. Under **Security**, choose **Enable MFA**.\n4. Follow the instructions to add a hardware MFA device.\n\n```markdown\n**Note:**\nWhile MFA helps secure your account, it's also important to regularly review and reduce AWS account root user credentials. This prevents the potential for escalated privileges and unauthorized access.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control can be costly in multiple ways:\n\n- **Security Breach Cost**: If the root user account (which has the highest level of access) is compromised, it can lead to a potential security breach. Unauthorized users can alter your AWS services, data theft, destruction of infrastructure, and also misuse the environment for illicit activities like hosting malicious content or perpetrating DDOS attacks. The cost of rectifying this can vary widely depending on the scale and severity of the breach, but it is often high.\n\n- **Regulatory Fines**: Non-compliance with recommended security measures can lead to substantial fines or sanctions from regulatory bodies, particularly if the breach involves sensitive or personally identifiable information.\n\n- **Business Downtime**: If the infrastructure is compromised, it will likely result in your business operations getting halted, resulting in significant financial losses.\n\n- **Reputation Damage**: A security breach can cause severe damage to a company's reputation, eventually affecting customer trust, which can have long-term financial consequences.\n\n- **Recovery and Investigation Costs**: A security breach often involves the cost of identifying the breach, investigation, data recovery, notifying customers, and reinforcing security measures.\n\nTo mitigate all these risks and associated costs, it is highly advised to protect the root user account with a hardware MFA."
            ],
            "x-kaytu-usefulness-example": [
                "For Example:\n\nCompany ABC hosts their website on an AWS server. The root user account manages all aspects of the website, from server configuration to databases. The root user account has the highest level of access and a breach could lead to serious consequences, including data loss or unauthorized access.\n\nTo safeguard against such potential breaches, the company decided to use Multi-Factor Authentication (MFA) for their root user account. They chose to use a hardware MFA for the level 2 protection, providing an extra layer of security.\n\nThe MFA enabled them to secure their account with an additional piece of evidence, ensuring that even if the root user's password was compromised, an attacker would still need physical possession of the MFA device to access their account. This significantly reduced the chance of unauthorized access.\n\nWith the MFA in place, whenever the root user tries to log in, they are prompted to enter a unique authentication code generated by their MFA device, along with their usual username and password. This secure system provides the necessary protection for the root user account, ensuring the website remains secure and the company's data is adequately protected. \nThis actionable control allows Company ABC to reinforce their security posture and protect their assets against potential phishing attacks and other cyber threats."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_4",
        "Title": "3.4 Ensure CloudTrail trails are integrated with CloudWatch Logs",
        "Description": "AWS CloudTrail is a web service that records AWS API calls made in a given AWS account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service. CloudTrail uses Amazon S3 for log file storage and delivery, so log files are stored durably. In addition to capturing CloudTrail logs within a specified S3 bucket for long term analysis, realtime analysis can be performed by configuring CloudTrail to send logs to CloudWatch Logs. For a trail that is enabled in all regions in an account, CloudTrail sends log files from all those regions to a CloudWatch Logs log group. It is recommended that CloudTrail logs be sent to CloudWatch Logs.",
        "QueryID": "aws_cloudtrail_trail_integrated_with_logs",
        "DocumentURI": "policies/aws_cis_v200_3_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.4"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "```markdown\n# AWS CloudTrail\n\nAWS CloudTrail is a web service designed to store and monitor all AWS API calls made on a specified AWS account. \n\n## Features of AWS CloudTrail\n\n- Records comprehensive details of each API call, including:\n\t- The identity of the API caller\n\t- The time of the API call\n\t- The source IP address of the API caller\n\t- The request parameters\n\t- The response elements returned by the AWS service.\n\n- Utilizes Amazon S3 for the storage and delivery of log files to ensure durability. \n\n- Enables the capture of CloudTrail logs within a specified S3 bucket for long-term analysis. \n\n- Facilitates real-time analysis by allowing CloudTrail to be configured to send logs to CloudWatch Logs.\n\n- For a trail that is enabled in all regions within an account, CloudTrail sends log files from every region to a CloudWatch Logs log group. \n\n\u003e *Note: It is recommended that CloudTrail logs be sent to CloudWatch Logs for effective monitoring and analysis.*\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control of configuring AWS CloudTrail to send logs to CloudWatch Logs may result in several potential costs:\n\n1. **Security risks**: Without proper analysis and monitoring of CloudTrail logs using CloudWatch Logs, your organization may overlook suspicious activity or potential threats occurring within your AWS environment. This may eventually lead to data breaches, cyber attacks, and unexpected regulatory penalties for noncompliance with specific requirements in data protection regulations.\n\n2. **Inefficient troubleshooting**: CloudTrail logs are valuable sources of data for debugging and troubleshooting. Failure to adequately store and analyze these logs can make it challenging to identify and resolve issues in your AWS services. It might lead to longer downtimes and consequently result in financial losses due to interrupted services.\n\n3. **Governance and compliance challenges**: Organizations in regulated industries are required to maintain and monitor detailed logs for audit purposes. If you don't send CloudTrail logs to CloudWatch, you may fail an audit for not having sufficient visibility over API activities in your AWS account. This could result in hefty fines and penalties for non-compliance. \n\n4. **Increased operational costs**: Without the ability to monitor logs in real-time and set alerts for potential issues, you may face higher operational costs. Manual monitoring and late detection of issues can result in larger operational overhead and more resources spent on issue detection and rectification.\n\nTherefore, it is crucial to maintain compliance with this AWS control to mitigate security risks, improve troubleshooting efficiency, stay audit-ready, and maintain operational efficiency."
            ],
            "x-kaytu-usefulness-example": [
                "CloudTrail can be incredibly useful in enforcing compliance and security in an AWS environment. For example, consider a large company that stores sensitive customer data in its AWS environment. It is required by law and company policies to maintain strict control over who accesses the data, when they access it, and what they do with it. \n\nWith AWS CloudTrail, the company can keep a detailed record of every API call made within their AWS account. This includes the identity of the person or service making the call, the source IP address, the parameters of the request, and the elements returned by the service.\n\nHere is a sample scenario: Suppose there is a data breach and customer data is leaked. The IT team of the company can use CloudTrail logs to find out the exact time the data was accessed, which account accessed it, the IP address from which the access was made, and what operations were performed. \n\nFurthermore, this detailed logging could work as a deterrent for internal threats since anyone with access to the data knows that their actions are being recorded. \n\nAdditionally, these logs could assist the IT team with troubleshooting issues across the AWS environment as they provide valuable info on the requests and responses of the AWS services.\n\nMarkdown Format:\n\n```markdown\n- **Compliance and Security**: AWS CloudTrail provides detailed records of every API call made within an AWS account, offering invaluable data for enforcing compliance and maintaining security of data stored in AWS.\n\n- **Incident Response**: In the event of a data breach or other security incident, CloudTrail logs can be used to identify the time of access, the account used, the originating IP address, and the executed operations.\n\n- **Deterrence for Internal Threats**: Knowing that every single action made within an AWS account is logged could deter internal threats from misusing their access rights.\n\n- **Troubleshooting Tool**: CloudTrail logs provide valuable info about the requests and responses of AWS services which can serve as a valuable resource for troubleshooting issues in the AWS environment.\n```\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_5_2",
        "Title": "5.2 Ensure no security groups allow ingress from 0.0.0.0/0 to remote server administration ports",
        "Description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389, using either the TDP (6), UDP (17) or ALL (-1) protocols.",
        "QueryID": "aws_vpc_security_group_remote_administration_ipv4",
        "DocumentURI": "policies/aws_cis_v200_5_2.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "AWS Security Groups function as virtual firewalls which regulate inbound (ingress) and outbound (egress) traffic for AWS resources such as EC2 instances. In other words, they determine which traffic is allowed to reach the instances and which traffic is allowed to depart from the instances.\n\nThese security groups are defined as stateful filters. This means the response to a request is automatically allowed, regardless of any rules specified, creating two-way communication for that specific session, even if only an inbound rule is specified.\n\nHowever, it's recommended practice to not allow unrestricted ingress access to certain ports that are typically used for remote server administration. SSH (Port 22) and RDP (Port 3389) are examples of such ports. SSH (Secure Shell) is a protocol used by system administrators to access and manage servers remotely. RDP (Remote Desktop Protocol) is another protocol used by system administrators to manage servers remotely, most commonly, Windows servers.\n\nUnrestricted ingress access refers to giving any IP address on the internet permission to access these above-mentioned ports.\n\nTCP (6), UDP (17), and ALL (-1) are the names for specific Internet protocols; the numbers in parentheses represent their identifiers. TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are both transport protocols. The TCP protocol is connection-based and offers error checking and correction, while UDP is connectionless.\n\nIn summary, this AWS control suggests to limit access to administrative ports like RDP and SSH on your instances. This can prevent unauthorized access and potential security threats. It's advisable to only allow traffic from trusted IP addresses or networks."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can have several potential costs:\n\n1. **Security Risk**: Allowing unrestricted access to server administration ports like SSH (22) and RDP (3389) potentially opens up your AWS resources to malicious activities like brute force attacks, unauthorized access, and data breaches. In worst-case scenarios, hackers could gain full control over your system.\n\n2. **Financial Impact**: A successful attack can result in data theft, data loss or system downtime, each of which can lead to significant financial loss. Additionally, you might incur legal costs from lawsuits if sensitive data is compromised.\n\n3. **Compliance Violations**: If your system is storing or processing sensitive data (e.g., personal identifying information, credit card information, health records, etc.), unrestricted access could lead to compliance violations (like GDPR, HIPAA, PCI DSS) which can result in hefty fines and damage to reputation.\n\n4. **Operational Impact**: Unrestricted access to administrative ports can lead to system instability if an unauthorized user manipulates the system or if the system becomes compromised. This could result in operational downtime and loss of productivity.\n\n5. **Reputation Damage**: Security breaches can lead to significant reputation damage. Customers may lose trust in an organization that cannot adequately protect its systems and data, leading to a loss of business."
            ],
            "x-kaytu-usefulness-example": [
                "Consider the case where a company has deployed a web service on AWS. The web service is contained within an EC2 instance and the company has set up a security group to control network access to that EC2 instance. \n\nBy correctly setting the inbound and outbound rules on the security group, the company ensures that only allowed network traffic can interact with their EC2 instance. For example, they could allow HTTPS (port 443) and HTTP (port 80) traffic from anywhere (0.0.0.0/0) to interface with their web service while denying all other traffic types. \n\n```markdown\nInbound Rules:\n| Type  | Protocol | Port Range | Source       |\n|-------|----------|------------|--------------|\n| HTTP  | TCP      | 80         | 0.0.0.0/0    |\n| HTTPS | TCP      | 443        | 0.0.0.0/0    |\n\nOutbound Rules:\n| Type  | Protocol | Port Range | Destination  |\n|-------|----------|------------|--------------|\n| ALL   | ALL      | ALL        | 0.0.0.0/0    |\n```\n\nThey can also ensure that remote server administration ports like SSH (port 22) and RDP (port 3389) are restricted to specific IP addresses only. This means only the authorized devices from the company network can access these administration ports, thereby limiting the risk of unauthorized access. For example, \n\n```markdown\nInbound Rules:\n| Type | Protocol | Port Range | Source       |\n|------|----------|------------|--------------|\n| SSH  | TCP      | 22         | 192.168.1.0/24  |\n```\nFollowing such recommended strategies with AWS Security Groups can significantly enhance the security of their AWS resources, minimizing potential attack vectors."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_3",
        "Title": "4.3 Ensure usage of 'root' account is monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms.",
        "QueryID": "aws_log_metric_filter_root_login",
        "DocumentURI": "policies/aws_cis_v200_4_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS (Amazon Web Services) provides services like CloudTrail and CloudWatch which allow users to monitor activity within their AWS environment. \n\nCloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account, by logging all the API calls made on your account.\n\nCloudWatch is a monitoring and observability service. You can use it to collect monitoring and operational data in the form of logs and metrics from a single platform.\n\nTo monitor API calls in real-time, you can use CloudTrail to capture logs of all the API activity and then direct these logs to CloudWatch. Alternatively, you can use an external Security Information and Event Management (SIEM) environment.\n\nHere is this in a markup format:\n\n```\nAWS provides services like **CloudTrail** and **CloudWatch** for monitoring activities. \n\n- **CloudTrail** is a service for governance, compliance, operational auditing, and risk auditing of your AWS account by logging all the API calls.\n\n- **CloudWatch** is a monitoring and observability service used to collect monitoring and operational data in the form of logs and metrics.\n\nTo monitor API calls in real-time, **CloudTrail** captures logs of all the API activity and then directs these logs to **CloudWatch**. Alternatively, one can use an external **Security Information and Event Management (SIEM)** environment.\n```\n\nOnce you have your logs in CloudWatch or in a SIEM, you can set up **metric filters and alarms**. \n\nMetric filters allow you to search logs for specific phrases, values, or patterns and CloudWatch alarms let you know when particular changes occur, this could be changes to your AWS resources or changes within your application. \n\nThis way, you can effectively monitor your API calls in real-time."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS Control could lead to various potential costs:\n\n1. **Undetected Security Threats:** Without real-time monitoring of API calls, unauthorized access, unusual activities, or security breaches might not be detected promptly, leading to potential damage.\n\n2. **Lack of Data for Incident Analysis and Forensics:** If a security incident does occur, the absence of adequate logs could hinder the investigation and forensics, making it harder to understand what happened and how to prevent it from happening again.\n\n3. **No Accountability and Traceability:** API call logs provide a history of actions taken, allowing you to trace which user did what and when. Without these logs, it becomes impossible to hold individuals accountable for their actions.\n\n4. **Risk of Non-compliance With Regulations:** Depending on the regulations your business is subject to (like GDPR, HIPAA, etc.), you may be required to maintain proper logging and monitoring. Non-compliance could lead to hefty fines or legal consequences.\n\n5. **Unexpected Resource Usage and Costs:** Without monitoring, it's harder to spot unexpected or abnormal API usages, which could indicate a problem or inefficiency that's costing you money.\n\n6. **Reputation Damage:** If your company experiences a breach or data loss due to the lack of security measures in place, it could damage your reputation and lose customer trust.\n\nTherefore, complying with this AWS control is critical to ensure security and operational efficiency."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, an eCommerce company's website is highly dependent on its APIs to ensure smooth interaction between its frontend and backend systems. The APIs are frequently called upon to fetch product information, process payments, manage customer data, etc. At peak shopping times, such as during a holiday sale, API usage increases drastically. \n\nIn such a scenario, real-time monitoring of API calls using AWS CloudTrail Logs and CloudWatch Logs can provide the following benefits:\n\n1. **Performance Monitoring**: The company can identify any unusual activity or spikes in API calls that could indicate performance issues. Timely detection allows the issue to be addressed before it impacts the user experience.\n\n2. **Security**: By monitoring API calls, the company can detect and respond to security threats quickly. For example, repeated failed API calls from an unfamiliar IP address might indicate a hacking attempt which could trigger an alarm.\n\n3. **Troubleshooting**: If any API starts to fail or return errors, real-time monitoring can quickly pinpoint the problem API, helping in rapid troubleshooting and minimizing downtime.\n\n4. **Capacity Planning**: Over time, monitoring data can help the company understand their normal API usage patterns and plan for required capacity during peak periods.\n\n5. **Compliance**: If the company is subject to regulatory compliance that requires oversight of data access, CloudTrail logs can provide the necessary audit trail.\n\nBy directing these logs to an external Security Information and Event Management (SIEM) system, the e-commerce company can also cross-reference this data with other security and event data for a more holistic view of the systemâ€™s behavior.\n\n```markdown\nExample:\n- [Real-time API monitoring](#)\n  - [CloudTrail Logs](#): For recording API activity\n  - [CloudWatch Logs](#): For real-time monitoring and alerting\n  - [SIEM system](#): For cross-referencing with other security and event data\n  - Benefits:\n    - [Performance Monitoring](#)\n    - [Security](#)\n    - [Troubleshooting](#)\n    - [Capacity Planning](#)\n    - [Compliance](#)\n```\nAbove example can help an eCommerce company in maintaining high performance, security, and user experience of its website."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_5",
        "Title": "3.5 Ensure AWS Config is enabled in all regions",
        "Description": "AWS Config is a web service that performs configuration management of supported AWS resources within your account and delivers log files to you. The recorded information includes the configuration item (AWS resource), relationships between configuration items (AWS resources), any configuration changes between resources. It is recommended AWS Config be enabled in all regions.",
        "QueryID": "aws_config_enabled_all_regions",
        "DocumentURI": "policies/aws_cis_v200_3_5.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.5"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/Config"
            ],
            "x-kaytu-explanation": [
                "```markdown\n\n# AWS Config\n\n[AWS Config](https://aws.amazon.com/config/) is a web service offered by Amazon Web Services that allows you to manage the configuration of supported AWS resources in your account. The service captures and tracks the configurations of your AWS resources, enabling you to assess and evaluate your resource configurations. It also allows you to examine the relationships between resources and explore their configuration history.\n\n## Main Features\n\n- ***Configuration Management:*** AWS Config automatically records and organizes resource configurations in your account, making it easy to retrieve, and simplifying compliance auditing.\n\n- ***Relationships Between Resources:*** AWS Config not only logs individual resource configurations, but it also records relationships between resources. This enables you to understand dependency relations between resources within your environment.\n\n- ***Configuration Change Management:*** AWS Config tracks changes in configurations and relationships between resources, notifying you about the changes.\n\nIt is recommended to enable AWS Config in all regions to have a full perspective of your resource configuration and changes, ensuring effective auditing, security, and governance.\n\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with AWS Config control can lead to several potential costs including:\n\n### 1. Financial Costs:\n\nNon-compliance could result in financial costs, either through fines imposed by the governance, legal or regulatory bodies due to non-adherence to the specific mandates or through the significant expenses incurred to rectify the compliance issue.\n\n### 2. Operational Inefficiencies:\n\nWithout AWS Config, you may not have a clear understanding of your AWS resource configurations and relationships. This could lead to operational inefficiencies, such as unnecessary resources or poorly configured resources that increase your costs or reduce the performance of your AWS services.\n\n### 3. Security Risks:\n\nWithout comprehensive configuration management, security vulnerabilities could go unnoticed. As AWS Config records the state of your resources and any changes, it's easier to identify and remediate security holes.\n\n### 4. Audit Failures:\n\nInability to provide proof of compliance during audits, for lack of required data visibility \u0026 audit trails. AWS Config provides a detailed view of the configuration of AWS resources, making compliance reporting easier.\n\n### 5. Damage to Reputation:\n\nWhether it's a security breach or non-compliance with regulatory bodies, either one could damage the companyâ€™s reputation. This could lead to loss of client trust and potential future business.\n\n### 6. Lack of Configuration Management:\n\nWithout enabling AWS Config, organisations might have a tough time managing and tracking configurations which could result in a lack of visibility towards infrastructure changes and pose challenges during troubleshooting.\n\nIn conclusion, the failure in adhering to the AWS Config control could potentially lead to hefty fines, lack throughout understanding of infrastructure \u0026 security, significant operational inefficiencies, and a damaging reputation hammering overall organisational growth. Hence, it's fundamental to comply with this control.\n"
            ],
            "x-kaytu-usefulness-example": [
                "For instance, assume you have an AWS environment with various resources like EC2 instances, S3 buckets, IAM roles, etc. Over time, these resources change, either due to scaling requirements, security needs or software updates.\n\nIn such situations, keeping track of changes manually becomes a very complex process. You may also have to comply with regulatory standards which demand the tracking of all resource changes. Here, AWS Config's ability to track and record changes to AWS resources becomes very significant.\n\n```markup\nFor example, if an EC2 instance's security group is changed, AWS Config will:\n1. Record the configuration details of the EC2 instance before the change.\n2. Log the change event (i.e., changing the security group).\n3. Record the configuration details of the EC2 instance after the change.\n4. Deliver these log files to you.\n\nFurthermore, the AWS Config dashboard provides a clear overview of resources, their configurations, and interrelations. This data can also be used to troubleshoot if any issue arises due to a specific change.\n\nIn addition to operational benefit, AWS Config helps in compliance as well. For example, if you are subject to PCI DSS, you are required to monitor all actions taken by any individual with root or administrative privileges. AWS Config helps fulfil this requirement by recording the history of changes to resources.\n```\n\nHence, enabling AWS Config across all regions is a best practice to monitor, assess, audit, and evaluate the configurations of your AWS resources."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_7",
        "Title": "1.7 Eliminate use of the 'root' user for administrative and daily tasks",
        "Description": "With the creation of an AWS account, a 'root user' is created that cannot be disabled or deleted. That user has unrestricted access to and control over all resources in the AWS account. It is highly recommended that the use of this account be avoided for everyday tasks.",
        "QueryID": "aws_iam_root_last_used",
        "DocumentURI": "policies/aws_cis_v200_1_7.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.7"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# The AWS Root User\n\nWhen you create an AWS account, a **'root user'** is automatically created. This user has complete, unrestricted access and control over all resources in the AWS account and cannot be disabled or deleted.\n\n## Key Points\n \n- The 'root user' has **full permissions** to all resources in your AWS account.\n- This user is **immune** to disabled or deleted.\n  \n## Strong Recommendation\n\nIt is **strongly recommended** that the use of the root user be avoided for everyday tasks. The root user should ideally only be used to perform a few account and service management tasks. This includes:\n  \n  1. Changing the root user password \n  2. Configuring CloudTrail to log API requests\n  3. Viewing certain billing information\n  4. Managing security credentials\n  \nThere can be some serious security implications for utilizing the root user for everyday tasks, and hence these tasks should be handled by IAM users. An IAM user is an entity that you create in AWS to represent the person or application that uses it to interact with AWS. Each user has unique security credentials that aren't shared with others."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS Control can be severe and may include the following:\n\n1. **Security Risk:** If the root user credentials are compromised, the attacker has unrestricted access and control over all AWS resources. They can gain access to sensitive data, modify configurations and potentially incur large costs for your organization.\n\n2. **Economic Impact**: Unrestricted access makes it possible to deploy or terminate any AWS resources leading to unexpected costs.\n\n3. **Loss or Manipulation of Data**: With unrestricted access, a user or attacker can either inadvertently or maliciously delete or manipulate important data from your AWS services.\n\n4. **Non-Compliance with Regulatory Standards**: Many compliance standards require limiting access to sensitive information to only authorized users, and using the root account for regular operations is in direct violation of such protocols.\n\n5. **Account Suspension**: AWS can suspend accounts violating the recommended best practices. In extreme cases, AWS may terminate the account.\n\nTo stay in compliance with this control, always use an IAM user with necessary permissions for everyday tasks and enable multi-factor authentication (MFA) on the root user. Secure the root user's credentials and only use them for necessary account and service management tasks."
            ],
            "x-kaytu-usefulness-example": [
                "In a startup company that uses AWS services for their business, the AWS 'root user' can be essential for the initial setup and configuration of all resources and services. The root user can create other IAM users, assign them specific roles and permissions, and manage all aspects of the AWS account effectively and efficiently.\n\nFor instance, if a Development team is working on an application that requires S3, EC2, and RDS services, the root user can setup these services, create an IAM user specifically for this project, and assign the necessary permissions to this user to manage these services.\n\nHowever, for day-to-day tasks, such as uploading files to S3 or managing EC2 instances, this IAM user should be used instead of the root user. This can help in reducing the risk of accidental changes or deletions, ensuring better security, and managing access more efficiently."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_5_3",
        "Title": "5.3 Ensure no security groups allow ingress from ::/0 to remote server administration ports",
        "Description": "Security groups provide stateful filtering of ingress and egress network traffic to AWS resources. It is recommended that no security group allows unrestricted ingress access to remote server administration ports, such as SSH to port 22 and RDP to port 3389.",
        "QueryID": "aws_vpc_security_group_remote_administration_ipv6",
        "DocumentURI": "policies/aws_cis_v200_5_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "AWS Security groups are essentially a virtual firewall for your service on Amazon Web Services (AWS) that controls the inbound and outbound network traffic to AWS resources. The term \"stateful filtering\" means it keeps track of network connections, and based on the state of the connection, it can allow or reject data packets.\n\nIn terms of a security perspective, it is recommended to not allow unrestricted ingress access to remote server administration ports. Essentially, this means it is not safe to allow anyone from any IP address to access your server's administration ports. \n\nThe examples given, SSH to port 22 and RDP to port 3389, are common ports for Secure Shell and Remote Desktop Protocol, respectively. If unrestricted access is allowed, it could lead to potential breaches of security. Someone could attack your server via these ports, so limiting the access here, perhaps only to certain trusted IP addresses, increases the security of your system.\n\nHere it is in markup format:\n\n```markdown\n# AWS Control\n\n**Security groups** in Amazon Web Services (AWS) are your virtual firewall that controls ingress (incoming) and egress(outgoing) network traffic to your service. This is done through a process called **stateful filtering** where the state of the network connection is monitored and data packets are allowed or rejected accordingly.\n\nFor security reasons, it is recommended to **restrict ingress access** to remote server administration ports, like:\n- **SSH** (Secure Shell) typically on `port 22` \n- **RDP** (Remote Desktop Protocol) typically on `port 3389`.\n\nUnrestricted access to these administrative ports could lead to potential security breaches, so it's best to limit the access to these ports, possibly only allowing access from trusted IP addresses.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control might lead to several potential costs:\n\n1. **Data Breaches**: Unrestricted access to server administration ports increases the vulnerability to cyber-attacks, which could lead to unauthorized access, data breaches, and data theft. The cost of a data breach is high, both in terms of tangible financial losses and intangible losses like reputation damage and loss of trust among customers and stakeholders.\n\n2. **Regulatory Fines**: Non-compliance could also lead to financial penalties from regulatory bodies. Depending on the severity of the breach and the nature of the data compromised, these fines can be substantial. For instances, under the GDPR, fines can reach up to 4% of the company's annual global revenue, or â‚¬20 million, whichever is higher.\n\n3. **Operational Disruptions**: Unauthorized access to servers could lead to operational disruptions in services and applications, impacting business operations and affecting the user experience, which could lead to financial losses and customer dissatisfaction.\n\n4. **Costs of Remediation**: In case of a breach, the organization would need to bear the expenses related to identifying and fixing the vulnerability, strengthening the security infrastructure, and possibly the costs associated with notifying the customers and other stakeholders about the breach.\n\n5. **Legal and Settlement Costs**: In case the data breach leads to lawsuits, the organization would have to bear legal fees, and settlement costs could also be significant.\n\n###### Disclaimer:\nThe actual costs would vary based on the nature of the non-compliance, the magnitude of the breach, the regulatory environment, and a variety of other factors."
            ],
            "x-kaytu-usefulness-example": [
                "An example of the usefulness of this AWS control can be seen in a scenario where a company XYZ is hosting their web application on AWS EC2 instances. They have a team of developers and administrators who require access to these instances for deployment, maintenance, and troubleshooting purposes. \n\n```\n## Example:\n\n1. **Control Access to SSH (Port 22):** As per the AWS Control, XYZ can create a security group that only allows access to SSH (port 22) from the specific IP addresses of their developers or administrators. This secures the instances by preventing unauthorized or malicious access.\n\n```markdown\n    Security Group Name: XYZ_SSH_Access\n    Inbound Rule: SSH TCP 22 Source: [Developers/Administrators IP Addresses]\n```\n\n2. **Control Access to RDP (Port 3389):** Similarly, if they have any Windows instances that require Remote Desktop access, they can restrict that to only the required IPs as well. \n\n```markdown\n    Security Group Name: XYZ_RDP_Access\n    Inbound Rule: RDP TCP 3389 Source: [Developers/Administrators IP Addresses]\n```\n\n3. **Restrict Unnecessary Ports:** In addition, they can ensure that no other ports are unnecessarily open which might pose a potential security risk. This adheres to the principle of least privilege, by allowing only the necessary access and nothing more.\n\n```markdown\n    Security Group Name: XYZ_Default_Security_Group\n    Inbound Rules: Only necessary ports and sources\n    Outbound Rules: Only necessary ports and destinations\n```\n\nBy using the AWS Control of stateful filtering of ingress and egress network traffic, based on security groups, the company XYZ effectively protects its AWS resources from unauthorized and potential malicious access. This also helps in regulatory compliance, preventing data breaches and ensuring system availability.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_4",
        "Title": "4.4 Ensure IAM policy changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established changes made to Identity and Access Management (IAM) policies.",
        "QueryID": "aws_log_metric_filter_iam_policy",
        "DocumentURI": "policies/aws_cis_v200_4_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.4"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "This AWS control refers to the practice of monitoring API calls in real-time using Amazon's CloudTrail Logs and CloudWatch Logs services, or an external Security Information and Event Management (SIEM) solution.\n\nHere's a breakdown of this control:\n\n## CloudTrail Logs:\n\nAmazon CloudTrail is a service that records AWS API calls for your account. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by the AWS service.\n\n## CloudWatch Logs:\n\nAmazon CloudWatch Logs can be used to monitor, store, and access your log files from Amazon EC2 instances, AWS CloudTrail, and other sources. With CloudWatch Logs, you can monitor your systems and applications in near real-time using your existing log files.\n\n## Security Information and Event Management (SIEM):\n\nSIEM is a technology set that consolidates data from multiple sources, correlates the data to find anomalies and takes corrective action when needed. It's a useful tool to provide a holistic view of a companyâ€™s information security.\n\n## Metric Filters and Alarms:\n\nCloudWatch allows you to create metric filters to extract values from the log events, transform them, and publish the results as CloudWatch metrics. You can then set alarms based on those metrics to automatically react to changes in your data.\n\nFor example, you can set a metric filter to monitor changes made to Identity and Access Management (IAM) policies. IAM is a web service that helps you securely control access to AWS resources. \n\nWhen this control is properly implemented, you can identify unusual or unauthorized activities such as changes in IAM roles and permissions. If such activities are detected, CloudWatch can trigger notifications or automated functions to respond. This proactive approach to monitoring can help you detect and address potential security incidents faster."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS Control of real-time monitoring of API calls could have several impacts on an organization:\n\n1. **Security Risk**: Without monitoring, suspicious activities or unauthorized access cannot be detected in real time. This increases the risk of a data breach, which can harm the company financially and reputationally.\n\n2. **Regulatory Penalties**: For certain industries, real-time monitoring may be a legal requirement. Failure to comply with these regulations could result in hefty fines.\n\n3. **Operational Issues**: If changes made to Identity and Access Management (IAM) policies aren't properly monitored and managed, it could lead to system outages or access issues for users, which could interrupt your operations.\n\n4. **Auditing Challenges**: Without proper logging and monitoring, audits become increasingly difficult and time-consuming as the necessary data may not be readily available.\n\n5. **Financial impact**: In the event of a security breach, the financial implications can be massive. Not only will there be penalties, but the organization may also incur costs related to fixing the breach, potential lawsuits, and lose business due to damaged trust and reputation.\n\nTherefore, it's essential for organizations to comply with this control to avoid these potential risks and costs."
            ],
            "x-kaytu-usefulness-example": [
                "For example, a large company uses multiple AWS services across various departments. The IT department wants to keep track of all the API calls, especially related to Identity and Access Management (IAM) policies, for security and auditing purposes. \n\nTo achieve this, they configured CloudTrail to monitor and log all the API requests and directed these logs to CloudWatch Logs, setting up real-time monitoring. They also established corresponding metric filters and alarms for changes made to IAM policies.\n\nOne day, an unexpected change was made to an IAM policy. The real-time monitoring system detected this change and triggered an alarm. This allowed the IT team to immediately identify the change and investigate who made it and why. If it was an unauthorized change, they could quickly revert that change mitigating potential security risks.\n\nThis shows how CloudTrail, CloudWatch, metric filters, and alarms can be useful in protecting AWS resources and data by providing real-time monitoring and immediate alerts on activities that could potentially compromise security."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_5",
        "Title": "4.5 Ensure CloudTrail configuration changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, where metric filters and alarms can be established. It is recommended that a metric filter and alarm be established changes made to Identity and Access Management (IAM) policies.",
        "QueryID": "aws_log_metric_filter_cloudtrail_configuration",
        "DocumentURI": "policies/aws_cis_v200_4_5.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.5"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "# AWS Control - Real-time Monitoring of API Calls \n\nAWS control provides real-time monitoring of API calls which can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security Information and Event Management(SIEM) environment. This real-time API monitoring is achieved through the setting up of metric filters and alarms on these logs. \n\n## AWS CloudTrail \nCloudTrial is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. It provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. \n\n## AWS CloudWatch \nAmazon CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real-time. You can collect and track metrics, collect and monitor log files, set alarms, and automatically react to changes in your AWS resources. \n\n## Security Information and Event Management(SIEM)\nSIEM is a comprehensive threat management solution that combines Security Information Management (SIM) and Security Event Management (SEM) principles for advanced analytics, compliance, and reporting.\n\n## Metric Filters and Alarms \nA metric filter extract metric observations from ingested events and transforms them into CloudWatch metrics. It can be created for different types of logs like VPC flow logs, AWS CloudTrail, and others.\n\nWhen significant changes are made to the Identity and Access Management(IAM) policies, an alarm can be established to notify the necessary parties or trigger specific actions. \n\nThis allows administrators to maintain tight control over who can access which services and resources, and ensure they can quickly respond should any unauthorized changes or access attempts occur.\n\n**Example:**\n\n```\n {\n   \"MetricName\": \"IAMPolicyChanges\",\n   \"Dimensions\": [\n       {\n           \"Name\": \"IAM\",\n           \"Value\": \"PolicyChanges\"\n       }\n   ],\n   \"Timestamp\": \"2017-08-14T12:00:00Z\",\n   \"Value\": 1.0,\n   \"Unit\": \"Count\"\n }\n```\nThis AWS Control, combines logs, metrics and alarms in AWS CloudWatch and CloudTrail to monitor API calls in real-time. This gives better insights into API usage, better system health checks, pinpointing of issues, and improved security and compliance."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the aforementioned AWS Control could be significant and it mainly revolves around security risks, potential financial costs, and reputational damage. Here's how:\n\n1. **Security Risks**: Without real-time monitoring of API calls, an organization can be left vulnerable to security threats. Misuse of API calls or unauthorized changes made to IAM policies could lead to data breaches or potential unauthorized access to secure information.\n\n2. **Potential Financial Costs**: Following AWS security best practices is not just about protecting data, but also about avoiding potential financial penalties. If an organization doesn't comply with security measures, it can face hefty fines for not adhering to data protection regulations depending on the jurisdiction it operates in.\n\n3. **Operational Issues**: Not monitoring API calls in real-time could lead to operational disruptions. It could remain unnoticed if somebody made changes to IAM policies that affect the functioning of important services.\n\n4. **Reputational Damage**: In case of a data breach or unauthorized access due to non-compliance with this control, customer trust and brand reputation could be severely damaged, leading to potential business losses.\n\n5. **Regulatory Non-Compliance**: Non-compliance to security measures could also lead to non-compliance with certain industrial regulations or standards such as GDPR, PCI DSS, HIPAA, etc., which may result in additional fines and penalties.\n\nAs a result, it is of utmost importance to have real-time monitoring of API calls enabled and proper alarm systems set up for changes made to IAM policies. Compliance to this AWS control allows for proactive identification and mitigation of security risks, thereby safeguarding the organization's confidential data and services."
            ],
            "x-kaytu-usefulness-example": [
                "In an organization, the security team may need to keep track of any changes made to IAM policies to ensure there aren't any unexpected or unauthorized changes that could potentially lead to breaches. \n\n    ```markdown\n    Example:\n    \n    A company XYZ has set up their AWS environment with multiple departmental accounts that are managed through IAM policies. Some employees in the company have superuser privileges that allow them to modify these policies, which can be a risk.\n\n    To mitigate this risk, the company has enabled real-time monitoring of API calls with CloudTrail, sending the logs to CloudWatch Logs. They have established a metric filter that keeps an eye on API calls related to IAM policy changes, for example the `iam:CreatePolicy`, `iam:CreatePolicyVersion` and `iam:DeletePolicy` actions. \n\n    Additionally, an alarm has been configured to notify the security team in an instance if such an event occurs. This allows the team to promptly review the relevant user, time, and change details, and follow up with the employee or close the security hole if the policy change was not part of standard procedures.\n\n    By doing so, Company XYZ has additional security and control over policy changes, reducing the risk of unexpected surprises or unwanted access to AWS resources.\n    ```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_8",
        "Title": "1.8 Ensure IAM password policy requires minimum length of 14 or greater",
        "Description": "Password policies are, in part, used to enforce password complexity requirements. IAM password policies can be used to ensure password are at least a given length. It is recommended that the password policy require a minimum password length 14.",
        "QueryID": "aws_iam_account_password_policy_min_length_14",
        "DocumentURI": "policies/aws_cis_v200_1_8.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.8"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "```markdown\n# AWS Control - Password Policies\n\nAmazon Web Services (AWS) Identity and Access Management (IAM) service allows administrators to manage access to AWS services and resources securely. A crucial part of this management is enforcing password policies.\n\n## Password Complexity Requirements\nPassword complexity requirements are part of password policies that seeks to improve password security. These requirements could include:\n\n- Minimum password length\n- Required mix of uppercase \u0026 lowercase letters\n- Inclusion of one or more numerical digits\n- Inclusion of special characters\n\n## IAM Password Policies\nIAM password policies are a means of enforcing password complexity requirements. IAM enables you to manage permissions and grant access to your AWS resources by creating individual users within your AWS account and assigning policies to them.\n\n## Recommended Minimum Password Length\nTo enhance the security of your Amazon IAM, it is recommended that the password policy require a minimum password length of 14. Lengthier passwords are generally more difficult to crack, providing an extra layer of security against unauthorized access.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS Control can be significant and impactful to an organization. These costs are majorly tied to the potential security risks and legal consequences that can arise due to a lack of enforcing strong password policies. The following points explain these costs in detail:\n\n1. **Increased Security Risks**: Weak passwords are one of the most common ways that unauthorized individuals can gain access to sensitive data and systems. If the password policy does not require a minimum length of 14, it potentially enables the creation of easily guessable passwords. This makes the system vulnerable to brute force or dictionary attacks, leading to data breaches. The cost associated with a data breach is substantial, both financially and reputationally.\n\n2. **Legal and Compliance Penalties**: Depending on the nature of a business, various laws and regulations such as GDPR, HIPAA, etc, mandate strict data protection practices, including password policies. If an organization does not comply with these, they might face legal penalties, fines, and regulatory sanctions.\n\n3. **Loss of Trust**: If a data breach occurs due to weak passwords, it can lead to a significant loss of customer and stakeholder trust. This can have a long-term impact on the organization's reputation, leading to a loss of business.\n\n4. **Costs of Incident Response and Remediation**: In the event of a security incident, costs will be incurred in identifying the breach, stopping it, analyzing the impact, and remedying the breach. These could include bringing in outside expertise, purchasing new equipment, and implementing new security measures.\n\n5. **Downtime Costs**: If a security incident results in downtime for the company's systems or services, there may be direct financial losses from lost transactions, as well as indirect losses from lost productivity.\n\nImplementing a strong password policy, including length requirements, is a relatively low-cost measure that can prevent these potentially significant costs."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nConsider a corporate business setting where all the organization's sensitive data and information are stored on AWS. The IT department in this organization needs to adhere to stringent security measures to protect this information. \n\nBy using IAM password policies, they can inculcate good password habits among the employees which significantly reduces the potential risks. For instance, if they set a policy that requires a minimum password length of 14, they ensure all user passwords are not easy to crack, thereby denying unauthorized access to their AWS resources.\n\nHere is a simple markup or JSON code for this password policy:\n\n```\n{\n    \"PasswordPolicy\": {\n        \"MinimumPasswordLength\": 14,\n        \"RequireSymbols\": true,\n        \"RequireNumbers\": true,\n        \"RequireUppercaseCharacters\": true,\n        \"RequireLowercaseCharacters\": true,\n        \"AllowUsersToChangePassword\": true\n    }\n}\n```\n\nThis policy enforces a password length of at least 14 characters, needing at least one symbol, one number, one uppercase letter, one lowercase letter, and allows users to change their password when required."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_5_4",
        "Title": "5.4 Ensure the default security group of every VPC restricts all traffic",
        "Description": "A VPC comes with a default security group whose initial settings deny all inbound traffic, allow all outbound traffic, and allow all traffic between instances assigned to the security group. If you don't specify a security group when you launch an instance, the instance is automatically assigned to this default security group. Security groups provide stateful filtering of ingress/egress network traffic to AWS resources. It is recommended that the default security group restrict all traffic.",
        "QueryID": "aws_vpc_default_security_group_restricts_all_traffic",
        "DocumentURI": "policies/aws_cis_v200_5_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.4"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "**AWS Control: VPC Default Security Group**\n\nA Virtual Private Cloud (VPC) in AWS is provided with a default security group. The primary configurations of this security group are as follows:\n\n- All inbound traffic is denied.\n- All outbound traffic is permitted.\n- All traffic between instances that are assigned to the security group is allowed.\n\nWhen launching a new instance, if no specific security group is selected, the instance is automatically assigned to this default security group. \n\nSecurity groups in AWS serve to provide stateful filtering of ingress (incoming) and egress (outgoing) network traffic to resources in AWS. This means the security groups are designed to examine each packet of data within its context, not as an isolated unit, providing more nuanced and secure filtering.\n\nFor added security, it is recommended that this default security group is configured to restrict all traffic. This can then be customized as needed, allowing only necessary and secure connections. This ensures that newly launched instances that are automatically assigned to this group are not left open to potential threats. \n\nIn summary, the AWS VPC default security group plays a critical role in protecting resources within the AWS environment and needs to be precisely managed to ensure maximum security."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS control that the default security group should restrict all traffic could lead to several significant repercussions.\n\n**1. Increased Vulnerability**\n\nWithout appropriate restrictions, an AWS VPC becomes unnecessarily exposed to potential threats. Any authorized or unauthorized device can connect to instances in the AWS environment, leading to an increased risk of harmful activities from DDOS attacks to malicious code execution.\n\n**2. Network Congestion**\n\nNot restricting traffic can result in resources being used unnecessarily leading to potential network congestion. If the AWS environment is being used for critical functions, the excess traffic might cause service disruption due to high latency or unavailability of resources.\n\n**3. Data Breach Risk**\n\nThe open nature of the traffic means that the potential for a data breach is heightened. Malicious actors could potentially infiltrate the environment and gain access to sensitive data. The consequences of a data breach can be significant, from the loss of customer trust to hefty regulatory fines.\n\n**4. Regulatory Compliance**\n\nMany regulations such as GDPR, HIPAA, and others require organizations to implement strong access controls and protect data at rest and in transit. Non-compliance with the AWS control may likely mean non-compliance to these regulations, leading again to potential fines, legal action, and damage to reputation.\n\n**5. Difficulty in Traffic Analysis**\n\nFailing to restrict traffic could lead to difficulties in analyzing network traffic patterns. It can be challenging to differentiate legitimate traffic from potential threats when all traffic is allowed. This can also create difficulties in identifying the cause of any security incidents that occur.\n\nTo summarize, non-compliance to this AWS control has potential to put your organization at significant security risk, impair the operation of your services, cause regulatory non-compliance and make breach detection more difficult."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, let's consider a digital advertising company requiring to run numerous advertisement campaigns for various clients at any given time. These campaigns require a huge amount of data processing, and the company decides to store and process this data on the AWS Cloud.\n\nWhen the company sets up their Virtual Private Cloud (VPC) on AWS, the default security group settings provide robust initial safeguards against potential undesired traffic. By default, it denies all inbound traffic, which means no unapproved traffic could potentially access the company's resources on AWS. It allows all outbound traffic as the company expects to send data to several clients. Finally, it enables all traffic between instances assigned to the security group by default, letting various sections of the company's cloud infrastructure to communicate with one another seamlessly.\n\nAt the onset, the company might not restrict all traffic to their default security group for initial setup, testing, and data migration. Once the company's cloud infrastructure is fully operational, they should set the default security group to restrict all traffic as suggested, strengthening the security around their cloud resources. The IT team can specify exceptions separately for different processes, such as specific instances requiring to communicate with each other or transfer data outside effectively.\n\nThis use of the default security group in a VPC on AWS improves the overall security of the cloud resources by only allowing necessary traffic, thereby lowering the chances of a potential cybersecurity incident for the company."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_6",
        "Title": "3.6 Ensure S3 bucket access logging is enabled on the CloudTrail S3 bucket",
        "Description": "S3 Bucket Access Logging generates a log that contains access records for each request made to your S3 bucket. An access log record contains details about the request, such as the request type, the resources specified in the request worked, and the time and date the request was processed. It is recommended that bucket access logging be enabled on the CloudTrail S3 bucket.",
        "QueryID": "aws_cloudtrail_s3_logging_enabled",
        "DocumentURI": "policies/aws_cis_v200_3_6.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.6"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "Yes, sure. Below is the AWS control explanation in markup format (markdown). \n\n```\n## S3 Bucket Access Logging\n\nS3 Bucket Access Logging is a feature provided by AWS, which creates a log record of all requests made to your S3 bucket. These logs can give valuable insights on the nature of requests such as the request type, the resources specified in the request, and the exact time and date the request was processed. \n\nHere is an example of access log record:\n\n```\n- Request Type: GetObject\n- Resource: mybucket/myphoto.jpg\n- Time: 06/Mar/2021:14:11:49 +0000\n- Processing Time: 77\n- Source IP: 192.0.2.3\n- User-Agent: [Mozilla/5.0]\n```\n\nIt's recommended to enable bucket access logging on your CloudTrail S3 bucket for security and auditing purposes. This practice also aids in understanding the nature of requests your assets are receiving, which can be beneficial for optimizing costs and performance.\n\n\u003e **Note:** Creating log files for all requests can use a large amount of bucket storage. It's a good practice to frequently archive and delete old log files to free up storage space.\n```\nPlease, substitute the example data in a codeblock with real-world or more relevant examples."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS control of enabling S3 Bucket Access Logging on CloudTrail S3 bucket can lead to several significant costs:\n\n1. **Security Threat Cost**: Non-compliance increases the likelihood and potential impact of a security breach. Without access logging, it's challenging to detective unauthorized activity or access until itâ€™s too late. This can result in significant financial costs from theft of data, disruption to the business, and potential fines for regulatory non-compliance.\n\n2. **Cost of Investigation**: In the event of a security incident, having complete and reliable access logs can significantly speed up and reduce the cost of any investigations. Without these access logs, the time and money required to identify, isolate, and remedy the incident increases dramatically.\n\n3. **Loss of Trust**: If your customers find out about weak security controls or a breach, it could be damaging to the trust that the business has worked to build and maintaining. This trust loss can lead to direct financial loss from lost business and difficulty acquiring new customers.\n\n4. **Regulatory Compliance Cost**: If your organization operates within an industry that has regulations requiring specific security measures and/or logging (such as GDPR, HIPAA, PCI-DSS), non-compliance to this control could result in substantial fines and penalties.\n\n5. **Operational Inefficiency**: Without access logs, IT staff may find it more difficult to troubleshoot application performance issues, which can potentially result in extended downtime and unnecessary operational costs.\n   \n6. **Forensic Costs**: In case of potential data breaches, it is essential to perform forensic analysis to understand the cause and impact of the breach for which logs are crucial. Without logs, the cost of this analysis can significantly increase. \n\nIn conclusion, enabling S3 Bucket Access Logging on the CloudTrail S3 bucket is a critical security control that, if ignored, can result in substantial costs associated with security incidents, regulatory compliance, and operational inefficiency."
            ],
            "x-kaytu-usefulness-example": [
                "An example instance might be if a company wants to audit and monitor the activities in their Amazon S3 bucket. Suppose there is a highly confidential file which is stored in S3 bucket, and the company wants to track which user is accessing this file and when. By enabling S3 Bucket Access Logging, the company can get details about every request made to access that file, such as who (the requester), what (type of request), when (time and date of the request) and how (resources used for the request). \n\nThis not only helps in keeping a record for security purposes but also assists in detecting any anomalous activities or potential security breaches. For example, if an unauthorised user tries to access or delete data, it would be recorded in the access log, allowing for prompt identification and corrective action. \n\nMoreover, in case of any unexpected data loss or alteration, the company could refer to the access logs to determine what led to such incident. The AWS Control of S3 Bucket Access Logging hence ensures enhanced surveillance and control over the data stored in the S3 bucket."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_7",
        "Title": "3.7 Ensure CloudTrail logs are encrypted at rest using KMS CMKs",
        "Description": "AWS CloudTrail is a web service that records AWS API calls for an account and makes those logs available to users and resources in accordance with IAM policies. AWS Key Management Service (KMS) is a managed service that helps create and control the encryption keys used to encrypt account data, and uses Hardware Security Modules (HSMs) to protect the security of encryption keys. CloudTrail logs can be configured to leverage server side encryption (SSE) and KMS customer created master keys (CMK) to further protect CloudTrail logs. It is recommended that CloudTrail be configured to use SSE-KMS.",
        "QueryID": "aws_cloudtrail_trail_logs_encrypted_with_kms_cmk",
        "DocumentURI": "policies/aws_cis_v200_3_7.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.7"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudTrail"
            ],
            "x-kaytu-explanation": [
                "# AWS CloudTrail and Key Management Service (KMS)\n\n**AWS CloudTrail** is a web service provided by Amazon Web Services (AWS) that keeps track of all API calls made for an account. These logs or records of activity are made available to users and resources according to IAM policies. \n\nThe ability to record these API calls helps in auditing and monitoring of an AWS account's activity, providing visibility into resource usage and changes, and compliance reviewing.\n\n**AWS Key Management Service (KMS)** is another managed service provided by AWS. It assists in the creation and management of encryption keys used for encrypting your data. KMS employs Hardwares Security Modules (HSMs) to offer additional protection for these encryption keys.\n\nAccount data is of vital importance and needs to be safeguarded from unauthorized access or disclosure. This is where AWS KMS plays a pivotal role by facilitating the encryption of this data.\n\n## Integration of AWS CloudTrail with KMS\n\nCloudTrail logs are a potential source of sensitive data, making their protection a priority. These logs can be protected by configuring them to utilize server-side encryption (SSE) and Customer Master Keys (CMK) that are created by the customers via AWS KMS. \n\nUsing server-side encryption, your CloudTrail logs are encrypted at rest. Starting from when they are received by the service, during their storage, till their retrieval. Encryption, as well as decryption, are handled transparently and need not concern you. \n\nWhen you use a customer-created CMK for encryption, you retain precise control over the permissions to use the CMK and you are given the ability to revoke those permissions if necessary.\n\nIt is recommended that CloudTrail be configured to use **SSE-KMS** for enhanced protection of your CloudTrail logs. It combines the strengths of SSE with the control that AWS KMS offers, making your security more robust."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS Control can result in several potential costs:\n\n- **Data Breach**: If a malicious actor gains access to your AWS API call logs due to improper encryption, they could gain valuable information about your system and potentially identify vulnerabilities. This could lead to a data breach, that could reveal sensitive customer data, company secrets, or other confidential information. Cost of a data breach can vary, but it generally includes direct financial losses, reputational damage, and legal liabilities.\n\n- **Regulatory Fines**: Many industries are regulated by government bodies or industry groups that mandate certain security measures (like encryption of sensitive data). Non-compliance with these regulations could result in significant fines.\n\n- **Loss of Customer Trust**: If your customers find out (especially through a data breach) that you weren't taking necessary steps to protect their data, they may lose trust in your service and move their business elsewhere.\n\n- **Increased Auditing Costs**: If non-compliance is discovered during an audit, it can increase the time and cost of auditing as auditors may need to perform additional testing to understand the extent of non-compliance and provide recommendations.\n\nHere is the cost explanation in the markup language:\n\n```markdown\n## Cost of Non-compliance to AWS Control\n\n1. **Data Breach**: Unencrypted AWS API call logs might be accessed by malicious threats leading to potential data breaches. This could expose sensitive customer data, leading to direct financial losses, reputation damage, and legal liabilities.\n\n2. **Regulatory Fines**: Non-compliance with certain industry regulations that mandate security measures such as data encryption can result in hefty fines.\n\n3. **Loss of Customer Trust**: Customers may lose trust and move their business elsewhere if they discover that necessary steps to protect their data are not being taken.\n\n4. **Increased Auditing Costs**: The discovery of non-compliance during an audit could lead to increased time and cost of the audit as additional tests might be required to understand the extent of non-compliance and provide recommendations.\n```\n"
            ],
            "x-kaytu-usefulness-example": [
                "`Example Instance:`\n\nA growing e-commerce company is using multiple Amazon Web Services like EC2, S3, DynamoDB, etc., to maintain its large-scale applications. As more team members started to use AWS for various services, tracking who is doing what became difficult for the system admins. Ensuring whether all actions are adhering to company standards and security policies became a task.\n\nTo overcome this challenge, the system admins decided to use AWS CloudTrail for recording all API calls in their AWS account. As CloudTrail logs sensitive company information, they also decided to encrypt the logs using AWS KMS. \n\nBy enabling server-side encryption with KMS managed keys (SSE-KMS) in CloudTrail, they were able to provide an additional layer of security to their logs. The company created a CMK (customer master key) with AWS KMS and made sure that all the trails in their AWS account are encrypted using this CMK.\n\nThe admins were able to access and audit the logs, but due to the encryption, even if someone with malicious intent gained access to the logs, they couldn't read the information without the CMK. \n\nThus, by using AWS CloudTrail with SSE-KMS, the company was able to maintain a secure record of all actions carried out in their AWS environment, ensuring security, compliance and operational audit of their AWS resources."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_9",
        "Title": "1.9 Ensure IAM password policy prevents password reuse",
        "Description": "IAM password policies can prevent the reuse of a given password by the same user. It is recommended that the password policy prevent the reuse of passwords.",
        "QueryID": "aws_iam_account_password_policy_reuse_24",
        "DocumentURI": "policies/aws_cis_v200_1_9.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.9"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS Identity and Access Management (IAM) allows you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources. One of the key aspects of this management is the setting of password policies.\n\nAWS password policies can be configured to prevent the reuse of a given password by the same user. This simply means that once a user has used a specific password, that password cannot be used by the same user again.\n\nHere's how to set this up in markup:\n\n```markdown\n**Configure Password Policy for IAM Users:**\n\n1. Sign in to the AWS Management Console and open the IAM console.\n\n2. In the navigation pane, choose **Account Settings**.\n\n3. In the **Password Policy** section, choose **Change Password Policy**.\n\n4. In the **Prevent password reuse** section, you can specify the number of passwords to remember, and thereby prevent the reuse of old passwords.\n\n5. Choose **Apply password policy**. \n\nThis setting helps to increase the security of your AWS resources by ensuring that users consistently create new and unique passwords.\n```\n\nIt's important to encourage users to create unique and strong passwords. This recommendation is part of best practices in password management and helps enhance the overall security of your AWS environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS control that recommends the prevention of reusing passwords can lead to several costs. \n\n1. **Security Risk**: First and foremost, the cost is in terms of a security breach. If the password policies do not prevent the reuse of passwords, it means an attacker who might have previously obtained a user's password can gain unauthorized access if the user reuses the same password.\n\n2. **Financial Losses**: In case of a breach, the organization might suffer financial losses. This could be through theft of sensitive financial data, disruptions to regular operations, or fines and penalties for non-compliance with regulatory standards.\n\n3. **Reputation Damage**: A security breach could lead to significant damage to the organization's reputation, which can also translate into loss of business and trust from clients and customers.\n\n4. **Data Loss or Corruption**: The attacker having the reused password might access and modify, delete, or even corrupt the data, leading to information loss or heavy expenses in terms of data recovery.\n\n5. **Regulatory Compliance**: Non-compliance with this control could also imply non-compliance with data protection regulations such as GDPR, HIPAA, etc., which can lead to legal consequences and hefty fines.\n\n6. **Operational Inefficiency**: Time and resources may need to be spent on dealing with the aftermath of a security breach, creating operational inefficiency.\n\nThis makes the cost of non-compliance with IAM password policies potentially high and risky. Businesses and organizations should therefore ensure that they prevent the reuse of passwords by putting in place and strictly enforcing robust password policies."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n```markdown\nConsider a scenario where your organization uses AWS resources and you have multiple IAM users with distinct roles and responsibilities. Over time, users may tend to reuse passwords, which might increase the likelihood of unauthorized access if any past or current employee deceitfully uses someone else's earlier credentials. \n\nBy implementing IAM password policies that prevent password reuse, you safeguard your systems by making unauthorized access more difficult. This feature is particularly useful in scenarios where an employee leaves the company, and there might be a risk associated with them knowing current employee passwords they might have previously used. \n\nIn a simple scenario, suppose you have a user 'UserA,' who changes their password every month. Without the password reuse prevention, 'UserA' might cycle between two passwords: 'Password1' and 'Password2.' \n\nImplementing a policy that prevents password reuse forces 'UserA' to create a new password: 'Password3'. As a result, even if someone had access to previous passwords, they cannot use them, hence enhancing AWS security.\n```\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_5_5",
        "Title": "5.5 Ensure routing tables for VPC peering are \"least access\"",
        "Description": "Once a VPC peering connection is established, routing tables must be updated to establish any connections between the peered VPCs. These routes can be as specific as desired - even peering a VPC to only a single host on the other side of the connection.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v200_5_5.md",
        "ManualVerification": true,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.5"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "AWS Control allows for the creation of VPC (Virtual Private Cloud) peering connections, which enables the users to share resources across different VPCs. This is a direct network route using private IP addresses. So, once a VPC peering connection is established, the VPCs can communicate on a private and secure network connection as if they were on the same network, but for the VPCs to communicate over the peering connection, you must update the routing tables.\n\nRouting tables direct the network traffic, defining where the network traffic is directed. For VPC peering to function properly, routing tables in each peered VPC need to be updated so that they include routes towards each other's CIDR blocks (IP address ranges) via the VPC peering connection.\n\nThese routes can be as specific as required. In other words, it's highly flexible - you're not limited to peering entire VPCs together. AWS Control allows you to define specific routes so that a VPC can peer with only a specific host (single device or server) on the other side of the connection.\n\nSo, this control provides not only the ability to create network connections between separate VPCs, but also the specificity to designate individual hosts within those VPCs.\n\nIn markup format it can be defined as:\n\n```markup\n# AWS VPC Peering Control\n\nWith AWS, you can establish **VPC peering connections** which enables sharing of resources across different VPCs. Once established, to enable the VPCs to communicate over the peering connection, routing tables need to be updated to include routes towards each other.\n\nThese routes can be made as specific as *targeting a single host* on the other side of the connection, making this control flexible and versatile.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance with this AWS control can lead to several issues:\n\n1. **Unavailability of Services:** If the routing tables are not properly updated, services and resources might not be reachable across the peered VPCs. This could lead to downtime and unavailability of services that depend on these resources, causing business disruptions.\n\n2. **Security Risks:** Misconfigured routing could potentially expose traffic to unintended networks or resources. This may open up potential security vulnerabilities that could be exploited.\n\n3. **Degraded Network Performance:** Inadequate routing could lead to inefficient network paths, causing slower connection speeds, higher latencies, and reduced overall network performance.\n\n4. **Operational Inefficiencies and Costs:** Investigation and troubleshooting network connectivity issues can consume valuable time and resources. Any downtime or availability issues could also have indirectly associated costs â€“ such as loss of reputation, customer dissatisfaction or SLA-associated penalties.\n\n5. **Audit and Compliance Failures:** If your AWS environment needs to comply with specific regulatory requirements or internal policies that require correct setup and management of VPC connections, then non-compliance with this control could lead to failed audits. This could further result in fees, fines or other legal implications. \n\nEach of these costs could have major implications depending on the criticality of the systems and data involved. As such, proper management of VPC connections including appropriate routing configurations is necessary."
            ],
            "x-kaytu-usefulness-example": [
                "Consider the following scenario:\n\nA company, TechCorp, has two departments, Engineering and Accounting. Each department has their own VPC in the AWS ecosystem, giving them the isolated network environments they need for their unique applications and services. \n\nThe Engineering department, located in the U.S., develops a critical web application hosted on EC2 instances within their VPC. On the other hand, the Accounting department, located in Germany, uses specific financial analytics tools that require data from this application. \n\nTo maintain high security levels, direct access to the application is limited solely to the Engineering department. However, for the Accounting department to function properly, a secure connection is needed to fetch the required data without exposing the whole network to potential threats.\n\nTo address this need, TechCorp establishes an AWS VPC peering connection between both departments' VPCs. With the peering connection, the traffic norm is that networks do not get exposed completely to each other, only necessary resources are shared.\n\nBut, just creating the peering connection alone will not make these resources available, routing tables need to be updated. In our scenario, this will enable the Accounting department to connect to the specific web application host but not any other resources within the Engineering VPC. By amending the routing table, a secure, direct and efficient connection can be established to this one required resource.\n\nHence, by making use of routing tables in a VPC peering connection, TechCorp can maintain strict network isolation while effectively sharing needed resources across departments located in different geographical locations."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_6",
        "Title": "4.6 Ensure AWS Management Console authentication failures are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for failed console authentication attempts.",
        "QueryID": "aws_log_metric_filter_console_authentication_failure",
        "DocumentURI": "policies/aws_cis_v200_4_6.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.6"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS provides two powerful tools for monitoring API calls and handling security events - CloudTrail and CloudWatch.\n\nCloudTrail records API calls for your AWS account. It provides you with logs of all API calls, including the source IP address, the time of the call, and the parameters used.\n\nCloudWatch on the other hand, allows you to collect and track metrics, set and manage alarms, and monitor log files. You can integrate CloudTrail with CloudWatch to actively monitor and take actions upon specific API call patterns.\n\nHere, a Security Information and Event Management (SIEM) environment is another method to analyze security alerts generated by applications in real-time.\n\nAn example of a good implementation for a metric filter and alarm is one that targets failed console authentication attempts.\n\nThe steps are as follows:\n\n- Create a new metric filter in your CloudWatch Logs group that looks for the phrase 'ConsoleLogin: Failure' in your AWS CloudTrail captured logs.\n- This will then be used to increment a count in CloudWatch Metrics every time a new matching event happens.\n- Following this, an alarm is configured on this metric, such that if the count goes above a specified threshold within a certain time period, it can execute an action such as notifying a security administrator for instance.\n\nThis entire setup provides an automatic and real-time security monitoring system that can inform administrators about potential security issues on their AWS accounts."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control could result in several potential costs to an organization:\n\n1. **Security risks:** Without real-time monitoring of API calls, malicious attempts to access your cloud resources could go unnoticed until substantial damage is already done. This could lead to unauthorized access to sensitive data, resulting in a significant breach of information security.\n\n2. **Financial loss:** Should a security breach occur, it can result in financial loss due to business downtime, loss of customer trust, penalties for non-compliance with regulatory standards, and potential lawsuits.\n\n3. **Regulatory penalties:** For businesses operating in regulated industries (such as finance or healthcare), failure to implement appropriate monitoring and alarming can lead to non-compliance with regulations such as PCI-DSS or HIPAA. This can result in substantial fines and penalties, in addition to reputational damage.\n\n4. **Operational issues:** Without sufficient monitoring and alarming, operational issues (like misconfigurations or system failures) may go unnoticed, potentially leading to system unavailability and disruption of business operations.\n\n5. **Troubleshooting difficulties:** If failed console authentication attempts and other events are not properly logged and monitored, it will impair the ability of your IT team to troubleshoot issues when they occur, leading to increased time to resolution.\n\n```\nIn essence, the cost of non-compliance could be quite significant, ranging from financial loss, reputational damage, penalties for non-compliance with regulatory standards, operational disruption, and reduced efficiency.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nLet's say you're in charge of securing a large and complex infrastructure on AWS for your organization. There are numerous configurations, components, and API calls within various services that are challenging to manually track. \n\nHaving real-time monitoring of these API calls through CloudTrail and CloudWatch can assist in noticing potentially malicious activities. For instance, there can be repeated failed console authentication attempts that might signal a brute force attack attempt. \n\nBeing able to catch such activities in real time with CloudTrail, sending the logs to CloudWatch, and setting up appropriate metric filters and alarms allows the Infrastructure or Security Team to swiftly react and apply necessary security measures. The metric filter could be set to pick out logs that indicate failed login attempts, while alarms could be set to notify the relevant team when the count of these filtered events hit a specific threshold within a specific time frame. \n\nThis way, even if someone tries to breach the system via brute force login attempts, the Security Team will have the opportunity to quickly act, mitigating potential harm to the system and enhancing the protection of the company's important data."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_5_6",
        "Title": "5.6 Ensure that EC2 Metadata Service only allows IMDSv2",
        "Description": "When enabling the Metadata Service on AWS EC2 instances, users have the option of using either Instance Metadata Service Version 1 (IMDSv1; a request/response method) or Instance Metadata Service Version 2 (IMDSv2; a session-oriented method).",
        "QueryID": "aws_ec2_instance_uses_imdsv2",
        "DocumentURI": "policies/aws_cis_v200_5_6.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "5.6"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "5"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/EC2"
            ],
            "x-kaytu-explanation": [
                "Sure. Here is the explanation in markup format:\n\n# AWS Metadata Service\n\nWhen working with **EC2 instances** in **AWS**, there's an important service to note, which is the **Metadata Service**. This service can be configured in two different ways:\n\n## Instance Metadata Service Version 1 (IMDSv1)\n\nThis is a **request/response** based method. That is, your instances make a request to the metadata service, and they receive a response back with the required metadata. It's essentially a one time information grab from the metadata service.\n\n## Instance Metadata Service Version 2 (IMDSv2)\n\nUnlike IMDSv1, IMDSv2 is a **session-oriented** method. Here, your instances establish a *session* with the metadata service. This approach is considered more secure as it requires a valid session token, which is generated at the begining of every session. This method can prevent some attacks such as Server Side Request Forgery (SSRF).\n\nTo summarize, when enabling the Metadata Service on AWS EC2 instances, don't forget about the security implications and the different options you have to best suit your use case."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with enabling either IMDSv1 or IMDSv2 could expose sensitive data and configurations to unauthorized individuals or systems, potentially leading to data breaches or system vulnerabilities. Specifically, the following costs and consequences could arise:\n\n1. **Security Breaches**: If an unauthorized individual or system gains access to sensitive metadata (like IAM roles and security credentials), they can potentially misuse this information to gain further access into the system, leading to security breaches.\n\n2. **Financial Costs**: Remedying a security breach can result in significant financial costs, from the immediate costs of identifying and closing the security gap to the potential loss of revenue or fines due to regulatory non-compliance.\n\n3. **Operational disruption**: Depending on the severity of the breach, there may be an operational disruption while the security gap is being addressed. This could result in delays or loss in productivity.\n\n4. **Reputation Damage**: A security breach, especially one that results in a significant loss of data or service availability, can severely damage a company's reputation, potentially leading to a loss in customers.\n\n5. **Regulatory Penalties**: In regulated industries or jurisdictions, non-compliance with specific security measures can result in substantial fines or legal penalties.\n\nTo avoid these costs, it is recommended to utilize IMDSv2, as it provides enhanced security compared to IMDSv1. IMDSv2 is a session-oriented method that requires an initial \"PUT\" request to start the session and obtain a secret token, which needs to be included in subsequent requests. This mechanism reduces the chance of unauthorized access as compared to IMDSv1 which uses a simple request/response method without a session token."
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a scenario where you have a company that uses AWS EC2 instances for its business operations. The company needs to regularly access and update various metadata associated with these instances such as AMI ID, instance type, IAM roles, security groups, etc.\n\nIf the company uses IMDSv1, they might encounter security issues. Any process running on the instance, even those that don't need access to instance metadata, can access the instance metadata, creating a potential security vulnerability.\n\nOn the other hand, if they enable IMDSv2, they benefit from better security protections. This is because unlike IMDSv1, IMDSv2 requires that the requests to the metadata service are not only made from the instance, but also accompanied with a secret token making it harder for unauthorized entities to access the metadata. \n\nThus, enabling IMDSv2 becomes crucial in ensuring the company's instance metadata are safe and access is properly authenticated and authorized, thereby greatly enhancing its business security and data management capabilities."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_8",
        "Title": "3.8 Ensure rotation for customer created symmetric CMKs is enabled",
        "Description": "AWS Key Management Service (KMS) allows customers to rotate the backing key which is key material stored within the KMS which is tied to the key ID of the Customer Created customer master key (CMK). It is the backing key that is used to perform cryptographic operations such as encryption and decryption. Automated key rotation currently retains all prior backing keys so that decryption of encrypted data can take place transparently. It is recommended that CMK key rotation be enabled for symmetric keys. Key rotation can not be enabled for any asymmetric CMK.",
        "QueryID": "aws_kms_cmk_rotation_enabled",
        "DocumentURI": "policies/aws_cis_v200_3_8.md",
        "ManualVerification": false,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.8"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/KMS"
            ],
            "x-kaytu-explanation": [
                "## AWS Key Management Service (KMS)\n\nAWS Key Management Service (KMS) allows you to manage cryptographic keys that control access to your data. One of its features is the ability to rotate the backing key, which is the actual key material stored within the KMS. \n\n### Backing Key\n\nThe backing key is tied to the key ID of the Customer Master Key (CMK) created by the customer. When cryptographic operations, such as encryption and decryption are performed, it's the backing key that performs these functions. \n\n### Automated Key Rotation\n\nIn AWS KMS, the automated key rotation feature retains all previous backing keys. This means that you can continue to decrypt your encrypted data transparently, even when new keys are generated at each rotation.\n\nIt's worth noting that ***it is recommended to enable the CMK key rotation for symmetric keys***. This adds an additional layer of security by regularly changing the CMK. \n\n### Limitations\n\nHowever, ***key rotation cannot be enabled for asymmetric CMK***, which is a limitation of this service."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS Key Management Service (KMS) control that recommends enabling key rotation for symmetric keys can have several important implications:\n\n1. **Security Risk**: Not enabling key rotation increases the risk of a security breach. If a key is compromised and is not rotated, the attacker could decrypt the data encrypted with it. This could lead to unauthorized access to sensitive information.\n\n2. **Regulatory Compliance**: Many industries and regions have strict regulations regarding the secure handling of data, including key rotation. Non-compliance could lead to hefty fines and penalties.\n\n3. **Reputation Damage**: If a security breach occurs due to not rotating keys regularly, this could lead to loss of customer trust and damage to a company's reputation.\n\n4. **Operational Efficiency**: Without enabling automated key rotation, a company would have to manually change the keys, which could lead to errors and increased workload for the security team.\n\n```\nIn conclusion, non-compliance could lead to severe security vulnerabilities, potential regulatory fines and penalties, damage to the companyâ€™s reputation, and possible operational inefficiencies. Therefore, it is crucial to comply with the AWS KMS control and enable CMK key rotation for symmetric keys.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "For example, let's assume you are a CTO at a large healthcare company that is storing sensitive patient records in the AWS Cloud. These records contain highly sensitive information that needs to be securely encrypted to meet compliance requirements and assure clients about their data safety.\n\nWith AWS Key Management Service (KMS), you set up Customer Created customer master keys (CMK) to encrypt and decrypt these records. To improve your security even further, you could enable the key rotation feature available with AWS KMS for symmetric keys. \n\nNow, every year, AWS KMS automatically rotates the backing key associated with your CMK. However, all previously used backing keys are retained, not discarded, ensuring that older data encrypted with those keys can still be decrypted transparently. This results in increased security as active keys are rotated periodically, reducing the risk of a potential breach due to key exposure.\n\nThis automatic key rotation can be particularly invaluable in healthcare industry, where maintaining the confidentiality of patient data is crucial and at the same time allows for minimizing a key management overhead, hence improving efficiency and compliance with industry standards and regulations like HIPAA."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_7",
        "Title": "4.7 Ensure disabling or scheduled deletion of customer created CMKs is monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for customer created CMKs which have changed state to disabled or scheduled deletion.",
        "QueryID": "aws_log_metric_filter_disable_or_delete_cmk",
        "DocumentURI": "policies/aws_cis_v200_4_7.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.7"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "This AWS control is about monitoring the activity on your API calls in real-time to ensure data and system security in your AWS environment.\n\nUsing Amazon's CloudTrail Logs or an external SIEM system, you can oversee and analyse logs for any suspicious activity or anomalies. CloudTrail provides event history of your AWS account activity, including actions taken in your AWS Management Console, AWS SDKs, command line tools, and other AWS services. \n\nCloudWatch Logs is a feature of CloudWatch that you can use to monitor, store, and access your log files from AWS CloudTrail or other sources. \nMetric filters can be set up to turn log data into numerical CloudWatch metrics that you can graph or set an alarm on.\n\nAn alarm can be set to send a notification or automatically make changes to the resources you are monitoring when a specific metric exceeds a predefined threshold.\n\nThe document also recommends setting up a metric filter and alarm for changes in state to 'disabled' or 'scheduled deletion' for customer created CMKs (Customer Master Keys). AWS Key Management Service (KMS) gives you centralized control over the cryptographic keys used to protect your data. The service is integrated with other AWS services making it easier to encrypt data and manage keys.\n\nHere is an example of how it can be written in markdown format:\n\n```markdown\n## Real-time Monitoring of API Calls with AWS\n\n* __CloudTrail Logs__: Provides event history of your AWS account activity. Can be directed to CloudWatch Logs or an external SIEM system for analysis.\n* __CloudWatch Logs__: This feature of CloudWatch can be used to monitor, store, and access log files.\n* __Metric Filters and Alarms__: Metric Filters turn log data into numerical CloudWatch metrics. Alarms notify or makes automatic changes when a specific metric exceeds a threshold.\n* __Customer Master Keys (CMKs)__: The state of customer created CMKs should be monitored for changes to 'disabled' or 'scheduled deletion', to ensure data security.\n```\nBy implementing this control, you are increasing the security and integrity of your AWS assets and data by being able to continuously monitor and act upon any changes in your environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the aforementioned AWS Control relating to monitoring of API calls can result in several adverse impacts, which in turn represent potential costs for an organization.\n\n1. **Security Breach Costs**: Without real-time monitoring of API calls, malicious activity such as unauthorized access or data leaks could go undetected. This can lead to financial loss, damage to company reputation, and even legal repercussions if sensitive information is exposed. The cost of a security breach can be significantly high.\n\n2. **Operational Disruption Costs**: If the CMK (Customer Master Key) changes state to disabled or scheduled for deletion without the organization's knowledge, it may disrupt critical operations dependent on the key. The disruption can lead to productivity loss and potential financial implications arising from the inability to deliver services.\n\n3. **Non-compliance Penalties**: If real-time monitoring is a requirement for regulatory compliance, non-adherence to this control can also lead to penalties and fines levied by regulatory bodies.\n\n4. **Forensic Costs**: In the absence of real-time monitoring and logging, investigating an incident and pinpointing its cause can become far more complex, time-consuming, and expensive. Forensic investigations in the aftermath of an issue can often cost a significant amount.\n\n5. **Recovery Costs**: If real-time monitoring is not in place, it may take longer to discover and respond to adverse events, which can increase the extent of damage and consequently, the cost and complexity of recovery.\n\nTherefore, ensuring real-time monitoring of API calls and proper alarm setup for state changes in customer created CMKs is vital both from a security and operational perspective. It is important to comply with this AWS control to prevent these potential costs."
            ],
            "x-kaytu-usefulness-example": [
                "Luke is a system administrator for a fast-growing startup that runs several applications on the AWS cloud. As a security measure, their company uses AWS Key Management Service (KMS) to create and manage cryptographic keys which are termed as Customer Master Keys (CMKs). \n\nHowever, Luke has noticed some unusual activities involving CMKs. He noticed that some CMKs had been disabled or scheduled for deletion without any given reason. This raised a concern about security or internal issues that could potentially lead to future complications.\n\nTo resolve this issue, Luke decides to implement real-time monitoring of API calls using CloudTrail Logs formatting of API data. These logs are directed to CloudWatch Logs allowing the system to track, store, and access log data from Amazon EC2 instances, AWS CloudTrail, Route 53, and other sources.\n\nTo make this process more effective, Luke established corresponding metric filters and alarms. Every time a CMK is either disabled or scheduled for deletion, an automatic alarm is triggered. Luke receives real-time notifications keeping him informed on the state of every CMK in the system.\n\nThis makes the work more efficient as any unusual activities can be quickly detected and resolved in real-time. Thus, it not only ensures their system's security and performance, but also plays a key role in maintaining the overall health of their AWS environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_8",
        "Title": "4.8 Ensure S3 bucket policy changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for changes to S3 bucket policies.",
        "QueryID": "aws_log_metric_filter_bucket_policy",
        "DocumentURI": "policies/aws_cis_v200_4_8.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.8"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Real-Time Monitoring of API Calls\n\n**Amazon Web Services (AWS)** offers various monitoring tools that help in tracking user activity and resource usage. One way to achieve real-time monitoring of API calls is by using **CloudTrail Logs** in conjunction with **CloudWatch Logs** or an external **Security Information and Event Management (SIEM)** environment. \n\n## CloudTrail Logs\n\nAWS **CloudTrail** is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. It provides event history of AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command-line tools, and other AWS services. \n\nThe CloudTrail Logs record these activities and enable you to spot anomalous behaviour, track changes to your resources and troubleshoot operational issues.\n\n## CloudWatch Logs\n\n**CloudWatch Logs** lets you monitor, store, and access your log files from Amazon EC2 instances, AWS CloudTrail, and other sources. You can then retrieve the associated log data from CloudWatch Logs using the AWS Management Console, CloudWatch Logs commands in the AWS CLI, CloudWatch Logs API, or CloudWatch Logs SDK.\n\n## Metric Filters and Alarms\n\nIn the context of CloudWatch Logs, **Metric Filters** allow you to extract metric observations from ingested events and transform them to data points in a CloudWatch metric. And **Alarms** perform one or more actions based on the value of a metric or expression relative to a threshold over a number of time periods.\n\n## S3 Bucket Policy Changes\n\nIt's recommended to set up a metric filter and alarm for changes to **S3 bucket policies**. AWS S3 (Simple Storage Service) is an object storage service. A bucket policy is used to control the permissions on the bucket level and applies to all objects within that bucket.\n\nIn S3, a bucket policy change may signify unauthorized changes or potential security threats. Creating an alarm for this scenario can help you to quickly identify and rectify potential security lapses.\n\n```markup\nRemember: Effective and efficient use of AWS security services can ensure the reliability, integrity, and safety of your AWS resources.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS Control could potentially result in significant costs for an organization, both in terms of financial loss and damage to reputation. The costs can be categorized into the following areas:\n\n1. **Security Breaches**: Not real-time monitoring of API calls can lead to undetected unauthorized access or malicious activity. If sensitive data stored in S3 buckets is altered or breached, this could lead to significant financial penalties and loss.\n\n2. **Regulatory Penalties**: Certain industries are heavily regulated and require strict adherence to data handling and protection standards. Non-compliance can lead to hefty fines and penalties.\n\n3. **Loss of Customer Trust**: If data breaches occur due to non-compliance, customers may lose trust in the business and switch to competitors. This can lead to loss of revenue and negative business growth.\n\n4. **Operational Disruptions**: Unauthorized changes to S3 bucket policies might disrupt services, causing outages. During this time, you might lose sales, plus the cost of time and resources taken to identify and resolve the issue.\n\n5. **Increased Recovery Costs**: If unauthorized or malicious changes are made to the S3 bucket policies, the cost of correcting these changes and recovering from any associated damage can be significant.\n\nIn conclusion, non-compliance to this AWS Control not only makes the system vulnerable to cyber attacks but might also have financial repercussions and damage the corporation's reputation. Therefore, establishing a metric filter and alarm for changes to S3 bucket policies is highly recommended."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, let's assume Company X is operating a complex infrastructure on AWS, involving different services. These services include multiple S3 buckets used for data storage and backup. To maintain security and integrity of their data, it is crucial for Company X to monitor any changes to their S3 bucket policies in real-time. These changes, if done inappropriately, can possibly expose sensitive data or disrupt operations.\n\nThey can set up AWS CloudTrail to log all API calls, which include any actions to change S3 bucket policies. These logs can then be directed to CloudWatch Logs or an external SIEM environment to analyze and provide insights. \n\nIn this context, Company X can establish a metric filter targeting any API calls related to changes in S3 bucket policies. Then, an alarm can be configured to notify the administering team about such events via email or SMS immediately.\n\nThis gives the team the opportunity to verify the action or quickly react if the change was not authorized, enhancing the security posture and ensuring the continuity of services. In addition, it allows them to always stay compliant with security regulations and internal policies. \n\nHere's an example of CloudWatch alarm configuration in YAML format for monitoring changes to S3 bucket policies:\n\n```\nResources:\n  S3BucketPolicyChangesAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      AlarmDescription: \"Detects changes to S3 Bucket Policies\"\n      Namespace: AWS/S3\n      MetricName: BucketPolicyChanges\n      ComparisonOperator: GreaterThanThreshold\n      Threshold: 1\n      EvaluationPeriods: 1\n      AlarmActions:\n        - arn:aws:sns:us-east-1:012345678910:notify-me\n      Dimensions:\n        - Name: Filter\n          Value: \"eventName='PutBucketPolicy' || eventName='DeleteBucketPolicy'\"\n      Statistic: SampleCount\n```\n\nThis alarm will send a notification to the \"notify-me\" SNS topic whenever there is a 'PutBucketPolicy' or 'DeleteBucketPolicy' event."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_9",
        "Title": "3.9 Ensure VPC flow logging is enabled in all VPCs",
        "Description": "VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. After you've created a flow log, you can view and retrieve its data in Amazon CloudWatch Logs. It is recommended that VPC Flow Logs be enabled for packet \"Rejects\" for VPCs.",
        "QueryID": "aws_vpc_flow_logs_enabled",
        "DocumentURI": "policies/aws_cis_v200_3_9.md",
        "ManualVerification": false,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.9"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/VPC"
            ],
            "x-kaytu-explanation": [
                "# VPC Flow Logs\n\nVPC Flow Logs is a feature provided by Amazon Web Services (AWS) that allows you to capture, monitor, and store information about the IP traffic coming to and going from the network interfaces present in your Virtual Private Cloud (VPC). Once a flow log is created, its data can be accessed and retrieved through Amazon CloudWatch Logs.\n\n---\n\n## Key Points \n\n- VPC Flow Logs captures IP traffic information of your VPC.\n\n- The data of the flow logs can be viewed and retrieved in Amazon CloudWatch Logs.\n\n- It is strongly recommended to enable Flow Logs for tracking packet \"Rejects\" in your VPCs.\n\n---\n\n## Enabling VPC Flow Logs\n\nTo enhance the security and monitoring of your VPC, it is advisable to enable Flow Logs for packet \"Rejects\". This helps in tracking and monitoring refused connect attempts which might indicate possible security threats.\n\n---\n\nRemember, the vigorous monitoring of network traffic can help detect unusual patterns or activities and possibly prevent harmful cyber attacks. VPC Flow Logs is a substantial tool in maintaining a high level of network security in your AWS VPC."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the AWS control that recommends enabling VPC Flow Logs for packet \"Rejects\" can result in:\n\n- **Increased Security Risks:** Without VPC Flow Logs, the ability to monitor and troubleshoot security and connectivity issues can be severely hindered. If an unwanted or suspicious IP traffic pattern is present, the lack of flow logs could allow such activity to go unnoticed, potentially leading to a serious security breach.\n\n- **Troubleshooting Difficulties:** Without VPC flow logs for packet \"rejects\", it can be difficult to trace why certain traffic isn't reaching its intended destination, increasing time and complexity in troubleshooting network issues.\n\n- **Regulatory and Compliance Issues:** In certain industries or regions, regulations may require detailed logging of network activity. Non-compliance with these directives could result in legal penalties or restrictions.\n\n- **Increased Operational Costs:** Additional time spent on troubleshooting issues, and potential legal penalties or security breaches, could increase the organization's operational costs.\n\nIn short, the cost of non-compliance can include operational, financial, legal, reputational and security costs. Keeping VPC flow logs enabled for rejected packets can help avoid these unnecessary expenditures and support a more secure, efficient operation."
            ],
            "x-kaytu-usefulness-example": [
                "Here's a potential instance of usefulness for VPC Flow Logs:\n\nFor a software development company, managing and protecting their digital assets, ensuring the security of their networks, and troubleshooting network issues are top priorities. They might be the targets of various cyber threats like DDoS (Distributed Denial of Service) attacks, IP spoofing, or port scanning. \n\nTo get ahead of these issues, they would choose to use VPC Flow Logs. For example, engineering teams can use this feature to log all network traffic data, including source and destination IP addresses, packet and byte data, and action taken (ACCEPT/REJECT) for every network interface in their AWS VPC. \n\nIn an instance where there is suspicious activity such as unexpected traffic spikes, data flow to unknown IP addresses, or repeated REJECT actions, engineers can quickly turn to VPC Flow Logs data to investigate what's causing the anomalies. \n\nThe 'REJECT' records are particularly useful in identifying potential security threats where unauthorized attempts to access or connect to secured networks are being blocked. \n\nAfter analyzing this data, the team can identify problematic areas, take necessary action to enhance security - like creating more stringent security group rules, or blocking certain IP addresses - and prevent potential threats or system failures. \n\nIn summary, by enabling VPC Flow Logs for packet \"Rejects\", companies can enhance their security, troubleshoot and resolve network issues more effectively, and maintain high network performance and reliability."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_9",
        "Title": "4.9 Ensure AWS Config configuration changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for detecting changes to AWS Config's configurations.",
        "QueryID": "aws_log_metric_filter_config_configuration",
        "DocumentURI": "policies/aws_cis_v200_4_9.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.9"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS (Amazon Web Services) provides a suite of cloud services that organizations can use to build, deploy, and manage applications and data. \n\nOne of the core capabilities of AWS is its extensive logging and monitoring features, which are primarily enabled through two services: AWS CloudTrail and Amazon CloudWatch.\n\nCloudTrail Logs is a service that records all API (Application Programming Interface) calls made on your AWS account. This includes actions taken in the AWS Management Console, AWS CLI, and AWS SDKs and APIs. \n\nCloudWatch Logs, meanwhile, helps to monitor, store, and access your log files from these resources. \n\nBy directing these CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment, you can achieve real-time monitoring of API calls. This allows you to detect any anomalies or potentially unauthorized activities in near real-time.\n\nTo automate the process of anomaly detection, it is possible to establish metric filters and alarms on the CloudWatch Logs. A metric filter extracts data from the logs and converts it into a CloudWatch metric, while the alarm triggers whenever the metric crosses a pre-defined threshold.\n\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. Monitoring changes to AWS Config configurations can help ensure that your environment remains secure and compliant with your defined policies. Therefore, it is recommended to establish a metric filter and alarm for detecting changes to this configuration.\n\nMarkup Format:\n\n    AWS provides extensive logging and monitoring features through `AWS CloudTrail` and `Amazon CloudWatch`. With `CloudTrail Logs`, all API calls made on your AWS account are recorded, and with `CloudWatch Logs`, these log files can be monitored, stored, and accessed.\n\n    For real-time monitoring of API calls, you can direct these `CloudTrail Logs` to `CloudWatch Logs` or an external `SIEM` environment. You can automate anomaly detection by establishing metric filters and alarms on the `CloudWatch Logs`. \n\n    It's recommended to monitor changes to `AWS Config's` configurations using metric filters and alarms to ensure security and compliance of your environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "The failure to comply with the above AWS control would imply the absence of real-time monitoring of API calls. This non-compliance might lead to multiple potential costs and risks:\n\n1. **Security Risk:** Without real-time monitoring, malicious activities or unwarranted changes may go unnoticed. This could potentially lead to major security breaches, which could compromise your customers' data and result in a significant loss of trust and reputation.\n\n2. **Financial Cost:** Any security breach or data leak may result in financial penalties due to non-compliance with standards, such as GDPR, HIPAA, etc.\n  \n3. **Operational Interruption:** If an unauthorized change is made in your AWS Config's configurations and it goes unnoticed, it could affect your operations. The system might stop working as intended, leading to potential downtime for your services and financial losses.\n   \n4. **Audit Failure:** If your organization has to comply with certain industry standards that require real-time monitoring of API calls and log management, then non-compliance could lead to the failure of audits.\n   \n5. **Unoptimized Performance:** Real-time monitoring also gives insights into the systemâ€™s performance. Without it, performance issues could go unnoticed leading to inefficient use of resources and higher costs. \n\nCognizant of the above, it is sensible and recommended to adhere to the AWS control - directing CloudTrail Logs to CloudWatch Logs or an external SIEM environment for real-time monitoring, and setting up corresponding metric filters and alarms for changes to AWS Config's configurations."
            ],
            "x-kaytu-usefulness-example": [
                "For example, a company needs to ensure it maintains compliance with certain data protection and security regulations. They have implemented AWS Config to manage their AWS resources and have specific configurations related to security and data protection in place. \n\nIf there is any unauthorized or unusual changes to these configurations, it could put the company at risk of non-compliance and potential security breaches. By setting up CloudTrail, CloudWatch, or an external SIEM system to monitor API calls, they can detect such changes in real-time. \n\nIf the metric filter and alarm for changes to AWS Config's configurations are established, any change would trigger the alarm and notify the appropriate personnel. This allows the company to take prompt actions to investigate and rectify the issue, minimizing any potential damage or risk. \n\nTherefore, acquiring real-time intelligence of AWS resources can help ensure regulatory compliance, safeguard from security threats, and maintain the standard operational performance."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_10",
        "Title": "1.10 Ensure multi-factor authentication (MFA) is enabled for all IAM users that have a console password",
        "Description": "Multi-Factor Authentication (MFA) adds an extra layer of authentication assurance beyond traditional credentials. With MFA enabled, when a user signs in to the AWS Console, they will be prompted for their user name and password as well as for an authentication code from their physical or virtual MFA token. It is recommended that MFA be enabled for all accounts that have a console password.",
        "QueryID": "aws_iam_user_console_access_mfa_enabled",
        "DocumentURI": "policies/aws_cis_v200_1_10.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.10"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control - Multi-Factor Authentication (MFA)\n\nMulti-Factor Authentication (MFA) is a function provided by Amazon Web Services (AWS) that offers an additional layer of security to the standard login process. This increases your account's protection from unauthorized access.\n\n## How Does MFA Work?\n\nWith MFA enabled, a user attempting to sign in to their AWS Console will be required to provide:\n1. Their user name and password (primary authentication method).\n2. A unique authentication code provided by a physical or virtual MFA token (secondary authentication method).\n\nThe authentication code changes with time, further enhancing the security. This means, even if someone is able to get hold of your user name and password, without the second factor of authentication (authentication code from MFA token), they will be unable to access your account.\n\n## Who Should Use MFA?\n\nIt is recommended for all accounts with a console password to enable MFA. This increases security and reduces risk, especially for root accounts where administrative decisions are made.\n\nIn addition to root accounts, MFA should also be used by IAM users who require console access, especially those with higher privileges.\n\n## Conclusion\n\nIn conclusion, MFA is a critical security measure that should be adopted in all AWS accounts. By having multiple forms of authentication, not only does it increase security, but it also provides peace of mind knowing your data is better protected from unauthorized access."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the multi-factor authentication (MFA) control may pose substantial costs such as :\n\n1. **Security breach costs**: Without MFA, unauthorized people could more easily gain access to a company's AWS console by cracking or guessing user names and passwords. If an unauthorized person gains access, they might compromise sensitive data or deploy expensive resources causing financial loss.\n\n2. **Reputation damage**: Successfully hacking or breaching a company's data security can significantly harm its reputation. This loss of trust can lead to decreased sales or use of services, which could be costly, especially if the company has a broad customer base.\n\n3. **Regulatory fines and sanctions**: In certain industries or regions, regulations such as GDPR (General Data Protection Regulation) and HIPAA (the Health Insurance Portability and Accountability Act) require strong security measures, including MFA. Non-compliance with such regulations can result in substantial fines and sanctions.\n\n4. **Cost of recovery**: In case of a security breach, costs associated with restoring systems, resolving vulnerabilities, and protecting against future threats can be significant. These might include incident response services, cyber risk insurance premiums, or infrastructure upgrades.\n\n5. **Loss of intellectual property**: If unauthorized people gain access to proprietary company information, it could give competitors an unfair advantage, leading to potential revenue loss.\n\nIn short, without MFA, a company's AWS environment becomes significantly more vulnerable to security risks, the costs of which far surpass the costs of enabling and maintaining MFA."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nLet's imagine that you are the head of a company called `Global Solutions Inc.` who uses AWS services for their business operations. \n\nOne of your major concerns is the security of your systems and preventing unauthorized access. As the system holds sensitive information, even a slight lapse in security can have disastrous consequences for your company.\n\nBy using `AWS Multi-Factor Authentication (MFA)`, you can secure your AWS services at another level. When this is enabled, whenever someone tries to access the AWS console, they need to prove their identity by providing two forms of identification. \n\nThe first form of identification is in the shape of traditional credentials - username and password. However, these alone would not grant access. They will also be required to provide an authentication code that is generated by their MFA device which can be a physical or a virtual unit.\n\nWith AWS MFA, you can assure an additional authentication assurance beyond the primary security measure, providing another protective layer over sensitive data. Now even if someone manages to sniff out a password, they couldn't get through to the system without the MFA code which is impossible to acquire without physical possession of the MFA device, thereby reducing the risk of unauthorized access. \n\nFrom the perspective of `Global Solutions Inc.`, this would be highly beneficial, as it provides you with the reassurance and confidence that your AWS services are protected with an enhanced level of security."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_11",
        "Title": "1.11 Do not setup access keys during initial user setup for all IAM users that have a console password",
        "Description": "AWS console defaults to no check boxes selected when creating a new IAM user. When creating the IAM User credentials you have to determine what type of access they require.",
        "QueryID": "aws_iam_user_access_keys_and_password_at_setup",
        "DocumentURI": "policies/aws_cis_v200_1_11.md",
        "ManualVerification": false,
        "Severity": "Low",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.11"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS provides the Identity and Access Management (IAM) service which enables an administrator to securely control access to AWS services and resources for users. Typically, when creating a new IAM user in the AWS Management Console, no checkboxes are selected by default. Here, checkboxes refer to options with regard to the type of access a user will have once the account is created.\n\nWhen creating user credentials, it's important to set the correct level of permissions based on the userâ€™s role and the tasks they need to accomplish. This is in accordance with the principle of least privilege which states that a user should be given the minimum levels of access to perform their job functions.\n\nThe options provided range from programmatic access, which allows users to access AWS services via the API, SDK, and command line interface, to AWS Management Console access, granting users access via the AWS console.\n\n```markdown\n- **IAM User Settings:**\n\n    ![IAM User Settings](image-link)\n\n    1. **Programmatic access**: Enables an access key ID and secret access key for the AWS API, CLI, SDK, and other development tools.\n\n    2. **AWS Management Console access**: Enables a password that allows users to sign-in to the AWS Management Console.\n\n    \u003e **Note:** It's crucial to set the correct level of permissions based on the user's role and the tasks they'll need to perform. This is to ensure adherence to the principle of least privilege.\n```\n\nRemember to replace `image-link` with the actual link of the image."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control can be quite hazardous and can lead to potential problems:\n\n1. **Security risk:** If check boxes are not properly selected when creating a new IAM user, it might give them unnecessary permissions, which can be a considerable security risk. They might find access to sensitive data, perform actions that they are not supposed to, or even pose a threat to your AWS infrastructure.\n\n2. **Audit failure:** If your organization needs to comply with various security standards and regulations, the misconfiguration of IAM user policies can be an audit failure. This can lead to fines, penalties, losing customers' trust, or even legal actions in severe cases.\n\n3. **Resource misuse:** If the IAM users get more access than required, they can perform unnecessary actions that can consume resources or degrade the performance of your AWS services.\n\n4. **Financial implications:** AWS services consumption translates to costs. Misconfigured access might lead to unexpected service usage, resulting in budget overruns.\n\n5. **Operational disruptions:** Unauthorized or unintentional actions performed by IAM users due to access misconfiguration can lead to system disruptions or service degradations, leading to operational inefficiencies.\n\nIt's crucial to spend adequate time determining the type and level of access each IAM user requires and configuring their permissions accordingly to avoid these risks. Follow the principle of least privilege, under which a user is given the minimum levels of access necessary to complete their job functions."
            ],
            "x-kaytu-usefulness-example": [
                "```markdown\nAn example of the usefulness of AWS console's default behavior of not selecting any check boxes when creating a new IAM user can be in the context of a large organization that needs to create multiple IAM users with customized permissions.\n\nScenario: A financial organization is setting up its infrastructure on AWS. They need to create IAM users for their tech team, finance team, and HR team. Each team needs different sets of permissions.\n\n1. Tech Team: Full access to EC2, S3, and Lambda services for application development, testing, and deployment. They do not need access to financial and personnel data. \n\n2. Finance Team: Read-only access to cost and usage reports, but no access to the actual services.\n\n3. HR Team: Access to WorkDocs and WorkMail, but no access to financial data.\n\nIn this scenario, having no default check boxes selected when creating IAM users becomes beneficial, as it allows the administrator to consciously specify the type of access a user requires, enhancing both security and efficiency. By ensuring that services are not accidentally granted due to them being selected by default, it can reduce the risk of unnecessary access, enhancing the organization's data security.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_20",
        "Title": "1.20 Ensure that IAM Access analyzer is enabled for all regions",
        "Description": "Enable IAM Access analyzer for IAM policies about all resources in each region. IAM Access Analyzer is a technology introduced at AWS reinvent 2019. After the Analyzer is enabled in IAM, scan results are displayed on the console showing the accessible resources. Scans show resources that other accounts and federated users can access, such as KMS keys and IAM roles. So the results allow you to determine if an unintended user is allowed, making it easier for administrators to monitor least privileges access. Access Analyzer analyzes only policies that are applied to resources in the same AWS Region.",
        "QueryID": "aws_iam_access_analyzer_enabled",
        "DocumentURI": "policies/aws_cis_v200_1_20.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.20"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# Enable IAM Access Analyzer for IAM Policies\n\n## Description\nIAM Access Analyzer is a powerful tool introduced at AWS re-invent 2019. It provides detailed insights on the accessibility of your AWS resources. After enabling it, the scan results are shown on your console, helping you determine if any unintended users have access to certain resources. This makes it easier for administrators to monitor and maintain least privileges access.\n\n## Enabling IAM Access Analyzer\n- Navigate to IAM in your AWS Management Console.\n- In the IAM Dashboard, go to the Access Analyzer section.\n- click on \"Create analyzer\" button and follow the steps.\n  \n## Considerations\nAccess Analyzer only analyzes policies applied to the resources in the same AWS Region where it is enabled. This means you need to enable IAM Access Analyzer for all your resources in each Region to get a comprehensive accessibility overview.\n\n## Benefits\n- Discover resources that other AWS accounts and federated users can access, such as KMS keys and IAM roles.\n- Easily identify unintended permissions, enhancing your security posture.\n- Keep track of your resource accessibility in accordance with the least privilege best practice.\n\n## Drawbacks\n- Scan results might vary based on the policies applied at the time of performing the scan.\n- Accurate results only provided for the AWS Region in which IAM Access Analyzer is enabled.\n  \n## Conclusion\nIAM Access Analyzer is a crucial service for AWS resource management and security. By providing detailed insights on resource accessibility, this tool assists in identifying potential security risks and helps in maintaining least privilege access to AWS resources. Remember to enable it for each region to ensure comprehensive coverage."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to AWS Control, Enable IAM Access analyzer for IAM policies about all resources in each region, could have a number of cost implications for an organization:\n\n1. **Security Risks**: Non-compliance can lead to potential security risks like data breaches or unauthorized access, which could result in substantial financial penalties, legal repercussions, and damage to a company's reputation.\n\n2. **Regulatory Penalties**: Depending on the organization's field of operation, non-compliance may result in non-compliance with certain national and international regulations such as GDPR, HIPAA, etc. This could result in regulatory penalties and fines.\n\n3. **Operational Disruptions**: Any data breach or unauthorized access could lead to operational disruptions in the organization leading to inefficiencies, which ultimately translates into financial losses.\n\n4. **Increased Operational Costs**: Without the IAM access analyzer, an organization could potentially need more resources and manpower to continually monitor and manage access controls, leading to increased operational costs.\n\n5. **Loss of Trust**: Non-compliance with the controls and potential security breaches can lead to loss of trust among clients and users, affecting business relationships and resulting in potential loss in business and revenue. \n\nIn conclusion, enabling IAM Access Analyzer is key to ensuring that access permissions and policies are optimally set up to prevent unauthorized access, thereby helping safeguard an organization from potential security threats and the associated costs."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider that an organization uses AWS for multiple purposes, including hosting of their web platform and data storage. Many different employees and external consultants have access to various degrees, depending upon their role in the organization. Over time, this complex web of permissions can become difficult to manage, with potential for security risks if inappropriate access is granted.\n\nWhen the organization enables IAM Access Analyzer, it swiftly scans all their IAM policies and outputs a detailed report listing the resources that can be accessed by external accounts or federated users. The report may show, for example, that an external consultant has access to a particular KMS key he or she shouldn't have.\n\nAn administrator in the organization can then review this report and revoke that access if it is unintended, thereby rectifying a possible security vulnerability. In this way, the IAM Access Analyzer helps simplify the process of managing and auditing access within the organization, making it easier to maintain least privileges access and enhance overall security. \n\nSo, this example shows how the IAM Access Analyzer can be a powerful tool in helping organizations to maintain robust security by identifying and correcting potential access-related vulnerabilities."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_12",
        "Title": "1.12 Ensure credentials unused for 45 days or greater are disabled",
        "Description": "AWS IAM users can access AWS resources using different types of credentials, such as passwords or access keys. It is recommended that all credentials that have been unused in 45 or greater days be deactivated or removed.",
        "QueryID": "aws_iam_user_unused_credentials_45",
        "DocumentURI": "policies/aws_cis_v200_1_12.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.12"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS Identity and Access Management (IAM) is a service that controls users and their levels of access to the AWS resources. This service allows you to manage users, security credentials (like access keys, passwords), and permissions that control which AWS resources users and applications can access.\n\nRegarding unused credentials, they can pose a security risk if they are leaked or discovered by unauthorized individuals. Therefore, it's a best practice to regularly review and manage AWS IAM credentials. The potential risk of misuse is higher for unused credentials since their activity is not regularly monitored or expected. \n\nAs per the AWS Security Best Practices, it is suggested that AWS IAM credentials (passwords, access keys) that have not been used for 45 or more days should be deactivated or removed to minimize the risk of unauthorized access, accidental exposure, or misuse. If these keys are not needed, you can rotate them or delete them to enhance your security posture.\n\nIf the credentials haven't been used in a while, it is likely that they are not necessary for ongoing operations. Therefore, deleting or deactivating them won't affect the normal operation of your services. However, if these credentials are required later, they can be regenerated or reactivated.\n\nUnderstanding and managing AWS credentials effectively is essential to maintain secure and scalable use of the AWS Cloud, and this control emphasizes this security-focused mindset."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS IAM control that recommends deactivating or removing any credentials not used in 45 or more days can greatly impact an organization. Here are the potential consequences:\n\n1. **Increased Security Risk:** Idle credentials are an unnecessary security risk. If these credentials are breached, they grant unauthorized access to your AWS resources. This could lead to data loss, data corruption, or unexpected charges if a malicious actor uses them.\n\n2. **Compliance Failures:** Many industry regulations and data protection standards require organizations to have controls in place to manage and regularly update access credentials. Failure to deactivate or remove unused access keys could result in non-compliance with these regulations, leading to hefty fines and potential legal action.\n\n3. **Additional Costs:** Idle credentials also add up to your AWS costs because AWS charges for active but unused resources. By leaving unused credentials active, you're essentially wasting money on resources that aren't providing any value to your organization.\n\n4. **Harder to Manage Infrastructure:** The more access keys or passwords are active, the harder it gets to manage AWS infrastructure. It becomes challenging to keep track of who has access to what, increasing the likelihood of human error or mismanagement.\n\nTherefore, it is heavily advised to adhere to AWS IAM control to deactivate or delete any unused credentials which have not been used in the prior 45 days to mitigate these risks and costs. \n\n```markdown\n- **Increased Security Risk:** Idle credentials, if compromised, can be used by unauthorized entities to gain access to AWS resources.\n- **Compliance Failures:** Non-compliance with industry regulations requiring administrative control of access keys can lead to sanctions, fines, and legal action.\n- **Additional Costs:** Unused AWS resources contribute to increased AWS charges.\n- **Harder to Manage Infrastructure:** An excess of active credentials can make managing AWS infrastructure more difficult, increasing the likelihood of errors and mismanagement.\n```\n"
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider a scenario where you have a team of developers working on various aspects of your AWS operations. Over time, some of these developers might migrate to other projects or leave the organization, thereby leading to deactivation or validity expiration of their AWS user accounts. However, if their AWS credentials (passwords or access keys) are not deactivated or removed, they still have potential access to the AWS resources linked to those credentials. \n\nThis is an unneeded security risk. These old, unused access keys are particularly susceptible, as they could fall into the wrong hands and be used to gain unauthorized access. \n\nBy enforcing the AWS control of deactivating or removing all AWS user credentials that have been unused in 45 or greater days, you can help fortify your AWS security posture. This practice helps eliminate possible entry points into your system for malicious intents - particularly useful if an individual with knowledge of your AWS operations exits your team. \n\nSo, this AWS control is extremely useful in maintaining a tightening and continually optimized security system with the least privileges required."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_10",
        "Title": "3.10 Ensure that Object-level logging for write events is enabled for S3 bucket",
        "Description": "S3 object-level API operations such as GetObject, DeleteObject, and PutObject are called data events. By default, CloudTrail trails don't log data events and so it is recommended to enable Object-level logging for S3 buckets.",
        "QueryID": "aws_cloudtrail_s3_object_write_events_audit_enabled",
        "DocumentURI": "policies/aws_cis_v200_3_10.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.10"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: S3 Object-level API Operations Logging\n\nIn the realm of AWS S3, object-level API operations like `GetObject`, `DeleteObject`, and `PutObject` are referred to as data events. These are the activities or operations that perform read/write operations on an object in an S3 bucket. \n\n## Role of CloudTrail\n\nAWS CloudTrail is a service that provides event history for your AWS account. It records and delivers log files to an Amazon S3 bucket, capturing a comprehensive list of actions and changes that occur within that account. \n\nHowever, by default, CloudTrail trails do not log these data events. This means that API calls to perform data events in your S3 buckets are not automatically tracked and documented.\n\n## Enabling Object-Level Logging in S3 Buckets\n\nAlthough CloudTrail provides valuable monitoring for your AWS environment, its default configuration may not provide complete visibility into all activities associated with your S3 buckets. \n\nFor this reason, it's recommended to enable object-level logging for S3 buckets. This ensures that all API operations which modify the data objects in your S3 buckets are logged and can be reviewed at a later date, providing a more granular level of insight into bucket activity. \n\nTo enable object-level logging in an S3 bucket, you should:\n\n- Navigate to the S3 bucket in the AWS Management Console\n- Go to the Properties tab\n- Look for the Server access logging feature and enable it\n\nRemember that CloudTrail logs incur standard S3 storage costs, so be mindful of the volume of data your logs may generate.\n\n## Conclusion\n\nData events such as `GetObject`, `DeleteObject`, and `PutObject` are crucial elements in interacting with S3 buckets. Despite their importance, they are not logged by default in CloudTrail, necessitating object-level logging to be enabled on S3 buckets for comprehensive monitoring and troubleshooting. This provides you with a complete picture of how your S3 buckets are being used and modified."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS Control can be significant and detrimental to organizations, especially those that work with sensitive data. Here is a detailed explanation in markdown format:\n\n1. **Lack of Accountability and Traceability**: By default, AWS CloudTrail doesnâ€™t log S3 object-level API operations meaning that if you don't enable object-level logging, you won't be able to track who's accessing, adding, or deleting your S3 data objects. This lack of accountability can make your storage system vulnerable to unauthorized access and misuse of data.\n\n2. **Compromise of Data Integrity**: When object-level logging is not enabled, it's hard to ensure data integrity as you can't effectively track changes and modifications to data files. This may lead to inconsistent or tainted data, and ultimately business operation issues.\n\n3. **Security Incident Response and Forensics Challenges**: If a security incident occurs, without Object-level logging, you would have limited visibility and information to identify the root cause and perform post-incident analysis. This could hinder your organization's ability to respond effectively and recover quickly from security incidents.\n\n4. **Regulatory Compliance**: Certain industry standards and regulations require the logging and monitoring of all data access and modifications. Non-compliance with this AWS control might result in failing to meet such regulatory requirements, leading to heavy fines, sanctions, and reputational harm.\n\n5. **Increased Operational Costs**: Non-compliance to this AWS control may necessitate damage control efforts, including system corrections, data recovery, and security hardening, which could inflate operational costs. In worst-case scenarios, the cost of recovering from a data breach could be crippling. \n\nHere is a suggested format:\n\n```markdown\n- Lack of Accountability and Traceability\n- Compromise of Data Integrity\n- Security Incident Response and Forensics Challenges\n- Regulatory Compliance\n- Increased Operational Costs\n```\nRemember, implementing object-level logging is a good security practice to monitor and protect your S3 data objects. It also provides detailed visibility for better management and decision-making regarding your data."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a healthcare company storing patient records on AWS S3 may require stringent tracking of who, when, and what operations were performed on their data for compliance (like HIPAA). \n\nFor example, when an unauthorized user attempts to download (GetObject) or delete (DeleteObject) patient data, or when a new record is added (PutObject), object-level logging would be extremely useful. \n\nBy enabling object-level logging for S3 buckets, every GetObject, DeleteObject, and PutObject event is recorded in AWS CloudTrail. This allows the company to have a full audit trail of all data events, enhancing data security, enabling compliance and providing a precise log for troubleshooting and forensics. \n\nMark up:\n\n```\nHealthcare company XYZ stores patient records on an ```AWS S3 bucket```. To comply with regulations like ```HIPAA```, they need to track who accesses or makes changes to their patient data. To achieve this, they have enabled ```object-level logging for their S3 bucket``` in AWS CloudTrail. This means every time someone attempts to ```download (GetObject)```, ```delete (DeleteObject)```, or ```add (PutObject)``` a record, the action is logged. This provides a comprehensive audit trail, helping to enhance data security, ensure regulatory compliance and enabling investigation in case of any security incidents.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_21",
        "Title": "1.21 Ensure IAM users are managed centrally via identity federation or AWS Organizations for multi-account environments",
        "Description": "In multi-account environments, IAM user centralization facilitates greater user control. User access beyond the initial account is then provide via role assumption. Centralization of users can be accomplished through federation with an external identity provider or through the use of AWS Organizations.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v200_1_21.md",
        "ManualVerification": true,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.21"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS Control is a system that provides centralized control across multiple AWS accounts. The IAM (Identity and Access Management) tool in AWS allows you to create and manage AWS users and groups, and use permissions to allow and deny their permissions to AWS resources. In multi-account environments, centralization of IAM users not only facilitates better user control but it is also convenient for user management. \n\nYou can grant access to users in one AWS account (the initial account) to access resources in another AWS account (beyond the initial one). This is done through the process of \"role assumption\". Role assumption in AWS Security Token Service is a way for a federated user to access resources that the owner of the account could access. A role is assumed by a user to take on permissions of the role temporarily to carry out permitted tasks.\n\nThis centralization of users can be accomplished through federation with an external identity provider (like Microsoft Active Directory) or through the use of AWS Organizations - a service that allows you to centralize the administration of multiple accounts. The federation process combines a user's identity and attributes, stored in the external identity provider, with AWS defined policies to grant access to AWS resources. On the other hand, AWS Organizations is an account management service that enables you to consolidate multiple AWS accounts into an organization that you create and centrally manage.\n\nHere's an example in markup format:\n\n```markdown\n# AWS Control in Multi-Account Environments\n\n- **IAM User Centralization**: AWS Identity and Access Management (IAM) allows you to centralize users for greater control. You can manage user access and permissions across multiple AWS accounts.\n\n- **Role Assumption**: Users can access resources beyond the initial account through role assumption. This is a process that allows a user to take on a role temporarily to access AWS resources.\n\n- **User Federation**: AWS allows federation with an external identity provider for user centralization. This combines a user's identity and attributes, with AWS defined policies to grant access to AWS resources.\n\n- **AWS Organizations**: Centralized administration of multiple AWS accounts can be achieved using AWS Organizations. This service allows you to consolidate multiple AWS accounts into an organization that you create and centrally manage. \n```\nThis explanation provides a summarized understanding of how AWS Control works in multi-account environments. It is a recommended practice for organizations with large number of AWS accounts and users for easier management and increased security."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS (Amazon Web Services) control can lead to several consequences:\n\n1. **Lost Productivity**: It will be more challenging to manage individual user permissions across separate accounts. This can result in wasted time and lost productivity. \n\n2. **Increased Security Risks**: If IAM (Identity and Access Management) users are not centralized, it becomes more difficult to monitor and manage each user's permissions. This can increase the risk of unauthorized access to your AWS resources. \n\n3. **Higher Operational Costs**: The use of an external identity provider or AWS Organizations in the centralization of users can significantly reduce operational costs. Non-compliance will mean you'll have higher costs in managing multiple AWS accounts. \n\n4. **Audit Difficulties**: Centralizing IAM users makes it easier to audit user activities and ensure compliance with regulatory standards. If you're not centralized, you run into more complexities while conducting audits. \n\n5. **Lack of Visibility**: Without IAM user centralization, there would be decreased visibility and control over user accounts and roles, which could further lead to mismanagement and possible security breaches. \n\n6. **Non-Compliance Penalties**: If your industry is subject to regulations that require certain security controls, including centralized IAM, non-compliance with these controls could lead to hefty penalties. \n\nIn conclusion, centralized IAM users in a multi-account environment not only facilitates greater user control but also helps reduce risks and costs associated with non-compliance."
            ],
            "x-kaytu-usefulness-example": [
                "Let's say for example, a corporation named 'ABC Corporation' has various departments such as Finance, IT, Marketing, etc. These departments have their respective AWS accounts for handling their workloads. However, managing users and their access in each account can be a challenging task for the IT department.\n\nHere IAM user centralization shines. With the help of AWS Organizations, they can create a management account, and under that, they can create an account for each department. They can create users in this management account and grant them access to the departmental accounts. Now, instead of managing users for each department, they can manage all users from this central account.\n\nAdditionally, they can also use external identity providers to manage users, which not only provide user centralization, but also provide additional security features such as two-factor authentication, password policies etc.\n\nFor example, they might already have an Active Directory (AD) server which manages users for their on-premises systems. They can federate this AD with AWS, and users can assume IAM roles in AWS accounts depending on their user role in AD. This reduces the burden of user management by removing the need to create individual IAM users in AWS for each of their employees."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_22",
        "Title": "1.22 Ensure access to AWSCloudShellFullAccess is restricted",
        "Description": "AWS CloudShell is a convenient way of running CLI commands against AWS services; a managed IAM policy ('AWSCloudShellFullAccess') provides full access to CloudShell, which allows file upload and download capability between a user's local system and the CloudShell environment. Within the CloudShell environment a user has sudo permissions, and can access the internet. So it is feasible to install file transfer software (for example) and move data from CloudShell to external internet servers.",
        "QueryID": "aws_aws_iam_user_group_role_cloudshell_fullaccess_restricted",
        "DocumentURI": "policies/aws_cis_v200_1_22.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.22"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "```\n# AWS CloudShell\n\n[AWS CloudShell](https://aws.amazon.com/cloudshell/) is a browser-based shell that you can use to run commands and work with AWS services. It provides you with command-line access to your AWS resources directly from your browser. It comes pre-installed with AWS CLI `v2.0`.\n\n## Full Access with Managed IAM Policy\n\nAWS provides a managed IAM policy, 'AWSCloudShellFullAccess', which gives full access priviliges to CloudShell. This allows users to upload and download files between their local system and the CloudShell environment. \n\n## Sudo Permissions and Internet Access\n\nUsers in the CloudShell environment have 'sudo' permissions, which means that they can act as the 'root' user and have administrative level control over the environment. Additionally, users can access the internet from within the CloudShell environment. \n\nThis opens up possibilities for running a wide range of commands and even installing new software. For instance, you can install a file transfer software like `scp` or `rsync` and transfer data to/from external internet servers.\n\n**Note:** Exercise caution while installing third-party software or transferring data to/from external servers as it might have implications on security and compliance.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS Control referring to the use of AWS CloudShell could lead to severe implications in terms of cost, including potential financial loss, regulatory penalties and reputational damage. Here's an explanation:\n\n1. **Data Breaches**: Unauthorized users may gain access to sensitive corporate or customer information if any malicious software or trojans are installed unnoticed. This could result in identity theft or violation of privacy laws. The associated cost of a data breach can be significant, including incident response, legal fees, penalties, and potential payouts to affected individuals.\n\n2. **Regulatory Compliance Violations**: Not having a control mechanism over data transfer from AWSCloudShell to external servers might lead to non-compliance with various data protection regulations and standards (such as GDPR, HIPAA, CCPA, SOX, PCI-DSS etc.). These violations could result in severe penalties and fines, and increased scrutiny from regulatory bodies.\n\n3. **System's Compromise**: Since users have sudo permissions within the CloudShell environment, any potential misuse could lead to a compromised system â€“ a breach that could, in the worst case scenario, provide root access to an adversary. The costs associated with system compromises can be substantial and could involve expenses related to detection, response, mitigation, system hardening, and other remediation efforts.\n\n4. **Reputational Damage**: Any sort of data breach or system compromise can significantly damage a company's reputation, leading to potential loss of business, decreased customer trust and potentially leading to loss of competitive edge.\n\n5. **Increased Operational Costs**: Without limiting and monitoring access to AWS CloudShell, organizations may face increased costs in terms of managing security incidents, dealing with complex threat landscapes, performance troubleshooting, and system maintenance.\n\nThus, implementing proper controls around the use of AWS CloudShell, including restricting full access to essential personnel, monitoring activity, and taking a proactive approach to security best practices can help mitigate these potential costs."
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a scenario where a developer is tasked with analyzing a large dataset that resides in an Amazon S3 bucket. Their local machine doesn't have enough resources to handle such a large amount of data and they need a practical solution to extract insights from the data.\n\nIn this case, the developer can use AWS CloudShell to access the S3 bucket using AWS CLI commands. They can then install the necessary data processing libraries, say Python pandas, using the sudo privilege available in the shell. \n\nIt is also possible to transform or pre-process the data within CloudShell and save the cross-processed data back into the S3 bucket for future use. \n\nPost data preprocessing, they can use python libraries like matplotlib or seaborn to extract insights or visualize the data. \n\nAdditionally, if the data needs to be shared with an external team, the developer can install secure file transfer protocol (SFTP or SCP) tools and transfer the preprocessed data to the external servers from the CloudShell environment.\n\nAWS CloudShell provides a powerful and flexible environment to interact with AWS services as well as external servers, which enhances the developer's productivity and eradicates the necessity of additional local resources for heavy computational tasks."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_3_11",
        "Title": "3.11 Ensure that Object-level logging for read events is enabled for S3 bucket",
        "Description": "S3 object-level API operations such as GetObject, DeleteObject, and PutObject are called data events. By default, CloudTrail trails don't log data events and so it is recommended to enable Object-level logging for S3 buckets.",
        "QueryID": "aws_cloudtrail_s3_object_read_events_audit_enabled",
        "DocumentURI": "policies/aws_cis_v200_3_11.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "3.11"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "`S3 object-level API operations` are actions performed on objects (the data that you store) within your `S3 bucket` (where your data is stored). Some examples of these operations include `GetObject` (retrieving an object from your S3 bucket), `DeleteObject` (deleting an object in your S3 bucket), and `PutObject` (adding an object to your S3 bucket). \n\nThese operations are collectively referred to as `data events`. \n\nHowever, by default, `CloudTrail trails` (which record the activity in your `AWS environment`) do not keep a log of these data events. This means that AWS isn't tracking any modifications made to the data within your S3 buckets by default.\n\nTherefore, it's recommended that you `enable Object-level logging` for S3 buckets. By enabling this feature, AWS will keep track of any operation that changes the state of an object in a S3 bucket, such as creation, deletion or retrieval of objects. This can aid in security and auditing, as it would allow you to know who has been accessing your data, what changes they made, and when they made them.\n  \nHere's how would you enable S3 object-level logging in AWS:\n\n1. Open the Amazon `S3 console`.\n2. In the Bucket name list, choose the name of the bucket that you want to enable logging for.\n3. Choose `Properties`.\n4. In the Logging section, choose `Edit`.\n5. In the Logging page, do one of the following:\n   * To turn on logging, select `Enable logging`. Then for Target bucket, enter the name of the bucket where you want Amazon S3 to save the access logs as objects. You can also use the S3 Object Prefix field to add a prefix to the names of the access log objects.\n   * To turn off logging, select `Disable logging`.\n\nAfter you enable logging, every access to a data event in your bucket will be logged into the target bucket specified."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS control, which recommends enabling the Object-level logging for S3 buckets, could result in several potential costs:\n\n1. **Loss of Visibility and Auditability**: Without enabling object-level logging, businesses will lose visibility into who is accessing their data and what is being done with it. This lack of traceability can significantly complicate auditing processes and make it harder to identify and address potential security or compliance issues.\n\n2. **Potential Data Breaches**: In case of unauthorized access or actions on an S3 object, it would be challenging to identify the culprit. This can lead to potential data breaches which can result in significant financial costs and damage to the company's reputation.\n\n3. **Non-compliance penalties**: Businesses operating in regulated industries may be required to maintain detailed logs of all data operations. If object-level logging is not enabled for S3 buckets, it may lead to non-compliance with these regulations, resulting in potential penalties or fines.\n\n4. **Difficulty in Troubleshooting**: If any data corruption or loss happens, not having a comprehensive log of operations at the object level can hinder your troubleshooting efforts, leading to higher downtime and potential financial loss.\n\n    ```markup\n    Therefore, not enabling S3 Object-level logging can pose significant financial, reputational, and operational risks to a business. Compliance to this AWS control assists in maintaining the integrity, confidentiality, and availability of data stored in S3 buckets.\n    ```"
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider you run an online platform that stores user-generated content in an S3 bucket. Object-level logging can be extremely useful for auditing and security purposes. For instance, if an unauthorized deletion operation occurs, logging the `DeleteObject` data event could potentially provide valuable insights into who made the request, from where, and when.\n\nThe log data provided by these S3 data events can also prove useful in troubleshooting issues. For instance, if a user complains about not being able to access certain content, the `GetObject` record can help determine if a legitimate access request was made. Similarly, logging `PutObject` events can help to keep track of all the uploaded content.\n\n```markdown\n- **AWS Control:** S3 Object-level API operations logging \n- **Example Use Case:**\n  - **Scenario:** You run an online platform for content creators who store their content on your platform. The content is stored in an AWS S3 bucket. \n  - **Issues:** Unauthorized deletion of content, users unable to access their content, and auditing all the content upload operations.\n  - **Solution:** Enable S3 data events logging for `GetObject`, `DeleteObject`, and `PutObject` operations.\n  - **Outcome:** A detailed audit trail of each S3 operation is maintained, providing visibility into who is accessing what content and when. Detect any unauthorized access or modification to the content stored in S3 bucket in a timely and reliable manner.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_13",
        "Title": "1.13 Ensure there is only one active access key available for any single IAM user",
        "Description": "Access keys are long-term credentials for an IAM user or the AWS account root user. You can use access keys to sign programmatic requests to the AWS CLI or AWS API (directly or using the AWS SDK).",
        "QueryID": "aws_iam_user_one_active_key",
        "DocumentURI": "policies/aws_cis_v200_1_13.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.13"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "**AWS Control - Access Keys**\n\nAccess keys allow you to authenticate and authorize access to your AWS account programmatically. They are composed of two parts: an access key ID and a secret access key.\n\nYou would use access keys when interacting with AWS services through:\n\n- The AWS Command Line Interface (AWS CLI)\n- AWS Software Development Kits (AWS SDKs)\n- Direct HTTP calls to the AWS APIs.\n\nNote that, root user access keys are the credentials for the account owner, and it's important to take special care with these keys. Amazon recommends managing AWS resources via IAM users rather than the root account for better control over access.\n\nIAM users each have their own set of access keys, allowing them to interact with your AWS resources and services. As the account owner, you can control IAM users' permissions to perform different tasks.\n\nThe use of access keys is a vital part of AWS access control and should be managed thoughtfully. For example, it is a best practice to regularly rotate keys and to revoke them when they are not needed to reduce security risk.\n\nDo not share your secret access keys and protect them as you would your password. Amazon employees will never ask you for either part of your access keys.\n\nKeep in mind that creating new access keys might lead to changing or disabling existing keys, therefore, testing your applications accordingly is necessary. \n\nAWS Management Console is where you manage access keys (create, disable, delete)."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the AWS Control relating to user access keys could lead to several potential costs:\n\n1. **Security Incidents and Data Breaches:** Not properly managing and securing access keys could lead to unauthorized access of your AWS resources. This may result in data breaches, potentially exposing sensitive data to malicious users. \n \n2. **Regulatory penalties:** In certain industries, a regulatory body might issue heavy fines or other penalties due to non-compliance of accepting standards, especially if customer data is exposed due to poor access control management.\n \n3. **Operational Disruptions:** Poor management of access keys can lead to disruption in business operations. For example, a user with elevated privileges might accidentally modify or delete important resources.\n\n4. **Reputation Damage:** A breach or misuse of customer data may damage a company's reputation. A loss of customer trust can lead to a decline in business and loss of revenue.\n\n5. **Costs of remedial actions:** If a breach happens due to misuse or mishandling of AWS access keys, the business will bear the cost of identifying and addressing the security flaw. This might include conducting a forensic investigation, recovery of lost data, mitigation of exploited vulnerabilities and improvement of security procedures.\n\nTherefore, it's crucial to comply with AWS control policies about access keys, as non-compliance is not only expensive, but it also drags down business operations, compromises security and damages the reputation of the business.\n"
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company may require regular automated reporting regarding its AWS resources such as computational services, storage, or databases. This information might be crucial to keep an eye on resource usage, performance, and overall management of applications running on AWS. \n\nA developer is tasked to build a script that automatically generates these reports, formats them, and sends them over to appropriate stakeholders. To enable the script to access AWS resources, he might need to utilize certain AWS services with the AWS SDK or CLI. To authenticate and authorize this, he would need to use the AWS Access Keys associated with an IAM user that has the appropriate permissions. \n\nHere's a cement example where Access Keys would be used in this scenario. Consider a Python script using the boto3 library (which is the AWS SDK for Python):\n\n```python\nimport boto3\n\n# Set AWS Access Keys\naws_access_key_id = 'AKIAIOSFODNN7EXAMPLE'\naws_secret_access_key = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'\n\n# Create session using your AWS Access Keys\nsession = boto3.Session(\n    aws_access_key_id=aws_access_key_id,\n    aws_secret_access_key=aws_secret_access_key,\n)\n\n# Use the session to create a resource service client (e.g. for S3)\ns3 = session.resource('s3')\n\n# Now, you can use 's3' to make requests (e.g. list all buckets)\nfor bucket in s3.buckets.all():\n    print(bucket.name)\n```\n\nIn this script, AWS Access Keys are being used to authenticate the script's access to AWS services. With the session created with these Access Keys, the script can make programmatic requests to AWS (in this case, listing all S3 buckets). This example illustrates the usefulness of Access Keys in automating and managing AWS resources programmatically."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_10",
        "Title": "4.10 Ensure security group changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. Security Groups are a stateful packet filter that controls ingress and egress traffic within a VPC.",
        "QueryID": "aws_log_metric_filter_security_group",
        "DocumentURI": "policies/aws_cis_v200_4_10.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.10"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "This AWS Control refers to techniques used to monitor and control access and usage of APIs (Application Programming Interfaces) in real-time. These APIs allow two software applications to communicate with each other and are often used in cloud environments.\n\nIt mentions CloudTrail Logs and CloudWatch Logs. These are two services offered by Amazon Web Services (AWS).\n\n1. AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. It allows you to log, continuously monitor, and retain account activity related to actions across your AWS infrastructure.\n\n2. AWS CloudWatch Logs is a monitoring service for AWS resources and the applications you run on AWS. It allows you to view logs from your servers, databases, and applications, enabling you to diagnose problems in your infrastructure. \n\nThe control suggests directing CloudTrail Logs to CloudWatch Logs or an external SIEM (Security Information and Event Management) environment. \n\nSIEM systems provide real-time analysis of security alerts generated by applications and network hardware. They are used to collect, store, analyze, and present security data in a way that's useful for security teams.\n\nNext, it highlights the importance of establishing corresponding metric filters and alarms. This methodology allows you to receive notifications or automated responses when specific events occur or thresholds are breached.\n\nFinally, the reference to Security Groups pertains to a feature of AWS that provides virtual firewalls to control inbound and outbound traffic on service instances. These are stateful, meaning that changes in state, such as opening a port to incoming traffic, are remembered and influence how future packets are processed. \n\nThe term VPC stands for Virtual Private Cloud. It is a virtual network dedicated to your AWS account where you can launch AWS resources in a virtual network that you define.\n\nIn sum, this AWS Control refers to a combination of AWS services and external analysis systems to monitor and control traffic to and from APIs to maintain security and operational efficiency."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to AWS Control about real-time monitoring of API calls through CloudWatch Logs or SIEM and controlling ingress/egress traffic using Security Groups can lead to multiple implications which can be evaluated in terms of potential costs:\n\n1. **Security breach cost**: Failure to monitor API calls and control network traffic can expose your system to various types of attacks, such as Distributed Denial of Service (DDoS), data breaches or unauthorized access to your AWS resources. The cost of a security breach may include financial losses, reputational damage, and regulatory fines.\n\n2. **Data Loss cost**: In case of a successful breach, confidential data might get compromised. There can be significant cost implications for any lost data or breaches of sensitive/regulated data like customer data, credit card information, etc. |This includes potential damages in lawsuits, regulatory fines, and lost business due to reputational harm.\n\n3. **Regulatory Compliance Fine cost**: For industries subject to regulatory standards like GDPR, HIPAA, etc., failure to adhere to compliance controls can result in heavy fines.\n\n4. **Operational cost**: Without real-time monitoring, the detection of issues, malfunctions, or security threats depends on active user reporting or other detection systems, potentially leading to delayed response times during which services may be interrupted or compromised.\n\n5. **Forensic cost**: If you do not have a real-time tracking of all the API calls, it would be cumbersome, time-consuming and resource-intensive to perform an investigation post a security incident.\n\n6. **Resource Misuse cost**: Without appropriate egress filtering, resources could be misused, leading to higher operational costs.\n\nTherefore, potential costs of non-compliance can be highly significant regarding financial implications, operational efficiency, and organizational reputation. It's thus crucial to comply with stated AWS controls to ensure robust security and efficient operations."
            ],
            "x-kaytu-usefulness-example": [
                "Suppose you have a cloud-based application hosted on AWS platform that provides real-time currency conversion services. This application does a high volume of API calls to pull current currency rates from various exchanges around the world. Real-time monitoring of these API calls is crucial to keep the service robust, secure, and efficient. \n\nYou can use the feature of directing CloudTrail Logs to CloudWatch Logs to keep track of each API call, such as when it was made, the response time and information about any errors that occurred. If there are any unusual trends or spikes, like a sudden increase in the number of API calls or an unexpected number of error responses, CloudWatch can trigger alarms to notify the system administrators or even auto-scale the resources as needed.\n\nSecurity Groups are important in this scenario to ensure that only approved traffic is allowed to communicate with your VPC. This way, any unauthorized access attempts, either inbound or outbound, can be blocked automatically, providing a necessary layer of security to your application. You can customize the rules to allow only specific IP ranges, port numbers, or protocols, ensuring that your VPC is not exposed to unnecessary risks.\n\nExample of the useful instance in markup format:\n```markdown\n- **CloudTrail Logs to CloudWatch**: The real-time monitoring feature of AWS can be used to monitor API calls made by the currency conversion application. This application makes a large volume of API calls regularly to fetch current currency rates. If there is unplanned or unexpected activity, like a surge in the number of API calls or increase in error responses, CloudWatch can trigger an alarm to notify the system administrators of this unusual activity.\n\n- **Security Groups**: With Security Groups in AWS, VPC traffic is monitored and controlled, ensuring only approved communications are allowed with your application. This feature proves useful in automatically blocking any unauthorized access attempts to your application, both inbound and outbound, thus providing a necessary layer of security. Custom rules can be set up to allow only certain IP ranges, port numbers, or protocols, further minimizing potential risks.\n```\nThis setup provides administrators with enhanced control and visibility over their application's activities, making it easier to maintain performance stability and system security."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_11",
        "Title": "4.11 Ensure Network Access Control Lists (NACL) changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. NACLs are used as a stateless packet filter to control ingress and egress traffic for subnets within a VPC. It is recommended that a metric filter and alarm be established for changes made to NACLs.",
        "QueryID": "aws_log_metric_filter_network_acl",
        "DocumentURI": "policies/aws_cis_v200_4_11.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.11"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "# AWS Control Explanation \n\n## Real-time monitoring of API calls \n\nAPI calls can be monitored in real time by directing CloudTrail Logs to CloudWatch Logs, or an external Security Information and Event Management (SIEM) environment. CloudTrail is a service that logs all API calls made on your account. \n\nWhen directed to CloudWatch, you can establish metric filters and alarms. Metric filters are rules that define how CloudWatch will transform and aggregate log data into time-ordered metrics. These metrics help you understand the API traffic, identify trends, debug issues, and set up alarms for when certain thresholds are breached. \n\nAn alternative to CloudWatch is to direct the logs to an external SIEM environment. SIEM tools collect logs and other security-related documentation for analysis. \n\n```markdown\n*Cloudtrail -\u003e CloudWatch/SIEM -\u003e Metric Filters -\u003e Alarms*\n```\n\n## Network Access Control Lists (NACLs)\n\nNACLs are used as a stateless packet filter to control incoming (ingress) and outgoing (egress) traffic for subnets within a Virtual Private Cloud (VPC).\n\n* **Ingress**: Incoming data to a network from a different network. A network access control list (NACL) controls which traffic is allowed from where.\n* **Egress**: Outgoing data from your network to a different one. A NACL also controls what traffic is permitted to leave. \n\nAWS recommends that a metric filter and alarm be established for changes made to NACLs. This monitoring can help you assess the security of your VPC and respond quickly to any unexpected changes.\n\n```markdown\n*NACLs -\u003e Control Ingress/Egress -\u003e Monitor with Metric Filters/Alarms*\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS (Amazon Web Services) control can result in several costs:\n\n- **Security Risk:** Not monitoring changes to your Network Access Control Lists (NACLs) increases your risk of security breaches. NACLs control what traffic is allowed in and out of your subnets. If unauthorized changes were to be made, this could potentially allow malicious activity.\n\n- **Financial Impact:** Security breaches can end up being costly, both from the immediate impact of the breach, such as data theft or systems disruptions, and from the longer-term consequences such as reputational damage, lost business, and potential regulatory fines.\n\n- **Regulatory Compliance:** In many industries, monitoring access and changes to your network is not just a best practice but a requirement. Failure to do so can result in non-compliance with certain regulations, leading to penalties and fines.\n\n- **Operational Disruptions:** Unauthorized changes to NACLs could disrupt your services, leading to downtime for your applications and potential loss of business.\n\nTo sum up, non-compliance with this AWS control could lead to serious security risks, potential regulatory infractions, and disruptions to your operations and services - all resulting in significant costs for your organization."
            ],
            "x-kaytu-usefulness-example": [
                "As an example:\n\nA company has implemented microservices architecture for its application in AWS. Each microservice is exposed as an API and is being consumed by other microservices or third-party applications. This setup requires a strict security check on who is accessing these APIs and what actions are being performed. So, they have enabled CloudTrail Logging for all their APIs and directed these logs to CloudWatch and their external SIEM solution.\n\nBy setting up metric filters and alarms on these logs, the company can immediately identify any suspicious activities on their APIs. For instance, if there is an unusual spike in a specific API call or from a specific IP address, the company can receive real-time alerts.\n\nFurthermore, the firm uses NACLs to control the ingress and egress traffic in their VPC. This helps them isolate their microservices and ensure only authorized traffic can reach them. In a scenario where a new intern unintentionally opens up all the ports in a NACL, this can lead to potential security threats. To mitigate this risk, the company has established a metric filter and alarm for any changes made to NACLs. Once changes are detected, an alarm is triggered, and the security team can review and act on the changes if necessary. \n\nThis Real-time monitoring capability of AWS is highly useful for the company to maintain the security of their services and also comply with external audit requirements.\n\nExample in Markup:\n\n```markdown\nThe company has enabled:\n* **CloudTrail Logging** for all APIs.\n* Directed logs to **CloudWatch** and the **external SIEM** solution.\n* Setup **metric filters** and **alarms** for identifying suspicious activities.\n* **NACLs** used to control **ingress and egress traffic** in VPC.\n\nBenefits:\n* Real-time monitoring of API activities.\n* Immediate identification of suspicious activities.\n* Isolation and protection of microservices with NACLs.\n* Quick alarm on unintentional changes to NACLs.\n* Compliance with external audit requirements.\n```\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_14",
        "Title": "1.14 Ensure access keys are rotated every 90 days or less",
        "Description": "Access keys consist of an access key ID and secret access key, which are used to sign programmatic requests that you make to AWS. AWS users need their own access keys to make programmatic calls to AWS from the AWS Command Line Interface (AWS CLI), Tools for Windows PowerShell, the AWS SDKs, or direct HTTP calls using the APIs for individual AWS services. It is recommended that all access keys be regularly rotated.",
        "QueryID": "aws_iam_user_access_key_age_90",
        "DocumentURI": "policies/aws_cis_v200_1_14.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.14"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS Access keys are a component of AWS Identity and Access Management (IAM) that allow you to authenticate and authorize programmatic requests to AWS services. They comprise of an Access Key ID and a Secret Access key, which pair together to grant you access to AWS services.\n\nYou need these keys whenever you want to make programmatic calls to AWS, such as using AWS CLI, Windows PowerShell Tools, AWS SDKs, or direct HTTP calls through AWS service APIs.\n\nIn terms of AWS security best practices, it is recommended to regularly rotate your access keys. This means that old keys should be replaced with new ones on a regular basis to reduce the risk of unauthorized access in case the keys are compromised.\n\nHere's an example in markup:\n\n```markup\n### AWS Access Keys\n\nAWS Access keys are used to sign programmatic requests that you make to AWS. Each user has their own set of access keys which consist of an Access Key ID and Secret Access Key. The keys are used when making programmatic calls to AWS from various interface such as:\n\n1. AWS Command Line Interface (AWS CLI)\n2. Tools for Windows PowerShell\n3. AWS SDKs\n4. Direct HTTP calls using the APIs for individual AWS services.\n\nRegularly rotating your access keys is a recommended AWS security best practice.\n```\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the stated AWS control can result in multiple costs:\n\n1. **Security Breaches**: If access keys are not regularly rotated, the risk of unauthorized access increases. This could lead to malicious activities such as data theft, data loss, or unplanned service disruption, which could have significant financial and reputational costs.\n\n2. **Non-compliance to Regulatory Standards**: Certain regulations (such as PCI DSS, GDPR, etc.) require companies to implement specific controls regarding access to sensitive data. Not regularly rotating access keys could be seen as a failing to meet these regulatory standards, leading to potential fines and reputational damage.\n\n3. **Increased Operational Risk**: If access keys are compromised and used without authorization, it could lead to abnormal usage patterns or unpredictable system behavior. This could increase the operational risk and potential downtime, affecting business continuity and increasing the cost of operations.\n\n4. **Loss of Trust**: If a security breach occurs due to non-compliance with this control, customers' trust could be lost, negatively impacting brand reputation and future business.\n\n5. **Risk of Audit Failure**: Non-compliance may lead to failure in meeting the requirements of an internal or external audit, leading to potential penalties or increased scrutiny from regulatory bodies.\n\nIn summary, non-compliance with this AWS control around the rotation of access keys increases the risk of security breaches and operational issues, impacts regulatory compliance, and could result in monetary losses, reputational damage, and a potential decrease in customer trust."
            ],
            "x-kaytu-usefulness-example": [
                "**Example:**\n\nSuppose you are an engineer who is part of a team working on a large-scale, cloud-based application that extensively uses services provided by AWS. You have adopted a DevOps approach meaning there's a lot of automation across the development, testing, and deployment processes.\n\nThe application's architecture involves service interactions ranging from computing (EC2), storage (S3), database (DynamoDB), to machine learning (ML) services. This would require frequent programmatic interactions using AWS APIs.\n\nHere, having your own set of Access Keys is not just useful but essential. You could easily integrate them in SDKs or CLI tools to automate and also manage service requests you require for your work. For instance, with the `aws` CLI tool installed, you could use your Access Key ID with a Secret Access Key to manage your EC2 instances:\n\n```bash\n    aws configure set aws_access_key_id YOUR_ACCESS_KEY\n    aws configure set aws_secret_access_key YOUR_SECRET_KEY\n```\n\nAlso, regularly rotating the keys can help the team manage the security risks associated with key leaks or breaches. This policy can be automated through AWS IAM policies, further enhancing your ability to maintain a secure and efficient development environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_15",
        "Title": "1.15 Ensure IAM Users Receive Permissions Only Through Groups",
        "Description": "IAM users are granted access to services, functions, and data through IAM policies. There are three ways to define policies for a user: 1) Edit the user policy directly, aka an inline, or user, policy; 2) attach a policy directly to a user; 3) add the user to an IAM group that has an attached policy. Only the third implementation is recommended.",
        "QueryID": "aws_iam_user_no_inline_attached_policies",
        "DocumentURI": "policies/aws_cis_v200_1_15.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.15"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "Sure! Here is the explanation of the AWS Control mentioned, formatted in markdown:\n\n______________________________________________________________________________________________________\n\nAWS's **Identity and Access Management** (IAM) service allows you to manage access to AWS services and resources securely. Through IAM, you can create and manage AWS users and groups and use permissions to allow and deny their access to AWS resources.\n\nIn AWS, users are granted access to services, functions, and data through IAM policies. IAM Policies define permissions for an action regardless of the method that you use to perform the operation.\n\nThere are three ways to define policies for a user:\n\n1. **Edit the user policy directly:** Here, you formulate a policy specifically for the user in the form of an inline policy. These policies are directly embedded in a single user, and are not standalone policies.\n\n2. **Attach a policy directly to a user:** Instead of creating an inline policy, an existing standalone policy can be directly attached to a user.\n\n3. **Add the user to an IAM group that has an attached policy:** This involves adding a user to an IAM group (a collection of IAM users) that already has a policy attached to it. This allows the policy's permissions to be shared among all of the groupâ€™s members.\n\nFrom a best practices standpoint, it is ***recommended*** to use the third method â€” adding the user to an IAM group. This allows for easier management and control over permissions, especially when dealing with multiple users.\n  \n______________________________________________________________________________________________________\nIn each of these methods, please note that IAM policies control who (the principal), what (the action), when (the conditions), and where (the resources).\nAlso, remember, IAM is universal, it does not apply to regions, and does not charge you extra for using it."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance with this AWS Control could be substantial, encompassing both financial and operational aspects:\n\n1. **Security risks**: Not adhering to these best practices could lead to unregulated access and threats to information security. A poorly managed IAM policy could expose sensitive data to unauthorized individuals, potentially leading to significant security breaches.\n\n2. **Operational inefficiencies**: If users are not grouped and policies are attached individually, management of users and their permissions becomes more complex and time-consuming. Having to add or modify policies on a per-user basis is inefficient and more prone to errors.\n\n3. **Inconsistent permissions**: Without a uniform policy provided by IAM groups, individual users may end up with very different permissions which can lead to inconsistencies while accessing services or functionalities. This could also complicate troubleshooting efforts in case of issues with access or permissions.\n\n4. **Potential non-compliance with regulations**: If your organization is under any kind of data privacy and protection regulations, failing to properly manage access control may result in non-compliance, which could result in hefty fines or lawsuits.\n\n5. **Increased Financial Cost**: All of the above issues compound into increased operational costs. Security breaches can cause significant financial damage, the inefficient operation can increase operational cost and potential non-compliance can result in penalties.\n\nTherefore, it is vital to abide by the prescribed AWS Control to ensure optimum security, efficiency, consistency, and regulatory compliance in managing access to AWS services."
            ],
            "x-kaytu-usefulness-example": [
                "Imagine a company called XYZ Corp that utilizes AWS for its multiple services such as S3 (Simple Storage Service), EC2 (Elastic Compute Cloud), etc. They have different roles such as developers, database administrators, and managers. They all need different levels and kinds of access to the AWS resources. Here is where IAM policy comes into play.\n\n1) Inline Policy: Bob, a new hire, needs access to a specific S3 bucket for a single project which is not common across the team. So, an inline policy is directly attached to Bob, giving him required permissions for this specific case. This function is beneficial when unique permissions are needed for a user.\n\n2) Attach Policy to User: Alice, a senior developer at XYZ Corp, needs access to several AWS services that are commonly used by the other developers. A policy is created with access to these services and directly attached to Alice's IAM user.\n\n3) IAM Group Policy: Most of the database administrators require a common set of access permissions. Instead of attaching policies to each user individually, an IAM group named 'DBAdmins' is created. A policy granting these permissions is attached to this group. Now, any new or existing database administrator can be added to this IAM group, which will automatically grant them the required permissions. This approach promotes ease of user management and control over access permissions.\n\nAll of the above methods are functional, but AWS recommends the third method because it allows businesses to manage permissions more effectively and reduces the chances of error when allocating permissions to individual users. This is particularly beneficial as the number of users grows."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_12",
        "Title": "4.12 Ensure changes to network gateways are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. Network gateways are required to send/receive traffic to a destination outside of a VPC. It is recommended that a metric filter and alarm be established for changes to network gateways.",
        "QueryID": "aws_log_metric_filter_network_gateway",
        "DocumentURI": "policies/aws_cis_v200_4_12.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.12"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS, Amazon Web Services, provides an array of services for cloud computing. It offers capabilities such as real-time monitoring of API (Application Programming Interface) calls. This can be done by directing CloudTrail Logs to CloudWatch Logs or an external Security Information and Event Management (SIEM) environment.\n\n```markdown\n**CloudTrail Logs:** AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain account activity related to actions across your AWS infrastructure.\n\n**CloudWatch Logs:** Amazon CloudWatch Logs lets you monitor, store, and access your log files from Amazon EC2 instances, AWS CloudTrail, and other sources. You can then retrieve the associated log data from CloudWatch Logs.\n\n**Security Information and Event Management (SIEM):** SIEM software collects and aggregates log data generated throughout the organizationâ€™s technology infrastructure, from host systems and applications to network and security devices such as firewalls and antivirus filters.\n\n**Network Gateways:** It's a network node that connects two networks using different protocols together. In the context of VPC (Virtual Private Cloud), network gateways are necessary to send/receive traffic to a location outside of a VPC.\n\nTo ensure the security of your AWS services, it is suggested that a metric filter and alarm be set up for changes to network gateways. A metric filter extracts data from a log and translates it to a numeric value that can be graphed or set an alarm on. By setting an alarm, you will be immediately notified of any changes, ensuring that no changes slip through unnoticed.\n```\n\nIn a nutshell, this AWS Control aims to strengthen the security of your AWS services by monitoring API calls and network gateway changes in real-time."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control can have several potential costs:\n\n1. **Security Risks**: Without real-time monitoring of API calls, chances of malicious activities, data breaches, and unauthorized access in the system can increase significantly. Security risks can lead to significant financial and reputational damage.\n\n2. **Operational Inefficiencies**: Lack of real-time monitoring can lead to underutilization or overutilization of resources, leading to inefficient operations and increased costs.\n\n3. **Regulatory Violations**: Certain industries or applications may be subject to stringent regulatory requirements about auditing and logging. Failure to comply with these can result in hefty fines and penalties.\n\n4. **Network Vulnerabilities**: Not establishing a metric filter and alarm for changes to network gateways make the system vulnerable to potential threats. Any changes in network gateways might go unnoticed, leading to security breaches.\n\n5. **Reduced Trust**: Non-compliance with recommended AWS controls can impact the trust of stakeholders, including customers, partners, and regulators. This might translate into lost business or stiffer regulatory scrutiny.\n\n6. **Incident Response and Forensics Costs**: In case of an incident, lack of proper logging information from API calls and network gateway changes can make incident response, problem diagnosis, and forensic investigations more difficult and costly.\n   \nIn conclusion, non-compliance with this control doesn't just open your system for potential attacks but also raises operating costs, potential regulatory penalties, and the cost of lost trust. It's therefore essential to establish monitoring, alarms and corresponding metrics for proper security control."
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\nA company has various AWS applications being used across different business units, generating a large number of API calls. However, the network security team suspects that there is unauthorized usage or potentially malicious activity going on within these API calls. \n\nThrough AWS CloudTrail, they can record and log all API calls including the identities of callers, the time of the calls, the request parameters, and the responses elements returned by the AWS resource. They then stream these logs to CloudWatch or an external SIEM environment where metric filters and alarms are established to auto-detect anomalies or unauthorized API calls, and immediately flag them for review. \n\nMoreover, the company's IT infrastructure, hosted on VPC, communicates with various third-party solutions, potentially making it a target for cyber threats. Changes to network gateways can signal a security breach or an unauthorized attempt to divert network traffic. \n\nBy establishing a metric filter and alarm on network gateway changes, the security team can receive instant alerts when there are alterations. This allows for immediate action, reducing the potential damage caused by delays in detecting and reacting to security breaches or misconfigurations. \n\nIn conclusion, real-time monitoring of API calls and changes to network gateways significantly strengthens the company's security posture by enabling rapid response to potential security incidents."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_16",
        "Title": "1.16 Ensure IAM policies that allow full \"*:*\" administrative privileges are not attached",
        "Description": "IAM policies are the means by which privileges are granted to users, groups, or roles. It is recommended and considered a standard security advice to grant least privilege -that is, granting only the permissions required to perform a task. Determine what users need to do and then craft policies for them that let the users perform only those tasks, instead of allowing full administrative privileges.",
        "QueryID": "aws_iam_policy_all_attached_no_star_star",
        "DocumentURI": "policies/aws_cis_v200_1_16.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.16"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: IAM Policies\n\nIAM (Identity and Access Management) policies in AWS (Amazon Web Services) are the tool utilized to grant privileges to various entities such as users, groups, or roles within the AWS ecosystem. \n\n## Principle of Least Privilege\n\nOne basic and essential recommendation for ensuring security within these systems is the **principle of least privilege**. This principle involves allocating only the necessary permissions required to carry out a task, rather than giving full administrative controls. \n\nThis strategy reduces the risk of unnecessary exposure and potential damage, by preventing additional and potentially harmful activities.\n\n## Policies Overview\n\nBefore crafting policies, it's critical to identify and articulate the specific tasks that the users need to carry out. The IAM policies should then be specifically designed so that the users can perform *only these tasks*, and no more. \n\nThis approach delivers a safer, more controlled system that effectively balances user need with security concerns. Rather than adopting an all-or-nothing approach in terms of access, each entity is given a customized level of permission that is sufficient for their tasks, but not excessive to permit activities beyond their scope.\n\nThe IAM policies embodying these permissions should be regularly reviewed and updated as necessary, to ensure they still align with the users' tasks and risk profiles.\n\n## Key Takeaway\n\nEstablishing targeted IAM policies and following the principle of least privilege is a vital best practice for maintaining security in AWS. By limiting the permissions granted to the minimum necessary for each user, role or group, the associated security risks are effectively minimized."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to this AWS control about Identity and Access Management (IAM) policies could be catastrophic and significantly impact the organization financially, reputationally, and operationally. \n\nHere are some potential costs:\n\n1. **Security breaches and data leaks:** If users are provided with excessive permissions beyond their job responsibilities, this increases the attack surface for malicious actors. Attackers who compromise such an account get broader access, resulting in significant data breaches.\n\n2. **Financial loss:** A compromised account with full administrative privileges could lead to unauthorized usage of AWS services, potentially resulting in a huge financial cost due to unexpected AWS usage bills.\n\n3. **Compliance penalties:** Non-compliance could lead to failure in audits, resulting in hefty penalties and fines from regulatory bodies, depending on the industry and jurisdiction of operation.\n\n4. **Reputational damage:** Loss of trust from customers or partners due to a security breach can significantly impact the business in the long term.\n\n5. **Operational disruptions:** Unauthorized alterations or deletion of important data or infrastructure can lead to service disruptions, which directly affect business operations.\n\n6. **Resource Mismanagement:** With broader permissions, it is easier for users to accidentally mismanage resources, resulting in unintentional costs or even the loss of data or services.\n\n7. **Time and Resources:** In the event of a breach, a lot of time and resources have to be spent on investigations, fixes, mitigation and on any resulting legal issues.\n\nIn conclusion, adhering to the principle of 'least privilege' in IAM policies is critical for managing risks and preventing potential negative implications for your company."
            ],
            "x-kaytu-usefulness-example": [
                "```markdown\nExample:\nImagine a software development company, ABC Corp, use AWS services for different aspects of their operation. They use EC2 for web servers, S3 for data storage, RDS for database, and so on. The company has different teams - the Web team, Database team, and Data Analysis team - each requiring different access levels on AWS.\n\nIAM policies come into play here. \n\nThe Web team needs access to EC2 instances, but they do not need access to the RDS databases or S3 buckets. Therefore, an IAM policy is created by ABC Corp which allows members of the web team to read, write, and modify EC2 instances, but doesn't provide any access to RDS databases or S3 buckets, thereby adhering to the principle of least privilege. \n\nSimilarly, different IAM policies are created for the Database team allowing required privileges on RDS, and the Data Analysis team allowing access to S3 buckets, but not EC2 or RDS. \n\nThis way, ABC Corp ensures every team has just enough access to perform their tasks without any unnecessary permissions, ensuring the AWS resources are secured, and the chances of accidental changes or breaches are minimized.\n```\n"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_13",
        "Title": "4.13 Ensure route table changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. Routing tables are used to route network traffic between subnets and to network gateways. It is recommended that a metric filter and alarm be established for changes to route tables.",
        "QueryID": "aws_log_metric_filter_route_table",
        "DocumentURI": "policies/aws_cis_v200_4_13.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.13"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "This AWS control refers to the process of continuously monitoring API (Application Programming Interface) calls in real-time. This can be accomplished by directing AWS CloudTrail Logs (which records API call history) to AWS CloudWatch logs, or an external SIEM (Security Information and Event Management) environment. In AWS, SIEM environments are tools used to provide real-time analysis of security alerts.\n\nTo enhance this monitoring further, you can set up specific metric filters and alarms. These alarms can notify you of specific actions or events within your AWS environment. For example, if a certain API call frequency passes a defined threshold, you could receive a notification.\n\nIn terms of route tables, they are crucial components for directing network traffic between subnets (a logical subdivision of an IP network) and network gateways in AWS. Given their importance in managing network flow, monitoring changes to route tables becomes critical. \n\nHence, it is recommended to establish a metric filter and alarm for any changes/modifications to these route tables to maintain control and visibility across your network infrastructure. This will allow you to respond to any unexpected changes or potentially suspicious activities in a timely manner."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the mentioned AWS control may lead to various possible implications, including but not limited to: \n\n1. **Security risks**: Without monitoring API calls in real-time, unauthorized or malicious activities might go undetected. This could put your resources and data at risk of breaches or leakages. \n\n2. **Operational disruptions**: Any unauthorized changes to the routing tables could result in disrupted network traffic, affecting your services and operations.\n\n3. **Data compliance risks**: If you are under regulations (like the GDPR, HIPAA, etc.) that require you to monitor access to certain data, you could face compliance violations, triggering potential regulatory fines and sanctions.\n\n4. **Unanticipated Costs**: Non-compliance might result in unexpected changes which might increase the resource utilization, leading to increased costs.\n\n5. **Loss of Trust**: If a breach occurs and is made public, trust from customers and partners might be lost, affecting business relationships and reputation.\n\nAs a result, it is crucial to establish a metric filter and alarm for changes to route tables and ensure real-time monitoring of API calls by directing CloudTrail Logs to CloudWatch Logs or an external SIEM environment. These measures will provide timely alerts about any suspicious activity, enabling you to take quick action and minimize damage."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a company has a production environment deployed in an AWS VPC (Virtual Private Cloud). The network traffic within this environment is routed using AWS routing tables. These routing tables are critical for ensuring that network traffic is properly directed to the correct resources.\n\nSuddenly, there's a change in the routing table, which diverts the traffic to a different unauthorized subnet, leading to a potential security threat or service disruption. If the company had set up real-time monitoring for API calls on the AWS CloudTrail logs, it could have directed these logs to AWS CloudWatch or an external SIEM environment.\n\nHere's an example of how this can be established in a CloudFormation template:\n\n```markdown\nMyRouteTableAlarm:\n  Type: 'AWS::CloudWatch::Alarm'\n  Properties:\n    AlarmDescription: Alert on route table changes\n    Namespace: AWS/Logs\n    MetricName: RouteTableChangeCount\n    Statistic: SampleCount\n    Period: 300\n    EvaluationPeriods: 1\n    Threshold: 1\n    ComparisonOperator: GreaterThanOrEqualToThreshold\n    AlarmActions:\n    - arn:aws:sns:us-west-1:123456789012:myRouteTableAlertTopic\n```\n\nThis configuration specifies that an alarm 'MyRouteTableAlarm' should be triggered when there is at least one change (`Threshold: 1`) in the route table within a 5-minute interval (`Period: 300`). The alarm notification can then be sent to the specified SNS topic (`AlarmActions`).\n\nThis real-time monitoring and alarm on changes to the routing table can help the company detect potential security issues or misconfigurations promptly, therefore increasing the robustness of their cloud environment security."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_14",
        "Title": "4.14 Ensure VPC changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, or an external Security information and event management (SIEM) environment, and establishing corresponding metric filters and alarms. It is possible to have more than 1 VPC within an account, in addition it is also possible to create a peer connection between 2 VPCs enabling network traffic to route between VPCs. It is recommended that a metric filter and alarm be established for changes made to VPCs.",
        "QueryID": "aws_log_metric_filter_vpc",
        "DocumentURI": "policies/aws_cis_v200_4_14.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.14"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "```markdown\nThe **AWS feature**, allows real-time tracking of API calls by sending `CloudTrail Logs` to `CloudWatch Logs` or an external `Security Information and Event Management (SIEM)` system. Then, you can set up appropriate metric filters and alarms. \n\nOne AWS account can have **multiple Virtual Private Clouds (VPCs)**. This allows for the segregation of resources and network traffic for different applications or environments under the same AWS account. \n\nMoreover, it's possible to create a **VPC peering connection** between two VPCs. This provides a direct, private connection between the VPCs and allows for the routing of network traffic between them. \n\nIt is strongly recommended to set up a `metric filter` and `alarm` for any changes made to your VPCs. This provides constant monitoring and alerts for modifications, thereby enhancing the security of your resources by quickly detecting and responding to any unauthorized changes.\n```\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the mentioned AWS control can lead to multiple costs. These are:\n\n1. **Loss of Data Confidentiality**: If the real-time monitoring of API calls is not performed, it can lead to the chance of unauthorized access to API services without being detected. This may lead to data breaches.\n\n2. **Decreased Network Visibility**: Non-compliance to this control will result in decreased network visibility and control over activities that are being performed. \n\n3. **Security Breaches**: Without monitoring changes made to VPCs, it's possible that an attacker could make changes that allow them to infiltrate the systems or exfiltrate valuable data.\n\n4. **Infrastructure Damage**: An attacker can create, modify or delete VPCs, potentially causing damage to the cloud infrastructure.\n\n5. **Non-Compliance to Regulatory Standards**: Non-compliance to this AWS control might be a violation of certain industry regulations (like SOX, HIPAA, or GDPR) which can lead to legal penalties.\n\n6. **Potential System Disruptions**: Malicious changes to VPCs can cause system downtime or failure, impacting business continuity.\n\nIn summary, the cost of non-compliance can be significantly high considering the loss of data, potential infrastructure damage, decreased business continuity, potential legal penalties and massive security risks."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, let's imagine that a company has several virtual private clouds (VPCs) in their AWS environment, one for their development team, another for staging, and a different one for production. All of this environment handles sensitive data and configurations specific to the company's business process and the services it offers to its customers.\n\nHowever, there have been situational reports of security incidents where changes made to VPCs have not been properly tracked, leading to unauthorized access, data leakage, and non-compliance with the company's internal/external audit standards. This poses a serious security vulnerability that could affect the company's business integrity.\n\nTo solve this problem, the company can take advantage of real-time monitoring of API calls by directing CloudTrail Logs to CloudWatch Logs for all VPC-related activities. This way, they utilize AWS services to track every operation made on their VPCs, monitor those API calls in real-time, and obtain comprehensive details about API actions. \n\nThese actions include who made the request, the services used, the actions performed, parameters for the actions, and the response elements returned by the AWS service. In case any unauthorized or unexpected changes are made to the VPC(s), they can be instantly flagged and investigated with the collected data.\n\nFurthermore, having an attached metric filter and alarm to track changes made on VPCs would alert the security team in real-time if there are any configurations or security group changes that deviate from the company's baseline. This could help the company to quickly prevent any potential damaging operations through immediate alarm notifications, thereby enhancing the security posture of VPCs and, in general, the AWS environment. \n\nNotably, if the company has an external SIEM environment, these logs could be directed there for further granulation and correlation with other logs for a full-fledged security monitoring."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_17",
        "Title": "1.17 Ensure a support role has been created to manage incidents with AWS Support",
        "Description": "AWS provides a support center that can be used for incident notification and response, as well as technical support and customer services. Create an IAM Role to allow authorized users to manage incidents with AWS Support.",
        "QueryID": "aws_iam_support_role",
        "DocumentURI": "policies/aws_cis_v200_1_17.md",
        "ManualVerification": false,
        "Severity": "Medium",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.17"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "```\n# AWS Support Center\n\nAmazon Web Services provides a comprehensive **Support Center** that serves as a platform for incident notification and response. It is also designed to provide technical support and customer services.\n\n## Incident Management with AWS Support\n\nEnsuring quick response and effective management of incidents is crucial in any system. AWS provides the ability to manage incidents via the *AWS Support Center*. \n\nYou can create an **IAM role** to enable authorized users to manage incidents. A user with this IAM role can access AWS Support Center and perform tasks depending on granted permissions.\n\nTo set up an IAM Role for managing incidents with AWS Support, follow the steps below:\n\n1. Login to AWS Management Console.\n2. Navigate to the IAM service.\n3. Click on *Roles* in the left navigation panel.\n4. Click on *Create role* button.\n5. Select *Another AWS account* for the *Select type of trusted entity*.\n6. Provide the necessary information including Account ID etc. and click *Next*.\n7. Choose a policy that best fits your security requirement. If the policy doesn't exist, you need to create it before this point.\n8. Click *Next* twice.\n9. Provide a name and a description for the role.\n10. Click on *Create role* button.\n\nThe users with this IAM role now have the ability to manage incidents with AWS Support.\n\n***Note:*** *Beware that any permissions you grant in your IAM policy give the specified permissions to the role in the AWS environment, so grant them wisely.*\n```\nThis Markdown document explains the AWS Support Center, its features for incident management and the steps to add an IAM role to allow a user to manage incidents with AWS Support."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS Control can lead to several adverse implications:\n\n1. **Increased Security Risks:** Without allowing authorized users the ability to manage incidents with AWS Support, you may be missing out on timely and necessary security updates or fixes, which can potentially expose your system to unnecessary risks.\n\n2. **Delayed Resolution:** Managing incidents effectively is crucial to minimize their potential impact. If unauthorized users are tasked with managing incidents, resolution times may increase.\n\n3. **Poor Customer Service:** Should there be service disruptions or other operational problems, your end-users may suffer from poor customer service due to a lack of incident management.\n\n4. **Compliance issues:** In industries with certain regulatory requirements, not providing roles to manage incidents may lead to non-compliance, which could result in fines or sanctions.\n\n5. **Increased Operational Cost:** Unauthorized users might not be able to fully utilize AWS Support, resulting in improper solutions being applied, causing more issues down the line and thereby increasing overall operational costs.\n\nSo, the cost of non-compliance to this AWS Control can vary from regulatory fines, increased operational cost, to significant business losses due to service disruptions and poor customer service."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, let's say a retail company has its e-commerce store hosted on AWS. The company has an IT team that manages and monitors the AWS resources and applications. Typically, the team members will need access to AWS Support for various reasons such as incident response, troubleshooting, and technical consultations. \n\nIn such a case, creating an IAM role specifically dedicated to AWS Support can be highly beneficial. It will ensure that only the authorized IT employees will have the necessary permissions to work with AWS Support, thus maintaining the security and integrity of the company's AWS resources.\n\nHere is how the markup might look:\n\n```markup\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"AWSSupportAccess\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"support:*\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n``` \n\nThis policy grants permissions to execute any action on the AWS Support service. By attaching this policy to IAM roles, the company can manage who has the ability to access AWS Support services. This allows the IT team to effectively respond to incidents, consult with AWS technical support, and access customer services when necessary, while maintaining a secure environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_18",
        "Title": "1.18 Ensure IAM instance roles are used for AWS resource access from instances",
        "Description": "AWS access from within AWS instances can be done by either encoding AWS keys into AWS API calls or by assigning the instance to a role which has an appropriate permissions policy for the required access. \"AWS Access\" means accessing the APIs of AWS in order to access AWS resources or manage AWS account resources.",
        "QueryID": null,
        "DocumentURI": "policies/aws_cis_v200_1_18.md",
        "ManualVerification": true,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.18"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "AWS offers two core methods for enabling programmatic access from within an AWS instance. These include directly embedding AWS keys into API calls and attaching an IAM role to the instance that includes the necessary permissions policy. \n\n**Encoding AWS Keys**\n\nAccess to AWS APIs can be facilitated by embedding AWS keys into the API requests moving back and forth within an instance. These keys consist of the AWS Access Key ID and Secret Access Key, which are linked with an IAM user. This approach allows for the execution and control over AWS services within that instance.\n\nHowever, it might pose security risks because if these keys are disclosed or compromised, an unauthorized user could potentially access and control AWS resources linked to those keys.\n\n```markdown\nNote: Embedding AWS keys directly in your code is not recommended as the best practice for securing AWS keys due to potential security risks.\n```\n\n**Assigning IAM Role to the Instance**\n\nA safer approach is to assign an IAM (Identity Access Management) role to the instance and set an appropriate permissions policy for that role. The permissions policy delineates which AWS services and resources the instance with that role can access.\n\nTo assign a role to an instance, you create the role and assign permissions to that role first. Then when launching the instance, you choose the IAM role to associate with the instance. The role then grants permissions that are necessary for applications running on the instance to interact with other AWS resources.\n\nIn the context of AWS, \"Access\" generally refers to the ability to interact with AWS APIs, which allows manipulation and management of AWS resources within an AWS account.\n\n```markdown\nKey Terms\n- **AWS API**: Enables interaction with AWS services.\n- **IAM Role**: An entity in AWS that defines a set of permissions for making AWS service requests.\n- **Permissions Policy**: A document that defines access permissions for AWS resources.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control could potentially lead to a range of problems, such as:\n\n1. **Cost Implications**: Without proper controls, users might misuse the services leading to increased cost. Unexpectedly high usage from one or more resources could result in inflated charges that could have been avoided with appropriate access policies in place.\n\n2. **Security Threat**: If AWS keys are hard-coded into AWS API calls, then anyone who gains access to these scripts or code will effectively gain potentially unlimited access to your AWS account. This could lead to unauthorized access to sensitive information, attacks on your AWS resources, or unauthorized alterations.\n\n3. **Difficulty in Auditing and Tracking**: Lack of compliance to this control means it would be very difficult to track who did what within the AWS environment. This could cause significant issues when attempting to audit usage for compliance or investigate a security incident.\n\n4. **Data Breach**: Non-compliance could mean potential data breaches if an unauthorized person can gain access to your AWS account. This can lead to loss of sensitive data, harm to the companyâ€™s reputation and potential legal implications.\n\n5. **Inefficient Resource Management**: With unrestricted access, resources might not be optimally utilized, leading to wastage and further increased costs.\n\nTo avoid these problems, itâ€™s best to assign an appropriate IAM role to the instance at launch time, which endows the instance with the permissions it needs to interact with other AWS services, adhering to the principle of least privilege. This way, access keys are automatically rotated, reducing the chance of credentials being compromised."
            ],
            "x-kaytu-usefulness-example": [
                "AWS Access allows users to manage their cloud resources programmatically via API calls, which can range from launching new instances, storage services, database operations, network setups, and much more.\n\nHere's an example:\n\nA web application called `MyWebApp` is hosted on an EC2 instance in AWS. This application needs to access files from an S3 bucket named `MyBucket` to display certain contents on the web page. However, you want to ensure that your access keys are not exposed and security is maintained.\n\nYou can achieve this by assigning a role to the EC2 instance on which `MyWebApp` is running. This role should have a permissions policy that includes access to the necessary S3 services.\n\nSteps to achieve this:\n\n1. Create an IAM role and name it `MyWebAppRole`.\n2. Attach a policy to this role that allows access to S3. \n\n   In markup format, the policy would look something like this:\n    ```\n    {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": \n                    \"s3:GetObject\",\n                    \"s3:ListBucket\"\n                ],\n                \"Resource\": [\n                    \"arn:aws:s3:::MyBucket\",\n                    \"arn:aws:s3:::MyBucket/*\"\n                ]\n            }\n        ]\n    }\n    ```\n3. Assign this IAM role (`MyWebAppRole`) to the EC2 instance of `MyWebApp`.\n\nNow `MyWebApp` can access the necessary files from `MyBucket` securely without exposing AWS access keys. The application will retrieve temporary security credentials to the AWS services, which are automatically rotated. This leverages the power of AWS Access from within AWS instances. \n\nTherefore, AWS Access is incredibly useful for managing services securely and also grants access to AWS resources to perform the necessary functions of your applications hosted on EC2 instances."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_15",
        "Title": "4.15 Ensure AWS Organizations changes are monitored",
        "Description": "Real-time monitoring of API calls can be achieved by directing CloudTrail Logs to CloudWatch Logs, and establishing corresponding metric filters and alarms. It is recommended that a metric filter and alarm be established for AWS Organizations changes made in the master AWS Account.",
        "QueryID": "aws_log_metric_filter_organization",
        "DocumentURI": "policies/aws_cis_v200_4_15.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.15"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/CloudWatch"
            ],
            "x-kaytu-explanation": [
                "AWS Organizations is a service that allows you to centrally manage and enforce policies for multiple AWS accounts. AWS Control is a recommendation under AWS Security Best Practices to ensure that any changes made in the organizations within AWS are monitored and alarmed in real time. This control mechanism assists in preventing unauthorized or inadvertent changes to the AWS environment.\n\nHere's the control explained in detail:\n\n### AWS Control: \n\n- **What it is:** AWS Control is about maintaining a real-time monitoring system for AWS Organizations changes made in the master AWS Account using CloudTrail Logs, CloudWatch Logs, metric filters, and alarms.\n\n- **How it works:** \n  - **CloudTrail Logs:** AWS CloudTrail is a service that provides event history of your AWS account activity, including actions made through the AWS Management Console, AWS SDKs, command-line tools, and other AWS services. This activity includes any actions taken in the AWS Organizations. The CloudTrail logs all the API calls and delivers them to a specified S3 bucket. By logging API calls, CloudTrail helps you to review changes and improve the security of your account.\n  - **CloudWatch Logs:** The CloudTrail logs can be directed to AWS CloudWatch Logs, a monitoring and observability service.\n  - **Metric Filters:** They can extract data about AWS Organizations changes and transform them into CloudWatch metrics.\n  - **Alarms:** These can be established after setting metric filters to get notified when specific changes occur.\n\n- **Why it is important:** Setting up the alarm for changes assists in taking immediate action when unexpected changes occur. It helps you keep track of the organization's modifications and ensures those changes do not lead to a security risk.\n\n```markdown\nAWS Control in Summary:\n\n1. [AWS CloudTrail](https://aws.amazon.com/cloudtrail/) logs API calls in AWS Organizations.\n2. These logs are directed to [AWS CloudWatch Logs](https://aws.amazon.com/cloudwatch/).\n3. [Metric filters](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CloudWatchLogsConcepts.html) are set up for the logs to extract data about AWS Organizations changes.\n4. [Alarms](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html) are established for the metrics from the filters to notify when specific changes occur.\n```\n\n- **Recommendations:** To enhance the benefits of AWS Control, it is crucial to review and update your metric filters and alarms regularly. It is also suggested to limit who has access to making changes within AWS Organizations and to regularly analyze the established alarms. \n\nTo ensure the best usage of AWS Control, invest time in understanding the organizational requirements and define metrics and alarms that would be most useful for the specific AWS environment."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS Control and not setting up real-time monitoring of API calls can lead to several potential risks and costs. \n\n1. **Security Risks**: A significant risk is the security vulnerabilities it can cause. If not monitored, unauthorized API calls could be made, leading to the potential for data breaches.\n\n2. **Operational Risks**: Any changes in the AWS organization without proper monitoring can lead to operational issues. This can affect the performance, availability, and efficiency of applications in the AWS environment.\n\n3. **Compliance Risks**: For companies in regulated industries, non-compliance can result in penalties, fines, or major legal consequences. This could also affect their certification status with bodies like ISO, PCI DSS, etc.\n\n4. **Increased Costs**: Without proper monitoring of changes made in the AWS Organizations, you could have increased usage and hence, increased costs. \n\n5. **Reputation Damage**: If unauthorized changes lead to data loss or downtime, it can result in loss of customer trust and damage to your business reputation. \n\nHence, it is recommended that real-time monitoring of API calls in AWS Organizations be established to secure your AWS environment."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, an IT firm uses AWS Organizations to manage multiple accounts under one master account. A potential security threat could include unauthorized changes made to the AWS Organizations structure from within the master account. \n\nBy directing CloudTrail Logs to CloudWatch Logs and establishing corresponding metric filters and alarms, the firm can achieve real-time monitoring of API calls, especially those related to AWS Organizations changes.\n\n```markdown\n- Suppose an unauthorized user attempts to create a new account, remove an existing account, or change the organizational units' structure. \n- CloudTrail Logs would capture this API call event.\n- The logs are then directed to CloudWatch, where the corresponding metric filter detects the AWS Organizations change.\n- An alarm is instantly triggered, sending alerts to the IT firm's security team in real time. \n- This allows the team to promptly investigate and respond to the potential security threat, minimizing any potential damage. \n```\n\nThus, this AWS Control enables the IT firm to maintain strong security oversight over its AWS Organizations structure, helping to prevent unauthorized changes and potential breaches."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_1_19",
        "Title": "1.19 Ensure that all the expired SSL/TLS certificates stored in AWS IAM are removed",
        "Description": "To enable HTTPS connections to your website or application in AWS, you need an SSL/TLS server certificate. You can use ACM or IAM to store and deploy server certificates. Use IAM as a certificate manager only when you must support HTTPS connections in a region that is not supported by ACM. IAM securely encrypts your private keys and stores the encrypted version in IAM SSL certificate storage. IAM supports deploying server certificates in all regions, but you must obtain your certificate from an external provider for use with AWS. You cannot upload an ACM certificate to IAM. Additionally, you cannot manage your certificates from the IAM Console.",
        "QueryID": "aws_iam_server_certificate_not_expired",
        "DocumentURI": "policies/aws_cis_v200_1_19.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "1.19"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/IAM"
            ],
            "x-kaytu-explanation": [
                "# AWS Control: Enabling HTTPS Connections using SSL/TLS Server Certificates \n\nAmazon Web Services (AWS) provides secure mechanisms to enable HTTPS connections for your website or application. This is mainly facilitated through the use of SSL/TLS server certificates.\n\nAWS provides two services for storing and deploying these server certificates:\n\n1. **AWS Certificate Manager (ACM)** \n2. **Identity and Access Management (IAM)** \n\nYou can use either of these services depending on the regions your application must support HTTPS connections.\n\n## AWS Certificate Manager (ACM)\n\nACM is typically the preferred service to manage SSL/TLS certificates. However, you should note that not all regions are supported by ACM.\n\n## Identity and Access Management (IAM)\n\nFor cases where you need to support HTTPS connections in regions which are not supported by ACM, you should use IAM as a certificate manager. IAM provides secure encryption for your private keys and stores the encrypted version in IAM SSL certificate storage.\n\nIAM supports deployment of server certificates in all regions. However, you must obtain your certificate from an external provider for use with AWS.\n\n## Limitations\n\nThere are some limitations to understand:\n\n* You **cannot** upload an ACM certificate to IAM.\n* You **cannot** manage your certificates from the IAM Console.\n\nThese constraints require you to ensure you properly understand the regions in which your application requires HTTPS connections and thus, which AWS service may best suit your needs."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to the above Amazon Web Services (AWS) control could have several potential costs for an organization:\n\n- **Security Risks**: If an organization fails to properly encrypt its HTTPS connections with valid SSL/TLS server certificates, it would expose user data to potential interception and unauthorized access. This could potentially lead to data breaches.\n\n- **Monetary Costs**: Data breaches could result in severe financial penalties depending on the jurisdiction and the nature of the data compromised. For example, under GDPR, companies can be fined up to 4% of annual global turnover or â‚¬20 million for the most serious infringements.\n\n- **Loss of Reputation**: Data breaches could result in loss of trust from customers, impacting the company's reputation and leading to loss of business.\n\n- **Non-compliance Fees**: If AWS detects non-compliance with their security controls repeatedly, they may impose penalties or fees on the AWS user. Non-compliance could also violate the terms of service leading to AWS service suspension or termination.\n\n- **Operational Costs**: If HTTPS connections are not supported in a region not supported by ACM and an organization doesn't utilize IAM to manage certificates, they may encounter significant operational difficulties or downtime, impacting business operations and resulting in additional costs.\n\n- **Vendor Dependency**: If you must obtain your certificate from an external provider for use with AWS and do not adhere to the guidelines, it may lead to vendor lock-ins, restricting freedom and flexibility to shift to other vendors or solutions.\n\nOverall, ensuring compliance with this control is essential in maintaining data security, avoiding penalties, and ensuring smooth business operations within AWS."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider a scenario where you have a web application hosted in an AWS region that is currently not supported by ACM (AWS Certificate Manager). In this case, you may choose to use IAM (Identity and Access Management) as your certificate manager to enable HTTPS connections to your application.\n\nHere are the steps to do this:\n\n- Obtain your SSL/TLS server certificate from an external provider.\n- Upload the certificate to AWS using the IAM command line interface (CLI).\n- Then, when configuring your AWS resources like Elastic Load Balancer or CloudFront, specify the IAM certificate for the HTTPS listener. \n\nLet's consider you're using Elastic Load Balancer. You would then update your ELB with the newly uploaded SSL certificate using the AWS Management Console, CLI, or SDKs.\n\n```\naws iam upload-server-certificate \\\n  --server-certificate-name ExampleCertificate \\\n  --certificate-body file://Certificate.pem \\\n  --private-key file://PrivateKey.pem \\\n  --certificate-chain file://CertificateChain.pem\n```\n\nOnce the SSL certificate is uploaded and confirmed to IAM, the HTTPS connections to your web application are secured, providing users with secure access to your application, even though your hosted region does not support ACM. \n\nThis use-case clearly demonstrates how IAM's ability to store and deploy server certificates helps in cases where ACM cannot be utilized due to certain regional limitations."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_4_16",
        "Title": "4.16 Ensure AWS Security Hub is enabled",
        "Description": "Security Hub collects security data from across AWS accounts, services, and supported third-party partner products and helps you analyze your security trends and identify the highest priority security issues. When you enable Security Hub, it begins to consume, aggregate, organize, and prioritize findings from AWS services that you have enabled, such as Amazon GuardDuty, Amazon Inspector, and Amazon Macie. You can also enable integrations with AWS partner security products.",
        "QueryID": "aws_securityhub_enabled",
        "DocumentURI": "policies/aws_cis_v200_4_16.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "4.16"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "4"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/SecurityHub"
            ],
            "x-kaytu-explanation": [
                "## AWS Security Hub \n\nAWS Security Hub is a comprehensive security and compliance management solution. It gathers security data from across AWS accounts, services, and even supported third-party partner products. \n\n```markdown\nKey Features:\n1. **Data Collection:** Security Hub collects security data from various sources across your AWS services, accounts, and even third-party partner products.\n2. **Security Analysis:** It helps you to analyze your security trends and identify the top priority security issues that need to be addressed.\n3. **Integration:** It integrates with various AWS services, such as Amazon GuardDuty, Amazon Inspector, and Amazon Macie. Plus, it also supports integration with AWS partner security products for an extensive security coverage.\n\nHow it Works:\n- When you enable Security Hub, it starts consuming, aggregating, organizing, and prioritizing the findings from the AWS services that you have enabled.\n- These findings are then presented in a clear and organized way for you to identify top priority security issues and trends.\n```\n\nOverall, AWS Security Hub is a powerful tool when it comes to managing security and handling compliance tasks on AWS."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance with the AWS Security Hub control could be significant, and can be categorized into financial, reputational, and operational impacts. \n\n1. **Financial Impacts**: Non-compliance can lead to hefty fines and penalties from regulatory authorities if the company is found to be violating data protection or industry-specific regulations. These fines can be substantial and could inflict a serious blow to the company's financial health. In addition, the company may have to bear the cost of security incidents such as data breaches which could prove expensive in terms of recovery, legal fees, customer compensation, among others.\n\n2. **Operational Impacts**: Non-compliance can potentially lead to operational disruptions. In the event of a cyber-attack or data breach, a company's operations may have to be halted to identify the root cause of the attack, to mitigate the risk, and to implement necessary security measures. This can result in operational inefficiencies, reduced productivity, and loss of business, especially if the company is heavily reliant on its digital infrastructure and data systems.\n\n3. **Reputational Impacts**: Companies that fail to comply with the AWS Security Hub control may harm their reputation. This could result in a loss of customer trust and loyalty, diminishing customer base, and even impair the company's ability to attract new customers or partners. Furthermore, it can negatively impact relationships with stakeholders and lead to further financial consequences. \n\nThus, non-compliance with AWS Security Hub, a critical control for managing and analyzing security trends across AWS services and third-party integrations, poses serious risks and costs from financial, operational, and reputational perspectives. To avoid these potential consequences, it is crucial for companies to prioritize adherence to this control."
            ],
            "x-kaytu-usefulness-example": [
                "AWS Security Hub can be extremely useful in a scenario where an organization has multiple AWS accounts and uses various AWS services. For example, a large corporation may have separate AWS accounts for different departments, such as marketing, sales, and IT. Each of these departments might use different AWS services like S3 for storage, EC2 for computing, and RDS for databases. Alongside these core services, they might also use security services like GuardDuty, Inspector, and Macie to monitor and protect their infrastructure.\n\nIf each department is managing security separately, it can be a daunting task to maintain an overview of the overall security posture. There might be risks and vulnerabilities that are going unnoticed because of the lack of centralized management and reporting.\n\nBy enabling AWS Security Hub in this scenario, the organization can consolidate and centralize their security findings. Security Hub will automatically collect security data from all accounts, services, and even supported third-party products. This will provide the security team with a comprehensive view of the company's security posture.\n\nThe security team can quickly identify the highest priority security issues across all accounts and services, allowing them to respond promptly. Security Hub also analyzes trends in security data, which can help the organization identify systemic issues and vulnerabilities. \n\nFurthermore, with data from all accounts and services in one place, the organization can save time and resources that would otherwise be spent on gathering and managing security data. They can also enable integrations with other AWS partner security products for additional insights.\n\n    ```\n    Enable AWS Security Hub in your AWS console -\u003e Associate all your AWS Accounts -\u003e Enable all the Services -\u003e Start receiving aggregated and prioritized security findings from all your associated accounts and enabled services.\n    ```\n\nSo, in the provided scenario, the AWS Security Hub plays a major role in simplifying security management and improving the overall security posture across a large, dispersed AWS environment."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_1_1",
        "Title": "2.1.1 Ensure S3 Bucket Policy is set to deny HTTP requests",
        "Description": "At the Amazon S3 bucket level, you can configure permissions through a bucket policy making the objects accessible only through HTTPS.",
        "QueryID": "aws_s3_bucket_enforces_ssl",
        "DocumentURI": "policies/aws_cis_v200_2_1_1.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.1"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "Amazon S3 bucket policies define the permissions for the Amazon S3 resources theyâ€™re attached to, and you can use these policies to define and control access to your S3 buckets and objects. A bucket policy allows you to make the objects within a specific S3 bucket accessible only through HTTPS, which means the client protocol for data transmission must be secure.\n\nYou can add a bucket policy to enforce secure transfer of data (that is HTTPS) with Amazon S3 by specifying a condition in the bucket policy that denies any Amazon S3 operation if the request is not over HTTPS.\n\nHere is an example of such a policy:\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Id\": \"ForceHttpsPolicy\",\n  \"Statement\": [\n    {\n      \"Sid\": \"ForceHttpsSid\",\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\", \n      \"Action\": \"s3:*\",\n      \"Resource\": \"arn:aws:s3:::BucketName/*\",\n      \"Condition\": {\n        \"Bool\": {\n          \"aws:SecureTransport\": \"false\"\n        }\n      }\n    }\n  ]\n}\n```\n\nIn the above sample bucket policy:\n\n- `\"Effect\": \"Deny\"` - Specifies that the action is denied.\n- `\"Principal\": \"*\"` - The user, service, or anonymized user to apply the policy. `*` applies the policy to all users.\n- `\"Action\": \"s3:*\"` - Denies all S3 actions.\n- `\"Resource\": \"arn:aws:s3:::BucketName/*\"` - The bucket and objects within the bucket the policy is applied to.\n- `\"Condition\": { \"Bool\": { \"aws:SecureTransport\": \"false\" } }` - The policy specifies that if the condition is not met (that is, if the `aws:SecureTransport` key isn't set to true), then the action is denied; in this case, communication must be over HTTPS."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control might lead to multiple costs â€“ professionally, financially, and reputationally. Here's a breakdown of potential costs:\n\n1. **Data Breaches**: The primary cost is the risk of data breaches. If your S3 buckets are accessed using HTTP, data transferred can be intercepted and possibly altered or stolen. In today's digital age, data is a critical entity and any breach could result in massive damage, both financial and reputational.\n\n2. **Financial Loss**: Depending upon the nature of the data, the financial costs can be huge. Data breach costs include incident response, legal fees, potential fines under regulations like GDPR, recovery of lost data, system upgrades, and potential for ransom if this was a ransomware attack. \n\n3. **Loss of Trust and Reputation**: Post a data breach, organizations often face a significant loss of customer trust, which impacts their reputation in the market. This can lead to decreased business, as customers and potential business partners may choose to collaborate with organizations that have better security controls.\n\n4. **Regulatory Sanctions**: If the leaked data is of a sensitive nature (personal identifying information, financial data, health data, etc.), your organization might face regulatory sanctions. This can be in form of penalties or fines imposed by legal authorities like the Federal Trade Commission or under regulations like the General Data Protection Regulation (GDPR) or the California Consumer Privacy Act (CCPA).\n\n5. **Non-compliance Costs**: Organizations are required to meet certain standards and regulations for data security. If found not to be in compliance with those, again, there could be heavy penalties and fines.\n\n```markdown\n## Cost of Non-Compliance to AWS Control (HTTPS Access)\n\n- Data Breaches: Risk of sensitive data being intercepted, altered, or stolen due to insecure transfer over HTTP.\n- Financial Loss: Massive financial costs due to incident response, legal fees, potential fines, lost data recovery, system upgrades, and potential ransomware attacks.\n- Loss of Trust and Reputation: A significant reputation damage leading to loss of customer trust and a decrease in business opportunities.\n- Regulatory Sanctions: Possibility of penalties or fines imposed by legal authorities if the leaked data is of a sensitive nature.\n- Non-compliance Costs: Potential penalties and fines for not meeting the required standards and regulations for data security.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "Let's consider an example of a company named SecureCorp. SecureCorp deals with highly sensitive data and uses Amazon S3 for storing and retrieving their data. Due to the sensitive nature of their data, they take security very seriously and want to make sure their data is as secure as possible when in transit. \n\nTo add an extra layer of security, SecureCorp decides to use AWS Control to configure permissions through a bucket policy and make the objects in their Amazon S3 bucket accessible only through HTTPS. The use of HTTPS ensures that their data remains encrypted in transit thus reducing the risk of data interception.\n\nHere's how SecureCorp can write the bucket policy in AWS S3:\n\n```markdown\n{\n   \"Version\":\"2012-10-17\",\n   \"Id\":\"SecureCorpBucketPolicyHTTPS\",\n   \"Statement\":[\n      {\n         \"Sid\":\"RequireHTTPS\",\n         \"Effect\":\"Deny\",\n         \"Principal\":\"*\",\n         \"Action\":\"s3:*\",\n         \"Resource\":\"arn:aws:s3:::SecureCorpBucket/*\",\n         \"Condition\":{\n            \"Bool\":{\n               \"aws:SecureTransport\": \"false\"\n            }\n         }\n      }\n   ]\n}\n```\nThis policy ensures that all access to SecureCorpBucket must be made over an SSL (Secure Sockets Layer) connection. In other words, this configuration makes objects accessible only through HTTPS. This is highly useful for situations where the sensitive data needs to be protected from potential eavesdropping or tampering during transmission."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_2_1",
        "Title": "2.2.1 Ensure EBS Volume Encryption is Enabled in all Regions",
        "Description": "Elastic Compute Cloud (EC2) supports encryption at rest when using the Elastic Block Store (EBS) service. While disabled by default, forcing encryption at EBS volume creation is supported.",
        "QueryID": "aws_ebs_volume_encryption_at_rest_enabled",
        "DocumentURI": "policies/aws_cis_v200_2_2_1.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.2.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.2"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/EBS"
            ],
            "x-kaytu-explanation": [
                "This AWS (Amazon Web Services) control is related to data protection and encryption in the Elastic Compute Cloud (EC2) service. \n\n### Amazon Elastic Compute Cloud (EC2) \nIs a part of the Amazon Web Services (AWS) and it provides scalable computing capacity in the AWS cloud. By using Amazon EC2, you can obtain and set up virtual servers in the cloud, also known as instances.\n\n### Elastic Block Store (EBS)\nThe Elastic Block Store (EBS) is a service for creating block-level storage volumes. These volumes can be attached to Amazon EC2 instances to allow persistent storage, beyond the lifetime of a single Amazon EC2 instance.\n\n### Encryption at Rest \n\"Encryption at rest\" means that data is encrypted when it is stored. For EBS volumes, this means that the entire block device is encrypted. It's a security measure that's designed to prevent unauthorized access and ensure data privacy by encoding the data when it's stored, or \"at rest\". \n\n### Enabling Encryption on EBS Volumes\nWhile this encryption is disabled by default, Amazon EC2 supports enabling it when creating EBS volumes. This means that you can force data to be encrypted when it is stored in the EBS volume attached to EC2 instances. When you create an encrypted EBS volume and attach it to a supported instance type, the following types of data are encrypted:\n- Data at rest on the volume\n- Data moving between the volume and the instance\n- All snapshots created from the volume\n\nIt helps to make your application more secure by protecting sensitive data. \n\n```markdown\n# Encryption Features of Amazon EC2 and EBS\n- **Amazon EC2**: Offers scalable computing capacity in the cloud.\n- **Amazon EBS**: Provides block-level storage volumes for EC2 instances.\n- **Encryption at Rest**: A security measure to prevent unauthorized access and ensure data privacy. Disabled by default on EC2 instances.\n- **Enabling Encryption on EBS Volumes**: EC2 supports enabling encryption at the time of EBS volume creation. This forces data to be encrypted when stored in the EBS volume.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance with the AWS control that necessitates encryption at rest when using Elastic Block Store (EBS) service can be substantial. If your organization fails to implement this control, it could be exposing its data and systems to multiple potential threats, resulting in the following costs:\n\n## Financial Costs\n\n### 1. Regulatory fines or penalties\nIf identifiable information (e.g., PII, PHI) is compromised, your organization may face fines imposed by bodies such as GDPR for EU residents or HIPAA for US healthcare data.\n\n### 2. Data Breach Costs\nThe financial impact of a data breach can be significant depending on the criticality of the data. It includes the cost of forensic investigations, disruption to normal operations, and potential lawsuits if the data breach leads to identifiable damages to customers or users.\n\n## Reputation Damage\n\nReputational harm can have long-term consequences for an organization, reducing customer confidence and hampering business growth. This can be challenging to calculate in terms of monetary value but will often exceed the immediate financial costs of a breach.\n\n## Potential Risk Of Data Loss\n\nData stored without encryption can tamper with or completely deleted by unauthorized individuals. The cost of this could be significant if your company loses important data.\n\n## Compliance Costs\n\nIf you become non-compliant with regulations due to a lack of proper encryption measures, you may have to spend money to implement compliant solutions later on. In addition, if a breach was due to non-compliance, future audits might be more stringent and require additional resources to pass.\n\nTherefore, it is highly recommended to enable encryption at rest while using EBS to protect from all the above-mentioned costs."
            ],
            "x-kaytu-usefulness-example": [
                "- Ensuring High Data Security\n\nFor companies and organizations that handle sensitive data like government agencies, healthcare institutions or financial firms, the availability of encryption is absolutely useful. \n\nUsing the EC2 Service in AWS, these organizations can have their data encrypted at rest when using the Elastic Block Store (EBS) service. This means that even when the data is not in transit and is just being stored, it is encrypted and thus, kept safe from unauthorized access or potential breaches.\n\nFor example, a healthcare company can use this feature to keep their patients' medical records safe. By forcing encryption at EBS volume creation, the company ensures that the data remains encrypted from the moment it's stored. This is especially vital in compliance with standards like HIPAA that require patient information to be highly secured.\n\n```markdown\n## Maintaining High Data Security with EC2 \n\nA healthcare company has to secure their patients' medical records in compliance with HIPAA standards. They decide to utilize AWS and specifically, the EC2 service which supports encryption at rest. \n\nBy simply enabling the encryption which is disabled by default, their data is kept secured even while it's not in transit. \n\n```aws\naws ec2 create-volume --availability-zone us-west-2a --size 80 --encrypted \n```\nWith just one command, they force encryption at EBS volume creation, providing an extra layer of security to the stored data. \n\nThis ensures that even in the event of a potential security breach, the data remains inaccessible due to the encryption.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_1_2",
        "Title": "2.1.2 Ensure MFA Delete is enabled on S3 buckets",
        "Description": "Once MFA Delete is enabled on your sensitive and classified S3 bucket it requires the user to have two forms of authentication.",
        "QueryID": "aws_s3_bucket_mfa_delete_enabled",
        "DocumentURI": "policies/aws_cis_v200_2_1_2.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.2"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "Multi-Factor Authentication Delete (MFA Delete) is a feature provided by AWS S3 for enhanced security. \n\nWhen you enable MFA Delete on an Amazon S3 bucket, it provides an extra layer of security. It requires additional authentication for the 'Change Versioning State' and 'Permanently Delete an Object' operations. It uses two forms of authentication: \n\n1. Your security credentials (access key id and secret access key)\n2. A valid MFA code from a device associated with the AWS account\n\nBy doing so, it essentially adds an additional safeguard against accidental bucket object deletion.\n\nHere's a sample markup explaining it:\n\n```markdown\n## Enabling MFA Delete in AWS S3\n\n**Multi-Factor Authentication Delete (MFA Delete)** is a feature in AWS S3 that provides an additional layer of security. \n\nOnce this feature is enabled on your sensitive and classified S3 bucket, you need to have _two forms of authentication_ to change the versioning state and permanently delete an object.\n\nThe two forms of authentication required are:\n\n1. **Security credentials**: This includes your assigned access key id and secret access key.\n2. **Valid MFA code**: A code generated by an MFA device that is specifically associated with the AWS account.\n\nThis feature is particularly helpful in _preventing accidental deletion_ of objects from your S3 bucket.\n\n```\n\nPlease replace the italic and bold parts of the text with your own precise information while using this markup code."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to AWS Control related to Multi-Factor Authentication (MFA) Delete on sensitive and classified S3 buckets can result in a significant cost to your organization. Below is an explanation of these costs in markdown format:\n\n1. **Data Breaches**: One major cost of non-compliance is the increased risk of data breaches. If MFA Delete isn't enabled, unauthorized users may gain access to your S3 buckets and delete valuable data. This could lead to financial losses, disrupted operations, and potentially severe reputational damage. \n\n2. **Compliance Penalties**: Many industries must comply with certain regulations regarding data protection (e.g., GDPR, HIPAA). Not enabling MFA Delete could be considered a failure to meet these standards, potentially resulting in hefty fines or penalties.\n\n3. **Data Recovery Costs**: If valuable data is deleted without authorization, the costs to retrieve or rebuild this data can be high. Depending on the data's nature, it could require significant time and resources to recover.\n\n4. **Loss of Customer Trust**: If data breaches occur, especially with sensitive or classified data, it may result in a loss of customer trust. This could have a direct impact on revenue and customer retention.\n\n5. **Increased Vulnerability to Cyber Attacks**: Not using MFA Delete increases an organization's vulnerability to cyber attacks, including phishing and other forms of hacking.\n\nHere is how to write it up in markdown:\n```\n1. **Data Breaches**: Unauthorized users may gain access to your S3 buckets and delete valuable data, leading to financial losses, disrupted operations, and potential severe reputational damage.\n2. **Compliance Penalties**: Many industries must comply with certain regulations regarding data protection (e.g., GDPR, HIPAA). \n3. **Data Recovery Costs**: If valuable data is deleted without authorization, it might require significant time and resources to recover.\n4. **Loss of Customer Trust**: Data breaches, especially with sensitive or classified data, may result in loss of customer trust, directly impacting revenue and customer retention.\n5. **Increased Vulnerability to Cyber Attacks**: Not using MFA Delete increases an organization's vulnerability to cyber attacks, including phishing and other forms of hacking.\n   ```"
            ],
            "x-kaytu-usefulness-example": [
                "For instance, an application development company that stores their highly confidential source codes and customer data in an AWS S3 bucket could find MFA (Multi-Factor Authentication) Delete very useful. They could enable MFA Delete to add an extra protection layer and prevent unauthorized users from accidentally or maliciously deleting objects inside the bucket. The extra authentication step would require more than just having the user's credentials to delete an item, thereby significantly reducing the risk of data loss due to malicious activity. In this way, the MFA Delete control can enhance the company's security measures to manage and protect their sensitive data."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_3_1",
        "Title": "2.3.1 Ensure that encryption-at-rest is enabled for RDS Instances",
        "Description": "Amazon RDS encrypted DB instances use the industry standard AES-256 encryption algorithm to encrypt your data on the server that hosts your Amazon RDS DB instances. After your data is encrypted, Amazon RDS handles authentication of access and decryption of your data transparently with a minimal impact on performance.",
        "QueryID": "aws_rds_db_instance_encryption_at_rest_enabled",
        "DocumentURI": "policies/aws_cis_v200_2_3_1.md",
        "ManualVerification": false,
        "Severity": "Low",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.3.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/RDS"
            ],
            "x-kaytu-explanation": [
                "Amazon RDS (Relational Database Service) supports encryption of your databases using keys you manage through AWS Key Management Service (KMS). When you create a new DB instance, you have the option to enable encryption and select a specific KMS key. \n\nThe algorithm used for encryption is AES-256, considered to be among the top ciphers. It is a symmetric key block cipher that encrypts and decrypts data in blocks of 128 bits using a 256-bit key. In simpler terms, it provides a high level of security for your database's data.\n\nOnce the data is encrypted, Amazon RDS then takes care of authenticating access and decrypting your data transparently, meaning you don't have to manually manage the decryption process. This process has been optimised to have a minimal impact on database performance.\n\nBelow is an example of markup which can be used in `AWS CloudFormation` template to implement an encrypted RDS instance:\n\n```yaml\nResources:\n  MyDB:\n    Type: 'AWS::RDS::DBInstance'\n    Properties:\n      AllocatedStorage: 5\n      DBInstanceClass: db.t2.small\n      Engine: MySQL\n      MasterUsername: Admin\n      MasterUserPassword: Password\n      StorageEncrypted: true\n      KmsKeyId: \"arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"\n```\n\nIn the given example:\n\n- `MyDB` is the logical name of the RDS database.\n- `AWS::RDS::DBInstance` is the resource type that creates an Amazon RDS database instance.\n- `AllocatedStorage`, `DBInstanceClass`, `Engine`, `MasterUsername`, `MasterUserPassword` are all properties of AWS RDS \n- `StorageEncrypted` is set to \"true\", which means encryption is enabled.\n- `KmsKeyId` is the ARN (Amazon Resource Number) of the KMS key to use for the encryption."
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance to this AWS control (i.e, not using Amazon RDS encrypted DB instances) may expose the organisation to various costs and risks such as:\n\n1. **Data Breaches:** If data isn't encrypted, it may be easily accessed by unauthorized users, leading to potential data breaches. The cost of a data breach can be substantial including both direct costs (fines, legal fees, customer notification and support, etc.) and indirect costs (brand damage, lost customer trust, etc.).\n\n2. **Non-Compliance Penalties:** Many industry regulations and standards (e.g., GDPR, HIPAA, PCI DSS) require data to be encrypted at rest. Failing to comply with these rules can result in significant fines and penalties.\n\n3. **Loss of Intellectual Property:** Without encryption, sensitive intellectual property (e.g., proprietary algorithms, research data) may be at risk, potentially leading to competitive disadvantages if such data is leaked.\n\n4. **Data Integrity Issues:** In some cases, not applying encryption controls may cause data integrity issues. This can result in inaccurate decision-making and may lead to financial losses and strategic missteps.\n\n5. **Business Continuity Issues:** In a worst-case scenario, non-compliance could lead to a major data breach or data loss incident that disrupts business operations. This could impact revenue and lead to increased costs to restore normal operations.\n\nIn markdown:\n\n```\nNon-compliance to this AWS control (i.e, not using Amazon RDS encrypted DB instances) may expose the organisation to various costs and risks such as:\n\n1. **Data Breaches:** If data isn't encrypted, it may be easily accessed by unauthorized users, leading to potential data breaches. The cost of a data breach can be substantial including both direct costs (fines, legal fees, customer notification and support, etc.) and indirect costs (brand damage, lost customer trust, etc.).\n\n2. **Non-Compliance Penalties:** Many industry regulations and standards (e.g., GDPR, HIPAA, PCI DSS) require data to be encrypted at rest. Failing to comply with these rules can result in significant fines and penalties.\n\n3. **Loss of Intellectual Property:** Without encryption, sensitive intellectual property (e.g., proprietary algorithms, research data) may be at risk, potentially leading to competitive disadvantages if such data is leaked.\n\n4. **Data Integrity Issues:** In some cases, not applying encryption controls may cause data integrity issues. This can result in inaccurate decision-making and may lead to financial losses and strategic missteps.\n\n5. **Business Continuity Issues:** In a worst-case scenario, non-compliance could lead to a major data breach or data loss incident that disrupts business operations. This could impact revenue and lead to increased costs to restore normal operations.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "For instance, a healthcare company needs to store and handle sensitive patient data. Their IT team decided to use Amazon RDS for their database needs. They also use the encryption feature to ensure that their data is secure from unauthorized access.\n\nThe information is encrypted using the AES-256 encryption algorithm, an industry-standard method known for its high security. Whenever a hospital staff member needs to access the patient data, Amazon RDS handles the process of authenticating their access and decrypting the data. \n\nThe health company benefits from this setup in two main ways:\n\n1. Enhanced Security: Sensitive data such as health records are encrypted, reducing the risk of unauthorized access or data breaches, which is essential compliance regulations like HIPAA.\n   \n2. Performance: The decryption and authentication process is transparent and has minimal impact on performance - staff can access needed information quickly and efficiently without lag. \n\nExample in markup format:\n\n```\nThe Healthcare Co. benefits from Amazon RDS encrypted DB instances in two main ways:\n\n- **Enhanced Security**: Sensitive data such as health records are encrypted using the AES-256 encryption algorithm, reducing the risk of unauthorized access or data breaches.\n\n- **Performance**: Amazon RDS handles the decryption and authentication process transparently with a minimal impact on performance, ensuring staff have quick and efficient access to necessary information.\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_1_3",
        "Title": "2.1.3 Ensure all data in Amazon S3 has been discovered, classified and secured when required",
        "Description": "Amazon S3 buckets can contain sensitive data, that for security purposes should be discovered, monitored, classified and protected. Macie along with other 3rd party tools can automatically provide an inventory of Amazon S3 buckets.",
        "QueryID": "aws_s3_bucket_protected_by_macie",
        "DocumentURI": "policies/aws_cis_v200_2_1_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.3"
            ],
            "cis_level": [
                "2"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "# Amazon S3 Buckets and Macie for Data Security\n\nAmazon S3 (Simple Storage Service) buckets are an essential component of data storage in AWS. These buckets can contain sensitive information that needs to be protected, classified and regularly monitored for security.\n\n## Protecting Sensitive Data \n\nFor security reasons, it is vital that sensitive data in Amazon S3 buckets is located, monitored, classified, and protected. Many initiatives and regulatory frameworks, such as GDPR or PCI DSS, require a clear understanding and management of sensitive data. \n\n## Role of AWS Macie\n\n[AWS Macie](https://aws.amazon.com/macie/) is a security service that uses machine learning to automatically discover, classify, and protect sensitive data like Personally Identifiable Information (PII). \n\nMacie recognizes sensitive data such as personal data identifiers, providing an inventory of Amazon S3 buckets, along with comprehensive insights about any potential security policy violations or suspicious activities.\n\n## Integration with 3rd-Party Tools \n\nIn addition to Macie, a number of third-party tools and utilities are available which can also assist with providing an inventory of Amazon S3 buckets. These tools can automate the task of cataloging bucket contents and identifying sensitive data stored in them.\n\nIn summary, leveraging AWS Macie along with other third party tools, organizations can implement robust controls to manage, supervise, and protect the sensitive data within their Amazon S3 buckets."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the AWS Control of \"Inventory and Control of AWS S3 Data\" can be detrimental for an organization, both financially and in terms of reputation damage.\n\n1. **Data Breaches**: If Amazon S3 buckets containing sensitive information aren't correctly inventoried and controlled, unauthorized individuals might access, steal, or manipulate data they weren't meant to access. This could potentially lead to a data breach.\n\n2. **Fines and Penalties**: If sensitive data, such as personally identifiable information (PII), credit card data, or health information, is breached due to non-compliance, regulatory bodies such as GDPR, PCI-DSS, or HIPAA might impose significant fines and penalties.\n\n3. **Loss of Business**: Depending on the severity of the breach, customers and partners might choose to discontinue their relationships with the organization, resulting in loss of business and revenue.\n\n4. **Reputation Damage**: A data breach can greatly damage an organization's reputation, affecting customer trust and long-term profits.\n\n5. **Legal Consequences**: In certain instances, affected parties might sue the organization for negligence or breach of contract, leading to potential legal costs and damage payments.\n\n6. **Resource Costs**: The organization will have to spend significant resources to handle a data breach â€“ this includes conducting a thorough investigation, informing affected parties, rectifying the issue, and implementing new security measures. \n\n7. **Downtime Costs**: There may also be a period of operational downtime where systems and services are down which can lead to further financial loss.\n\nIn sum, compliance with this control helps shield the organization from data breaches, financial damages, legal consequences, and reputation loss. AWS Macie and other third party tools automate this process, reducing the possibility of human error or oversight. Furthermore, it enables quicker response times should a potential data security incident occur."
            ],
            "x-kaytu-usefulness-example": [
                "For example, consider a multinational corporation that stores vast amounts of customer data across diverse databases for their global operations. An inadvertent data leak could result in substantial fines for violations of privacy regulations like GDPR.\n\nThis is where AWS Macie and third-party tools come into the picture. They can provide an automatic inventory of all the Amazon S3 buckets in the corporation's AWS accounts, as shown:\n\n```\n{\n   \"BucketInventory\": [\n       {\n          \"BucketName\": \"example-bucket-1\",\n          \"Region\": \"us-east-1\",\n          \"ClassifiedDataCount\":1000,\n          \"SensitiveDataCount\":200\n       },\n       {\n          \"BucketName\": \"example-bucket-2\",\n          \"Region\": \"us-west-2\",\n          \"ClassifiedDataCount\":1500,\n          \"SensitiveDataCount\":100\n       }\n    ]\n}\n```\nThis inventory assists the corporation in several ways:\n\n- Identifies which S3 buckets contain sensitive data in need of additional layers of protection, such as stricter access policies or encryption.\n- Helps in prioritizing which buckets to focus on for security audits or compliance checks based on the amount of classified or sensitive data they contain.\n- Provides an easy way to keep track of where classified data is being stored, promoting better data governance and reducing the risk of data breaches.\n   \nThus, by implementing these AWS controls the corporation can ensure they are meeting privacy standards, hence protecting itself from penalties and maintaining trust with customers and partners."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_3_2",
        "Title": "2.3.2 Ensure Auto Minor Version Upgrade feature is Enabled for RDS Instances",
        "Description": "Ensure that RDS database instances have the Auto Minor Version Upgrade flag enabled in order to receive automatically minor engine upgrades during the specified maintenance window. So, RDS instances can get the new features, bug fixes, and security patches for their database engines.",
        "QueryID": "aws_rds_db_instance_automatic_minor_version_upgrade_enabled",
        "DocumentURI": "policies/aws_cis_v200_2_3_2.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.3.2"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/RDS"
            ],
            "x-kaytu-explanation": [
                "AWS RDS (Relational Database Service) offers an `Auto Minor Version Upgrade` feature which, when enabled, allows your RDS instances to automatically receive minor engine upgrades during the specified maintenance window. This feature is crucial to keep your database instances updated with the latest features, fixing bugs, and applying security patches automatically.\n\nHere's some markup text to display this control info:\n\n```markdown\n# RDS Auto Minor Version Upgrade Control\n\nAWS RDS provides a feature called **Auto Minor Version Upgrade**. This feature, when enabled, lets your RDS instances to automatically receive minor engine upgrades. These updates occur during your predetermined maintenance window.\n\n```alert alert-info\nEnabling Auto Minor Version Upgrade ensures your RDS instances are always up-to-date with the latest features, bug fixes, and important security patches for their database engines. This ensures higher stability, better performance, and improved security for your database instances.\n```\nWe recommend you to **always enable this feature** to ensure your RDS instances are running the latest and most secure version of their database engines.\n```\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "1. **Security Violation Risk**: \n   Disabling the Auto Minor Version Upgrade flag for RDS instances may expose the databases to potential security threats. AWS continually improves its services and one of the ways it addresses bugs and security issues is through minor version upgrades. If these upgrades are not applied, it leaves the databases vulnerable to security issues which may have been fixed in the newer versions. This could potentially lead to data breaches, loss of sensitive information and denial of services attacks.\n\n2. **Performance Degradation Risk**: \n   Minor version upgrades might include performance optimizations, new features and bug fixes which can improve performance and reliability of your databases. Not having these updates could potentially lead to unstable and inefficient operation, resulting in slower response times, higher resource consumption and possible outages.\n\n3. **Compliance Violations Risk**: \n   If your organization is operating under certain IT compliance requirements (like ISO 27001, HIPAA, PCI DSS, etc.), one of the common mandates is to ensure that the systems are up-to-date with security patches and updates. Non-compliance with this control could therefore lead to violation of such standards, which might attract significant fines, penalties and can damage the company's reputation.\n\n4. **Operational Issues and Cost**: \n   If the Auto Minor Version Upgrade flag is disabled for your RDS instances, manual intervention would be needed to apply those upgrades. This requires additional operational effort and potential downtime during the upgrade process which could have been avoided with auto upgrades. This not only increases the cost but it can also lead to operational inefficiencies. \n\nRemember that keeping systems updated is part of a good security, operation and compliance strategy. Non-compliance with this control can lead to increased risks and costs."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, consider you are running a highly trafficked e-commerce website whose database is powered by AWS RDS. In such a scenario, ensuring customer data security and consistent performance are two crucial aspects. Over time, Amazon may release minor upgrades to the RDS engine that offer security patches, bug fixes, or performance improvement features.\n\nIf 'Auto Minor Version Upgrade' flag is not enabled, you will have to manually monitor and apply these updates. This can divert your attention away from primary business operations. However, by enabling this feature, Amazon RDS service will automatically apply these minor upgrades during the maintenance window. This would mean improved security and performance without manual intervention, allowing you to focus on crucial business operations.\n\nIn markup format:\n\n```\n\u003cdiv\u003e\n \u003cp\u003eFor instance, consider you are running a highly trafficked e-commerce website whose database is powered by AWS RDS. Ensuring customer data security and consistent performance are two crucial aspects here.\u003c/p\u003e\n  \u003cp\u003eOver time, Amazon may release minor upgrades to the RDS engine that offer security patches, bug fixes, or performance improvement features. If you do not have the 'Auto Minor Version Upgrade' flag enabled, you will have to manually monitor and apply these updates, diverting your attention away from primary business operations.\u003c/p\u003e\n  \u003cp\u003eHowever, by enabling this feature, the Amazon RDS service will automatically apply these minor upgrades during the maintenance window. This means improved security and performance without manual intervention, which allows you to focus on crucial business operations.\u003c/p\u003e\n\u003c/div\u003e\n```"
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_1_4",
        "Title": "2.1.4 Ensure that S3 Buckets are configured with 'Block public access (bucket settings)'",
        "Description": "Amazon S3 provides Block public access (bucket settings) and Block public access (account settings) to help you manage public access to Amazon S3 resources. By default, S3 buckets and objects are created with public access disabled. However, an IAM principle with sufficient S3 permissions can enable public access at the bucket and/or object level. While enabled, Block public access (bucket settings) prevents an individual bucket, and its contained objects, from becoming publicly accessible. Similarly, Block public access (account settings) prevents all buckets, and contained objects, from becoming publicly accessible across the entire account.",
        "QueryID": "aws_s3_public_access_block_bucket_account",
        "DocumentURI": "policies/aws_cis_v200_2_1_4.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.1.4"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.1"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/S3"
            ],
            "x-kaytu-explanation": [
                "# Amazon S3 Public Access Block Controls\n\n**Amazon S3** provides two key methods to help manage public access to S3 resources. These are:\n\n1. **Block public access (bucket settings)**: This setting works at the individual bucket level. If enabled, it ensures that the selected bucket and its objects are not publicly accessible. \n\n2. **Block public access (account settings)**: This setting applies to an entire account. If it is enabled, then all buckets and their contained objects in that specific account are not publicly accessible.\n\nBy default, when you create S3 buckets and objects, public access is disabled. However, an Identity and Access Management (IAM) principal with sufficient S3 permissions has the authority to grant public access at the bucket or object level.\n\n## Overview of the Procedures\n\n### Block Public Access (Bucket Settings)\n\nThis allows you to prevent public accessibility for a single bucket and all objects contained within it. This can be useful if you only need to limit access for some of your buckets, but not all.\n\nHere's how you might enable this setting through the S3 console:\n\n```markdown\n- Navigate to the Amazon S3 console.\n- Choose the bucket you want to update.\n- In the 'Permissions' tab, find the 'Block public access' setting.\n- Click 'Edit', then check the 'Block all public access' box.\n- Choose 'Save changes'.\n```\n\n### Block Public Access (Account Settings)\n\nThis is a universal setting that will apply to all buckets and objects within your account.\n\nHere's how you might enable this setting through the S3 console:\n\n```markdown\n- Navigate to the Amazon S3 console.\n- In the left navigation pane, choose 'Block Public Access settings for this account'.\n- Click 'Edit', then check the 'Block all public access' box.\n- Choose 'Save changes'.\n```\nBear in mind that these changes will apply to all current and future buckets and objects in your account, so use this option carefully."
            ],
            "x-kaytu-noncompliance-cost": [
                "The cost of non-compliance to the Amazon S3 Block Public Access control could be severe, primarily concerning data security and privacy. Possible repercussions in both monetary and reputational terms include:\n\n**1. Data Breaches and Information Leakage:** If the public access control is not properly implemented, unauthorized individuals may gain access to sensitive information. This can result in data breaches, leading to financial penalties, lawsuits, and loss of trust from customers and partners.\n\n**2. Regulatory Compliance Violations:** Certain industries have strict regulations for data privacy and security (like GDPR, HIPAA, etc.). Non-compliance with these norms due to improper S3 bucket settings can lead to legal sanctions, fines, and damaged reputation.\n\n**3. Increased Costs:** Publicly accessible S3 buckets can be exploited by malicious actors for data egress, leading to higher data transfer charges.\n\n```\nSo, it's important to monitor and regulate the public access settings in the AWS environment. Always ensure to follow the principles of least privilege, giving only necessary permissions, and keep audit logs for any changes made in the settings.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "**Example Instance:**\n\nA company named 'EliteTech' has multiple S3 buckets on AWS to store and handle various types of data including confidential corporate data, employee information and customer data. Maintaining data privacy and security is of utmost importance to EliteTech, hence they cannot risk any data becoming publicly accessible.\n\nEliteTech implements the 'Block public access' feature for all their S3 buckets. This results in the following:\n\n1. For specific S3 buckets containing highly confidential data, they use 'Block public access (bucket settings)', ensuring individual buckets and their contained objects cannot become publicly accessible.\n\n2. For their entire AWS account, they use 'Block public access (account settings)', precautionarily ensuring all of their buckets and contained objects cannot become publicly accessible.\n\nThus, even if someone accidentally or intentionally tries to change the settings to make the data public, 'Block public access' feature will prevent that, protecting EliteTech from potential data breaches and loss of reputation. This also aids in compliance with data protection regulations. \n\nIn particular cases where they need to make some buckets or data public, the admin with the right permissions can modify the specific settings accordingly, providing both security and flexibility in managing data accessibility."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_4_1",
        "Title": "2.4.1 Ensure that encryption is enabled for EFS file systems",
        "Description": "EFS data should be encrypted at rest using AWS KMS (Key Management Service).",
        "QueryID": "aws_efs_file_system_encrypt_data_at_rest",
        "DocumentURI": "policies/aws_cis_v200_2_4_1.md",
        "ManualVerification": false,
        "Severity": "High",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.4.1"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.4"
            ],
            "cis_type": [
                "manual"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/EFS"
            ],
            "x-kaytu-explanation": [
                "AWS Control essentially provides guidelines and standards for securing services and infrastructure within the AWS environment. To explain this AWS Control in Markdown format, it could be expressed like this:\n\n`## AWS Control\n\n### EFS Data Encryption at Rest using AWS KMS\n\nAWS recommends that all data stored in EFS (Elastic File System) should be encrypted at rest. Encryption at rest enhances the security by encrypting the data that is not actively moving or being used. The encryption keys should be managed via the AWS Key Management Service (KMS). \n\nKey Management Service (KMS) is a managed service that makes it easy for you to create and manage cryptographic keys and control their use across a wide range of AWS services and in your applications.\n\n**Implementation Steps:**\n\n1. Login to the AWS Management Console and navigate to EFS.\n2. If creating a new EFS, under the \"Add tags and configure advanced settings\", select 'Enable encryption of data at rest'. \n3. If updating an existing EFS, select the filesystem, and under the 'General' tab, select 'Edit' on the encryption field to enable encryption.\n4. By default, AWS manages keys that are used to encrypt the file system data. However, you also have the option to use AWS KMS to manage your keys.\n\nBy implementing these steps, you ensure that your EFS data remains secure even when it is at rest.`\n"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with the recommended AWS control of encrypting EFS (Elastic File System) data at rest using AWS KMS might result in several potential costs, including:\n\n1. **Data Breach Risks**: Without encryption, sensitive data becomes exposed and vulnerable to unauthorized access and breaches. Such scenarios can lead to significant financial losses due to possible regulatory fines, litigation, and reputational damage.\n\n2. **Non-compliance with Regulatory Requirements**: Many industries (like healthcare, finance, etc.) are required to comply with specific regulations (HIPAA, GDPR, PCI-DSS) that mandate data encryption. Non-compliance could lead to hefty fines.\n\n3. **Loss of Data Confidentiality**: Encryption is key in ensuring data confidentiality. Not using KMS for data encryption could lead to incidents where data's confidentiality is compromised.\n\n4. **Customer Trust Issue**: If your business cannot establish that it adequately protects sensitive customer data through measures like data-at-rest encryption, it could cause a significant decline in customer trust and potential loss of business.\n\n5. **Lack of an Audit Trail**: AWS KMS provides the ability for key usage to be logged and audited. Without this in place, there is a loss of visibility and accountability on who is accessing your data and when.\n\nTherefore, not encrypting EFS data at rest using AWS KMS can potentially induce significant financial, operational, and reputational risks to an organization."
            ],
            "x-kaytu-usefulness-example": [
                "For instance, if your company is operating in a highly-regulated industry such as healthcare or finance, where sensitive customer data is stored and processed, meeting compliance requirements is essential. By utilizing AWS KMS to encrypt EFS data at rest, you can provide an added layer of data security for compliance.\n\n```\n{\n\"RuleName\": \"encrypt-efs-data-at-rest\",\n\"Description\": \"Checks whether Elastic File Systems (EFS) data is encrypted at rest using AWS Key Management Service. The rule is compliant if the KmsKeyId is specified.\",\n\"Source\": \"AWS\",\n\"SourceIdentifier\": \"ENCRYPTED_CHECK\",\n\"Trigger\": {\n    \"Type\": \"Periodic\",\n    \"Periodic\": {\n        \"Frequency\": \"TwentyFour_Hours\"\n    }\n},\n\"InputParameters\": {\n    \"KmsKeyId\": \"arn:aws:kms:\u003cregion\u003e:\u003caccount-id\u003e:key/\u003ckmsKeyId\u003e\"\n},\n\"Scope\": {\n    \"ComplianceResourceTypes\": [\n        \"AWS::EFS::FileSystem\"\n    ]\n}\n}\n```\nIn this example, a periodic AWS Config rule checks every 24 hours to ensure that EFS data is encrypted at rest using the specified KMS Key ID. If the KMS Key ID is not specified, the rule will show as non-compliant. This automation can greatly assist in maintaining compliance and auditing efficiency."
            ]
        },
        "Managed": true
    },
    {
        "ID": "aws_cis_v200_2_3_3",
        "Title": "2.3.3 Ensure that public access is not given to RDS Instance",
        "Description": "Ensure and verify that RDS database instances provisioned in your AWS account do restrict unauthorized access in order to minimize security risks. To restrict access to any publicly accessible RDS database instance, you must disable the database Publicly Accessible flag and update the VPC security group associated with the instance.",
        "QueryID": "aws_rds_db_instance_prohibit_public_access",
        "DocumentURI": "policies/aws_cis_v200_2_3_3.md",
        "ManualVerification": false,
        "Severity": "Critical",
        "Tags": {
            "category": [
                "Compliance"
            ],
            "cis": [
                "true"
            ],
            "cis_item_id": [
                "2.3.3"
            ],
            "cis_level": [
                "1"
            ],
            "cis_section_id": [
                "2.3"
            ],
            "cis_type": [
                "automated"
            ],
            "cis_version": [
                "v2.0.0"
            ],
            "plugin": [
                "aws"
            ],
            "service": [
                "AWS/RDS"
            ],
            "x-kaytu-explanation": [
                "```markdown\n# AWS Control: Restrict Unauthorized Access to RDS Database Instances\n\nThis AWS control ensures that any RDS (Relational Database Service) database instances in your AWS account are secure and minimize any security risks. To achieve this, you should restrict unauthorized access by disabling the public accessibility of your RDS . \n\n## Steps:\n\n1. **Disable Public Access:** \nEnsure to switch off the 'Publicly Accessible' status of the database instance. This makes certain that your database isn't accessible openly from the internet.\n\n2. **Update VPC Security Group:** \nUpdate your VPC (Virtual Private Cloud) security group settings associated with the RDS instance to limit the incoming connections to specific IP ranges or other AWS instances.\n\nRemember, it's important for the security of your AWS resources to regularly review and monitor the access controls and settings.\n```"
            ],
            "x-kaytu-noncompliance-cost": [
                "Non-compliance with this AWS control can lead to several significant costs, including:\n\n1. **Security Breach Costs**: Unauthorized access can lead to data breaches with tangible costs such as legal penalties, compensations to affected parties, and the expense of forensic investigation, system repairs and security updates.\n\n2. **Regulatory Fines**: Depending on the type of data stored, violation of data privacy regulations like GDPR, HIPAA, or PCI DSS due to a security breach can result in hefty fines.\n\n3. **Loss of Business**: Depending on the severity of the breach, an organization could lose customer trust, resulting in loss of business and a decrease in market value.\n\n4. **Reputation Damage**: Recovery from a data breach also includes regaining customer and public trust, which can be a long and costly process. \n\n5. **Operational Disruptions**: Unauthorized access can disrupt business operations, causing productivity losses. \n\nHereâ€™s a markup explanation:\n\n```markdown\n- **Security Breach Costs**: When unauthorized access occurs, it can lead to data breaches. This can come with various tangible costs like the expense of forensic investigation, system repairs and necessary security updates, legal consequences, and compensation for affected groups.\n\n- **Regulatory Fines**: Depending on the kind of data stored in the RDS database instances, a breach can violate regulations like [GDPR](https://gdpr.eu/), [HIPAA](https://www.hhs.gov/hipaa/index.html), or [PCI DSS](https://www.pcisecuritystandards.org/pci_security/). Such violations can attract hefty fines.\n\n- **Loss of Business**: The severity of a data breach could erode customer trust, leading to decreased patronage and a consequent dip in market value.\n\n- **Reputation Damage**: Recovering from a data breach often includes the long and expensive process of rebuilding trust with customers and the public in general.\n\n- **Operational Disruptions**: Unauthorized access can cause business operation disruptions leading to losses in productivity and increased downtime.\n```"
            ],
            "x-kaytu-usefulness-example": [
                "Example:\n\n```\nA retail company uses Amazon RDS to manage their customer database. An AWS admin working for this company has an important task of preventing unauthorized access to the company's sensitive customer data. To accomplish this, they use the RDS database instances control in their AWS account to ensure access restrictions.\n\nHere's how they do it:\n\n1. Login to the AWS Management Console.\n2. Under the Database section of the Amazon RDS dashboard, choose the \"DB Instances\" option.\n3. Select the RDS instance that you'd like to restrict access to.\n4. Scroll down to the \"Connectivity \u0026 Security\" tab, locate the \"Public accessibility\" setting.\n5. If the setting is set to \"Yes\", click on the \"Modify\" button to change it.\n6. In the \"Network \u0026 Security\" section of the form that opens, turn off the \"Publicly accessible\" option.\n7. To apply the changes instantly, choose \"Apply Immediately\". Then click \"Continue\", review the changes, and if everything is correct, click \"Modify DB Instance\".\n8. Next, update the VPC security group by navigating to the \"Security\" section in the EC2 dashboard.\n9. Click on the security group associated with your instance, then add rules that allow only the IP addresses or ranges which should have access to your RDS instance.\n\nThis way, the admin ensures that only authorized IP addresses can access the company's customer information, thereby significantly reducing the risk of data breaches or other cyber security risks.\n```"
            ]
        },
        "Managed": true
    }
]