[
  {
    "ID": "aws_es_domain_in_vpc",
    "Title": "ES domains should be in a VPC",
    "Description": "Manage access to the AWS Cloud by ensuring Amazon Elasticsearch Service (Amazon ES) Domains are within an Amazon Virtual Private Cloud (Amazon VPC).",
    "QueryID": "aws_es_domain_in_vpc",
    "DocumentURI": "policies/aws_es_domain_in_vpc.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/ES"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "This AWS Control is about controlling and managing the access to the AWS Cloud by ensuring that Amazon Elasticsearch Service Domains are located within an Amazon Virtual Private Cloud (VPC). This allows the users to have more control over their Elasticsearch Service and they can manage who has access to it. \n\nHere's a markup format explanation of this AWS control:\n\n```\n## AWS Control: Amazon Elasticsearch Service Domains within an Amazon VPC\n\nThis AWS control focuses on managing access to the [AWS Cloud](https://aws.amazon.com/) by ensuring that all [Amazon Elasticsearch Service (Amazon ES) Domains](https://aws.amazon.com/elasticsearch-service/) are located within an [Amazon Virtual Private Cloud (Amazon VPC)](https://aws.amazon.com/vpc/).\n\nBy keeping your Elasticsearch Service Domains in a VPC, you can better manage the access and security of your service. With a VPC, you can define a virtual network in your own logically isolated area within the AWS Cloud, giving you complete control over your virtual networking environment.\n\nThis is especially beneficial in maintaining the security and privacy of your data, as the VPC limits access to your resources, thereby reducing the risk of data breach and unwanted external access.\n```\n\nThis control emphasizes the importance of utilizing Amazon VPC for privacy, security, and giving more control over who can access your Elasticsearch Service Domains."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control can carry several costs, which are summarized below:\n\n1. **Security Risks**: The main cost of non-compliance could be an increased risk of security breaches. Placing Amazon ES domains within an Amazon VPC provides an added layer of security. If unprotected, this could give unauthorized individuals easier access to sensitive data.\n\n2. **Financial Loss**: A security breach could conceivably lead to financial loss. This could arise from data theft, especially if the data pertains to financial information or intellectual property. \n\n3. **Reputation Damage**: In the event of a data breach, a company’s reputation may be damaged. Depending on how clients react to this, it could result in a loss of business and strained relationships with customers.\n\n4. **Regulatory Penalties**: For companies operating in industry sectors where compliance is mandatory (e.g., healthcare, finance), failure to implement the required security controls could result in hefty fines or sanctions from regulatory bodies. \n\n5. **Operational Disruption**: A security breach could disrupt a company's normal operations, especially if the breach impacts the availability of critical systems or data.\n\n6. **Data Loss**: If a breach results in the loss or corruption of data, it could have significant impacts on a company's operations and require substantial effort and cost to recover."
      ],
      "x-kaytu-usefulness-example": [
        "One common scenario where controlling access to AWS Cloud through Amazon Elasticsearch Service (ES) Domains within an Amazon Virtual Private Cloud (VPC) is useful is when an organization is dealing with sensitive data.\n\nLet's say a healthcare company uses AWS to store and analyze patient data. They use Amazon ES for full-text search and analytics capabilities. The data includes sensitive patient information which demands high levels of security and must be in compliance with healthcare regulations (like HIPAA) across all stages of data handling.\n\nIn this scenario, the company can manage access to the AWS cloud by ensuring that the Amazon ES Domains are only accessible within the Amazon VPC. This control will protect Amazon ES domains from unauthorized access as traffic within VPC is isolated from the outside world and access to resources are strictly regulated.\n\nThis instance is useful as it makes sure that the sensitive data is safely stored and processed within a controlled environment and by authorized users only, ensuring compliance with necessary data privacy acts and regulations. Thus, maintaining the integrity and confidentiality of the sensitive data.\n\n```\nExample Markup:\n\nAs a healthcare company, we handle sensitive patient data that requires robust security measures. Leveraging AWS, we ensure our data is secure and compliant. Our data analysis relies heavily on Amazon ES, but given the sensitive nature of this information, access to these domains needs to be strictly controlled and isolated.\n\nBy managing access to the AWS cloud and confirming Amazon ES Domains are contained within Amazon VPC, we create a secure environment for our data. This way, we not only benefit from the powerful analysis capabilities of Amazon ES but also ensure the confidentiality and integrity of our sensitive data, maintaining compliance with healthcare regulations.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_guardduty_enabled",
    "Title": "GuardDuty should be enabled",
    "Description": "Amazon GuardDuty can help to monitor and detect potential cybersecurity events by using threat intelligence feeds.",
    "QueryID": "aws_guardduty_enabled",
    "DocumentURI": "policies/aws_guardduty_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/GuardDuty"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon GuardDuty is a continuous security monitoring service provided by Amazon Web Services (AWS). It utilizes threat intelligence feeds, machine learning, and anomaly detection techniques to identify suspicious activities and unauthorized behavior that can indicate a possible cyber attack on your AWS environment.\n\n```markdown\n# Amazon GuardDuty \n\nAmazon GuardDuty is a threat detection service provided by AWS, which enables you to protect your AWS accounts, workloads, and data stored in Amazon S3. With the use of machine learning and anomaly detection, GuardDuty can identify potentially unauthorized and malicious activity such as escalation of privileges, uses of exposed credentials, or communication with malicious IP, URLs, or domains.\n\n## Key Features\n\n- **Threat Detection:** GuardDuty identifies unusual or unauthorized activities by continuously monitoring your AWS environment for signs of compromise.\n \n- **Machine Learning:** GuardDuty uses machine learning to identify anomalies in your AWS usage and to detect threats more effectively.\n\n- **Integrated Threat Intelligence Feeds:** GuardDuty uses threat intelligence feeds such as lists of malicious IPs and domains to enhance its threat detection capabilities. \n\n- **Continuous Security Monitoring:** This service operates 24/7, continuously monitoring and assessing the activity in your AWS accounts to identify potential security incidents.\n\n- **Automatic Updates:** It automatically updates its threat detection capabilities based on the latest threat intelligence feeds, without requiring any user intervention.\n\nUsing GuardDuty, you can automate security detection and create customized responses to potential threats in your AWS environment.\n```\nNote: The definition and explanations of AWS GuardDuty varies based on AWS documentation and can be more technical based on context."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the Amazon GuardDuty control can manifest in several ways:\n\n1. **Increased Risk of Cyber Threats**: Non-compliance means that you're not actively using GuardDuty to monitor for potential threats, increasing your vulnerability to cyber attacks including DDoS attacks, malware, and phishing scams.\n\n2. **Financial Consequences**: In cases of breaches, you may face significant financial fallout, from potential fines and penalties to the cost for recovery and damage control (including potential data loss or system downtime).\n\n3. **Reputation Damage**: A significant breach can severely damage a business's reputation, impacting customer trust and loyalty.\n\n4. **Regulatory Compliance**: If you're in a sector with specific regulatory requirements around data security (such as healthcare or financial services), non-compliance with a service like GuardDuty may mean that you're also not meeting those regulatory requirements, which can result in additional penalties or sanctions.\n\n5. **Liability for Breach**: In the event of a data breach, businesses can be held liable for damages, particularly if it can be shown that they did not take sufficient steps (such as using services like GuardDuty) to secure their systems. \n\nOverall, non-compliance with such AWS control like Amazon GuardDuty can lead to an increased risk of cybersecurity threats, financial losses, regulatory penalties, and damage to client trust and reputation."
      ],
      "x-kaytu-usefulness-example": [
        "Consider a healthcare organization that stores highly sensitive patient data on AWS. They have strict compliance requirements and need to ensure that they are actively monitoring for any cybersecurity threats that could compromise their data's integrity.\n\nThis is where Amazon GuardDuty comes into play. The organization can use GuardDuty to continuously analyze and monitor data generated from their AWS environment. GuardDuty uses threat intelligence feeds, machine learning, and anomaly detection to identify unusual behavior patterns or unauthorised activities that might indicate a threat.\n\nFor instance, if an unknown IP address tries to access one of the databases stored in their AWS environment, GuardDuty will detect this activity based on its threat intelligence feeds and immediately alert the organization's security team. They can quickly identify the threat, investigate it, and take the necessary steps to mitigate it.\n\nSo, in this scenario, Amazon GuardDuty helps the healthcare organization protect patient data, satisfy compliance requirements, and reduce the risk of a potential data breach."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_user_in_group",
    "Title": "IAM users should be in at least one group",
    "Description": "AWS Identity and Access Management (IAM) can help you restrict access permissions and authorizations, by ensuring IAM users are members of at least one group.",
    "QueryID": "aws_iam_user_in_group",
    "DocumentURI": "policies/aws_iam_user_in_group.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS IAM helps you manage access to your AWS resources.\n\n# Title: **AWS Identity and Access Management (IAM)**\n\nAWS IAM enables you to manage security credentials and access to AWS services and resources securely. Through IAM, you can create and manage AWS users, groups, roles, and permissions to allow and deny their access to AWS resources.\n\n## **Controlling access permissions with IAM**\n\nBy default, IAM users don’t have permissions to manage the resources in the AWS services you’re using. You need to grant them the necessary permissions by adding them to groups that have appropriate permission policies.\n\n### **Ensuring IAM users are members of at least one group**\n\nTo restrict access and control permissions and authorizations effectively, you should ensure each IAM user you create is a member of at least one group. This practice enables you to manage permissions for multiple users, making it easier to assign and revoke permissions as user roles change. If a user is not a member of a group, that user would have full permissions, which can lead to accidental access to confidential resources.\n\nHere is how you can add a user to a group:\n\n```\n- In the IAM console, in the navigation pane, choose Users.\n- Choose the name of the desired user, then choose Add user to groups.\n- In the Add User to Groups dialog box, select the AWSManagedPolicy ARN box, and then choose one or more groups from the list.\n- Choose Add to groups.\n```\n\nBy using IAM effectively, you can minimize the risk of unauthorized access to your AWS resources and ensure the principle of least privilege is adhered to in your organization.\n\n## IAM Features\n\n* **Shared Access to Your AWS Account**\n* **Granular Permissions**\n* **Secure Access to AWS Resources**\n* **Identity Federation**\n* **Multi-Factor Authentication**\n* **Password Policies**\n* **AWS CloudTrail Integration**\n* **Identity Information for Assurance**\n* **PCI DSS Compliance**\n\nFor more details, visit the official [AWS IAM Documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html)."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with the AWS Identity and Access Management (IAM) control can have several costs involved:\n\n1. **Increased Risk of Security Breaches:** If IAM users are not members of at least one group, they might end up with broad or administrative privileges. This could put your AWS environment at risk if these credentials are compromised. This could lead to unauthorized access to sensitive data, or potentially malicious activity such as deleting data, starting up services, etc.\n\n2. **Increased Operational Costs:** Without using groups to manage permissions, you might need to embed policies directly with users. This can increase the time and complexity in managing permissions, particularly as your organization scales. The extra management overhead can lead to greater operational costs.\n\n3. **Reputational Costs:** Any security breach emerging from insufficient access control can impact the organization's reputation. In many businesses, a reputation for weak security can lead to loss of customers and revenue.\n\n4. **Regulatory Fines:** If your company operates in a regulated environment (such as healthcare or finance), non-compliance with IAM controls can result in hefty fines from relevant regulatory bodies.\n\n5. **Auditing Difficulties:** It is more difficult to manage and audit individual users than managing through groups. Non-compliance can lead to additional auditing requirements and increased costs.\n\nTherefore, ensuring that IAM users are part of at least one group can mitigate these potential costs. With AWS IAM, you can efficiently manage user access and monitor activity to keep your AWS resources secure."
      ],
      "x-kaytu-usefulness-example": [
        "For example, an online e-commerce company wants to ensure that their AWS services and resources are only accessed by authorized personnel. They have different departments handling various responsibilities. The IT department is responsible for managing and maintaining the infrastructure, the Sales team needs to analyze the sales data for reporting, and the Marketing team handles campaigns and promotional activities. \n\nThe IT personnel need full access to services like EC2, RDS, and S3. However, the Sales and Marketing teams only need read access to certain S3 buckets for their respective data. Implementing AWS IAM, the organization can create different groups for each department – 'IT', 'Sales', and 'Marketing'. \n\nThe organization can then assign policies to these groups reflecting their access needs. For instance, the 'IT' group can have an AdministratorAccess policy. The 'Sales' and 'Marketing' groups can have AmazonS3ReadOnlyAccess to their respective data buckets.\n\nBy ensuring each IAM user is a member of at least one group, IAM will enable the company to implement least privilege principles, control access to AWS resources, and maintain security according to their organizational structure and needs. This will also reduce the administrative overhead of managing individual user's permissions.\n\n```\nExample:\nCreate New IAM Group:\n\n    aws iam create-group --group-name IT_Group\n\nAdd IAM User to Group:\n\n    aws iam add-user-to-group --user-name Bob --group-name IT_Group\n\nAttach Policy to Group:\n\n    aws iam attach-group-policy --group-name IT_Group --policy-arn arn:aws:iam::aws:policy/AdministratorAccess\n```\n\nThis instance highlights the usefulness of AWS IAM in managing access permissions and authorizations in AWS environment."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_policy_unused",
    "Title": "IAM policy should be in use",
    "Description": "This control checks whether the IAM policy ARN is attached to an IAM user, or a group with one or more IAM users, or an IAM role with one or more trusted entity.",
    "QueryID": "aws_iam_policy_unused",
    "DocumentURI": "policies/aws_iam_policy_unused.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Identity and Access Management (IAM) is a web service that helps you securely control access to AWS resources. You use IAM to control who is authenticated (signed in) and authorized (has permissions) to use resources.\n\nIn AWS, each IAM policy carries an Amazon Resource Name (ARN), a unique identifier for the policy. ARNs enable unique identification of individual resources across all of AWS.\n\nThis control signifies a check or validation to ensure that a particular IAM policy, identified by its ARN, is properly attached to:\n\n1. An IAM User – It’s an entity that you create in AWS to represent the person or service that uses it to interact with AWS. A user in AWS consists of a name and credentials.\n\n2. A group with one or more IAM users – An IAM group is a collection of IAM users. Groups let you specify permissions for multiple users, which can make it easier to manage the permissions for those users. If the check is for a group, then it expects the group to have one or more users in it.\n\n3. An IAM role with one or more trusted entity – An IAM role is an IAM entity that defines a set of permissions for making AWS service requests but isn't associated with a specific user or group. Instead, trusted entities (other AWS accounts, IAM users, or applications like EC2) assume roles and obtain temporary security credentials to make AWS API calls. \n\nThe check is basically a way to audit if a certain policy is effectively associated with potential actors within your AWS resources, to check if the best practices of granting the least privilege necessary are being adhered to. It's a way to enhance visibility and governance in your AWS environment."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control could involve:\n\n1. **Security Risks**: Without the proper IAM policy ARN attached to respective IAM users or groups, there could be unauthorized access to AWS resources leading to potential security breaches.\n\n2. **Operational Disruptions**: Incorrect IAM policy configurations might lead to operational disruptions, such as users not being able to access essential AWS services required for their tasks, or services not functioning as expected due to limited or excessive permissions.\n\n3. **Financial Consequences**: Security breaches or operational disruptions could lead to financial losses, either as a result of malicious activity, loss of business continuity, or penalties for not meeting compliance criteria in certain regulated industries.\n\n4. **Reputation Damage**: If unauthorized access or data breaches occur due to an improper IAM policy configuration, this could lead to severe reputation damage, which can have long-term effects on client trust and business stability. \n\nThe IAM policy ARN (Amazon Resource Name) is a critical component of AWS access control and identity management, ensuring that the right individuals have the proper access to the relevant AWS resources. Compliance with this control is fundamental to safeguarding AWS environments and should be a crucial part of every organization's AWS compliance strategy. \n\nAppropriate IAM policy management, audited and checked regularly, contributes to preventing potential data breaches, security risks, and the subsequent financial and reputation consequences."
      ],
      "x-kaytu-usefulness-example": [
        "Instance Example:\n\nConsider a scenario where a company XYZ Corp. is using AWS for their cloud infrastructure. They have multiple teams (DevOps, Back-end, Front-end, data scientists etc.) each requiring different sets of AWS resources and services. In order to have granular control and solid governance, the IT Admins define IAM policies with necessary permissions reflecting what operations/services each team can do in AWS. \n\nEach policy is then attached to respective IAM role or IAM group to which members of a particular team belong. This way the access control is managed at scale without much hassle. However, as team size grows and tweaks to the permissions are made, managing these access controls becomes a challenge. Using a control that checks if an IAM policy ARN is indeed attached to an IAM user or a group or a role becomes extremely useful. \n\nFor example, maybe a data science team needs access to Amazon S3, but the policy got detached due to an erroneous clean-up activity. Then such a control will provide valuable input to reattach the necessary IAM policy back to the data science IAM group, thus avoiding any productivity loss and ensuring secure and appropriate access to resources. \n\nHere's a markdown representation of a checklist generated by this control:\n\n- [ ] Check IAM User 'jsmith' has IAM policy ARN 'arn:aws:iam::aws:policy/AdministratorAccess' attached.\n- [ ] Check IAM Group 'DataScienceTeam' has IAM policy ARN 'arn:aws:iam::aws:policy/AmazonS3FullAccess' attached.\n- [ ] Check IAM role 'DevOpsRole' has IAM policy ARN 'arn:aws:iam::aws:policy/AmazonEC2FullAccess' attached.\n\nTherefore, this AWS control is incredibly useful for maintaining security configurations and making sure that the correct access permissions are in place for different roles, groups, and users within the AWS environment."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ebs_volume_unused",
    "Title": "EBS volumes should be attached to EC2 instances",
    "Description": "Checks if EBS volumes are attached to EC2 instances.",
    "QueryID": "aws_ebs_volume_unused",
    "DocumentURI": "policies/aws_ebs_volume_unused.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EBS"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Checking if EBS Volumes are Attached to EC2 Instances \n\nThis AWS control checks if an Elastic Block Store (EBS) volumes are attached to any Elastic Compute Cloud (EC2) instances. An EBS volume is a block level storage device that is used with EC2 instances for both throughput and transaction intensive workloads at any scale. \n\nThe purpose of this check is mainly for cost optimization and resource utilization. It can ensure that there are no dangling EBS volumes which are not attached to any EC2 instances as these can lead to unwanted costs. \n\n## Implementation \n\nThe control can be implemented using AWS Management Console, AWS CLI or AWS SDKs. \n\nFor example, using AWS Management Console, navigate to the EC2 dashboard, select `Volumes` under `Elastic Block Store`. Here, you can view the state of EBS volumes whether they are `in-use` (attached to an EC2 instance) or `avaliable` (not attached to any EC2 instance). \n\nSimilarly, AWS CLI command can be used to describe volumes and their state:\n\n```bash\naws ec2 describe-volumes\n```\n\n## Automation \n\nTo automate this control, AWS Lambda function can be used which will periodically check the EBS volumes and their status. If any unused EBS volume is identified then appropriate action like sending notification or deleting the volume can be performed.\n\nFor example, AWS Config is a service that lets you assess, audit, and evaluate the configurations of your AWS resources. It can be used to review the AWS resource configurations and allows you to simplify compliance auditing, security analysis, change management, and operational troubleshooting. \n\n```yaml\n{\n    \"rules\" : [\n        {\n            \"resourceType\": \"AWS::EC2::Volume\",\n            \"ruleId\" : \"ec2-volume-attached-check\",\n            \"lambdaFunctionArn\" : \"arn:aws:lambda:us-east-1:123456789012:function:EBSVolumeAttachedCheck\",\n            \"triggerTypes\" : [ \n                \"ConfigurationItemChangeNotification\" \n             ]\n        }\n    ]\n}\n```\n\nThis control is critical to managing your AWS resources effectively and reducing costs by deallocating resources that are not in use."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control, which checks if Elastic Block Store (EBS) volumes are attached to Elastic Compute Cloud (EC2) instances, can result in several potential costs.\n\n1. **Unnecessary Cost Increase**: AWS charges for EBS volumes, even if they are not attached to an EC2 instance. If an organization fails to comply with this control, it may be paying for EBS volumes that are not in use.\n\n2. **Data Management Risk**: Unattached EBS volumes could contain sensitive data that is not being securely controlled or appropriately backed up. This imposes a potential risk of data loss or breach.\n\n3. **Operational Inefficiency**: Keeping track of unattached EBS volumes can result in operational inefficiencies. It can be time-consuming for your AWS administrators to manage and identify the best uses for these volumes.\n\n4. **Compliance Risk**: In industries with strict data compliance guidelines, such as financial services or healthcare, having unattached EBS volumes could lead to potential compliance issues. This could result in substantial financial penalties.\n\n5. **Security Risks**: Unmanaged and unattached volumes could potentially be a vector for security threats. Intruders might be able to exploit these abandoned volumes as a way to gain access to an organization's data or infrastructure.\n\nSo, it is important that an organization follows this control to avoid the unwanted expenses and manage resources efficiently and securely."
      ],
      "x-kaytu-usefulness-example": [
        "`EBSChecker`\n---\nThe `EBSChecker` AWS control is particularly useful when managing resources within an extensive AWS environment.\n\nFor instance, in a scenario where an organization has multiple EC2 instances and EBS volumes across different departments, unattached or unused EBS volumes could lead to unnecessary costs. \n\nBy leveraging `EBSChecker`, the organization can rapidly determine which EBS volumes are not attached to an EC2 instance. This information can then be used to decommission unused volumes, consequently saving on costs.\n\n```markdown\nHere is an example instance:\n\n**AWS Control:** EBSChecker\n**Scenario:** Unnecessary cost due to unattached or dormant EBS volumes\n**Action:** Used EBSChecker to determine unattached EBS volumes\n**Result:** Identified X number of unattached EBS volumes. The IT department decommissioned these volumes, resulting in an estimated cost savings of Y.\n```\nThis example highlights the importance of maintaining AWS controls for efficient resource management and cost optimization. Furthermore, regular usage of these controls ensures a clean and optimized environment, which leads to heightened performance and a reduction in costs."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_eip_associated",
    "Title": "VPC EIPs should be associated with an EC2 instance or ENI",
    "Description": "This rule ensures Elastic IPs allocated to a Amazon Virtual Private Cloud (Amazon VPC) are attached to Amazon Elastic Compute Cloud (Amazon EC2) instances or in-use Elastic Network Interfaces.",
    "QueryID": "aws_vpc_eip_associated",
    "DocumentURI": "policies/aws_vpc_eip_associated.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/VPC"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Elastic IPs for Amazon VPC\n\nAWS has implemented a control rule to ensure that Elastic IPs, which are allocated for use with Amazon's Virtual Private Cloud (VPC) system, are correctly attached to Amazon Elastic Compute Cloud (EC2) instances or to currently in-use Elastic Network Interfaces (ENIs). \n\n## Rule Details \n\n- **Service**: Amazon Virtual Private Cloud (Amazon VPC) \n- **Control Category**: Security \n- **Control Description**: Ensure that all Elastic IPs allocated to your Amazon Virtual Private Cloud are attached to Amazon Elastic Compute Cloud instances or in-use Elastic Network Interfaces. \n\n```markup\nThis rule checks whether Elastic IPs are attached to Amazon EC2 instances or Elastic Network Interfaces. If an Elastic IP is found to be not attached to any Amazon EC2 instances or Elastic Network Interfaces, the rule will mark it as non-compliant, ensuring optimum utilization of Elastic IP resources and avoiding unnecessary costs.\n```\n\n## Benefits\n\nThe primary benefits of adhering to this rule include optimized resource allocation and cost management. Unused Elastic IPs are technically valuable resources that are going unused, so it makes sense from a resource management perspective to ensure that they are always attached to an EC2 instance or ENI. Beyond this, keeping Elastic IPs attached may help organizations avoid unnecessary charges, as AWS charges fees for allocated but unused Elastic IPs.\n\n## Compliance\n\nThis rule can contribute to an organization's overall compliance strategy by promoting efficient use of resources and by minimizing the risk of incurring unnecessary costs. It also aligns with best practice recommendations for resource management and cost control."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance can be both financial and functional for a business. \n\n- **Financial Cost**: AWS charges for any Elastic IP (EIP) that is allocated but not associated with an EC2 instance or a Network Interface. Therefore, if an EIP is allocated but not in use, businesses will incur unnecessary costs. \n\n- **Functionality Cost**: EIPs that are not associated with any instance or network interface would mean wasted resources which could otherwise be used for other requirements. This could impact the functionality and flexibility of the VPC configuration.\n\n- **Vulnerability Risk**: Unattached EIPs could potentially be leveraged by malicious actors to infiltrate the network if security measures are not appropriately configured.\n\n- **Audit Failure**: If your organization needs to comply with certain regulatory standards or internal policies that mandate such AWS controls, non-compliance could potentially lead to failing audits which could be detrimental to the business.\n\nSo, it's crucial for businesses to comply with this control to avoid unnecessary costs, mitigate security risks, maximize resource utilization, and adhere to regulatory requirements.\n\n```\n    The cost of non-compliance can be both financial and functional for a business:\n\n    1. **Financial Cost**: AWS charges for any Elastic IP (EIP) that is allocated but not associated with an EC2 instance or a Network Interface. Therefore, if an EIP is allocated but not in use, businesses will incur unnecessary costs. \n    2. **Functionality Cost**: EIPs that are not associated with any instance or network interface would mean wasted resources which could otherwise be used for other requirements. This could impact the functionality and flexibility of the VPC configuration.\n    3. **Vulnerability Risk**: Unattached EIPs could potentially be leveraged by malicious actors to infiltrate the network if security measures are not appropriately configured. \n    4. **Audit Failure**: If your organization needs to comply with certain regulatory standards or internal policies that mandate such AWS controls, non-compliance could potentially lead to failing audits which could be detrimental to the business.\n\n    So, it's crucial for businesses to comply with this control to avoid unnecessary costs, mitigate security risks, maximize resource utilization, and adhere to regulatory requirements.\n```"
      ],
      "x-kaytu-usefulness-example": [
        "As an example, consider a company that uses a fleet of EC2 instances for their web application. As part of their network architecture, they use Elastic IP addresses which are assigned to specific instances or network interfaces for consistent IP addressing.\n\nOne day, they allocate a new Elastic IP address for the deployment of a new service within their VPC. However, due to an oversight, they forget to attach this Elastic IP to the corresponding EC2 instance or network interface. This could lead to potential issues such as network connectivity problems or the new service being inaccessible.\n\nWith the AWS control rule, the company can ensure that all their Elastic IPs allocated to their VPC are attached, which promotes greater network reliability, minimizes downtime, and helps maintain consistent application accessibility. The rule can alert them about the unattached IP, allowing the IT team to correct the oversight and avoid potential issues. This rule provides a simple yet effective way to manage their network resources and maintain operational efficiency."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_instance_in_vpc",
    "Title": "EC2 instances should be in a VPC",
    "Description": "Deploy Amazon Elastic Compute Cloud (Amazon EC2) instances within an Amazon Virtual Private Cloud (Amazon VPC) to enable secure communication between an instance and other services within the amazon VPC, without requiring an internet gateway, NAT device, or VPN connection.",
    "QueryID": "aws_ec2_instance_in_vpc",
    "DocumentURI": "policies/aws_ec2_instance_in_vpc.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EC2"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# Deploy Amazon Elastic Compute Cloud (EC2) Instances in Amazon Virtual Private Cloud (VPC)\n\nThis guide is to reference about deploying EC2 instances within Amazon VPC that provides a secure communication channel between them and other services within the same VPC.\n\n## Overview\nAmazon Virtual Private Cloud (VPC) allows you to launch Amazon Elastic Compute Cloud (EC2) instances into a virtual network that you define. This network closely resembles a traditional network but with increased security benefits such as isolation and highly configurable IP address range, subsidiary networks, and security configurations.\n\n## Benefits\n1. **Secure Communication**: Instances within the same VPC can communicate with each other, reducing the need for an internet gateway, NAT device, or VPN connection.\n2. **Isolated Network**: This feature maintains security at a high level and reduces the risk of unwanted interactions with other systems.\n3. **Versatility**: Enable a wide variety of services and features within your isolated network.\n\n## Steps for Deploying EC2 in VPC\n*Please ensure that you have the necessary permissions to create and manage EC2 instances and VPC.*\n\n### 1. Create a VPC\nIn order to create an isolated network, we first need to create a VPC.\n\n1. Navigate to the [VPC Dashboard](https://console.aws.amazon.com/vpc/)\n2. Click on \"Your VPCs\" in the left menu\n3. Click \"Create VPC\"\n4. Follow the instructions to create your VPC.\n\n### 2. Create an EC2 Instance\nNext step is to create our EC2 instance. Make sure to place it within our VPC.\n\n1. Go to the [EC2 Dashboard](https://console.aws.amazon.com/ec2/)\n2. Click \"Instances\" on the left menu\n3. Click \"Launch instances\"\n4. Follow the prompts to create your instance. Make sure to place your instance in your previously created VPC.\n\nThe EC2 instances now can communicate with other services securely within the VPC. No need for an internet gateway, NAT device, or VPN connection to perform the operations.\n\n**Congratulations! You have successfully deployed an EC2 instance within your VPC!**"
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control can be tremendous and damaging to an organization. Non-compliance often results in the following ways:\n\n1. **Security Breaches:** If Amazon EC2 instances are not deployed within an Amazon VPC, data being sent and received might not be as secure. This increases the chances of security breaches and data exposure which can cause a company significant financial and reputational damage. \n\n2. **Increased Costs:** Not using a VPC might lead to higher costs. Organizations may need to invest in other security measures or mechanisms such as an internet gateway, NAT device, or VPN connection to ensure secure communication.\n\n3. **Inefficiencies:** Without using a VPC, the secure and efficient communication between services can be compromised. This can lead to not only security issues but also performance issues, resulting in poor user-experience and potential loss of business.\n\n4. **Regulatory Sanctions:** Non-compliance to this AWS control can also mean potential regulatory sanctions for not adhering to the best practices or standards set by regulatory bodies. This can lead to fines and penalties, and even legal actions in certain jurisdictions.\n\n5. **Operational Interruptions:** If your communication gets intercepted due to the lack of a secure environment, it may lead to operational interruptions. This can cost companies in terms of downtime and potential recovery costs.\n\nIn summary, the cost of non-compliance to this AWS control can be significant. It's not just about the direct financial implications; there are several potential indirect costs due to reputational damage, loss of customer trust, and potential legal implications. Hence, it is essential to adhere to AWS controls like these for secure and efficient operations."
      ],
      "x-kaytu-usefulness-example": [
        "AWS EC2 instances within an Amazon VPC can be very useful in various scenarios. Here is an example:\n\n## Scenario: Secure Data Analysis and Processing \n\nCompany X is a data analytics firm that processes large amounts of sensitive data for its clients. This data includes financial records, personal identifiable information (PII) and other confidential data. As a result, the company needs a secure environment for processing and analyzing this data, while also ensuring reliable connection with other internal services such as databases and storage.\n\nWith the use of Amazon EC2 instances within an Amazon VPC, Company X can create a secure, private network for their data processing tasks. All the data remains inside their VPC without the need of traversing the internet, which minimizes the risk of data exposure. \n\nThe internal services like databases can be hosted inside the same VPC, allowing EC2 instances to securely communicate with them without the need for an internet gateway, NAT device, or VPN connection. This would minimize the latency issues, increase the throughput and overall efficiency of their processes.\n\nThis architecture would also provide company X with additional control over their virtual networking environment, including selection of own IP address range, creation of subnets, and configuration of route tables and network gateways.\n\n```\nData flow:\n\n(Data Sources) --\u003e (EC2 instances in VPC) --\u003e (Internal Services in the same VPC)\n```\n\nThus, deploying EC2 instances within a VPC in such a case proves to be extremely beneficial in terms of both security and efficiency."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_securityhub_enabled",
    "Title": "AWS Security Hub should be enabled for an AWS Account",
    "Description": "AWS Security Hub helps to monitor unauthorized personnel, connections, devices, and software. AWS Security Hub aggregates, organizes, and prioritizes the security alerts, or findings, from multiple AWS services.",
    "QueryID": "aws_securityhub_enabled",
    "DocumentURI": "policies/aws_securityhub_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/SecurityHub"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Security Hub \n\nAWS Security Hub is a security service provided by AWS that helps you in monitoring unauthorized personnel, connections, devices, and software to protect your AWS environment. It acts as a comprehensive security and compliance solution that aggregates, organizes and prioritizes security alerts, also known as findings, from multiple AWS services such as Amazon GuardDuty, Amazon Inspector, and Amazon Macie, and from a many AWS Partner solutions.\n\n## Features\n\n### 1. Security Alert Aggregation\nSecurity Hub collects and aggregates findings from multiple AWS services and Partner solutions to provide you a comprehensive view of your security and compliance status in AWS.\n\n### 2. Organized and Prioritized Alerts\nIt organizes and consolidates findings in a way that makes sense and is easy to manage. The service also identifies and prioritizes the most important findings, making it easier for you to focus on what matters most.\n\n### 3. Easy Integration\nSecurity Hub integrates with a broad range of AWS services and third-party solutions. This makes it one of the most adaptable and versatile security solutions for AWS environments, capable of seamlessly working with existing systems and processes.\n\n## Benefits\n\nUsing AWS Security Hub, you can enhance your ability to detect security misconfigurations, unauthorized activities, and potential security risks. It automates the process of gathering and prioritizing security findings, reducing the time and effort required for threat detection and management. Also, with AWS Security Hub, it is easier to comply with external regulations and internal policies.\n\nIn summary, AWS Security Hub simplifies the process of managing security and compliance, by giving you a centralized and comprehensive view of your necessary security alerts in Amazon Web Services."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to controls provided by AWS Security Hub can prove costly for a company in several ways:\n\n1. **Financial Costs**: Without monitoring unauthorized personnel, connections, devices, and software, a company may suffer from data breaches that can result in heavy financial losses. You can face regulatory fines if the data breach involves customer data or other sensitive information. Moreover, recovering from a data breach can also be expensive.\n\n2. **Operational Costs**: Failure to adhere to this control can result in disruptions to your day-to-day operations. These disruptions could be from threats or vulnerabilities that go undetected, resulting in system downtime and decreased productivity.\n\n3. **Reputational Costs**: The occurrence of a data breach can severely damage the reputation of your company. It can cause customers to lose trust in your services and potentially cause them to cease relations with your company. Regaining customer trust post a security incident is a challenging and costly affair.\n\n4. **Legal and Regulatory Costs**: If you operate in a regulated industry, non-compliance with AWS Security controls may result in penalties from regulatory bodies.\n\n5. **Data Loss Costs**: Data breaches can lead to loss of vital business data which can have long-term impacts on business functioning and growth. Recovering or re-creating lost data can also pose a big cost.\n\nTo sum up, the cost of non-compliance to AWS Security Hub control is not just financial, but it affects all aspects of business - operation, reputation, and legal standing. It’s in an organization’s best interest to adhere to these controls to maintain a secure and efficient system."
      ],
      "x-kaytu-usefulness-example": [
        "Example Instance of Usefulness:\n\nA multinational company with substantial digital infrastructure uses several AWS services like AWS GuardDuty, AWS Inspector, etc., to manage its operations. As expected, the organization collects a large amount of security data from various sources, creating a management headache. Now, let's say they suspect a breach in their system due to several unusual activities on their servers. \n\nInstead of analyzing data from each AWS service separately, the company uses AWS Security Hub. It aggregates all the security findings from various sources, helping them to get a consolidated view of their security state within AWS. It prioritizes the security alerts, allowing them to focus on the most significant threats first, such as a potential breach that they suspected. They will be able to visually analyze which resources are affected and take relevant actions.\n\nMoreover, AWS Security Hub detecting a strange device trying to connect to their server would be crucial. This would provide a clue indicating an unauthorized personnel might be trying to break into their system. Thus, the AWS Security Hub significantly reduces the time taken for security analysis, bolstering their digital security efforts and counteracting the suspicious activities quickly."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_group_not_empty",
    "Title": "IAM groups should have at least one user",
    "Description": "AWS Identity and Access Management (IAM) can help you incorporate the principles of least privilege and separation of duties with access permissions and authorizations, by ensuring that IAM groups have at least one IAM user.",
    "QueryID": "aws_iam_group_not_empty",
    "DocumentURI": "policies/aws_iam_group_not_empty.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "```\n# AWS Identity and Access Management (IAM)\n\nAWS Identity and Access Management (IAM) is an Amazon Web Services tool that enables an administrator to create and manage AWS users and groups. It allows you to manage access to AWS services and resources securely.\n\n## Principles of Least Privilege and Separation of Duties \n\nIAM helps you to implement two important security concepts:\n\n1. **Least Privilege**: In security, the principle of least privilege (POLP) emphasizes minimal user profile privileges on computers, based on users' job necessities. It recommends that a user be given the minimum levels of access necessary to complete his/her job functions.\n\n2. **Separation of duties**: It is a security concept whereby a person is not given enough rights and privileges to perpetrate and conceal an wrongdoing on his own.\n\n## Access Permissions and Authorizations\n\nWith IAM, you can define which service(s) a user or group of users can access in your AWS environment. It allows you to specify permissions or actions that a user can perform on a piece of resource.\n\n## Ensuring at Least One IAM User\n\nIAM helps to ensure that at least one IAM user is present in an IAM group. This way, it further ensures that no unnecessary permissions are granted and that actions are accountable by being linked to specific users, thereby maintaining high security levels and accountability.\n\nTo sum it up, IAM allows you to securely manage access to AWS services and resources, apply the principles of least privilege and separation of duties, establish specific permissions for users and groups, and ensure accountability for actions performed in your AWS environment.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control means that your AWS resources could be at risk due to lack of proper access control. Implementing the principle of least privilege and separation of duties via IAM is crucial for securing your resources. Here are a few potential costs:\n\n1. **Security Risks:** If no IAM users are assigned to IAM groups, everyone might have unrestricted access to your AWS resources. This can lead to significant security risks as malicious actors could potentially gain access.\n\n2. **Audit Failures:** For companies required to comply with specific regulations such as GDPR, HIPAA or PCI-DSS, lack of proper IAM configurations may result in a failure in the compliance audit, resulting in hefty fines.\n\n3. **Operational Risks:** Overly permissive IAM policies can lead to operational risks, including accidental deletions or alterations of critical data.\n\n4. **Increased Costs:** Unmonitored and unrestricted access to AWS resources could lead to unnecessary spinning up of resources, resulting in increased costs.\n\n5. **Reputation Damage:** Security breaches or unauthorized access to customer data can lead to substantial reputation damage for businesses, which in turn can lead to reduced customer trust and potential loss of business.\n\nHere is a markup representation of the cost of non-compliance:\n\n```markdown\n- [Security Risks](#security-risks)\n- [Audit Failures](#audit-failures)\n- [Operational Risks](#operational-risks)\n- [Increased Costs](#increased-costs)\n- [Reputation Damage](#reputation-damage)\n```\n\nEach of the headings can link to a more detailed explanation of the potential risks and costs outlined."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, consider an e-commerce firm that utilizes AWS for their cloud services. The firm has various teams such as the software development team, testing team, and the operations team. Using AWS Identity and Access Management (IAM), the firm will be able to better manage the access privileges for these teams.\n\nFor example:\n\n- The software development team needs to have access to EC2 instances for deploying applications, but they should not have permissions to control networking components like VPCs, NLB, etc. This can be achieved with IAM by providing EC2 specific permissions to the software developers' IAM group.\n\n- The testing team might need permissions to access s3 buckets to view logs, but they should not have permissions to alter or delete the logs. The privilege to access S3 with read-only permission can be granted via IAM.\n\n- The operations team requires higher permissions to monitor the overall AWS activities, which can be granted via IAM control.\n\nThus, by using AWS IAM, the firm ensures that each group has access to the specific resources they require to complete their tasks, thereby incorporating the principles of least privilege and separation of duties. This will reduce the potential risk linked to human errors or malicious actions, and strengthens security by minimizing unauthorized access to certain resources."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_user_mfa_enabled",
    "Title": "IAM user MFA should be enabled",
    "Description": "Enable this rule to restrict access to resources in the AWS Cloud.",
    "QueryID": "aws_iam_user_mfa_enabled",
    "DocumentURI": "policies/aws_iam_user_mfa_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Control is a feature in the AWS (Amazon Web Services) platform which allows you to manage access to your AWS resources. You can establish and enforce varying levels of access to these resources through the use of different rules. \n\nOne such rule enabled in AWS Control is the rule to restrict access to resources. With this rule, you can ensure that only authorized users or systems can access specific resources in your AWS Cloud. Without the appropriate authorization, a user or system would be denied from viewing or manipulating these resources.\n\nIn Markdown format, the explanation might look like this:\n\n```markdown\n# AWS Control\n\nAWS Control is a component of the **Amazon Web Services (AWS)** suite that allows users to manage and control access to their AWS resources. \n\n## Restrict Access Rule\n\nAmong the variety of rules available in AWS Control is the **Restrict Access Rule**. As the name suggests, this rule can be enabled to limit access to certain resources found within the AWS Cloud. \n\nUpon activation, this rule requires that all users or systems must have the necessary authorization before they can gain access to these protected resources. If they are lacking the required authorization, access to the specified resources will be denied.\n```\nThis markdown will create a document with a title, subheadings, and body content, with important terms or phrases in bold for emphasis."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with the control rule to restrict access to resources in the AWS Cloud can have different types of costs for an organization. \n\n1. **Security Costs**: Given that this rule aims to limit access to AWS resources, non-compliance could lead to unnecessary or unauthorized access to important data or services. This can leave the systems vulnerable to hacking or accidental alterations, modifications, and deletions.\n\n2. **Financial Costs**: Unauthorized access may lead to consumption of AWS resources, causing unjustified charges. There may also be additional costs due to the time and resources spent on rectifying the problems or damages caused by unauthorized access.\n\n3. **Reputational Costs**: If a data breach occurs due to non-compliance, it can damage an organization's reputation. This can lead to loss of customers, business and potential legal penalties.\n\n4. **Regulatory Compliance Costs**: In industries where regulatory compliance is mandatory, non-compliance with AWS security rules could lead to regulatory fines, sanctions or legal actions.\n\nIn conclusion, while the direct financial cost of non-compliance might seem low at first, if you factor in the potential security threats, unauthorized usage of resources, potential reputational loss and possible legal implications, the cost of non-compliance can be significantly high. Therefore, it is imperative for organizations to comply with such essential control rules to maintain security, cost-effectiveness, and reliability of their AWS resources."
      ],
      "x-kaytu-usefulness-example": [
        "For example, consider a company maintaining a large application on AWS Cloud. The application may include various AWS resources like AWS RDS instances for databases, AWS S3 buckets for storage, EC2 instances for servers, etc. Some of these resources contain sensitive data that should only be accessed by specific staff members or departments.\n\nBy enabling this rule, the company can set up specific access rights and policies for these sensitive resources, ensuring that only authorized personnel can access, modify or delete them, thereby significantly improving their overall security posture. \n\n```markup\n\u003cAWSCloud\u003e\n  \u003cResources\u003e\n    \u003cResource name=\"RDS_Instance1\"\u003e\n      \u003cAccessControl\u003e\n         \u003cAllow access=\"DBAdmins\"/\u003e\n      \u003c/AccessControl\u003e\n    \u003c/Resource\u003e\n    \u003cResource name=\"S3_Bucket1\"\u003e\n      \u003cAccessControl\u003e\n         \u003cAllow access=\"StorageAdmins\"/\u003e\n      \u003c/AccessControl\u003e\n    \u003c/Resource\u003e\n    \u003cResource name=\"EC2_Instance1\"\u003e\n      \u003cAccessControl\u003e\n         \u003cAllow access=\"DevOps\"/\u003e\n      \u003c/AccessControl\u003e\n    \u003c/Resource\u003e\n  \u003c/Resources\u003e\n\u003c/AWSCloud\u003e\n```\n\nIn the above markup, access to the RDS instance is granted to DBAdmins group, access to S3_Bucket1 to StorageAdmins group, and access to EC2_Instance1 to DevOps group. This kind of access control can prevent unauthorized access and potential breaches."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_flow_logs_enabled",
    "Title": "VPC flow logs should be enabled",
    "Description": "The VPC flow logs provide detailed records for information about the IP traffic going to and from network interfaces in your Amazon Virtual Private Cloud (Amazon VPC.",
    "QueryID": "aws_vpc_flow_logs_enabled",
    "DocumentURI": "policies/aws_vpc_flow_logs_enabled.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/VPC"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Sure, here's how you would explain VPC flow logs in markup format:\n\n```markup\n# VPC Flow Logs in Amazon Web Services \n\nVPC Flow Logs is a feature that allows you to monitor the IP traffic moving to and from network interfaces in your Virtual Private Cloud (VPC). This can be crucial in understanding how your network is accessed and utilized.\n\n## Key Features\n\n1. **Traffic Monitoring**: VPC Flow Logs records all the network flow data at the metadata level. This helps you in auditing and reviewing your network traffic patterns in detail.\n\n2. **Security:** You can use Flow Logs data for security analysis purposes to detect unusual traffic behaviors.\n\n3. **Networking Performance Troubleshooting:** With the help of flow logs data, you can diagnose why specific traffic is not reaching an instance, helping you quickly address any operational issues.\n\n## How to Enable VPC Flow Logs\n\nYou can enable VPC Flow Logs through the Amazon VPC Console, AWS CLI, or AWS SDKs. After you've created a flow log, you cannot change its configuration; but, you can create a different one.\n\n## Viewing Flow Log Data\n\nOnce enabled, the flow log data is published to your desired destination - a CloudWatch Logs group or an Amazon S3 bucket. You can use different methods to retrieve and view the flow log data, depending on where it's published.\n\nPlease note there are some costs for using VPC Flow Logs, particularly for data ingestion and archival. The costs can vary based on your usage and configuration settings.\n\n```\n\nRemember, VPC Flow Logs is a powerful tool, but it does not provide information about individual application-level transactions, such as the actual content of the traffic - making it privacy-focused too."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS Control of utilizing VPC (Virtual Private Cloud) flow logs can result in substantial consequential costs for businesses such as:\n\n1. **Cybersecurity Risks**: VPC flow logs are crucial in detecting anomalies, security threats and violations in your network traffic. Not maintaining these logs puts your VPC at high risk of undetected intrusions, leading to possible loss of confidential data and cyberattacks that can result in large financial costs.\n\n2. **Data Loss**: Without VPC Flow Logs, the risk of data loss, corruption, or exposure to unauthorized sources increases exponentially. This could potentially lead to financial and reputation damage.\n\n3. **Compliance Violations**: If your business operates in a sector where specific compliance regulations mandatory (like GDPR, HIPAA, etc.), failure to implement VPC Flow Logs could result in substantial fines for non-compliance.    \n\n4. **Troubleshooting Difficulties**: VPC Flow Logs assist in diagnosing why specific traffic is not reaching an instance. If not implemented, it increases the time and thus the costs to troubleshoot and solve network errors.\n\n5. **Accountability Issues**: Without VPC Flow Logs, you lose the ability to track changes and usages within your network. This can hamper the resolution of disputes and cause accountability issues in your team.\n\nOverall, the cost of non-compliance to implementing Amazon VPC flow logs isn't just financial. It also includes cybersecurity risks, data protection, regulatory non-compliance, operational inefficiencies and accountability issues."
      ],
      "x-kaytu-usefulness-example": [
        "For example, a software company ABC has deployed its app on AWS and uses multiple services in addition to leveraging Amazon VPC for the app's backend. One day, they identify some suspicious activity and an unexpected increase in outbound data which is causing increased costs.\n\nTo investigate this issue and identify the source of the traffic, ABC company can use VPC flow logs. Through these logs, they can get detailed information about the IP traffic going to and from network interfaces in their Amazon VPC. \n\nBy auditing these logs, they can identify the IP addresses and ports that are showing unusual activity. Moreover, these logs can provide information like the source, destination, and protocol of the traffic which can help ABC company in identifying if their data is going to an unknown or suspicious IP address.\n\n```\n---\nAggregatedBytes: 1590\nAggregatedPackets: 23\nEndTime: 1566187200\nFlowDirection: OUTBOUND\nSourceAddresses: [192.0.2.1]\nDestinationAddresses: [198.51.100.15]\nDestinationPorts: [443]\nProtocol: TCP\nLogStatus: OK\nStartTime: 1566187140\n---\n```\nWith details like these from the logs, they can swiftly identify the issue, potentially spotting a security vulnerability that's being exploited and respond immediately to tackle the problem. This eventually helps in maintaining the security and cost-efficiency of their AWS infrastructure."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_enforces_ssl",
    "Title": "S3 buckets should enforce SSL",
    "Description": "To help protect data in transit, ensure that your Amazon Simple Storage Service (Amazon S3) buckets require requests to use Secure Socket Layer (SSL).",
    "QueryID": "aws_s3_bucket_enforces_ssl",
    "DocumentURI": "policies/aws_s3_bucket_enforces_ssl.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "## AWS Control: Enforcing SSL for Amazon S3 \n\nThis control concerns the application of Secure Socket Layer (SSL) for communication with Amazon Simple Storage Service (Amazon S3) Buckets. SSL is a protocol for encrypting information over the internet, ensuring the integrity and security of data in transit.\n\nIf requests to Amazon S3 do not use SSL, your data could be exposed to potential threats such as data breaches or cyber-attacks while in transit. When SSL is enforced, it helps prevent unauthorized access and ensures data confidentiality during transmission.\n\n```markdown\n### How to Enforce SSL on S3 Buckets\n\nTo enforce the use of SSL on S3 Buckets follow these steps:\n\n1. Log into the AWS Management Console and navigate to the S3 console.\n2. Select the S3 bucket you wish to enforce SSL on.\n3. Click on the 'Bucket Policy' option.\n4. Add a condition to the bucket policy that denies any S3 action if the request do not come over SSL. \n\nThe condition in the policy will look like this:\n\n```json\n\"Condition\" : {\n\t\"Bool\" : {\n\t\t\"aws:SecureTransport\" : \"false\"\n\t}\n}\n```\n\nThe `\"aws:SecureTransport\": \"false\"` condition denies all requests that do not use SSL (`https://`), thereby enforcing the use of SSL. Save and apply the bucket policy.\n```\n\nBy enforcing SSL on your Amazon S3 buckets, you enhance the safety of your data by ensuring it is secure while in transit. However, this security measure only covers data in transit, and you should also consider other security best practices for data at rest.\n\n---\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control can lead to a range of consequences, mostly revolving around data security issues:\n\n1. **Data Breaches**: If the data in transit is not encrypted, it becomes vulnerable to interceptions and unauthorized access. Hackers or other malicious entities could potentially access and misuse sensitive information.\n\n2. **Regulatory Sanctions**: Certain regulations and guidelines, like the General Data Protection Regulation (GDPR), Health Insurance Portability and Accountability Act (HIPAA), and Payment Card Industry Data Security Standard (PCI DSS), require the encryption of data in transit. Non-compliance could lead to penalties and legal repercussions.\n\n3. **Loss of Business**: If a data breach happens and becomes public knowledge, it can lead to loss of trust from customers, affecting the company's reputation and business.\n\n4. **Additional Costs**: The company might incur additional costs to handle the aftermath of data breaches, including investigation costs, damage control, and system security improvements.\n\nIn terms of financial implications, the cost of non-compliance can be huge, potentially running into millions of dollars. This, in addition to the non-financial consequences, underlines the critical importance of ensuring that Amazon S3 buckets require requests to use Secure Socket Layer (SSL) for data protection in transit."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, you operate a healthcare organization that uses Amazon S3 for storing and transferring sensitive patient data. This data includes personal identifiable information (PII) such as names, addresses, social security numbers, medical history etc, which are subjected to strict regulatory obligations like HIPAA. \n\nLeakage of this sensitive information can result in severe legal and financial consequences for your organization. To ensure maximum protection while data is being transmitted over the network, you need to enforce the use of SSL. \n\nBy enforcing the requests to use SSL, the data transmission between your network and Amazon S3 takes place using an encrypted link, which secures the data from potential eavesdropping or tampering threats. This way, the confidentiality and integrity of your patients' data are well-preserved during transit. \n\nHere is how you could include this setting in AWS:\n\n```markup\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyInSecureTransport\",\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:*\",\n      \"Resource\": \"arn:aws:s3:::YourBucket/*\",\n      \"Condition\": {\n         \"Bool\": {\n             \"aws:SecureTransport\": \"false\"\n          }\n       }\n    }\n  ]\n}\n```\n\nAs a result, this AWS control ensures data protection, helps meet compliance requirements, and enhances your organization's security posture."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_lambda_function_in_vpc",
    "Title": "Lambda functions should be in a VPC",
    "Description": "Deploy AWS Lambda functions within an Amazon Virtual Private Cloud (Amazon VPC) for a secure communication between a function and other services within the Amazon VPC.",
    "QueryID": "aws_lambda_function_in_vpc",
    "DocumentURI": "policies/aws_lambda_function_in_vpc.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/Lambda"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "## AWS Control: Deploy AWS Lambda Functions within an Amazon Virtual Private Cloud (Amazon VPC)\n\nYou can enhance the security of your AWS Lambda functions by deploying them within an Amazon Virtual Private Cloud (Amazon VPC). This sets up a secure communication channel between your Lambda function and other services within the Amazon VPC.\n\n### What is AWS Lambda?\n\nAWS Lambda is an event-driven, serverless computing platform provided by Amazon as a part of the Amazon Web Services (AWS). It is a compute service that lets you run code without provisioning or managing servers.\n\n### What is Amazon VPC?\n\nAmazon Virtual Private Cloud (Amazon VPC) is a service that lets you launch AWS resources in a virtual network that you define. VPC provides a more granular control over your virtual networking environment, including selection of your own IP address range, creation of subnets, and configuration of route tables and network gateways.\n\n### Why Deploy AWS Lambda in Amazon VPC?\n\nDeploying AWS Lambda functions within an Amazon VPC provides the following advantages:\n\n- **Secure Communication:** Communication between the Lambda function and other services in the Amazon VPC is secure which reduces the risk of data being exposed to external threats.\n\n- **Resource Accessibility:** Lambda functions deployed within a VPC can access resources and services within that same VPC. For instance, if your function needs to interact with an EC2 instance or a relational database service (RDS), being within the same VPC can make these interactions easier and more secure.\n\n- **Access Control:** By deploying your Lambda functions within a VPC, you can use VPC security groups and network access control lists (ACLs) to manage inbound and outbound traffic to your function.\n\nImplementing this control within your AWS environment improves the overall security of your deployments and reduces risks associated with data exposure."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS Control can have several potential costs:\n\n1. **Security Risks**: By not deploying AWS Lambda functions within an Amazon VPC, your functions may be more exposed to potential security threats. This could result in unauthorized access, data theft or manipulation, or other types of attacks.\n\n2. **Data Breaches**: If your functions process sensitive data and are not correctly secured within a VPC, there's a significant risk of a data breach, which could not only lead to negative impacts on your organization's reputation, but also financial penalties if private customer data is leaked.\n\n3. **Inefficient Communication**: VPCs allow for efficient and secure communication between different services. Not using a VPC could lead to more inefficient communication, possibly slowing down processes and impacting performance.\n\n4. **Regulatory Compliance**: Depending on your industry, there may be specific regulations regarding data protection and network security that you must comply with. Not deploying functions within a VPC could result in non-compliance with these regulations, leading to potential legal trouble and financial penalties.\n\n5. **Increased Costs**: In case of a security incident or data breach caused by lack of security precautions, the remedial measures, legal proceedings, penalties, and PR measures to repair your organization's reputation can result in substantial unplanned costs.\n\nIn conclusion, it's financially and operationally beneficial to comply with the AWS control and deploy AWS Lambda functions within a VPC."
      ],
      "x-kaytu-usefulness-example": [
        "For example, a healthcare company uses AWS Lambda functions to process sensitive patient data. This data is stored securely on Amazon RDS inside a VPC. The company needs to ensure the highest level of security and privacy for this data due to regulatory requirements.\n\nBy deploying the Lambda functions within an Amazon VPC, the functions can securely access the RDS database without exposing the sensitive data to the Internet. This setup allows secure communication between the Lambda function and RDS service within the Amazon VPC, ensuring the privacy and integrity of the patient data is maintained at all times. Moreover, the system can also take advantage of Amazon VPC features such as security group settings and network ACLs to add an additional layer of security."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_network_acl_unused",
    "Title": "VPC network access control lists (network ACLs) should be associated with a subnet.",
    "Description": "Ensure there are no unused network access control lists (network ACLs). The rule is compliant if each network ACL is associated with a subnet. The rule is non-compliant if a network ACL is not associated with a subnet.",
    "QueryID": "aws_vpc_network_acl_unused",
    "DocumentURI": "policies/aws_vpc_network_acl_unused.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/VPC"
      ],
      "x-kaytu-explanation": [
        "AWS Control mentions the condition for which a network access control list (network ACL) is deemed as compliant or non-compliant. AWS uses network ACLs as a kind of firewall for controlling traffic in and out of a subnet.\n\n- The rule is compliant: If every network ACL is associated with a subnet. In other words, every network ACL should be in use or active.\n\n- The rule is non-compliant: If a network ACL is not associated with any subnet. This means, if there are any unused or inactive network ACLs, they are considered non-compliant.\n\nThis specification helps keep your cloud environment clean and optimized, which is a good practice.\n\nIn markup format, the explanation would look like this:\n\n```\nAWS network ACLs control the traffic to and from a subnet within a VPC. \n\n**Compliance:** \n\n- All network ACLs should be associated with a subnet, meaning that they are in use or active. \n\n**Non-Compliance:**\n\n- Any network ACLs not associated with a subnet, i.e., they are unused or inactive. \n\nThis control enforces keeping cloud environments clean and eliminates the presence of unutilized resources. \n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS Control could potentially be significant for an organization as it may lead to several issues such as:\n\n1. **Security Risks**: Unused network access control lists (ACLs) can pose a threat to the security of your AWS resources. If an attacker gains access to these unused ACLs, they could potentially use them to bypass security measures and access your private resources.\n\n2. **Operational Inefficiencies**: Maintaining unused ACLs can lead to operational inefficiencies. Since they are not associated with any subnets, these control lists can simply clutter your system and make it more difficult to manage.\n\n3. **Increased Costs**: While the cost of maintaining an unused network ACL may not be highly significant, it can still add up over time. Especially in a larger organization with numerous unused ACLs, the cost could become substantial.\n\n4. **Non-Compliant to Standards**: Many organizations have internal or external standards for maintaining efficient and secure system configurations. Keeping unused ACLs can lead to non-compliance with these standards and can result in penalties. It can also lead to negative audits, which could potentially affect business contracts and client trust.\n\nAs a result, it is important to ensure that each network ACL is associated with a subnet to eliminate these potential risks and costs. Regularly reviewing and cleaning up unused network ACLs should be part of the standard operational procedures."
      ],
      "x-kaytu-usefulness-example": [
        "This control is useful in an Amazon Web Services (AWS) environment with multiple VPCs and subnets deployed for different applications or services. \n\nFor example, consider a large organization with various departments, such as R\u0026D, Operations, and HR, each having its own set of applications and services hosted on AWS. Each department may have its own VPC divided into several subnets for segregation of resources and better management. As part of security best practices, each subnet may have its own network ACL to control inbound and outbound traffic.\n\nOver time, as the organization evolves, it might consolidate certain applications or decommission some services. The network ACLs associated with these applications or services might get leftover in the process and remain unused in the system. These unused network ACLs become clutter making it hard for system administrators to manage the AWS networks and potentially leading to misconfigurations. \n\nWith this AWS control, system administrators can identify these unused network ACLs easily and remove them, thereby simplifying the management and reducing the risk of potential security breaches due to misconfigurations. It improves network hygiene and enforces a clean working environment, which is a critical aspect of best security practices.\n\nThis control becomes even more crucial in highly dynamic environments where infrastructure is codified (Infrastructure as Code - IaC), and resource provisioning and decommissioning happen frequently via automated pipelines."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_instance_uses_imdsv2",
    "Title": "EC2 instances should use IMDSv2",
    "Description": "Ensure the Instance Metadata Service Version 2 (IMDSv2) method is enabled to help protect access and control of Amazon Elastic Compute Cloud (Amazon EC2) instance metadata.",
    "QueryID": "aws_ec2_instance_uses_imdsv2",
    "DocumentURI": "policies/aws_ec2_instance_uses_imdsv2.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EC2"
      ],
      "x-kaytu-explanation": [
        "Amazon Elastic Compute Cloud (Amazon EC2) includes an instance metadata service which provides important data about your instances. This data, which includes user data and the system status checks, can be potentially exposed and accessed by malicious entities if left unprotected. Hence, to ensure the security and integrity of this data, the Instance Metadata Service Version 2 (IMDSv2) method is preferred over the earlier version (IMDSv1). Leveraging additional defense mechanisms, IMDSv2 requires a session-oriented approach which makes it more resilient against several types of vulnerabilities, primarily Server Side Request Forgery (SSRF) attacks.\n\n```markdown\n# Amazon EC2 Instance Metadata Service Version 2 (IMDSv2)\n\nThe Instance Metadata Service (IMDS) in **Amazon EC2** provides important data about your instances. This data, which includes user data and system checks, might be exposed and accessed by malicious entities if not properly protected. To bolster this protection, you should use the **Instance Metadata Service Version 2 (IMDSv2)** method rather than the earlier version. \n\n## Benefits of IMDSv2 over IMDSv1\n\nIMDSv2 has additional defenses over its predecessor, primarily:\n\n* It requires a **session-oriented** approach. This means that retrieving instance metadata requires establishing a session using the *PUT* request to the **IMDSv2** endpoint. Once a session has been established, it can then be used to retrieve any required metadata.\n\n* It is **resilient** against several security vulnerabilities, especially Server Side Request Forgery (SSRF) attacks.\n\nHence, by ensuring that the **IMDSv2** method is enabled, the risk of unauthorized access and control over Amazon Elastic Compute Cloud instance metadata is significantly reduced, thus contributing to the overall security of your AWS resources.\n```\n\nNote: Remember to replace important configurations like `access_keys` and `access_tokens` with your respective values."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS Control of enabling Instance Metadata Service Version 2 (IMDSv2) can sometimes lead to serious costs, many of which can be detrimental to daily operations, business procedures, and even the organization’s reputation. Let's dissect the potential costs involved in a brief manner:\n\n1. **Security Breaches and Data Leaks**\n   \n   When a lower version or improper configuration exists, it makes room for potential unauthorized access and data leakage. An attacker could potentially gain unauthorized access to metadata, including sensitive information like IAM role data, user data or even operational data linked to your instance. This could lead to severe privacy implications and data breach-related fines.\n\n2. **Financial Loss**\n   \n   A successful breach due to non-compliance could directly lead to financial losses. This could be through unauthorized access and abuse of AWS resources provided by metadata, resulting in unexpected high charges to your AWS account. In addition to this, addressing the breach and patching vulnerabilities costs resources.\n\n3. **Regulation-Related Fines**\n   \n   Non-compliance might compromise user data and directly lead to non-compliance with certain regulations, standards, and laws such as GDPR or HIPAA. Resulting penalties and fines can prove to be significant.\n\n4. **Reputation Damage**\n\n   Business reputation is critical and any security breach due to non-compliance could cause damage to the organization's reputation, potentially leading to loss of client trust, decline in sales, and a tarnished brand image.\n\n5. **Operational Disruption**\n\n   Non-compliance if exploited could cause serious business disruption. You may need to temporarily stop services to investigate the matter, correct the flaws etc. Overall impacting the customer experience.\n\nFor these reasons, embracing proactive measures - such as implementing the Instance Metadata Service Version 2 (IMDSv2) - can help organizations mitigate these costs by enhancing their security posture, ensuring compliance, and protecting sensitive metadata."
      ],
      "x-kaytu-usefulness-example": [
        "For example; \n\nYou are an administrator at a company, managing several Amazon EC2 instances. As a security best practice, you want to ensure that all sensitive data, including instance metadata, is protected from unauthorized access, both physically and electronically. \n\nIn this scenario, enabling the Instance Metadata Service Version 2 (IMDSv2) on your Amazon EC2 instances grants you additional security benefits over IMDSv1. \n\nIMDSv2 requires explicit ‘session-oriented’ requests and error messages from applications trying to access metadata. It also requires both PUT and GET requests, rather than just GET, which reduces the attack surface. \n\nNotably, if an attacker breaches your security layers and gains access to the instance, without valid session tokens for IMDSv2, they cannot fetch instance metadata. \n\nHence, by ensuring IMDSv2 is enabled across all EC2 instances, you add an extra layer of security. This reduces risk, protects sensitive data and complies with security best practices, demonstrating the usefulness of this AWS control."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_instance_ssm_managed",
    "Title": "EC2 instances should be managed by AWS Systems Manager",
    "Description": "An inventory of the software platforms and applications within the organization is possible by managing Amazon Elastic Compute Cloud (Amazon EC2) instances with AWS Systems Manager.",
    "QueryID": "aws_ec2_instance_ssm_managed",
    "DocumentURI": "policies/aws_ec2_instance_ssm_managed.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/SSM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Sure, here's an explanation in markup format:\n\n--- \n`AWS Systems Manager` is a service provided by [Amazon Web Services(AWS)](https://aws.amazon.com/). It is mainly utilized for gaining operational insights and managing the AWS resources at scale.\n\nThe service mentioned in the text, `[Amazon Elastic Compute Cloud (Amazon EC2)](https://aws.amazon.com/ec2/)` is a web service that provides resizable compute capacity in the cloud. It aims to make web-scale computing easier for developers.\n\nIn the context, by managing `Amazon EC2 instances` with `AWS Systems Manager`, an **inventory of the software platforms and applications within the organization** can be created. This essentially means that you can have a complete list or catalog of all the software platforms and applications which are currently in use within the organization, and are hosted on EC2 instances.\n\nThis catalog will serve as an inventory, allowing for greater transparency, efficient management, and simplified troubleshooting of applications.\n\nThis ability for inventory collection and management serves as a **control** mechanism. Control, in this scenario, refers to the measure that is put in place to check, manage, and maintain the systems in an organization.\n\nSo, through `AWS Systems Manager`, organizations can effectively track and control their software applications and platforms on `Amazon EC2 instances`, ensuring all systems run smoothly and issues are promptly detected and resolved.\n\n---\n\nI hope this detailed explanation gives a clear understanding of the provided text."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control would lead to several potential costs for an organization:\n\n1. **Increased Operational Costs**: Without an inventory, it can lead to underutilized or orphaned resources, leading to unnecessary expenses. By not using AWS Systems Manager to keep track of EC2 instances, an organization may end up paying for resources it doesn't need or use.\n\n2. **Security Risks**: Lack of visibility into software platforms and applications can increase the potential for security risks. Unknown resources can be exploited by malicious parties if not properly managed and secured. In severe cases, breach-related fines and loss of customer trust could be costly.\n\n3. **Increased Maintenance Costs**: Proper tracking of software platforms and applications can help avoid unnecessary duplication and ensure timely software updates. Without it, the organization may face higher costs for software maintenance.\n\n4. **Non-Compliance Penalties**: Depending on the industry and jurisdiction, non-compliant organizations may be subject to regulatory fines and penalties.\n\n5. **Inefficient Resource Allocation**: Without an accurate inventory, it would be challenging to allocate resources effectively and plan capacity accurately, impacting the overall operational efficiency.\n\n```markdown\nOverall, non-compliance to this AWS Control can result in:\n\n- Increased operational costs due to underutilization or orphaned resources\n- Increased security risks leading to potential breaches and penalties\n- Increased software maintenance costs due to unnecessary duplication and missed updates\n- Potential regulatory fines and penalties due to non-compliance\n- Inefficiency in resource allocation and capacity planning\n```"
      ],
      "x-kaytu-usefulness-example": [
        "A potential practical instance of using AWS Control for inventory management can be in the case of a large healthcare organization. \n\nThis organization has hundreds of sensitive data handling applications running across multiple Amazon EC2 instances. They need to regularly monitor and keep track of these applications for keeping them up-to-date and to ensure cybersecurity standards are met. \n\nThrough AWS Systems Manager, they can automate the process of inventory management by organizing all the software platforms and applications. This improves efficiency and security while reducing risks associated with human errors. Additionally, it aids in regulatory compliance, as the organization can easily provide the complete list and status of their software applications when required. \n\nAn example in markup format can be as follows:\n\n````\n{\n   \"AWS Systems Manager\": {\n       \"Inventory\": {\n             \"Applications\": {\n                 \"1\": {\"Name\": \"Patient Data Management\", \"EC2 Instance\": \"Instance 1\", \"Version\": \"2.0\", \"Last Updated\": \"2022-05-25\"},\n                 \"2\": {\"Name\": \"Insurance Claim Processing\", \"EC2 Instance\": \"Instance 2\", \"Version\": \"3.1\", \"Last Updated\": \"2022-06-10\"},\n                 \"3\": {\"Name\": \"Remote Patient Monitoring\", \"EC2 Instance\": \"Instance 3\", \"Version\": \"1.0\", \"Last Updated\": \"2022-04-30\"}\n                           },\n              \"Software Platforms\": {\n                 \"1\": {\"Name\": \"Linux Ubuntu\", \"EC2 Instances\": [\"Instance 2\", \"Instance 3\"], \"Version\": \"18.04\", \"Last Updated\": \"2022-06-15\"},\n                 \"2\": {\"Name\": \"Windows Server\", \"EC2 Instances\": [\"Instance 1\"], \"Version\":\"2019\", \"Last Updated\": \"2022-05-20\"}\n            }\n       }\n   }\n}\n````\n\nThis markup representation provides a quick look into the state of software platforms and applications, their versions and last update time."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_policy_no_star_star",
    "Title": "IAM policy should not have statements with admin access",
    "Description": "AWS Identity and Access Management (IAM) can help you incorporate the principles of least privilege and separation of duties with access permissions and authorizations, restricting policies from containing 'Effect': 'Allow' with 'Action': '*' over 'Resource': '*'.",
    "QueryID": "aws_iam_policy_custom_no_star_star",
    "DocumentURI": "policies/aws_iam_policy_no_star_star.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "The AWS Identity and Access Management (IAM) is a web service that helps AWS customers securely control access to AWS services and resources. It encompasses various aspects of managing security including user identity, roles, policy definitions etc.\n\nOne crucial security principle that IAM helps to enforce is **\"least privilege\"** and **\"separation of duties\"**. The principle of least privilege ensures a user must be able to access only the information and resources necessary for its legitimate purpose. Separation of duties is a key concept of internal controls whereby duties are divided, or segregated, among different people to reduce the risk of error or inappropriate actions.\n\nIAM achieves this by carefully managing and structuring access permissions and authorizations. For instance, IAM strongly advises against implementing too permissive policies like those with:\n\n```markdown\n'Effect': 'Allow'\n'Action': '*'\n'Resource': '*'\n```\n\nThis combination essentially means that a user is allowed (`'Effect': 'Allow'`) to perform any action (`'Action': '*'`) on any resource (`'Resource': '*'`).\n\nThis is typically not recommended as it progressively violates the principles of least privilege and separation of duties, and can pose a serious security risk. Instead, IAM recommends creating specific policies that restrict access to the minimum level necessary for users to perform their jobs."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control can potentially lead to serious financial, operational, and reputational implications.\n\n1. **Sizable Monetary Fines**: Regulatory bodies may impose hefty financial penalties for non-compliance with prescribed security guidelines and protocols.\n\n2. **Data Breaches**: Allowing unrestricted access to your cloud resources increases the risk of data breaches. This could lead to the exposure of sensitive and confidential data which could cause substantial financial loss. \n\n3. **Operational Disruption**: Non-compliance could lead to serious disruptions in your operational processes. Unrestricted access can cause unwarranted modification or deletion of critical data, affecting your operational continuity.\n\n4. **Loss of Customer Trust**: Data breaches often result in the damage of customer trust, which could be devastating to your business reputation. This can lead to customer attrition and lost business opportunities.\n\n5. **Legal Litigation**: Non-compliance could lead to legal action by affected clients or regulatory bodies, resulting in potential serious legal repercussions.\n\nBy applying the principle of least privilege, IAM ensures that every user is given the minimum levels of access necessary to perform their functions. This significantly minimizes the risk of unauthorized access and data breaches. It is a best practice to restrict 'Effect': 'Allow' with 'Action': '*' over 'Resource': '*' which effectively restricts complete access to all resources."
      ],
      "x-kaytu-usefulness-example": [
        "```markdown\nExample Instance:\n\nConsider an organization named ABC Corp which uses AWS services for its business operations. ABC Corp has hired data analysts, developers, and system administrators, each having different roles and responsibilities. \n\n- The developers may need access to instances for deploying codes and updating existing systems.\n- The system administrators may require permission to manage systems including launching, terminating and rebooting instances.\n- Data analysts may need read-only access to certain database instances for analytics and reporting purposes.\n\nBy utilizing AWS IAM, ABC Corp can design and assign custom access policies to each user or role based on their job functions, following the principle of least privilege. For example, the developers won't be able to terminate instances, and data analysts won't be able to modify databases. Additionally, company-wide operations like billing can be restricted to only certain users to strengthen the principle of separation of duties. \n\nAWS IAM also discourages the use of blanket permissions such as 'Effect': 'Allow' with 'Action': '*' over 'Resource': '*', which essentially gives a user full control over all resources. Instead, permissions can and should be granular, targeting specific needs of each role. This measure enhances the organization's ability to prevent unauthorized access, thereby increasing security in the AWS Environment.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudtrail_trail_enabled",
    "Title": "At least one enabled trail should be present in a region",
    "Description": "AWS CloudTrail can help in non-repudiation by recording AWS Management Console actions and API calls. You can identify the users and AWS accounts that called an AWS service, the source IP address where the calls generated, and the timings of the calls. Details of captured data are seen within AWS CloudTrail Record Contents.",
    "QueryID": "aws_cloudtrail_trail_enabled",
    "DocumentURI": "policies/aws_cloudtrail_trail_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/CloudTrail"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS CloudTrail for Non-Repudiation \n\n[AWS CloudTrail](https://aws.amazon.com/cloudtrail/) is an AWS service that helps organizations improve their non-repudiation by recording all activities and actions within the AWS Management Console and AWS API calls. \n\n## How it Works \n\nIt works by identifying and recording details about the users and AWS accounts that interact with an AWS service including:\n\n- The user or AWS account that made the call\n- The IP address from where the call was made\n- The timings of the call\n\nThese recordings are then categorized into records which are stored in log files available in AWS CloudTrail. \n\n## AWS CloudTrail Record Contents\n\nInside the [AWS CloudTrail Record Contents](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-record-contents.html), one can dive deeper into the captured data. For example, an event record within the record contents provides information about the source of the call such as event name, event ID and even the resources that were affected by the call. \n\nBy providing these detailed records, non-repudiation is improved since every action is attributable to an authenticated and uniquely identifiable source. \n\n```\nNote: Non-repudiation is a way to guarantee that the sender of a message cannot later deny having sent the message and that the recipient cannot deny having received the message.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS CloudTrail control can result in several costs:\n\n1. **Security Risk**: Without CloudTrail, an organization significantly reduces its ability to track user activity and detect unauthorized activity within their AWS environment. This increases the risk of a data breach or unauthorized access to sensitive data.\n\n2. **Forensic Investigation Difficulty**: In the event of a security breach, not having logs from CloudTrail can make it significantly more difficult for investigators to ascertain what actions were carried out, by whom, and when. This lack of visibility can also impede the ability to accurately determine the impact and scope of the breach.\n\n3. **Regulatory Compliance Fines**: Many industry standards and regulations such as GDPR, HIPAA, PCI DSS, and ISO 27001 require comprehensive logging of user activity within the IT environment. Non-compliance with these logging requirements can result in fines, penalties, and other regulatory actions.\n\n4. **Operational Inefficiency**: Without CloudTrail, organizations lose crucial visibility into their AWS environment, which can lead to operational inefficiency. It may become difficult for administrators to troubleshoot system issues, optimize performance, or make informed decisions about system changes.\n\n5. **Financial Losses**: The combination of potential fines, damage from a security breach, loss of customer trust, inefficiencies, and potential extended downtimes can all contribute to significant financial losses for an organization.\n\n```markdown\n- **Security Risk**: Increased vulnerability to data breaches or unauthorized access due to lack of visibility into user activities within AWS environment.\n- **Forensic Investigation Difficulty**: Hindered ability to investigate and assess the impact of a security breach due to lack of user activity logs.\n- **Regulatory Compliance Fines**: Potential fines and penalties due to non-compliance with industry regulations requiring comprehensive logging.\n- **Operational Inefficiency**: Possible operational challenges due to lack of crucial visibility for troubleshooting, performance optimization, or informed decision-making.\n- **Financial Losses**: A combination of potential fines, security breach damage, loss of customer trust, inefficiencies, and potential extended downtimes can result in significant financial losses.\n```\n"
      ],
      "x-kaytu-usefulness-example": [
        "Example Instance:\n\nIn one instance, a medium-scale company was facing unauthorized access to their AWS services despite security measures in place. They were unable to pinpoint the source of breach due multiple users and teams managing the AWS accounts.\n\nTo address this issue, the company used AWS CloudTrail. This tool allowed them to log and monitor all actions taken through their AWS Management Console, SDKs, command line tools and other AWS services. This means that all API calls made by users, user roles, or AWS services themselves were recorded.\n\nEvery log delivered by CloudTrail showed the identity of the API caller, the time of the call, the source IP address of the caller, the request parameters, and the response elements returned by the AWS service. With this data, they were able to monitor their AWS account activity and troubleshoot security or operational issues. \n\nBy examining these logs, they identified the source of the unauthorized access to their AWS services - it was an old credential from an ex-employee who was still able to access certain services due to a misconfiguration in user rights management.\n\nWithout AWS CloudTrail, identifying such a breach and its source would have been very difficult due to the magnitude of users and operations managed on AWS. This incidence highlights the importance of AWS CloudTrail in ensuring accountability, enhancing security and facilitating incident response in cloud environments."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_kms_cmk_rotation_enabled",
    "Title": "KMS CMK rotation should be enabled",
    "Description": "Enable key rotation to ensure that keys are rotated once they have reached the end of their crypto period.",
    "QueryID": "aws_kms_cmk_rotation_enabled",
    "DocumentURI": "policies/aws_kms_cmk_rotation_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/KMS"
      ],
      "x-kaytu-explanation": [
        "AWS has a feature that allows you to rotate the keys used for encryption. Key rotation is a good way to improve security because it ensures that each key is only used for a specific period of time, or crypto period. After a key has reached the end of its crypto period, it should be rotated—that is, it should be replaced with a new key. \n\nThis can be enabled as per the below markup script:\n\n```Markup\naws kms create-key --description \"Key with automatic key rotation\"\naws kms get-key-rotation-status --key-id 1234abcd-12ab-34cd-56ef-1234567890ab\naws kms enable-key-rotation --key-id 1234abcd-12ab-34cd-56ef-1234567890ab\naws kms get-key-rotation-status --key-id 1234abcd-12ab-34cd-56ef-1234567890ab\n```\nThe first command creates a new customer master key (CMK). \n\nThe second command gets the key rotation status for the specified CMK; by default, AWS KMS keys are created with key rotation disabled.\n\nThe third command enables automatic yearly rotation of the key material for the specified CMK. \n\nThe fourth command confirms that key rotation was successfully enabled.\n\nEnabling this feature helps to prevent a potential attacker from accessing your encrypted data by gaining access to a single key. It provides a layer of security that helps protect your data even if a key is compromised."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control can have significant business, financial, and reputational impacts.\n\n1. **Security Breach Cost:** If key rotation is not enabled, it increases the likelihood of a security breach. Cyber attackers may get enough time to break a key. Once they have access, they can steal sensitive information, modify data or even take down services.\n\n2. **Financial Impact:** The financial cost of data breaches can be huge. It includes the direct cost of investigation and remediation, possible fines for non-compliance to regulations, and potential lawsuits. If services are taken down, it could also lead to loss of business and revenue.\n\n3. **Reputation Damage:** A data breach can seriously affect a company's reputation. It can result in lost trust among clients, users and partners, and can adversely impact future business prospects.\n\n4. **Regulatory Fines:** Many regulatory bodies require regular key rotation for compliance. Not enabling key rotation can lead to failure to meet these standards, resulting in large fines and penalties.\n\nThus, non-compliance to the AWS control of enabling key rotation could lead to serious consequences, including security breaches, leaks of sensitive data, substantial financial loss, and damage to your business reputation and customer trust."
      ],
      "x-kaytu-usefulness-example": [
        "Key rotation is an important aspect of key management best practices. It helps to protect data over time and meets the security requirements of the application. Here is an instance where key rotation could prove useful.\n\nYou are running an e-commerce platform with millions of users registered. Each user has a password which is stored in a secured, encrypted format in a database. For this, you are using AWS Key Management Service (AWS KMS) as it provides a highly available key storage, management, and auditing solution. \n\nYou have a specific customer master key (CMK) used for encrypting the passwords. However, if the key is compromised once, all the user passwords would also be compromised. Also, the longer the keys are in use, the higher the risk of them being broken by brute force attacks.\n\nTo minimize these risks, you enable the key rotation feature in AWS KMS. This control ensures that a new cryptographic material is created for the CMK every year. The older versions of the key will still be available to decrypt the previously encrypted data, but all new encryptions will be done using new keys. \n\nThis key rotation feature provided by AWS plays a crucial role in reducing the potential hazards related to the encryption key being compromised.\n\nHere is an example of how to enable key rotation in AWS KMS in markup format:\n\n```xml\nAWSKMS client = AWSKMSClientBuilder.standard().build();\n \nEnableKeyRotationRequest request = new EnableKeyRotationRequest().withKeyId(\"\u003cYour Key ID\u003e\");\n\nclient.enableKeyRotation(request);\n\n```\n\nIn this example, you replace `\u003cYour Key ID\u003e` with the ID of the key that you want to enforce rotation.\n \nThis piece of code will ensure that your specified key in AWS KMS service is rotated once it has reached the end of its crypto period, improving the overall security of your sensitive data.\n  \nPlease note, AWS Managed keys enabled for rotation by default and for CMK key rotation is manual."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_logging_enabled",
    "Title": "S3 bucket logging should be enabled",
    "Description": "Amazon Simple Storage Service (Amazon S3) server access logging provides a method to monitor the network for potential cybersecurity events.",
    "QueryID": "aws_s3_bucket_logging_enabled",
    "DocumentURI": "policies/aws_s3_bucket_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon Simple Storage Service (S3) Server Access Logging is a facility that gives you the ability to track and record all requests made to your S3 bucket. This capability is crucial for auditing, security review, and monitoring purposes and can greatly aid in the identification of potential cybersecurity threats and breaches.\n\nAmazon S3 captures all request information, including requesting IP addresses, access times, requestor's ID, and request actions (like `GET` and `PUT`), and stores them in a server access log, which is then stored in your specified target S3 bucket.\n\nBelow is a markup format of AWS S3 Server Access Logging:\n\n```markdown\n\n## Amazon Simple Storage Service (S3) Server Access Logging\n\nAmazon S3 server access logging provides detailed records for the requests made to your S3 bucket. It is a crucial tool for monitoring and improve security of your AWS S3 buckets.\n\n### Key Features:\n\n- **Audit Trail**: Records all request information to your S3 bucket, allowing for tracking and auditing.\n- **Security Monitoring**: Helps in identifying and monitoring potential cybersecurity threats and breaches.\n- **Compliance Assistance**: Assists in maintaining regulatory compliance and standards adherence.\n- **Storage**: All server access logs are stored in a specified S3 bucket.\n\n### How to enable S3 Server Access Logging\n\n1. Navigate to the AWS management console.\n2. Open `Amazon S3` console.\n3. Choose the bucket for which you want to enable server access logging.\n4. Choose `Properties`.\n5. In the `Server access logging` section, choose `Enable`.\n6. In the `Target bucket` section, enter the name of the target bucket where you want Amazon S3 to save the access logs.\n\nAfter this setup, each access to the bucket will generate an access log record and save it in the target bucket.\n\n```\n\nThis logging feature enhances the overall security power of your storage infrastructure, enabling better control and transparency over your Amazon S3 resources."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with the AWS control which recommends the use of Amazon Simple Storage Service (Amazon S3) server access logging could possibly incur the following costs:\n\n1. **Security threats**: Without proper access logging, one could miss potential security events, leading to breaches. Depending on the breach's severity, it could cost the company a significant amount of money in damage control, regulatory fines, and customer loss.\n\n2. **Regulatory fines**: For certain industries (like healthcare or finance), compliance to regulations like GDPR, HIPAA etc., is mandatory. These regulations require adequate security measures to be in place, one of which is access logging. Not having these logs could result in hefty fines and penalties for non-compliance.\n\n3. **Forensic costs**: In case of an incident, access logs are crucial for analyzing what happened, when it occurred, and who was involved. If logs weren't maintained, the cost of forensic investigations will be significantly higher, as alternate, more resource-intensive ways would have to be employed for conducting the analysis.\n\n4. **Loss of reputation**: In the event of a security breach, if a company is found to have not adequately activated necessary controls like access logging, its reputation could be severely hit leading to loss of customers and revenue.\n\n5. **Troubleshooting and problem-solving**: Access logs aid in troubleshooting, performance tuning, and problem-solving activities by providing useful clues. Without these, the time and resources spent in issue resolution can increase, thereby increasing operational costs. \n\n6. **Loss of customer trust**: Failure to comply with security protocols can lead to loss of customer trust and decrease in customer satisfaction which can eventually lead to loss in business and revenue. \n\n7. **Legal consequences**: In event of a breach or data loss, without proper logging and monitoring, a company can face legal consequences which can result in financial losses. \n\nThese are just potential costs and the actual cost may vary based on the scale, severity and industry in which the business operates."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a financial firm dealing with highly sensitive data can utilize Amazon S3 server access logging to monitor and record all requests made to their S3 bucket. If there's an unusual spike in access requests or data retrieval from an unknown IP address, the access log will capture this information. These increase in requests can be an indication of a potential cyber threat or attack, such as a DDoS attack or data breach attempt. \n\nWith this log data, the firm's cybersecurity team can analyze and trace the source of these suspicious activities, helping them counteract the cyberattack proactively and effectively. It's worth noting that access logs can also provide useful information for routine auditing, usage monitoring, and regulatory compliance for the firm."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_root_user_mfa_enabled",
    "Title": "IAM root user MFA should be enabled",
    "Description": "Manage access to resources in the AWS Cloud by ensuring MFA is enabled for the root user.",
    "QueryID": "aws_iam_root_user_mfa_enabled",
    "DocumentURI": "policies/aws_iam_root_user_mfa_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# Manage Access to AWS Cloud Resources\n\nIt is essential to ensure that Multi-Factor Authentication (MFA) is enabled for the root user to manage access to resources in the AWS Cloud. The following steps will guide you to set this up.\n\n## AWS Root User MFA Setup\n\n1. **Sign in** to the AWS Management Console as the root user.\n\n2. Navigate to your account name in the navigation bar, and choose **Security Credentials**.\n\n3. In the Multi-Factor Authentication (MFA) section, choose to **Activate MFA**.\n\n4. Click on **Activate MFA**.\n\n5. In the Manage MFA device wizard, choose **A virtual MFA device**, then choose **Next Step**.\n\n6. Open your MFA app, choose to manually add an account, and then enter the secret configuration key displayed on the screen.\n\n7. In the **Authentication Code 1** box, type the one-time password that currently appears in the virtual MFA app.\n\n8. Wait up to 30 seconds for the next password to appear in the app, and then type it in the **Authentication Code 2** box, then choose **Activate Virtual MFA**.\n\n9. The status for the MFA device changes to **Activated**. Choose **Finish**.\n\n---\n\nBy enabling MFA for the root user, you add an extra layer of security that makes it more difficult for unauthorized individuals to access your AWS resources. Always remember not to share your MFA codes with anyone."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control of managing access to resources can have significant financial, operational, and reputational consequences. \n\n1. **Data Breaches**: If Multi-Factor Authentication (MFA) is not enabled for the root user, then there is a heightened risk of unauthorized access, which can lead to data breaches. The costs associated with data breaches can be enormous, including penalties by regulating organizations, legal fees, and compensation for the affected parties.\n\n2. **Loss of Trust**: Data breach caused by lack of adequate access control in the form of MFA could lead to a significant loss of customer trust and confidence which can affect the business reputation and potential future earnings.\n\n3. **Operational Disruption**: In case of unauthorized access, the operations might be disrupted which can cause significant operational cost and loss of business continuity.\n\n4. **Noncompliance Penalties**: AWS requires MFA for root users as part of its security best practices. Noncompliance could lead to penalties from AWS, including the potential suspension of services.\n\n5. **Remediation Costs**: Additional cost in terms of financial and human resources will be required to correct the non-compliance issue, perform a security audit, and ensure safeguards are in place to prevent future similar instances.\n\n6. **Violation of Regulatory Requirements**: Depending on the industry and the type of data handled, noncompliance with this control could lead to violation of regulatory requirements, such as GDPR, HIPAA, etc., which can result in hefty fines and penalties. \n\nIn sum, non-compliance with this AWS Control can result in substantial costs and potentially severe damage to a company's reputation and operations. Therefore, ensuring MFA is enabled for the root user is crucial to secure resources in the AWS Cloud."
      ],
      "x-kaytu-usefulness-example": [
        "Example:\n\nA software development company has multiple developers and other staff who regularly access various resources within the AWS Cloud. One day, the company falls victim to a phishing attack that compromises the login credentials of the root user, putting the sensitive data stored on their AWS Cloud at risk. \n\nBy having Multi-Factor Authentication (MFA) enabled for the root user, an additional layer of security is added. Simply knowing the username and password is not enough for someone to gain access to the account. They would also need to have the MFA device, which is typically a mobile device in possession of the root user.\n\nTherefore, even in the case of this phishing attack, the bad actors could not access the AWS Cloud resources, as they didn't have the MFA device to validate the second factor of authentication. All sensitive data remains secure until the company can re-secure their account, demonstrating the usefulness of enabling MFA for the root user on AWS Cloud."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ebs_volume_in_backup_plan",
    "Title": "EBS volumes should be in a backup plan",
    "Description": "To help with data back-up processes, ensure your Amazon Elastic Block Store (Amazon EBS) volumes are a part of an AWS Backup plan.",
    "QueryID": "aws_ebs_volume_in_backup_plan",
    "DocumentURI": "policies/aws_ebs_volume_in_backup_plan.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EBS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon Elastic Block Store (EBS) offers persistent block-level storage volumes for use with Amazon EC2 instances. In the cloud environment, data backups are crucial for protecting data and ensuring disaster recovery. AWS Backup service offers a centralized way to back up your data across AWS services in the cloud. Therefore, to enhance your data’s safety, it is recommended to ensure that your EBS volumes are part of an AWS Backup plan.\n\n```markdown\n# AWS Control: Amazon EBS Included in AWS Backup Plan\n\n## Overview\n\nData backup is a crucial function in any IT operation. This principle applies in the context of AWS, where **Amazon Elastic Block Store (EBS)** serves as a persistent block storage service when working with Amazon EC2 instances in the cloud. To improve the safety and continuity of data, your **EBS volumes should be included as part of an AWS Backup plan**.\n\n## What is AWS Backup?\n\n**AWS Backup** is Amazon's centralized backup service, designed to simplify the process of backing up multiple AWS services. The primary aim is to achieve cost-effectiveness, ease of use, and policy enforcement to manage data protection at scale.\n\n## Why Include EBS in an AWS Backup Plan?\n\nIncluding your EBS volumes in an AWS Backup plan provides the following benefits:\n\n- **Simplifies Backup Process:** Managing all your backups from AWS services at a single place enhances ease of use.\n\n- **Improves Disaster Recovery:** In any catastrophic event, the backed up EBS volumes can be easily utilized to recover data, ensuring business continuity.\n\n- **Automates Backups:** AWS Backup can automate backup operations, relieving you from setting up your own backup scripts, and improving efficiency.\n\nThus, AWS's best practice suggests incorporating **EBS volumes in an AWS Backup plan** to safeguard your valuable data effectively.\n```\nEnsure that you are complying with your organization's backup and retention policies when setting up your backups. AWS provides multiple options to automate and schedule these backups, but the specifics can vary based on individual business needs."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control can be significant. It can be explained as follows: \n\n1. **Data Loss**: If your Amazon Elastic Block Store (Amazon EBS) volumes are not a part of an AWS Backup plan, you risk losing your data in the event of accidental deletion, malicious activity, or a system malfunction. \n\n2. **Business Continuity**: If you lose your data, it could severely impact your business operations, resulting in downtime and loss of revenue.\n\n3. **Recovery Costs**: Trying to recover lost data can be a time-consuming and expensive process. Depending on the complexity and extent of the data loss, recovery may even be impossible.\n\n4. **Regulatory Compliance**: If your business is in an industry that requires strict data compliance (like finance or healthcare), you may face hefty fines and penalties from regulatory bodies for not adhering to data backup standards.\n\n5. **Reputation Damage**: Conducting business without a robust backup plan in place risks damaging your relationship with stakeholders, which can negatively impact your business’s reputation, image, and future prospects. \n\nTherefore, it is crucial to ensure your Amazon EBS volumes are a part of an AWS Backup plan to avoid potential financial loss, reputational damage, legal penalties, and interruptions to business operations."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, consider a fintech company that manages financial transactions and needs to handle sensitive data of their customers. They operate on AWS cloud platform and have a significant amount of data stored in Amazon EBS volumes. \n\nIn an unfortunate event of a system failure or data breach, they could risk losing all their crucial data, severely impacting their business operations as well as customer trust. In such situations, having their EBS volumes backed up as part of an AWS Backup plan proves to be extremely useful. This way, even if they lose data from their EBS volumes due to any unforeseen circumstances, they can recover the data from their backups. Not only it ensures business continuity, but it also complies with data regulation requirements and best practices. \n\nExample:\n\n```markdown\nA premier fintech company 'FinSecure' uses AWS to host their application and manage financial transactions on a daily basis. They have all their critical data stored in Amazon EBS volumes. To protect this data, they created an AWS Backup plan that regularly backs up their EBS volumes. This setup has been incredibly useful to them on several occasions:\n\n- System Malfunction: Due to a rare system glitch, one of their primary EBS volumes got corrupted. However, they managed to quickly restore the lost data from their backup, avoiding long hours of downtime.\n\n- Security Breach: They endured an advanced persistent threat (APT) where attackers managed to delete some key data. Thanks to the AWS Backup, they restored the deleted data and nullified the impact of the attack.\n\n- Regular Audits: As part of financial regulations, they have to comply with periodic data audits. Using the AWS Backup, they are assured that all data is stored securely and can be retrieved whenever required.\n```\n"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_instance_ebs_optimized",
    "Title": "EC2 instance should have EBS optimization enabled",
    "Description": "An optimized instance in Amazon Elastic Block Store (Amazon EBS) provides additional, dedicated capacity for Amazon EBS I/O operations.",
    "QueryID": "aws_ec2_instance_ebs_optimized",
    "DocumentURI": "policies/aws_ec2_instance_ebs_optimized.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EC2"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon Elastic Block Store (EBS) allows you to create block level storage volumes that are used with Amazon EC2 instances. Instance optimization refers to configuring or choosing your EC2 instances to make the best use of resources for your specific needs. An optimized instance provides additional, dedicated capacity for Amazon EBS I/O operations. This means that the instance is designed to provide better, dedicated throughput for dealing with input/output operations with EBS volumes.\n\nThis results in improved performance for EBS volumes as there is more resources available for I/O operations. This is particularly beneficial for applications that require high I/O workloads.\n\nIn markup format, it might look something like this:\n\n```markdown\n# Amazon EBS Optimized Instances\n\nAmazon Elastic Block Store (EBS) offers the ability to create block level storage volumes that can be used in conjunction with Amazon EC2 instances. \n\n## What is Instance Optimization?\nInstance optimization refers to the process of configuring or choosing your EC2 instances to make the most efficient use of resources according to your specific needs.\n\n## Benefits of Optimized Instances\nAn optimized instance provides additional, dedicated capacity for Amazon EBS I/O operations. This results in improved performance for EBS volumes since there are more resources devoted for I/O operations. This can be particularly beneficial for applications requiring high volume I/O workloads.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with the AWS control related to usage of optimized instances in Amazon Elastic Block Store (Amazon EBS) may lead to several costs or implications:\n\n1. **Performance Impact:** Non-optimized instances may lead to congested networking with an inability to effectively provide the necessary bandwidth for EBS I/O operations. It can diminish your application's performance regardless of the EBS volume type.\n\n2. **Increased Costs:** If your Amazon EC2 instance isn't EBS-optimized and you're trying to maximize the I/O to your EBS volumes, you might end up using a larger or more expensive EC2 instance than necessary. \n\n3. **Data Transfer Limitations:** EBS-optimized instances deliver dedicated bandwidth between Amazon EC2 and Amazon EBS, reducing competition between Amazon EBS I/O and other traffic from your Amazon EC2 instance.\n\n4. **Security issues:** EBS Optimized instances offer separate network capacity for volume IO which makes them satisfactorily immune to network attacks or traffic flooding. This can affect confidentiality, integrity and availability of the data residing on your EBS volumes.\n\n5. **Compliance Risks:** If you are dealing with sensitive data and require to adhere to standards like HIPAA or GDPR, any performance degradation or data security vulnerabilities might lead to non-compliance, therefore leading to potential fines or sanctions.\n\nEach of these factors represent a potential cost to the business, either directly (e.g. financial) or indirectly (e.g. user experience, reputation). It is therefore recommended to make use of EBS-optimized instances for critical applications with high I/O requirements."
      ],
      "x-kaytu-usefulness-example": [
        "A useful example of the application of optimized instances in Amazon Elastic Block Store (EBS) would be in high-demand applications such as a large ecommerce site.\n\nConsider a scenario where a big e-commerce company is deploying an extensive database for its inventory management which sustains high traffic throughout the day. Using a regular EC2 instance might result in inconsistent performance due to variability in I/O operations. \n\nBy leveraging an EBS-optimized instance, the company can ensure that they have dedicated I/O operations for their Amazon EBS volume, separate from other traffic on the EC2 instance. This can significantly improve the overall throughput of the system and ensure smooth and consistent performance, handling customer requests more efficiently without any delay or lag. \n\nAn EBS-optimized instance can therefore greatly improve the user experience on the platform by reducing their waiting times and ensuring they can process their orders quickly and smoothly.\n\n```\nExample:\n\n- Operate an e-commerce platform with high traffic volumes\n- Deploy the company's database on Amazon EBS\n- Use an EBS-optimized instance to ensure dedicated I/O capacity for the database\n- Improve overall performance and user experience on the platform\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_stopped_instance_30_days",
    "Title": "EC2 stopped instances should be removed in 30 days",
    "Description": "Enable this rule to help with the baseline configuration of Amazon Elastic Compute Cloud (Amazon EC2) instances by checking whether Amazon EC2 instances have been stopped for more than the allowed number of days, according to your organization's standards.",
    "QueryID": "aws_ec2_stopped_instance_30_days",
    "DocumentURI": "policies/aws_ec2_stopped_instance_30_days.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EC2"
      ],
      "x-kaytu-explanation": [
        "This rule is designed to assist with the standard configuration of Amazon Elastic Compute Cloud (EC2) instances by checking the duration for which these instances have been stopped. If an Amazon EC2 instance has been halted for more than the permitted number of days as per your organization's standards, the rule will spotlight that.\n\nHere is the code in markup format:\n\n```markdown\n# AWS Control: EC2 Instance Stopped Duration\n\nEnable this control rule if you need to ensure your Amazon Elastic Compute Cloud (EC2) instances are not stopped for extended periods.\n\nThis rule checks if any Amazon EC2 instances have been stopped for more days than your organization's standard allows. This is useful in maintaining baseline configurations for your EC2 instances.\n\nYour AWS governance policies may dictate specific run-time standards for your EC2 instances, and this control helps ensure those standards are met by identifying instances that have been stopped for longer than allowable days.\n\n**To enable this rule:**\n\n1. Access your AWS Management Console \n2. Navigate to the desired EC2 instance\n3. Input the number of allowable stopped days for your organization.\n4. Save and apply settings.\n\nTake note, you will receive alerts or notifications whenever this rule identifies any non-compliant resources. \n```\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS (Amazon Web Services) rule can come with several potential costs:\n\n1. **Operational Efficiency Costs**: If instances are left running for longer than necessary, it can lead to resource wastage, incurring unnecessary costs. By enabling this rule, one can keep track of lingering, unused instances and shut them down accordingly which promotes operational efficiency by reducing wastage.\n\n2. **Financial Costs**: AWS EC2 instances are billed for the time they are running. If an EC2 instance is stopped, you aren't billed for instance usage, although you are still billed for any attached EBS volumes. If EC2 instances are left running for more than the allowed days, the costs can accumulate over time and lead to high bills.\n\n3. **Security Costs**: Any running instance is a potential target for cyber threats. If instances are left running unconsciously, they might create a security loophole and become a target. If security breaches happen, it would lead to hefty penalties, reputation damage, and potential loss of sensitive data.\n\n4. **Regulatory Costs**: For industries or organizations that need to meet certain compliance standards, not following AWS rules could potentially lead to non-compliance penalties or loss of certifications, which could expose the organization to legal, financial, and reputational risks.\n\nIn summary, the cost of non-compliance to this AWS control can manifest in the above forms, emphasizing why it's crucial to enable and comply with the rules to manage EC2 instances."
      ],
      "x-kaytu-usefulness-example": [
        "As a SysOps administrator managing an organization's AWS resources, you may find yourself encountering high operational costs due to underutilized or unnecessary EC2 instances. \n\nAn example where this rule would be particularly useful is for non-production/pre-production environment where EC2 instances are commonly used for testing, staging or development purposes but are often left running when they are not needed. \n\n```markdown\nExample:\n\nConsider a scenario where your organization policy states that any EC2 instance that hasn't been used for more than 21 days should be considered for termination to conserve operational costs. \n\n1. You enable this rule to monitor your EC2 instances and set the allowed number of days to 21. \n2. After enabling this rule, the system begins to check the running times of all EC2 instances.\n3. After a period of observation, the rule identifies an instance 'test-server-001' that hasn't been used for 22 days. \n4. You receive a notification regarding instance 'test-server-001'.\n5. Based on this alert, you can review 'test-server-001' and decide to stop or terminate it, saving unnecessary costs.\n\nThis way, this AWS control rule helps to enforce your organization's standards, leading to more efficient resource usage and cost savings.\n```\n\nBy proactively tracking and alerting for EC2 instances that have been stopped for more than the allowed days, you are able to manage and optimize costs effectively."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_versioning_enabled",
    "Title": "S3 bucket versioning should be enabled",
    "Description": "Amazon Simple Storage Service (Amazon S3) bucket versioning helps keep multiple variants of an object in the same Amazon S3 bucket.",
    "QueryID": "aws_s3_bucket_versioning_enabled",
    "DocumentURI": "policies/aws_s3_bucket_versioning_enabled.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Bucket versioning is a feature provided by Amazon Simple Storage Service (Amazon S3) that allows you to keep multiple versions of an object in the same bucket. \n\nBy default, when you add an object to a bucket, the new obejct overwrites the existing one. However, if you enable versioning in your bucket, Amazon S3 automatically generates a unique version ID for the object. So, instead of overwriting, it creates a new version of the object.\n\nFor example:\n\n```markdown\n- When you upload a new version of an object, Amazon S3 assigns it a new version ID.\n- When you delete an object, S3 inserts a delete marker, which becomes the current object version. \n- If you delete a specific object version, it does not insert a delete marker. Instead, S3 permanently deletes that object version.\n- You can also use versioning to restore previous versions of an object.\n```\n\nOverall, versioning allows you to preserve, retrieve, and restore every version of every object in your Amazon S3 bucket, which makes it easier to recover from both unintended user actions and application failures."
      ],
      "x-kaytu-noncompliance-cost": [
        "Failure to comply with Amazon S3 bucket versioning could have potential financial, operational and reputational costs:\n\n1. **Data loss**: Not enabling versioning can lead to permanent data loss. If a file is deleted or overwritten without versioning, the old version can't be recovered. The cost of this can be significant if the data is crucial for business operations or customer services.\n\n2. **Financial Cost**: In the scenario where data is lost due to overwriting or deletion, you may spend significant resources to recover the data, or even worse, if not retrievable, recreate it. This could potentially lead to high unexpected costs.\n\n3. **Operational hitches**: If data is lost and can't be recovered quickly, this may disrupt operations leading to downtimes, decreased productivity, or customer services interruption.\n\n4. **Compliance and auditing issues**: For certain industries, keeping past versions of data might be a legal requirement for audit trails. Non-compliance may result in legal penalties or sanctions.\n\n5. **Reputation Damage**: Data loss, legal penalties, and operational hitches all contribute to damaging a company's reputation. This could potentially lead to loss of business and trust amongst customers, clients, or stakeholders.\n\n6. **Security implications**: Versioning also provides protection against malicious or accidental deletions or modifications. In lack of versioning, an attack or accidental deletion may result in a compromise of data integrity and possible security breaches."
      ],
      "x-kaytu-usefulness-example": [
        "Imagine you're working in a data-driven organization with a paramount need for proper file version management. Your team is constantly uploading files, updating existing files, and deleting irrelevant ones. In such a scenario, Amazon S3 bucket versioning can prove to be extremely useful.\n\nLet’s suppose your team accidentally deletes a critical data file or overrides it unknowingly. The consequences could be disastrous as it can cause a significant loss of valuable data or important business insights. \n\nWith Amazon S3 bucket versioning enabled, you'll have access to all versions of an object (file). This means, even if a team member accidentally deletes or overrides a file, you can still retrieve an older version. This not only ensures the safety of key data but also eliminates any potential downtime that could occur due to data loss. It thus brings about a secure and robust environment for collaborative work while mitigating the risks associated with human errors. \n\nSo, this shows how Amazon S3 bucket versioning can be useful in real-world scenarios. Its ability to keep multiple versions of a file provides a strong line of defense against both unintended user actions and application failures, making it a valuable feature for any business dealing with important data stored in AWS."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_wafv2_web_acl_logging_enabled",
    "Title": "Logging should be enabled on AWS WAFv2 regional and global web access control list (ACLs)",
    "Description": "To help with logging and monitoring within your environment, enable AWS WAF (V2) logging on regional and global web ACLs.",
    "QueryID": "aws_wafv2_web_acl_logging_enabled",
    "DocumentURI": "policies/aws_wafv2_web_acl_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/WAFv2"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS WAF (Web Application Firewall) is a service that helps protect your web applications from common web exploits. Logging is an important feature for monitoring and identifying security threats, as well as understanding the types of requests that are being processed by your application.\n\nEnabling AWS WAF (V2) logging on regional and global web ACLs (Access Control Lists) means that logs will be generated for these regions, giving insight into allowed and blocked requests. These logs can be used to analyze the habits of your users, identify and mitigate potential threats, and troubleshoot issues.\n\nHere's how you can describe this control in markup format (markdown):\n\n---\n\n# Enable AWS WAF (V2) Logging on Regional and Global Web ACLs\n\nFor effective logging and monitoring, it's advised to enable AWS WAF (V2) logging on both your regional and global web ACLs. This will generate logs for all processed requests, providing crucial information for security analysis, threat mitigation, and issue troubleshooting.\n\nTo enable logging, follow these steps:\n\n1. **Navigate to AWS WAF console:** Here, you'll see your regional and global web ACLs.\n2. **Select a web ACL:** Choose the ACL you want to enable logging for.\n3. **Enable Logging:** In the settings or properties for the selected ACL, look for 'logging' or similar, then enable it.\n\n*Note: The generated logs can be stored in your preferred storage system for later analysis and can also be used in real-time by other AWS services for immediate threat response.*\n\n---\n\nRemember, logging also consumes storage and may incur costs, so ensure to enable it for ACLs that handle important and sensitive data.\n\nWhen using AWS, always refer to the official documentation for accurate and detailed instructions. Markdown version of AWS documentation is not available, you need to manually convert or use third-party tools."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS (Amazon Web Services) control, particularly the enabling of AWS WAF (Web Application Firewall) logging on regional and global web ACLs (Access Control Lists), can result in severe consequences such as:\n\n* **Potential Security Breaches**: AWS WAF helps you to block common attack patterns, like SQL injection or cross-site scripting. Without enabling the logging, you might be blind to these potential attacks, leaving your infrastructure vulnerable.\n\n* **Lack of Traceability**: Logging provides traceability of access and modifications. Not having it enabled makes it impossible to track who did what and when, which can greatly inhibit your troubleshooting abilities and potentially breach audit compliance.\n\n* **Trouble in Audit Compliance**: Failing to log events may result in non-compliance during audits, especially those that require stringent logging and monitoring controls like SOC2 or ISO 27001.\n\n* **Forensic Analysis Difficulty**: Logging is a crucial part of forensic analysis. Without the appropriate logging, your ability to conduct accurate post-event analysis is severely limited.\n\n* **Infrastructure Management Difficulties**: Not having proper logging and monitoring can make managing your environment significantly more difficult. It becomes much harder to identify trends, spot issues, or optimize your setup without comprehensive data.\n\n* **Incurred Costs**: In a worst-case scenario, a significant security breach which is not detected in time because of lack of logging can result in substantial financial loss. Plus, it's common for organizations to be financially penalized for non-compliance with certain laws, regulations or standards. \n\n* **Potential Damage to Brand**: Any kind of security breach or non-compliance with data regulations can seriously damage your company's reputation, leading to loss of customers and revenue in the long-term.\n\nTherefore, it is recommended to enable AWS WAF logging on your regional and global web ACLs."
      ],
      "x-kaytu-usefulness-example": [
        "An example of the usefulness of AWS WAF (V2) logging for regional and global web ACLs can be seen in an e-commerce company looking to protect their website from attacks and unauthorized access.\n\nHere is a scenario: An e-commerce company uses their website as the primary channel for operations and customer transactions. To defend their site against web attacks (like SQL injection and cross-site scripting), they have implemented AWS WAF (Web Application Firewall).\n\nInitially, the company didn't have WAF logging enabled in their regional and global web access control lists (ACLs). One day, they noticed several undetermined instances of downtime and slowed performance of their site. Without the necessary logs, they found it difficult to identify the source of these issues and couldn't tell if they were due to normal traffic or malicious activities.\n\nBy enabling AWS WAF logging, they could now capture all web requests, including IP addresses, Geo locations, timestamps, and actions applied by WAF for each request. This provided the benefit of a comprehensive analysis for each incident, leading to quicker identification of the cause. \n\nThey observed an increase in requests from certain IP addresses that hinted at DDoS attacks. Having this insight, they were able to swiftly react and block those IP addresses in AWS WAF rules. Maintaining the logs also helped them in performance tuning and fine-tuning the WAF rules to reduce false positives. Additionally, the logs were beneficial during audits to provide evidence of their security measures.\n\nIn summary, enabling logging in AWS WAF (V2) significantly improved their ability to monitor web traffic, defend against attacks, and maintain their website performance by quickly identifying and reacting to potential risks."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_emr_cluster_kerberos_enabled",
    "Title": "EMR cluster Kerberos should be enabled",
    "Description": "The access permissions and authorizations can be managed and incorporated with the principles of least privilege and separation of duties, by enabling Kerberos for Amazon EMR clusters.",
    "QueryID": "aws_emr_cluster_kerberos_enabled",
    "DocumentURI": "policies/aws_emr_cluster_kerberos_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EMR"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon Web Service (AWS) controls provide infrastructure and management tools to maintain the security and integrity of your resources. This specific control focuses on incorporating two important security principles into the AWS environment:\n\n- **Principle of Least Privilege (PoLP)**: This concept implies that a user should have the bare minimum permissions necessary to perform their work. This decreases the chance of an individual accidentally or maliciously accessing and damaging vital system components.\n\n- **Separation of Duties (SoD)**: This concept divides critical functions among different employees or systems in order to avoid potential fraud or errors.\n\nHere is an example of how you can utilize AWS controls to enforce these concepts by managing access permissions and authorizations with the help of Kerberos for Amazon EMR clusters:\n\n```markdown\n# Managing Access Permissions and Authorizations with Kerberos\n\nWith AWS, you can manage your permissions and authorizations to incorporate the **Principle of Least Privilege (PoLP)** and **Separation of Duties (SoD)**. One specific way to achieve this is via enabling Kerberos for Amazon EMR clusters.\n\n## Principle of Least Privilege \n\nYou can manage access tightly by giving the least amount of permission that is necesary for a user to perform their work. For example, you can use AWS Identity and Access Management (IAM) to give granular permissions.\n\n## Separation of Duties \n\nBy applying separation-of-duty principles in your AWS environment, you can prevent one person or system from having too much control or access. Implementing SoD can help prevent security incidents.\n\n## Kerberos for Amazon EMR Clusters\n\nWith Kerberos, an advanced network authentication protocol, you can ensure only authorized users and services can access your Amazon EMR clusters. It uses \"tickets\" to allow nodes to prove their identity across a network in a safe manner.\n```\n\nRemember to adjust the workers' rights in such a way that each job requires limited permissions and uses a stable version of the software to establish secure connections between nodes."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control has several costs:\n\n1. **Security Risks**: If least privilege and separation of duties are not implemented, it means that all users may have access to all resources, potentially including those they don't need for their job. This raises the possibility of unauthorized access, data manipulation or data loss that can result from both malicious intent and unintentional user error. \n\n2. **Increased Vulnerability**: Not using a system like Kerberos for identity management in Amazon EMR clusters could leave your systems more susceptible to attacks. This could lead to severe consequences such as loss or theft of sensitive and valuable data, disrupting business operations.\n\n3. **Regulatory Fines**: If your data includes personally identifiable information (PII) or other sensitive information, non-compliance with this control could lead to substantial fines and penalties from regulatory bodies, as well as potential legal consequences. \n\n4. **Loss of Trust**: Non compliance can lead to loss of trust among your clients, which in turn could lead to loss in business. If a data breach were to occur due to non compliance, it could create a significantly negative impact on your company's reputation.\n\n5. **Cost of Remediation**: In case of non-compliance leading to security issues, the cost of remediation may be vastly higher than the cost of initially setting up the control. This could include the technical costs associated with incident response, potentially extensive loss of productivity, and any related legal or regulatory costs.\n\n6. **Potential for Competitive Disadvantage**: In today's marketplace, companies that can demonstrate they take data privacy and security seriously have an advantage. Those that don't may lose out on business opportunities.\n\nIn conclusion, strict adherence to recommended AWS controls protecting access permissions and authorizations, such as enabling Kerberos for Amazon EMR clusters, is not only a best practice but also crucial for minimizing risk and avoiding potential costs."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a company has a large data analysis team that is using Amazon EMR clusters to handle their Big Data workload. The team has multiple job roles each requiring different access levels such as data analyst, data scientist, DBA, etc. To effectively manage data security, Kerberos is enabled for the EMR clusters.\n\nHere is an example scenario of how the AWS control is useful:\n\n- Each team member is given an access level according to the principle of least privilege. This means a team member is given only the permissions necessary to perform his job. For example, a data analyst may only need read-only access to a data set, while a DBA might need additional administrative privileges.\n  \n- The separation of duties is achieved by making sure that the same person does not have control over all stages of a critical process. For example, someone who runs a specific EMR job does not have the permission to modify that job as well.\n\n- By using Kerberos, the company adds an extra layer of security. With Kerberos, when a user attempts to gain access to a certain resource, they must prove their identity with a password to a trusted third party - the Key Distribution Center (KDC). Only after authenticated by KDC, the user can access the required resource which prevents any unauthorized access attempt.\n\nThis shows that by using Kerberos with EMR clusters, the company can not only easily manage access controls according to the least privilege principle and separation of duties policy but also ensure strong data encryption, thereby enhancing data security and integrity."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_es_domain_logs_to_cloudwatch",
    "Title": "Elasticsearch domain should send logs to CloudWatch",
    "Description": "Ensure if Amazon OpenSearch Service (OpenSearch Service) domains are configured to send logs to Amazon CloudWatch Logs. The rule is compliant if a log is enabled for an OpenSearch Service domain. This rule is non compliant if logging is not configured.",
    "QueryID": "aws_es_domain_logs_to_cloudwatch",
    "DocumentURI": "policies/aws_es_domain_logs_to_cloudwatch.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/ES"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "This AWS control checks if the Amazon OpenSearch Service (OpenSearch Service) domains have been set up to send logs to Amazon CloudWatch Logs. Keeping logs is crucial for monitoring and diagnosing system issues, as well as security troubleshooting.\n\n**Compliant**: If a domain in the OpenSearch Service has enabled a log to be sent to CloudWatch Logs. \n\n```markup\n\u003cResource Name\u003e\n   Compliant\n```\n\nLogging is crucial for monitoring your system's health and diagnosing security incidents. If a domain is set up correctly, receiving logs from the OpenSearch Service into CloudWatch Logs will allow you to review them more easily for any anomalies or errors that may occur.\n\n**Non-Compliant**: If logging for an OpenSearch Service domain is not set up. \n\n```markup\n\u003cResource Name\u003e\n   Non Compliant\n```\n\nWithout logs configured correctly, you would lose visibility into the operations and potential security issues of the OpenSearch Service, which could result in a longer response and troubleshooting time. Therefore, a non-compliant status indicates a lack of proper logging set up for the resource."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the specified AWS control can result in numerous potential costs to an organization:\n\n1. **Operational Costs:** If logging to Amazon CloudWatch Logs is not configured, it can significantly impact operations. Troubleshooting issues related to OpenSearch Service can become more difficult as critical information might not be readily available. This leads to increased resolution time and, consequently, increased operational costs.\n\n2. **Security Costs:** Amazon CloudWatch Logs offers important security insights. Disabling logging can lead to blind spots in monitoring, resulting in potential undetected security breaches or system misuse. The financial implications of data breaches can be severe.\n\n3. **Compliance Costs:** For organizations that operate under regulatory requirements (like GDPR, HIPAA, etc.), the failure to log crucial information can result in non-compliance findings during audits. This can lead to hefty fines and penalties.\n\n4. **Reputation Costs:** Non-compliance can lead to reputational damage if it leads to undetected security breaches or downtime, eroding customer trust and potentially leading to customer churn.\n\n```markup\n* **Operational Costs:** Lack of logging can make troubleshooting issues difficult and time-consuming.\n* **Security Costs:** Without logging, monitoring for security issues could have blind spots, potentially missing critical security breaches or misuse.\n* **Compliance Costs:** Industries with strict regulatory requirements may face non-compliance, resulting in fines and penalties during audits.\n* **Reputation Costs:** Non-compliance can lead to customer distrust, potentially driving away clients and harming the company's reputation.\n```\n"
      ],
      "x-kaytu-usefulness-example": [
        "Example:\n\nMark is the IT manager of XYZ corporation, responsible for its tech infrastructure. His team uses Amazon OpenSearch Service for data querying and indexing. In order to maintain a secure and optimized system, he needs to make sure his team has complete and real-time visibility into their OpenSearch environment.\n\nIn order to achieve this, he configured OpenSearch Service domains to send logs to Amazon CloudWatch Logs. This allows him to track and monitor all the data that's been accessed or modified on the OpenSearch Service domains, including any data that was uploaded, deleted, or modified. Therefore, this AWS control’s compliance can help Mark ensure the security and integrity of their system, monitor the user activities, operational performance \u0026 troubleshoot in case of any issues or anomalies. \n\nIf Mark notices that an OpenSearch domain doesn't comply with this rule, i.e, it's not sending log data to CloudWatch Logs, he considers this a red flag. It could point to a misconfigured domain, or worse, a potential security vulnerability. He can then take immediate action to ensure that the domain is properly configured. \n\nTherefore, this AWS Control is instrumental in helping maintain the operational health and security of the system."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_public_access_block_bucket",
    "Title": "S3 public access should be blocked at bucket levels",
    "Description": "Ensure if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible. This rule is non compliant if an Amazon S3 bucket is not listed in the excludedPublicBuckets parameter and bucket level settings are public.",
    "QueryID": "aws_s3_public_access_block_bucket",
    "DocumentURI": "policies/aws_s3_public_access_block_bucket.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/S3"
      ],
      "x-kaytu-explanation": [
        "The AWS Control you're referring to is a security measure called the S3 Bucket Public Read Prohibited. This rule is used to check for and prevent unintended public access to S3 buckets and their content. If an S3 bucket isn't listed in the 'excludedPublicBuckets' parameter and its bucket-level settings are set to public, then the rule is considered non-compliant and will trigger an alert.\n\nIn simple words, this rule flags any S3 bucket that is publicly accessible and is not listed in a designated set of 'safe' S3 buckets known as 'excludedPublicBuckets'. \n\nHere's how you might represent the control in markup (Markdown format):\n\n```\n## AWS Control: S3 Bucket Public Read Prohibited\n\n- **Description**: This control ensures that Amazon S3 buckets are not publicly accessible, enhancing the security of your AWS environment.\n\n- **Compliance**: \n  - This rule is *non-compliant* if an Amazon S3 bucket is **not** listed in the `excludedPublicBuckets` parameter and the bucket level settings are set to public. \n\n- **Remediation**:\n  - Make sure all S3 buckets are private or add them to the `excludedPublicBuckets` parameter if they need to be publicly accessible.\n```\n\nThis is a basic representation and the actual content may differ based on specific needs or requirements."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS Control of ensuring Amazon Simple Storage Service (S3) buckets are not publicly accessible can be broken down into several areas:\n\n1. **Financial impact**: If sensitive data, such as customer information or intellectual property, is exposed due to a publicly accessible S3 bucket, this could result in heavy fines from regulatory bodies, lawsuits, or lost business.\n\n2. **Reputation damage**: Data exposure can severely damage a company's reputation, leading to a loss of trust from customers or partners and eventually significant loss in business.\n\n3. **Operational impact**: If critical data is leaked, it could disrupt business operations. It might enable competitors to gain advantage, or enable malicious actors to manipulate or disrupt business operations.\n\n4. **Regulatory non-compliance**: Many industries are regulated by laws and standards that require companies to adequately protect customer data. Non-compliance with these regulations (GDPR, CCPA, HIPAA, etc) due to an S3 bucket being publicly accessible could lead to hefty fines and sanctions.\n\nTo avoid these costs, it is important for the organization to ensure proper access control measures are in place on all AWS S3 buckets and no bucket is left publicly accessible unless it is intentionally excluded."
      ],
      "x-kaytu-usefulness-example": [
        "This AWS Config Rule is useful in multiple scenarios. A prime example would be a large organization with numerous S3 buckets that may contain sensitive data.\n\n```markdown\nFor instance, a media production house uses several AWS S3 buckets to manage their digital content, including scripts, raw footages, and original soundtracks. Although some buckets are meant to be public facing serving promotional assets, majority of buckets should remain private to protect confidential data. \n\nHaving this AWS Config rule in place, the company can conveniently monitor all their S3 buckets' permissions. If any bucket other than those listed in the 'excludedPublicBuckets' is found to be publicly accessible, administrators will be alerted to check the bucket and correct permissions if needed. It makes AWS security administration smoother, mitigating any possible risks and potential data breaches.\n```\nIt's a useful tool for ensuring the privacy and security of their Amazon S3 buckets."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_root_user_no_access_keys",
    "Title": "IAM root user should not have access keys",
    "Description": "Access to systems and assets can be controlled by checking that the root user does not have access keys attached to their AWS Identity and Access Management (IAM) role.",
    "QueryID": "aws_iam_root_user_no_access_keys",
    "DocumentURI": "policies/aws_iam_root_user_no_access_keys.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Control essentially means managing who can access certain resources and how users utilize these resources. Here in this context, the control refers to the limitation of the access level of the root user.\n\nThe root user of an AWS account is simply the user who created the account and has complete access to all the AWS services and resources. According to AWS recommended best practices, root users should not have access keys attached to them. This is because if a root user’s access keys are exposed, then an attacker can take full control over the user's AWS resources.\n\nBy attaching the access keys to an AWS Identity and Access Management (IAM) role instead, one can define and control the level of access a user has, thereby restricting the permissions that can be obtained with the access keys. Users can then assume the IAM role that carries the required permissions, reducing the need for sharing access keys.\n\nIn short, this control measure provides an added layer of security to an AWS account by limiting who can do what with which resources.\n\nHere's how it can be represented in a markup format using `Markdown Language`:\n\n```markdown\n# AWS Control - Restricting Root User Access \n\nAWS recommends to **not attach access keys** directly to the _root user_. These keys, if exposed, can lead to unauthorized access to all AWS resources. \n\nOn the other hand, AWS Identity and Access Management (IAM) allows control over who can **access** your AWS resources (Authentication) and what resources they can access and in what ways (Authorization). \n\nYou can follow below steps to ensure secure access:\n\n1. **Create an IAM user**: The root account should not be used for day-to-day tasks. Instead, create an IAM user.\n\n2. **Attach Policies to IAM user**: Policies are objects in AWS that, when associated with an identity or resource, define their permissions.\n\n3. **Use Roles for Applications that run on Amazon EC2 instances**: Roles are predefined sets of permissions that you assign to the users in your trusted entity.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control can lead to significant financial, operational, and reputational costs. Here's why:\n\n1. **Security Risk**: The root user has unrestricted access to all AWS resources. If the root user's access keys got into the wrong hands, it could lead to unauthorized activities like data breaches, unauthorized changes, or even total wiping off of data and resources. This will result in direct financial loses along with the cost of damage control. \n   \n2. **Financial cost**: Improper enforcement of this control can lead to misuse of AWS resources, causing spikes in the cost of AWS services. Unauthorized users could spin up expensive resources without business justification.\n\n3. **Regulatory Compliance cost**: Non-compliance with this control could mean failing to meet regulatory compliance standards like GDPR, HIPAA, etc. Failing compliance can lead to hefty fines, sanctions, and loss of business due to termination of contracts by clients.\n\n4. **Business Operation cost**: Unauthorized access or misuse of root account could lead to disruptions in key business operations, leading to loss of business and trust amongst clients.\n\n5. **Reputational Damage**: Data breaches or unauthorized changes due to root user access key misuse can severely damage the reputation of the company, leading to loss of current and potential customers, partners, and shareholders.\n\nSo, it's crucial to enforce this control - root user should not have attached access keys. Instead, AWS recommends creating individual IAM users for managing access to AWS services and resources. Also, use AWS managed policies to assign permissions whenever possible."
      ],
      "x-kaytu-usefulness-example": [
        "This control mechanism in AWS can be significantly useful in several instances. For example:\n\n1. **Securing Sensitive Data:** Consider a company that stores highly sensitive data in the AWS cloud. To prevent unauthorized access, they need to ensure the root user does not have access keys attached to their IAM role. This way, even if the root user credentials are compromised, the attacker can't access the cloud resources using the access keys.\n\n```\nCompany A stores its customer data in an Amazon S3 bucket. To secure its data from unauthorized access, they ensure the root user does not have access keys within its IAM role. This way, even when their root user credentials get compromised, the attacker can't access the S3 bucket using AWS CLI or SDKs.\n```\n\n2. **To Enforce Principle of Least Privilege:** AWS recommends not using the root user for daily work and enabling multi-factor authentication (MFA) for their account. Companies follow the principle of least privilege (PoLP), where only the necessary access to perform a function is given, minimizing the potential risk of unauthorized data access.\n\n```\nCompany B adheres to the principle of least privilege (PoLP) to secure its cloud resources. To enforce this, they ensure the root user does not have access keys attached to its IAM role, thereby reducing the potential risk of data breaching.\n```\n\n3. **Ideal for Large Teams:** In a large team, where multiple people might need access to the AWS account, not attaching access keys to the root user prevents accidental use of root privilege and hence avoids accidental modifications or deletions.\n\n```\nIn Company C, which is a large enterprise, multiple teams need access to their AWS account. To avoid accidental usage of root privilege, they ensure the root user does not have access keys within its IAM role, preventing unintentional changes to their critical cloud resources.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_dynamodb_table_in_backup_plan",
    "Title": "DynamoDB tables should be in a backup plan",
    "Description": "To help with data back-up processes, ensure your Amazon DynamoDB tables are a part of an AWS Backup plan.",
    "QueryID": "aws_dynamodb_table_in_backup_plan",
    "DocumentURI": "policies/aws_dynamodb_table_in_backup_plan.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/DynamoDB"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "```\n# AWS Control: DynamoDB in AWS Backup\n\nThe AWS Control specifies that all Amazon DynamoDB tables should be included in an AWS backup plan.\n\n## What is DynamoDB?\n\nAmazon DynamoDB is a NoSQL database service provided by Amazon Web Services. It's designed to provide seamless scalability, offering fast and predictable performance with seamless scalability. It’s ideal for applications that need consistent, single-digit millisecond latency at any scale.\n\n## What is AWS Backup?\n\nAWS Backup is a fully managed backup service that allows you to centralize and automate the backup of your data across AWS services.\n\n## Why DynamoDB Tables Should Be Included in AWS Backup Plan?\n\nIncluding DynamoDB tables in the AWS backup plan helps with:\n\n- **Disaster Recovery**: If your data is accidentally deleted or altered, you can restore it to a previous state.\n\n- **Compliance Requirements**: It helps meet regulatory compliance requirements by providing a way to backup and restore data.\n\n- **Data Durability**: It provides an additional level of data durability.\n\n## How to Include DynamoDB Tables in AWS Backup Plan?\n\nTo do this, navigate to the AWS Backup console. Select 'Create Backup Plan', and specify the necessary details required for your backup. In 'Resource Assignment', select the DynamoDB tables you want to backup. Repeat these steps for each table you want to add to the backup plan.\n\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control can result in high costs both financially and operationally.\n\n1. **Data Loss**: The most direct cost is the potential for data loss. If your DynamoDB tables are not part of an AWS Backup plan and a data corruption or loss occurs, restoring or recreating the data may be impossible or highly expensive. \n\n2. **Business Continuity**: Data loss could seriously threaten business operations, particularly if critical data for everyday operations is lost. This could lead to longer recovery time, result in service interruption, customer dissatisfaction, and ruin business reputation.\n\n3. **Financial Expense**: Depending on the extent of damage, the cost of data recovery or replication could be enormous. If not readily available, possible costs could include hiring external consultants, purchasing of new hardware, software, or services, and overtime payment for employees.\n\n4. **Compliance Penalties**: If you're operating in a regulated industry or handling sensitive user data, non-compliance to this control could result in heavy fines or penalties by regulatory authorities. \n\n5. **Loss of Customer Trust**: In the case of data loss which affects customer data or service provision, the loss of customer trust is a huge risk. This can result in reduced business and lost sales.\n\n6. **Additional Recovery Costs**: Restoring systems after a data loss event can be a major task. This will often take considerable time and resources, especially if backups are not readily available.\n\nTo summarize, the cost of non-compliance with the AWS control of ensuring your Amazon DynamoDB tables are part of an AWS backup plan can be immense. It not only includes potential financial loss, but also the disruption to normal business operations, reduced customer trust, and possible regulatory penalties."
      ],
      "x-kaytu-usefulness-example": [
        "For example, suppose you are running a major e-commerce platform on AWS. All transactional data, product catalog, customer data, etc., are stored on Amazon DynamoDB tables. The data is critical to your business operations.\n\nWithout a proper backup plan, you risk losing all the data due to unforeseen circumstances such as technical glitches, operational mistakes or malicious activities. This could lead to significant business losses, both in terms of financial resources and customer trust.\n\nNow let's say you have included your Amazon DynamoDB tables in an AWS Backup plan. In an unfortunate event where your primary data got corrupted or lost, you would be able to recover the data from AWS backups quickly. This would ensure business continuity, minimal loss of revenue and maintain customer trust.\n\nHence, incorporating AWS DynamoDB tables into an AWS backup plan is a useful control for any AWS hosted application relying on DynamoDB as a data storage solution."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_user_unused_credentials_90",
    "Title": "IAM user credentials that have not been used in 90 days should be disabled",
    "Description": "AWS Identity and Access Management (IAM) can help you with access permissions and authorizations by checking for IAM passwords and access keys that are not used for a specified time period.",
    "QueryID": "aws_iam_user_unused_credentials_90",
    "DocumentURI": "policies/aws_iam_user_unused_credentials_90.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Identity and Access Management (IAM) is an Amazon Web Service that provides controlled access to AWS services and resources. It enables you to manage access to AWS services and resources securely. \n\nOne of the main features involves IAM passwords and access keys. You can specify a time period where, if the IAM passwords and access keys are not being used, they become invalid.\n\nThis ensures that any unused and potential security loopholes are dealt with proactively. You can also specify the rules for rotating these keys and passwords based on your company's policies.\n\nHere's a simple explanation in the form of a markup document:\n\n```markdown\n# AWS Identity and Access Management (IAM)\n\nAWS Identity and Access Management (IAM) is a feature of your AWS Account that allows you to control who is authenticated or signed in and authorized to use resources.\n\n## Main Features\n\n1. **Controlled Access to AWS Services:** Manage access to AWS services and resources securely.\n\n2. **IAM Passwords And Access Keys:** Can set a specific time period after which, if not used, IAM passwords and access keys become invalid. This can help in dealing with unused and potentially insecure access routes.\n\n3. **Key Rotation Policies:** You can also specify the policies for rotating these keys and passwords based on your organization's norms.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the mentioned AWS control can be significant. AWS IAM ensures that access permissions and authorizations are properly managed and secure. It assists in managing IAM passwords and access keys that haven't been used for a specified duration. \n\nWhen the control is not observed:\n\n1. **Security Risks**: Non-compliance means you are giving room for potential attackers or inappropriate access to your sensitive data. This can lead to data breaches, unauthorized operations or legal implications.\n\n2. **Inefficiencies**: Unused access keys and passwords might indicate improper management of resources leading to inefficiencies. It could mean there are unused resources, or employees are not adequately using their access rights.\n\n3. **Financial Implications**: In case of a data breach, an organization can find it costly to recover the breached data. This may result in direct financial loss due to paying ransom in case of a ransomware attack or indirect costs such as loss of business, decreased customer trust and damaging the company's reputation. \n\n4. **Compliance Penalties**: If organisations are subject to compliance standards (like GDPR, HIPAA, PCI-DSS) and ignoring such important controls can lead to failing audits and associated penalties. \n\n5. **Operational Interruptions**: Incidents related to security breaches can disrupt the normal operations of a company leading to loss of business or downtimes. \n\nBy ensuring compliance with IAM control, your AWS environment remains safe and secure, maximizing efficiency and reducing potential risks."
      ],
      "x-kaytu-usefulness-example": [
        "An example where this might be useful is in the case of a large company called XYZ Corporation, which has multiple employees who have access to its AWS services for various tasks. However, some team members might have left the company, some accesses might be obsolete because specific projects are over, or some temporary accesses provided for consultants/contractors might no longer be necessary.\n\nIf not managed properly, these unnecessary accesses can be security loopholes potentially exploited by malicious attackers. XYZ Corporation can use AWS IAM to monitor all the IAM passwords and access keys. If it finds any access key or password that hasn't been used for a specified time period, like 90 days, it can send an alert to the management or automatically revoke its access to enhance the security.\n\nHere's a illustrative markup usage:\n\n```yaml\nresource \"aws_iam_access_key\" \"user\" {\n  user = aws_iam_user.lb.name\n}\n\nresource \"aws_iam_user\" \"lb\" {\n  name = \"loadbalancer\"\n  path = \"/system/\"\n\n  tags = {\n    tag-key = \"IAM\"\n    tag-value = \"AccessKey\"\n  }\n}\n\ndata \"aws_iam_access_key\" \"user\" {\n  user_name = aws_iam_access_key.user.user\n}\n\noutput \"user_access_key_last_used_date\" {\n  value = data.aws_iam_access_key.user.last_used_date\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"unused_iam_access_key\" {\n  alarm_name          = \"unused-iam-access-key\"\n  comparison_operator = \"LessThanOrEqualToThreshold\"\n  evaluation_periods  = \"2\"\n  metric_name         = \"AccessKeysLastUsed\"\n  namespace           = \"AWS/IAM\"\n  period              = \"86400\"\n  statistic           = \"Average\"\n  threshold           = \"90\"\n  alarm_description   = \"This metric checks if any IAM access keys have not been used for the last 90 days\"\n  alarm_actions       = [aws_sns_topic.example.arn]\n}\n```\n\nIn this example, the `aws_iam_access_key` manages the IAM access key for a user. A `aws_cloudwatch_metric_alarm` is set to monitor if the access key is used within a 90-days period. If not, it triggers an alarm and notifies using `aws_sns_topic`. This way, the system automatically keeps checking for unused IAM passwords/access keys and handles them for increased security."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_public_access_block_account",
    "Title": "S3 public access should be blocked at account level",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that Amazon Simple Storage Service (Amazon S3) buckets cannot be publicly accessed.",
    "QueryID": "aws_s3_public_access_block_account",
    "DocumentURI": "policies/aws_s3_public_access_block_account.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "**Control ID**: AWS_S3_PublicAccess\n\n**Control Name**: Restriction of Public Access to S3 Buckets\n\n**Description**: This control aims to prevent unauthorized access to your data stored in Amazon S3 by ensuring that none of the S3 buckets can be accessed publicly. This control requires that access to S3 resources should be explicitly specified and approved through a secure access mechanism.\n\n**Rationale**: Allowing public access to S3 buckets can potentially expose sensitive data to unauthorized users, leading to data leaks, penetration and breaches that might cause severe damage to the organization. This control helps to prevent the accidental exposure of data.\n\n**Policy**: All S3 buckets should be configured to deny public access unless specifically required and approved by the security team.\n\n**Audit Procedure**:\n\n- Check for bucket policies or ACLs that allow any public or global accesses.\n- Review the bucket Access Control Lists (ACLs) and bucket policies for any statement allowing access to the S3 bucket from any user.\n- Use Amazon S3 Block Public Access to block public access to all your S3 buckets at the account level.\n\n**Remediation Procedure**: \n\n- Remove any bucket policies or ACLs that allow public read or write access.\n- Use the AWS Management Console, AWS SDK, or AWS CLI to turn on Amazon S3 Block Public Access for the buckets that should remain private.\n\n**Frequency**: Monthly\n\n**References**: \n\n- AWS Security Best Practices\n- Amazon S3 Block Public Access documentation.\n\n**Responsible Roles**: \n\n- AWS Administrator\n- Security Team"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control can have severe consequences that can be both financial and reputational in nature. Here's a break down of the potential costs:\n\n1. **Monetary Loss:** In case of non-compliance, if your Amazon S3 bucket is publicly accessible, it can lead to unauthorized access and possible data breaches. Stolen data - depending on its sensitivity - can have substantial monetary value. Moreover, you might also have to bear the cost of potential litigation and fines, if sensitive personal data is exposed in the public.\n\n2. **Reputation Damage:** Data breaches due to lapses in securing S3 buckets can lead to significant damage to your organization's reputation. There is the possibility of loss of trust among customers, stakeholders and the general public. This reputational harm can also translate into financial losses, as customers may choose to leave in favor of more secure alternatives.\n\n3. **Intellectual Property Loss:** If the publicly accessible S3 bucket stores intellectual property, its exposure can lead to a loss of competitive advantage, resulting in potential revenue loss.\n\n4. **Regulatory Fines and Legal Fees:** Depending on the jurisdiction and the nature of the exposed data, you may face substantial fines due to non-compliance with regulations such as GDPR, HIPAA, etc. You might also have to face legal action from affected parties which can add to the cost.\n\n5. **Remediation Costs:** Post a data breach, you would need to invest in resources to understand the breach’s extent, eradicate the vulnerability, ensure future compliance, and potentially offer affected users services such as credit monitoring or identity theft protection. \n\nTherefore, it is crucial to manage access to resources in the AWS Cloud effectively and ensure Amazon S3 buckets cannot be publicly accessed, to avoid the costs of potential data breaches."
      ],
      "x-kaytu-usefulness-example": [
        "For example, a company that stores sensitive information, like customers' personal data or proprietary company data, in their AWS S3 bucket would want to ensure that these S3 buckets cannot be publicly accessed. With unregulated access, their business operations could be severely compromised due to data breaches or data loss from unintended deletions. \n\nBy applying this AWS control, the company can restrict access to their S3 bucket to only identified and authenticated users or applications. The information stored can still be quickly and conveniently retrieved by authorized users, while ensuring its security. This way, the company can comply with data protection regulations, avoid unnecessary business losses from security breaches, and maintain the trust of their customers."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_account_part_of_organizations",
    "Title": "AWS account should be part of AWS Organizations",
    "Description": "Ensure if an AWS account is part of AWS Organizations. The rule is non compliant if an AWS account is not part of AWS Organizations or AWS Organizations master account ID does not match rule parameter MasterAccountId.",
    "QueryID": "aws_account_part_of_organizations",
    "DocumentURI": "policies/aws_account_part_of_organizations.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "x-kaytu-explanation": [
        "This AWS Control is designed to check whether your AWS account is part of an AWS Organization, which is a service offered by AWS that allows you to manage multiple AWS accounts together. Within AWS Organizations, one account is designated as the master account.\n\nThe rule is straightforward:\n\n- If your AWS account is not part of any AWS Organizations, the rule is considered non-compliant. This means, your account is standalone and not managed under AWS Organizations.\n\n- If your AWS account is part of an AWS Organization, but the master account ID of your AWS Organization does not match the MasterAccountId specified in the rule parameter, the rule is considered non-compliant. Hence, your account should be part of the specific AWS Organization referenced by MasterAccountId.\n\nThe purpose of this control is to enforce proper management and oversight over AWS accounts within an organization. If running multiple AWS accounts, it's considered best practice to manage them under AWS Organizations for easier billing, access management, and compliance monitoring.\n\nHere's a simplified example in a markup format:\n\n```markdown\n# AWS Control: AWS Organizations Membership\n\nThis control checks if your AWS account is part of an AWS Organization.\n\n## Non-compliant cases:\n\n1. Your AWS account is not part of any AWS Organizations.\n2. Your AWS account belongs to an AWS Organization, but its master account ID does not match the `MasterAccountId` defined in the rule parameter.\n\n## Compliance purpose:\n\nUsing AWS Organizations helps streamline account management, simplify security and compliance, and delivers services across multiple AWS accounts.\n```\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS Control you've mentioned can have serious implications. Here's an explanation in markup format:\n\n1. **Security Risks**: With decentralized management of individual AWS accounts, you are at an increased risk of encountering security vulnerabilities. AWS Organizations allows centrally managed policies, which can enforce necessary security measures across all accounts.\n\n2. **Operational Inefficiencies**: Without AWS Organizations, trying to implement and monitor consistent policies across potentially hundreds of accounts can be operationally inefficient and time-consuming. \n\n3. **Cost Management Issues**: AWS Organizations allows for consolidated billing, offering potential volume-based discounts. Non-compliance with the rule could lead to higher operational costs.\n\n4. **Audit and Compliance Difficulties**: AWS Organizations simplifies your AWS usage audit. Non-compliance could render auditing and adherence to other compliance requirements difficult.\n\n5. **Limited Control and Governance**: AWS Organizations provide control over AWS service access, which could be limited if the account is not a part of it.\n\n6. **Increased Troubleshooting Time**: Policy changes or trouble shooting problems could take significantly longer as each account would have to be dealt with individually rather than collectively.\n\nIn conclusion, not ensuring that an AWS account is part of AWS Organizations or that the AWS Organizations master account ID does not match the rule parameter `MasterAccountId` would likely lead to increased security risks, higher costs, inefficient operations, and difficulties in auditing and achieving compliance."
      ],
      "x-kaytu-usefulness-example": [
        "This AWS Config rule can be useful in managing multiple AWS accounts effectively under an organisation. Below is an example:\n\n1. A company 'X' uses multiple AWS accounts for various departments and wants to ensure that all these accounts operate under a single operational umbrella for better management, billing, and administrative controls.\n\n2. They use AWS Organizations to centrally manage these accounts. However, they need to continuously check if any AWS accounts are not part of their organization due to missed addition or accidental removal which could potentially cause a failure to manage security, resources, and cost-effectiveness efficiently across all the accounts. \n\n3. Here's where AWS Config rule comes into the picture. The rule \"aws-account-part-of-organizations\" ensures that all AWS accounts are part of the organization. If any AWS account is not a part of the AWS Organization or its master account ID does not match with the MasterAccountId, it fires a non-compliant signal.\n\n4. This non-compliant signal warns the company 'X' about the inconsistency, helping them correct the issue timely - either by adding the account to the AWS organization or by checking the master account ID.\n\n5. Thus, this AWS Control improves the security posture by reducing the risk of uncontrolled or unmonitored AWS accounts, facilitates consistent policy application across all accounts, and ensures all the accounts consistently benefit from central AWS services."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_instance_backup_enabled",
    "Title": "RDS DB instance backup should be enabled",
    "Description": "The backup feature of Amazon RDS creates backups of your databases and transaction logs.",
    "QueryID": "aws_rds_db_instance_backup_enabled",
    "DocumentURI": "policies/aws_rds_db_instance_backup_enabled.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS RDS Backup Feature\n\nAmazon RDS (Relational Database Service) provides a backup feature for creating regular and reliable backups of your databases and transaction logs. This feature ensures data persistence and safe recovery in case of any accidental deletion, database errors, or other data-loss situations.\n\n## How it Works?\n\nAmazon RDS creates automated backups of your DB instance at a set frequency during your backup window. Amazon RDS saves your backup data in Amazon S3, which is designed for 99.999999999% durability. It backs up the entire DB instance and not just individual databases.\n\nThere are two types of backups:\n\n1. **Automated backups** - These are enabled by default when you create a DB instance. \n\n2. **Manual DB Snapshots** - You can manually initiate these snapshots, which are user-initiated backups of your entire DB instance.\n\nBoth types of backups provide a record of your data over a specific time, including all DB instance data, from the database engine's version and EC2 instance type.\n\n## Key Features\n\n1. **Point-in-Time Recovery (PITR)**: AWS also offers the Point-in-Time Recovery feature, allowing you to restore your DB instance to any second during your retention period, up to the Latest Restorable Time. \n\n2. **Retention Period**: You can define the retention period for saving automated backups. The default retention period is seven days, but it can be set up to a maximum of 35 days.\n\n3. **Backup Window**: You can define a regular time period during which your backups are created. If you do not specify a backup window, Amazon RDS will assign a default 30-minute window.\n\n4. **Storage**: The storage consumed by your backups comes under your allocated Backup Storage, which corresponds to the provisioned storage for your DB instance.\n\nRemember, regular backups do not only protect your data but also enable various use cases, like testing, compliance auditing, data analysis, and more."
      ],
      "x-kaytu-noncompliance-cost": [
        "AWS controls are essentially rules or guidelines set by Amazon Web Services to ensure a safe, consistent, and productive environment. One of such control is the backup feature of Amazon RDS, which helps in creating backups of your databases and transaction logs.\n\n**Non-compliance** to this control can lead to several costs:\n\n1. **Data Loss:** The biggest and most critical cost of non-compliance is the possibility of data loss. If backups are not appropriately created and maintained, any kind of system failure or accidental data deletion could lead to irreversible data loss. \n\n2. **Downtime:** In case of a system failure where there is no backup available, the time needed to rebuild the system and recover data can lead to significant downtime. This can disrupt user experience and the operation of your application. \n\n3. **Financial Consequences:** Data recovery efforts can be costly, especially when specialized IT expertise is required. Lost data might also lead to lost business, especially if it concerns critical application data or customer information. \n\n4. **Regulatory Compliance:** If your data handling falls under any regulatory requirements (e.g., GDPR), not having proper backups could lead to non-compliance, subjecting your company to heavy financial penalties.\n\n5. **Reputation Damage:** Data loss or downtime can lead to a loss of customer trust and damage to your company's reputation.\n   \nTherefore, complying with the AWS Control related to the backup feature of Amazon RDS is critical to avoid such costs."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, consider a scenario where you run an e-commerce website with a large database of customer transactions hosted on Amazon RDS. One day, a major software malfunction occurs and your entire database gets corrupted. The malfunction affects your website and disrupts your business operations.\n\nWithout a backup, restoring your database after such a disaster can be time-consuming and expensive. You may need to reload all the data from the original sources, which may not even be available. Data inconsistencies may also arise as a result.\n\nIn this situation, the backup feature of Amazon RDS proves to be extremely useful. If automatic backups are enabled, Amazon RDS would have been creating a backup of your database every day and storing transaction logs. This means you can restore your database back to any point in time within your retention period, ranging from one to 35 days.\n\nAlso, it can help you in meeting business and regulatory compliance requirements about data retention since all backups are automatically encrypted. Moreover, backups on RDS can also be useful for routine administrative purposes such as database replication, storing historical data, or migrations."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_instance_in_backup_plan",
    "Title": "RDS DB instances should be in a backup plan",
    "Description": "To help with data back-up processes, ensure your Amazon Relational Database Service (Amazon RDS) instances are a part of an AWS Backup plan.",
    "QueryID": "aws_rds_db_instance_in_backup_plan",
    "DocumentURI": "policies/aws_rds_db_instance_in_backup_plan.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "```markdown\n# AWS Control: Amazon RDS Instances in AWS Backup Plan\n\nThis control emphasizes the need for proper data backup protocols by including your Amazon Relational Database Service (RDS) instances in an AWS Backup plan. \n\n## What is Amazon RDS?\nAmazon RDS is a web service that simplifies setting up, operating, and scaling a relational database in the cloud. It provides cost-efficient, resizable capacity for an industry-standard relational database and manages common database administration tasks.\n\n## What is AWS Backup?\nAWS Backup is a fully managed backup service offered by Amazon that makes it easy to centralize and automate the backup of data across AWS services in the cloud and on-premises. \n\n## Why should Amazon RDS be part of an AWS Backup Plan?\nIn the case of an unforeseen disaster, data loss can be detrimental to a business. To ensure data reliability and safety, Amazon RDS instances should be included in an AWS Backup plan. This ensures that your data is frequently and automatically backed up, protecting your databases from potential failures, errors, or threats.\n\nThe AWS Backup service also allows you to set up customized backup strategies, specifying when and how often backups occur. By using AWS Backup with Amazon RDS, you can simplify the backup process and have peace of mind that your valuable data is secured.\n```\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control can potentially result in several impactful costs:\n\n1. **Data Loss**: The most significant cost of non-compliance is potential irrecoverable data loss. If the AWS RDS instances are not a part of an AWS Backup plan, critical data may be lost due to accidental deletion, hardware failure, or security compromise. This can disrupt operations, degrade customer trust, and may even lead to legal consequences in some cases.\n\n2. **Downtime Costs**: The lack of a proper backup plan can lead to significant application downtime. Research shows that companies lose an average of $5,600 to $9,000 per minute during downtime. Depending on how critical the data on the RDS instance is, downtime costs can go quite high.\n\n3. **Operational Disruptions**: If an RDS instance does not have a back-up plan and something goes wrong, the organization could lose valuable data and it may take significant time and resources to manually restore the data, if it's possible at all.\n\n4. **Compliance Penalties**: Various sector regulations and data privacy laws mandate regular backups and data loss prevention measures. Non-compliance could result in penalties and fines.\n\n5. **Reputation Damage**: Not having a backup for your RDS Instance, and consequently losing data, may harm your business's reputation. This could lead to lost business opportunities and decreased customer trust.\n\n6. **Restoration Costs**: In the absence of a backup, you might need to resort to expensive data recovery services or invest internal resources, both in terms of time and labor, for restoration, which could have been avoided with a proper backup plan."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, you are running a start-up that maintains users data on Amazon RDS. As your business grows, a sudden loss of data due to an unexpected error or disaster can lead to massive downtime and irreparable customer trust issues. By ensuring your Amazon RDS instances are part of an AWS Backup plan, you can ensure seamless data recovery if such a situation ever occurs. \n\nIn this manner, AWS Backup provides a centralized backup across AWS services, simplifying the backup process and enabling you to meet business and regulatory backup compliance requirements. AWS Backup automates previously manual tasks, such as scheduling backups and tracking their retention, so you can seamlessly uphold data governance and compliance policies.\n\n```\n# Example policy for AWS Backup\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"AllowBackupOfRDS\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"backup:StartBackupJob\",\n        \"backup:DescribeBackupJob\"\n      ],\n      \"Resource\": \"arn:aws:rds:region:account-id:db:example-instance\"\n    }\n  ]\n}\n```\n\nIn this policy, AWS Backup is permitted to back up an Amazon RDS database instance. If the database instance's data is lost or the instance gets deleted, you can quickly restore the database instance from the AWS Backup, ensuring business continuity."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_efs_file_system_in_backup_plan",
    "Title": "EFS file systems should be in a backup plan",
    "Description": "To help with data back-up processes, ensure your Amazon Elastic File System (Amazon EFS) file systems are a part of an AWS Backup plan.",
    "QueryID": "aws_efs_file_system_automatic_backups_enabled",
    "DocumentURI": "policies/aws_efs_file_system_in_backup_plan.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EFS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Backup is a fully managed backup service in AWS that provides an easy, cost-effective, fully centralized solution for backing up AWS resources. \n\nTo help with backup processes, it's essential for your Amazon Elastic File System (EFS) file systems to be part of an AWS Backup plan. This practice helps in the automatic and regular backup of your data, reducing the risk of data loss and ensuring operational continuity in case of any unprecedented events.\n\nBelow is the instruction in markup format on how to achieve it:\n\n```markdown\n1. **Open the AWS Management Console:** Using your AWS account, log in to the AWS Management console.\n\n2. **Go to AWS Backup:** In the AWS services search bar, type 'AWS Backup' and click on it. \n\n3. **Create Backup Plan:** On the AWS Backup dashboard, click on \"Backup plans\" on the left side menu then click \"Create Backup plan\". \n\n4. **Select configuration:** You can either select 'Build a new plan' or 'Start with a template'. Provide a name for the backup plan.\n\n5. **Set Rules for Backup:** Set the backup frequency, backup window, lifecycle, and transition into cold storage if required. \n\n6. **Add Resources:** Select 'Assign resources' and in the 'Assign resources by group' select the 'Choose by resource type' tab. Here, select 'EFS' for Amazon Elastic File System. \n\n7. **Backup selection:** Choose the AWS resources that you want to add in the backup plan. \n\n8. **Review and Create:** After setting all the details, review and create your AWS Backup plan. \n\nNow, your Amazon EFS file systems would be part of an AWS Backup plan, ensuring it gets backed up as per the schedule.\n```\nThis way, your file systems would periodically get backed up, providing a fast, scalable, and secure solution to back up data on AWS."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control could lead to multiple business risks and potential financial costs, such as:\n\n1. **Data Loss** - In case of any accidental deletion or unforeseen disaster which leads to data loss, lack of backup would hinder the recovery process resulting in significant data loss. This could disrupt business operations leading to potential revenue loss.\n\n2. **Estimate Recovery Cost** - If the EFS file systems are not part of an AWS backup plan, manual efforts will be needed to recover the data (if at all possible). This manual recovery could be very time-consuming and costly.\n\n3. **Regulatory Non-compliance** - Certain industries are subjected to regulatory requirements that mandate regular backup of data. Non-compliance with these regulatory requirements could lead to significant financial penalties and litigation costs.\n\n4. **Business Continuity and Reputation Damage** -In the absence of backup, significant disruption to business continuity could happen impacting customer trust and damaging brand reputation. This could have long-term financial impacts.\n\nTherefore, non-compliance with this AWS control could have both financial and reputational implications, impacting the organization's bottom line significantly."
      ],
      "x-kaytu-usefulness-example": [
        "Let's consider a scenario where a company operates a data analysis platform. They have multiple Amazon Elastic File System (EFS) that manages and stores the user-generated data. The data is quite critical for their operation and any loss of data could result in significant business impact.\n\nIn such a scenario, integrating AWS Backup plan with Amazon EFS becomes quite useful. During any incident of data loss or corruption, the AWS Backup allows the company to seamlessly restore the required data from a backup. Since AWS Backup automatically backs up the data in Amazon EFS according to the backup plan, the company can minimize its data loss and the associated business impact.\n\nAlso, during data migration or software updates, having a backup is beneficial to restore systems back to their previous state in case of any failures. AWS Backup plan provides a centralized place to manage backups, thereby simplifying the backup tasks.\n\n```markdown\n**Scenario:** A data analysis company using Amazon EFS for storing user-generated data\n\n**Usefulness of AWS Backup plan:**\n\n1. Minimize data loss: Even in the case of data loss or corruption, AWS Backup allows for seamless restoration of data.\n2. Simplified Backup Management: AWS Backup provides a centralized location to manage backups, simplifying backup tasks.\n3. Backup during data migration or software updates: It is beneficial to have a backup to restore systems back to their previous state in case of failures during data migration or software updates.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_instance_logging_enabled",
    "Title": "Database logging should be enabled",
    "Description": "To help with logging and monitoring within your environment, ensure Amazon Relational Database Service (Amazon RDS) logging is enabled.",
    "QueryID": "aws_rds_db_instance_logging_enabled",
    "DocumentURI": "policies/aws_rds_db_instance_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Control is a set of procedures put in place to safeguard the data hosted in the cloud. The control mentioned here emphasizes the importance of enabling logging for Amazon RDS. Logging is an essential process in monitoring as it records the activities happening on the database. This provides crucial visibility into the system for security reasons or troubleshooting purposes.\n\nHere is the explanation in markdown format:\n\n```markdown\n# AWS Control - Amazon RDS Logging\n\nAmazon RDS logging is a significant security control for monitoring and maintaining the safety and integrity of your data in the AWS cloud. When enabled, it records all the activities in your Amazon RDS environment. \n\nThese log files can be crucial in:\n\n- Identifying operational problems in your Amazon RDS database instances \n- Troubleshooting these issues \n- Making sure that the instances are working correctly\n- Providing valuable insights for security audit and compliance purposes\n\nBy ensuring that Amazon RDS logging is enabled, you enhance the visibility into the operations and interactions happening in your databases which might have potential security implications.\n\nTo enable Amazon RDS logging, navigate to the AWS Management Console, open Amazon RDS dashboard, select your database instance and then modify it. Look for 'Log exports', select the logs you want to export and then click on 'continue'. Review the changes and then 'apply immediately' or 'apply during the next scheduled maintenance window', then click 'Modify DB instance'.\n```\nIt is important to review and maintain the logs constantly as the files get updated with fresh data frequently. Please consult the AWS RDS documentation for full, up-to-date details on how to properly implement and utilize Amazon RDS logging."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control could have significant cost implications. Here's a breakdown in the markup format:\n\n1. **Operational inefficiency**: RDS logs are instrumental in assessing, monitoring, analyzing, and auditing the events unfolding in your RDS environment thus, maintaining optimal system operation. Without these logs, system troubleshooting would be difficult and time-consuming, thereby driving up operational costs.\n\n2. **Security Implications**: RDS logs contain information about instances and their connectivity. Missing such data can leave loopholes for security breaches, leading to potential financial losses.\n\n3. **Compliance Violations**: If your organization falls under regulations like SOX, HIPAA, GDPR, or PCI DSS that mandate detailed transaction logging, non-compliance might result in severe legal and financial penalties. Apart from the monetary aspect, it could damage the organization's reputation.\n\n4. **Breach of Accountability**: If logging is not enabled, it limits the visibility of who did what in the system, making accountability practically untraceable. Lack of accountability in case of an incident could lead to financial impropriety, fraud, and data breaches.\n\n5. **Incident Response and Forensics**: When a security incident occurs, logs are often the first place to look. They provide crucial clues in tracing the cause and understanding the impact. Non-compliance would mean inadequate information, leading to poorer response plans, whose result could be financially devastating depending on the severity and response time.\n\nIn summary, the cost of non-compliance to enabling Amazon Relational Database Service (Amazon RDS) logging can have significant financial implications beyond just a direct monetary penalty. It can lead to operational inefficiency, security vulnerabilities, breach of compliance rules, lack of accountability, and inefficient response to incidents, all of which can significantly affect an organization's bottom line."
      ],
      "x-kaytu-usefulness-example": [
        "In a healthcare organization, AWS is used to manage, share and store medical records. The organization uses Amazon RDS for storage purposes. \n\nThe system is supposed to run smoothly, and patient records should be easily retrievable when needed, but recently there have been unforeseen delays and intermittent issues with accessing the patient records from the RDS. \n\nBy enabling Amazon RDS logging, the IT team would be able to identify the cause of these delays quicker since the logs would show them detailed information about the entire system's performance, including specifically any encountered error messages, detailed sequential activities, and duration of each request, user connections and much more information.\n\nThese logs would be invaluable in enabling the IT team to conduct a thorough debugging and troubleshooting process, thus helping them rectify the problem, improve the service for end-user doctors and health care professionals, prevent future similar issues, and ultimately ensure the smooth running of the healthcare services. \n\n```markup\n{\n  \"dbInstanceIdentifier\": \"mydbinstance\",\n  \"enableCloudwatchLogsExports\": [\"error\", \"general\", \"slowquery\"]\n}\n```\nWith the help of above command IT team members can enable different types of logs for their RDS instance."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_apigateway_stage_logging_enabled",
    "Title": "API Gateway stage logging should be enabled",
    "Description": "API Gateway logging displays detailed views of users who accessed the API and the way they accessed the API.",
    "QueryID": "aws_apigateway_stage_logging_enabled",
    "DocumentURI": "policies/aws_apigateway_stage_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/APIGateway"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "**AWS API Gateway Logging**\n\nAPI Gateway is a fully managed service provided by Amazon Web Services (AWS) that enables developers to create, deploy, and manage secure Application Programming Interfaces (APIs) that access AWS or other web services. \n\nAPI Gateway logging is an integral feature of this service that allows developers to monitor and troubleshoot APIs at a detailed level. With logging, you can gain insights into who accessed your API and how they did it. This feature is extremely useful for detecting anomalies, identifying potential security risks, diagnosing issues, and understanding usage patterns. \n\nLogging in API Gateway comes in two types: Access logging and Execution logging. \n\n- **Access Logging**: This records each accessed API including details like request metadata, response metadata, requested resources, caller identity, source IP.\n   \n- **Execution Logging**: This captures information about the various stages in the API Gateway pipeline, which is helpful for debugging potential issues.\n\nAWS API Gateway logging leverages **Amazon CloudWatch**, a scalable monitoring and observability service for developers, system operators, site reliability engineers (SRE), and IT managers to maintain a check on their applications, collect and track metrics, collect and monitor log files, set alarms.\n\nAn example of an API Gateway Access Logging in markup format:\n\n    ```\n    {\n      \"requestId\":\"{request-id}\",\n      \"ip\": \"{source-ip}\",\n      \"caller\":\"{caller}\",\n      \"user\":\"{user}\",\n      \"requestTime\":\"{request-time}\",\n      \"httpMethod\":\"{http-method}\",\n      \"resourcePath\":\"{resource-path}\",\n      \"status\":\"{status}\",\n      \"protocol\":\"{protocol}\",\n      \"responseLength\":\"{response-length}\"\n    }\n    ```\n\nThis log format will provide you with a JSON object containing detailed information every time your API is accessed. Each field in the above script denotes a specific piece of information about the access request."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS Control of enabling API Gateway Logging can be significant and can be understood in following ways:\n\n1. **Security Vulnerabilities:** Without the detailed API logs, organizations wouldn't be able to track the access paths and usage patterns of the APIs. This brings in security vulnerabilities as unauthorized or suspicious activities can’t be detected or tracked. Thus, it might lead to possible data breaches or compromisation of sensitive data.\n\n2. **Difficult Troubleshooting:** API Gateway logging helps in troubleshooting API issues by providing valuable insights into how users interact with them. Non-compliance leads to a harder time understanding and debugging errors which can disturb the normal workflow and critical business operations.\n\n3. **Poor API Governance:** API logs are vital in measuring the performance metrics of the APIs. Without these logs, API administration, optimization, and management can be severely affected leading to poor overall API governance.\n\n4. **Compliance Violations:** Many industries are legally required to maintain such logs for compliance with regulations like GDPR, HIPAA, etc. Non-compliance could lead to significant legal penalties, sanctions, or fines. \n\n5. **Loss of customer trust:** In case of a security breach due to non-compliance, the reputation of an organization can be significantly affected, leading to the loss of customer trust and potentially business loss."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, consider a scenario where your application has a significant increase in error responses. API Gateway logging can help by providing a detailed report and breakdown of every request handled by your APIs during the period of the error increase.\n\nHere's how useful it could be:\n\n```markdown\nYou can check logs to identify:\n1. **Users who accessed the API**: capturing the IP address, location, and time.\n2. **Endpoints accessed**: Knowing which endpoints received the highest traffic can help identify potential bottleneck points causing the errors.\n3. **Method of access**: Information about whether a `GET`, `POST`, or `PUT`, etc., requests were made can help identify if the errors were due to a specific request type.\n4. **Response codes**: If there are any particular error codes repeatedly being returned, it can quickly help identify and rectify issues.\n5. **Payloads sent or received**: In case the errors are due to certain payload data.   \n\nRepresentation of real-time data allows for more swift identification, solutions and management of such issues that may arise. API Gateway logging through AWS cloud watch helps in rectifying faults in a more timely and efficient fashion.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_apigateway_stage_use_waf_web_acl",
    "Title": "API Gateway stage should be associated with waf",
    "Description": "Ensure if an Amazon API Gateway API stage is using a WAF Web ACL. This rule is non compliant if an AWS WAF Web ACL is not used.",
    "QueryID": "aws_apigateway_stage_use_waf_web_acl",
    "DocumentURI": "policies/aws_apigateway_stage_use_waf_web_acl.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/APIGateway"
      ],
      "x-kaytu-explanation": [
        "# AWS Control Explanation\n\n## Control: Ensure Amazon API Gateway API stage is using WAF Web ACL\n\nAmazon API Gateway provides developers with an easy-to-use tool for creating and managing REST APIs. To secure your APIs you can use AWS WAF, a web application firewall that protects any web application or API against common web exploits and bots.\n\nThis control is concerned with checking whether your API Gateway APIs stages are secured using AWS WAF. API stages can include different versions of your API or the same versions running in different environments.\n\n#### Non-Compliance:\n\nIf a Amazon API Gateway API stage is detected to not be using an AWS WAF Web ACL for security, it means this control is non-compliant. \n\nNot using WAF ACLs can expose your API to an increased risk of web exploits such as SQL injection and Cross Site Scripting (XSS), opening the potential for data breaches, loss of sensitive data or poor service performance.\n\n### How To Comply\n\n1. Sign into your AWS Console and navigate to the WAF \u0026 Shield service.\n2. When creating or editing a web ACL, under AWS resources to associate the web ACL with, select the resources you want.\n3. Choose your Amazon API Gateway API from the list and save changes.\n\n### Conclusion\n\nBy ensuring your Amazon API Gateway API stages utilise AWS WAF Web ACLs, you are adding an extra layer of protection against threats. It is considered a best practice in the realm of API security on AWS."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the specific AWS control that requires all Amazon API Gateway API stages to utilize a WAF (Web Application Firewall) Web ACL (Access Control List) can be broken down into several important areas:\n\n1. **Security Risks:** AWS WAF helps to protect your applications by filtering traffic based on conditions that you define (for example, IP addresses), which allows for the blocking of common web-based attacks such as SQL Injection and Cross-Site Scripting. Non-compliance might expose your API and potentially the underlying infrastructure to these attacks.\n\n2. **Data Breaches:** Without using the WAF ACL, malicious users may potentially exploit your APIs, leading to data breaches. This could result in costly penalties, loss of customer trust, and potential legal implications.\n\n3. **Increased costs:** In the event of an attack, without the protective layer of AWS WAF, your API Gateway could be overwhelmed with fake traffic (DDoS attack). This could lead to a potential surge in unwanted traffic, leading to higher usage and therefore, higher costs.\n\n4. **Non-compliance Penalties:** For organizations subject to regulatory compliance requirements (such as PCI-DSS, GDPR, or HIPAA), non-compliance with mandated security controls like a WAF may lead to audits, penalties, and fines.\n\n5. **Reputation Damage:** A successful attack or data breach due to non-compliance with this control can cause severe damage to your organization's reputation, which could lead to valuable customer losses or a declining market valuation.\n\n6. **Application Downtime:** In the case of successful security attacks, your service might go down causing business interruption, which leads to loss of revenue, and customers dissatisfaction.\n   \nBy ensuring compliance with AWS controls like this, you are taking steps to protect your infrastructure and data from threats, which can save your business from costs associated with data breaches and service disruptions."
      ],
      "x-kaytu-usefulness-example": [
        "AWS WAF (Web Application Firewall) provides a security layer for your web applications by protecting it from common web exploits that can affect availability, compromise security, or consume excessive resources. By integrating AWS WAF with Amazon API Gateway, you can provide an additional protective shield to your APIs hosted on AWS.\n\nFor example, consider you have a serverless application running on AWS, which uses API Gateway to expose its APIs over the internet. These APIs handle sensitive operations like user profile management, order placement, transactions info, etc. Since these APIs are exposed to the internet, they are vulnerable to various attacks like SQL injection, cross-site scripting (XSS), etc.\n\nSo, to add an extra layer of security to your APIs, you can associate an existing AWS WAF Web ACL (Access Control List) to API Gateway. This Web ACL contains rules that AWS WAF uses to identify and block malicious requests. \n\nEnsuring that the API Gateway API stage is using a WAF Web ACL can help your application maintain compliance with security standards and policies, and protect your valuable APIs and the data they handle from potential security threats.\n\nMarkup example:\n\n```markdown\n### Protecting APIs using AWS WAF on Amazon API Gateway\n\nWith the increasing threats to web applications, maintaining the security of your APIs becomes incredibly important. By leveraging the [AWS WAF](https://aws.amazon.com/waf/) on [Amazon API Gateway](https://aws.amazon.com/api-gateway/), you can add an additional layer of security to your APIs. \n\nAWS WAF offers features to protect your APIs against common web exploits such as SQL injection, cross-site scripting (XSS), and more, that could affect your data security and resource consumption. In case you have a serverless application with APIs vulnerable to these attacks, integrating AWS WAF can help you ensure data safety.\n\nFor using AWS WAF with Amazon API Gateway, follow the below steps:\n\n1. Navigate to the AWS WAF console.\n2. Create a new Web ACL or choose an existing one.\n3. Define your custom rules to identify the suspicious requests.\n4. Associate this Web ACL with the API stage in the API Gateway.\n \nUpon successful association, all the incoming request traffic to the APIs is monitored based on your defined rules in the AWS WAF Web ACL. Attaching a WAF Web ACL ensures stronger security for your APIs and aids in maintaining compliance as per set standards and policies.\n```\nBy implementing a necessary control to check if the API Gateway stage uses a WAF Web ACL, you can continuously monitor and ensure that the application APIs have the necessary protective measures enabled."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_instance_iam_profile_attached",
    "Title": "EC2 instances should have IAM profile attached",
    "Description": "Ensure if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access Management (IAM) profile attached to it. This rule is non compliant if no IAM profile is attached to the Amazon EC2 instance.",
    "QueryID": "aws_ec2_instance_iam_profile_attached",
    "DocumentURI": "policies/aws_ec2_instance_iam_profile_attached.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EC2"
      ],
      "x-kaytu-explanation": [
        "This AWS Control is essentially a rule or regulation that you need to enforce when setting up and managing your Amazon EC2 instances (which are virtual servers in Amazon's Elastic Compute Cloud). \n\nSpecifically, this control requires that every Amazon EC2 instance has an Identity and Access Management (IAM) profile associated with it. IAM is a service that helps you securely control access to AWS resources. An IAM profile is an entity that passes certain permissions to an EC2 instance at launch time.\n\nHere's this control described in markup format:\n\n```markdown\n## AWS Control: EC2 Instance IAM Profile Requirement\n\n**Rule**: Each Amazon EC2 instance **must** have an associated IAM profile.\n\n**Compliance**: \n\n- If an Amazon EC2 instance **does have** an associated IAM profile, it is compliant with this control.\n- If an Amazon EC2 instance **does not have** any associated IAM profile, it is non-compliant with this control.\n\n**Rationale**: IAM profiles for EC2 instances enable you to securely control the access that the instance has to AWS resources. This adds an additional layer of security and prevents instances from having more access rights than they need.\n```\n\nThis is a good security measure as it helps prevent unauthorized access to your AWS resources."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this particular AWS control can have serious implications in terms of security, operational efficiency, and regulatory adherence. Here are few potential costs associated with non-compliance:\n\n1. **Security Vulnerability**: Not attaching an IAM profile to an EC2 instance can expose your resources to unauthorized access. IAM profiles are used to manage permissions and control which actions can be performed on the associated resources. Non-compliance can thus lead to security breaches and potential data loss, incurring costs associated with data recovery and system repair.\n\n2. **Operational Inefficiency**: IAM profiles are essential to delegating and managing responsibilities efficiently within a team. A lack of IAM profiles can lead to operational inefficiencies where there's no clear ownership or control over instances, leading to wasted resources and higher operational cost.\n\n3. **Potential Regulatory Fines**: For certain industries, complying with security guidelines and protocols such as attaching IAM profiles to all EC2 instances is not an option, it's a necessity enforced by laws and regulations. Non-compliance with such regulations can result in substantial fines or legal consequences.\n\n4. **Reputational Damage**: Lastly, if a company faces a security breach due to non-compliance with basic AWS security protocols, it can lead to significant reputational damage. This can result in loss of customer trust, diminishing market share, and ultimately, reduced profits."
      ],
      "x-kaytu-usefulness-example": [
        "AWS Control allows for greater security and access management in the cloud. For example, a company may want to run certain applications or tasks on EC2 instances that require specific IAM roles. \n\nInstance:\n\nCompany 'X' has a series of EC2 instances running critical services that require access to other AWS services such as S3, DynamoDB, and SQS. They use IAM roles to grant the necessary permissions and attach these IAM profiles to the EC2 instances. \n\nOne day, a developer mistakenly launches a new EC2 instance for testing purposes but forgets to attach an IAM profile. Since the EC2 instances without IAM profiles are non-compliant according to the company's security policies, the AWS Control triggers a non-compliance alert. This helps the security team to quickly identify the issue and take corrective action. \n\nWithin a couple of hours, the developer or system admin can attach the correct IAM profile to the EC2 instance or, if the EC2 instance is not necessary, terminate it, thus helping to maintain the company's strict security posture. \n\nTherefore, this AWS Control check is crucial as it ensures that only EC2 instances with proper IAM profiles are running, reinforcing security and minimizing the risk of unauthorized access or actions. \n\nThis security control helps in identifying potential weak links in the company's infrastructure and aids in maintaining strict compliance with their security policies. \n\nIn the example scenario, this control is useful in identifying and rectifying a mistake that could have potentially led to security vulnerabilities."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudtrail_s3_data_events_enabled",
    "Title": "All S3 buckets should log S3 data events in CloudTrail",
    "Description": "The collection of Simple Storage Service (Amazon S3) data events helps in detecting any anomalous activity. The details include AWS account information that accessed an Amazon S3 bucket, IP address, and time of event.",
    "QueryID": "aws_cloudtrail_s3_data_events_enabled",
    "DocumentURI": "policies/aws_cloudtrail_s3_data_events_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/CloudTrail"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Control is a security service provided by Amazon that helps you track and observe actions made on your AWS account. This service provides a detailed record of actions made on your S3 buckets.\n\nOne of the many features of AWS Control is its ability to continuously monitor and log data events on your S3 buckets. This involves monitoring who accessed your S3 buckets, from where (IP Address), when (time of event), and what actions they performed.\n\n```markup\nAWS Control offers:\n\n- ***S3 Data Events Collection***: Enables capturing of detailed information about actions made on your S3 bucket. This includes viewing, creating, deleting, and modifying S3 objects.\n\n- ***In-depth Visibility***: Details such as AWS account information that accessed an S3 bucket, IP address, and the time of event are logged and can be used for analysis.\n\n- ***Anomalous Activity Detection***: By recording and analyzing event details, AWS Control helps in detecting any unusual or suspicious activity on your S3 buckets. This can be a critical tool in identifying and preventing potential data breaches.\n\n- ***Ease of Integration***: AWS Control can easily integrate with other AWS services and third-party applications for advanced threat analysis and auditing.\n```\n\nTo wrap it up, AWS Control provides a powerful tool for managing and securing your AWS infrastructure, especially in terms of monitoring access to your S3 buckets and detecting any abnormal activities."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control, i.e., not collecting Simple Storage Service (Amazon S3) data events, can lead to several costs. Some of them include potential fines for not adhering to certain compliances, untracked misuse of data which can result in data breach \u0026 privacy issues, and inability to perform forensic investigation in case of any security incident.\n\nCosts explained in details below:\n\n1. **Compliance Fines:**\nMany industries have regulations that require companies to have appropriate logging and monitoring of access to certain data. If your company is not complying with AWS Control by not collecting S3 data events, it may face significant fines.\n\n2. **Potential Data Breaches:**\nWithout collecting S3 data events, anomalous activity may go undetected. For instance, unauthorized users may access or download sensitive data, leading to a potential data breach. The cost of such a breach can be extraordinarily high, considering potential regulatory fines, loss of customer trust, and the associated business impact.\n\n3. **Forensic Costs:**\nLogs from AWS Controls are crucial for forensic analysis while investigating a security incident. Without these logs to provide insight into what occurred, investigations can be slowed and become more costly.\n\n4. **Operational Inefficiencies:**\nAbnormal use of resources, such as excessive downloads, can indicate a problem such as a misconfiguration or a poorly optimized process. If this goes unnoticed due to non collection of S3 data events, it could result in increased costs unnecessarily over time.\n\n5. **Reputation Damage:**\nInadequate control and auditing of S3 data events could potentially lead to public exposure of sensitive data, and in worst-case scenarios, hefty fines and damage to the company's reputation. The indirect cost of lost business due to reputation damage could be significant.\n\nIn conclusion, not complying with this AWS Control can lead to significant financial expenditures for a company, in addition to potential damage to its reputation. This AWS Control is a critical component in maintaining a secure and compliant AWS environment."
      ],
      "x-kaytu-usefulness-example": [
        "For example, an e-commerce company uses Amazon S3 to store customer details, order receipts, and other sensitive information. An unfortunate situation arises in which the company suspects unauthorized access to its data. \n\nHaving enabled the collection of Amazon S3 data events, they can use these event logs to identify the source of these unauthorized activities. The logs will instantly provide them with the AWS account information that accessed their S3 bucket along with the IP address and time of event. \n\nThis allows the company to quickly track and flag any anomalous activity, helping them protect the confidentiality and integrity of their stored data. This AWS control gives them the power to accurately audit and monitor their AWS infrastructure, ensuring higher levels of data security."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_codebuild_project_logging_enabled",
    "Title": "CodeBuild projects should have logging enabled",
    "Description": "This control checks if an AWS CodeBuild project environment has at least one log option enabled. The rule is non compliant if the status of all present log configurations is set to 'DISABLED'.",
    "QueryID": "aws_codebuild_project_logging_enabled",
    "DocumentURI": "policies/aws_codebuild_project_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CodeBuild"
      ],
      "x-kaytu-explanation": [
        "## AWS Control: CodeBuild Project Log Options Enabled\n\n**Control Description:**\nThis control is designed to ensure that an AWS CodeBuild project's setup includes at least one log option enabled. AWS CodeBuild is a fully-managed continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy.\n\nLogging in AWS CodeBuild gathers information about the build process, such as when phases start and end, and whether a phase ends successfully or fails. It can diagnose and troubleshoot failed build attempts, understand software build processes, and improve build speed.\n\n**Compliance:**\nThe rule finds this instance as non-compliant if the status of all configurations of logs (CloudWatch, S3, and others) in the project environment is set as 'DISABLED'. This means that no activity related to the build project is being logged, which can hinder monitoring, debugging, and auditing processes.\n\n**Remediation:**\nTo make the CodeBuild project compliant, ensure that at least one log option is enabled. This could be as simple as enabling AWS CloudWatch Logs or Amazon S3 logs in your AWS CodeBuild project environment settings.\n\n**Example Usage:**\n```markdown\n- AWS Control: CodeBuild Project Log Options Enabled\n  - Control Category: Monitor and Audit\n  - AWS Services: AWS CodeBuild\n```\n\n**Benefits:**\n- Enables activity monitoring, troubleshooting, and process improvement through logs.\n- Enhances security by providing audit trail.\n- Supports compliance with logging and monitoring requirements."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control could result in various cost implications and risks:\n\n1. **Loss of Traceability**: When the log options in AWS CodeBuild are disabled, it means that no logs for your build projects are gathered. This hurts your ability to debug and diagnose issues when things go wrong. It could lead to increased issue resolution times, thereby impacting productivity and operational efficiency.\n\n2. **Risk of Non-Audibility**: As part of best practices for security and governance, logging is essential for auditing purposes. If the logging is disabled, it could seriously hamper an organization's ability to conduct a thorough investigation in case of security or compliance incidents.\n\n3. **Regulatory Fines and Penalties**: Certain industries and regulatory bodies mandate the logging and monitoring of all activities for compliance purposes. The inability to provide necessary logs due to them being disabled, can lead to hefty fines and penalties.\n\n4. **Potential for Data Loss**: Logs often contain valuable information, which can be used for multiple purposes like application performance monitoring, user behavior analysis, etc. By not having these logs, this knowledge loses out, which might impact the development of better and more customer-centric products and services.\n\nSo, while it may not have a direct costing increasing operational costs, non-compliance to such controls results in potential indirect costs and risks that can have long-term implications for a business."
      ],
      "x-kaytu-usefulness-example": [
        "An example of the usefulness of this AWS Control would be in debugging and operational efficiency. Here's a scenario:\n\nA software company maintains a large number of applications and hence, consistently builds and updates them using AWS CodeBuild, which is a fully managed build service. In order to manage their operations and resources efficiently as well as to troubleshoot issues quickly when they occur, they need detailed logs from each build operation. \n\nHowever, without actively checking, it is possible for teams to accidentally disable logs or forget to enable them in the first place for a new project. This would lead to a lack of transparency and data about the execution of each build operation, impairing the teams' ability to react to potential issues quickly.\n\nWith this AWS Control, an automatic check would notify them if there are no log options enabled in their AWS CodeBuild project environment, which would significantly reduce the risk of disrupted operations, wasted resources and decreased response time for critical issues. This control ensures that they maintain high operational awareness and capability. \n\nHere's how it would look in markup format:\n\n```\nRule {\n  Description \"Check if AWS CodeBuild project environment has at least one log option enabled\",\n  Source {\n    Owner \"AWS\",\n    SourceIdentifier \"LOG_OPTIONS_ENABLED_IN_AWS_CODEBUILD\"\n  },\n  Scope {\n    ComplianceResourceTypes [\"AWS::CodeBuild::Project\"]\n  },\n  Trigger {\n    Type \"Periodic\",\n    PeriodicTriggerProperties {\n      Frequency \"TwentyFour_Hours\"\n    }\n  }\n}\n```\n\nThis rule would run a check every 24 hours, ensuring that there's at least one logging option enabled on all AWS CodeBuild projects within the governed resources."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_ebs_default_encryption_enabled",
    "Title": "EBS default encryption should be enabled",
    "Description": "To help protect data at rest, ensure that encryption is enabled for your Amazon Elastic Block Store (Amazon EBS) volumes.",
    "QueryID": "aws_ec2_ebs_default_encryption_enabled",
    "DocumentURI": "policies/aws_ec2_ebs_default_encryption_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EC2"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS recommends enabling encryption for your Amazon Elastic Block Store (EBS) volumes in order to increase data protection while at rest. Amazon EBS provides the ability to encrypt data at rest using AWS Key Management Service (AWS KMS) which uses 256-bit Advanced Encryption Standard (AES-256). By default, this encryption is not enabled and must be enabled by the user.\n\nHere are some key points to note:\n- When you create an encrypted EBS volume, the data at rest, the disk I/O, and all the snapshots created from the volume are all encrypted.\n- The encryption occurs on the servers that host the EC2 instances, providing encryption of data as it moves between EC2 instances and EBS storage.\n- You can also enforce encryption of an EBS volume by using a suitable IAM policy.\n\nBelow is the code in JSON markup to specify whether the EBS volume should be encrypted:\n```json\n{\n   \"Resources\":{\n      \"MyVolume\":{\n         \"Type\":\"AWS::EC2::Volume\",\n         \"Properties\":{\n            \"AvailabilityZone\":\"us-west-2b\",\n            \"Encrypted\": true,\n            \"KmsKeyId\":\"arn:aws:kms:us-west-2:012345678912:key/abcd1234-a123-456a-a12b-a123b4cd56ef\",\n            \"Size\": \"100\",\n            \"VolumeType\":\"gp2\" \n         }\n      }\n   }\n}\n```\nIn this JSON file,\n- `\"Encrypted\":true` enables the encryption.\n- `\"KmsKeyId\"` is the ID of the key used for the encryption.\n- You must also specify other details like `AvailabilityZone`, `Size`, and `VolumeType` as per the requirements."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control - enabling encryption for your Amazon Elastic Block Store (Amazon EBS) volumes to protect data at rest - could cost in numerous ways, such as:\n\n**1. Data Breach:**\n\n   Unencrypted data can be vulnerable to breaches. In case of a security compromise, unauthorized individuals can gain access to sensitive information which can degrade the customer's trust and the organization's public image. The monetary costs of a data breach can be substantial, from paying for remediation efforts to potential fines by regulatory bodies.\n\n**2. Regulatory Fines and Penalties:**\n\n   Lack of encryption might violate regulations such as the General Data Protection Regulation (GDPR), Health Insurance Portability and Accountability Act (HIPAA), and others. Failure to comply with these regulations can potentially lead to hefty fines or legal penalties.\n\n**3. Loss of Business:**\n\n   If data is not properly protected, it might lead to loss of customers, especially if a breach occurs. The cost of winning back client trust or acquiring new customers is significantly high.\n\n**4. Operational Disruptions:**\n\n   A data breach stemming from non-compliance could also lead to operational disruptions, leading to loss of productivity and revenue.\n\n**5. Increased Risk of Litigation:**\n\n    If sensitive or personal customer data is exposed, there could be increased risk of litigation. Customers may sue the company for not taking appropriate measures to secure their data, which can result in substantial financial costs.\n\nIn short, not complying with the AWS control to keep EBS volumes encrypted can have serious reputational, regulatory, and financial implications."
      ],
      "x-kaytu-usefulness-example": [
        "Example:\n\nIn a financial company, sensitive data such as credit card information, transaction details, and personal identifiers are typically stored and processed. In such scenarios, AWS EBS volumes are likely used to store this data.\n\nWithout encryption, if unauthorized users gain access to these EBS volumes, they could potentially view and exploit the sensitive information. This might result in huge financial and reputational loss for the company as well as severe inconvenience for their clients.\n\nBy enabling encryption for Amazon EBS volumes, it ensures that the data at rest is unreadable by any unauthorized users, even if they somehow get access to the data. In other words, the data is secure from unauthorized access and the associated risks are hence mitigated. This is particularly important for companies handling sensitive or personal data and those that must comply with data security standards and regulations.\n\nThis setup could be represented as follows in the AWS Management Console:\n\n```markup\n{\n    \"Ebs\": {\n        \"DeleteOnTermination\": true,\n        \"VolumeSize\": 8, \n        \"Encrypted\": true,\n        \"KmsKeyId\": \"arn:aws:kms:us-east-2:012345678901:key/abcd1234-a123-456a-a12b-a123b4cd56ef\",\n        \"VolumeType\": \"gp2\"\n    }\n}\n```\n\nIn this markup, `\"Encrypted\": true` enables encryption for the EBS volume, while `KmsKeyId` signifies the customer master key (CMK) to use with AWS Key Management Service (KMS) for encrypting the EBS volume. This is just an example encryption solution and a company’s encryption strategy will depend on their specific security needs and compliance requirements."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudtrail_security_trail_enabled",
    "Title": "At least one trail should be enabled with security best practices",
    "Description": "This rule helps ensure the use of AWS recommended security best practices for AWS CloudTrail, by checking for the enablement of multiple settings. These include the use of log encryption, log validation, and enabling AWS CloudTrail in multiple regions.",
    "QueryID": "aws_cloudtrail_security_trail_enabled",
    "DocumentURI": "policies/aws_cloudtrail_security_trail_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CloudTrail"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control for AWS CloudTrail Security Best Practices\n\nThis AWS control is designed to enforce the AWS recommended best practices for security in AWS CloudTrail. It evaluates numerous settings, including:\n\n1. **Log encryption**: This ensures that all your event logs recorded by CloudTrail are encrypted using AWS Key Management Service (KMS) keys. The encryption of logs helps to protect sensitive data and meet compliance requirements for data-at-rest encryption.\n\n2. **Log validation**: This setting helps to ensure the integrity of the event logs. It prevents any tampering, deletion or modification of the logs. Once log file validation is enabled, any changes to the log files are recognizable during the validation process.\n\n3. **Multi-region CloudTrail**: This setting enforces that AWS CloudTrail is enabled in all AWS regions, not just the region where you are currently operating. This helps to ensure that you can track API activity regardless of where it occurs in your AWS environment.\n\nThe control checks these settings regularly for compliance. If any of these settings are found non-compliant, it generates a report outlining these non-compliant resources and triggers necessary actions to mitigate any potential risks. This helps maintain high-security standards and protect your AWS resources from potential threats."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control of using recommended security best practices for AWS CloudTrail may result in the following costs:\n\n1. **Security Risks**: Without log validation, log encryption, and enabling AWS CloudTrail in multiple regions, you may expose your AWS operations to security vulnerabilities. An attacker could potentially alter or delete logs, which can impact audit trails. \n\n    1. **Costs from breaches**: Such security vulnerabilities could allow unauthorized access to sensitive data, resulting in costly data breaches and potentially legal repercussions.\n\n    2. **Regulatory fines**: Depending on the jurisdiction and the nature of the business, there could also be regulatory fines for not following prescribed security best practices.\n\n2. **Operational Inefficiencies**: Without CloudTrail being enabled in all regions, you might miss activities in regions that are not covered. This could lead to operational inefficiencies and issues in detecting abnormalities in your AWS environment.\n\n3. **Increased incident response time**: In the event of an incident, the absence of integral logs can drastically increase the time it takes to respond and recover.\n\nIn summary, non-compliance to this AWS Control might result in financial costs, legal issues, and inefficient and less secure operations. Therefore, it's strongly recommended to follow AWS's security best practices for AWS CloudTrail."
      ],
      "x-kaytu-usefulness-example": [
        "An example of the usefulness of this AWS control is in an e-commerce organization that handles sensitive customer data and credit card information. \n\n```markdown\nA large, multi-national e-commerce company that operates in multiple geographical locations, have a great deal of sensitive and classified information. In order to ensure the highest level of security integrity, it has to take several measures. One of them is utilizing AWS CloudTrail.\n\nWith this control, the organization can check whether the encryption and validation of logs are enabled. If these security measures are not enabled, it implies that they're at risk of unauthorized data breaches or alterations in log files. This may result in non-compliance to standards like PCI-DSS which can lead to heavy fines, and even jeopardize their credibility among customers.\n\nLikewise, by checking the enablement of CloudTrail in all regions, the organization ensures that all actions performed in every region are recorded. This is crucial since a blind spot in a single region can be manipulated by a malicious actor to gain unauthorized access and perform illicit activities. \n\nIn conclusion, the rule potentially helps this e-commerce company to increase overall security posture, compliance status, and credibility by making sure that valuable and sensitive customer data and credit card information are adequately protected.\n```\n"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_root_user_hardware_mfa_enabled",
    "Title": "IAM root user hardware MFA should be enabled",
    "Description": "Manage access to resources in the AWS Cloud by ensuring hardware MFA is enabled for the root user.",
    "QueryID": "aws_iam_root_user_hardware_mfa_enabled",
    "DocumentURI": "policies/aws_iam_root_user_hardware_mfa_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Enabling Hardware MFA for Root User \n\n## Overview \n\nMulti-Factor Authentication (MFA) is a feature that enhances security by requiring users to present two separate forms of identification: something they know (like a password) and something they have (like a hardware MFA device). It is recommended for AWS to enable MFA for the root user to increase the security of AWS resources. \n\n## Benefits \n\n- **Enhanced Security**: Prevent unauthorized access to AWS services and resources.\n- **Compliance**: Meet regulatory requirements for data protection and privacy. \n- **Risk Mitigation**: Minimize the risk of data breaches and maintain AWS functionality. \n\n## Enabling Hardware MFA for Root User\n\n1. Sign in to the AWS Management Console as the root user.\n2. Navigate to the IAM console.\n3. In the navigation pane, select `Users`.\n4. Choose your IAM username (not the check box).\n5. In the `Security credentials` tab, go to the `Assigned MFA device` section, and then choose `Manage`.\n6. In the `Manage MFA` page, choose `Multi-factor authentication (MFA)`.\n7. Select `Enable` and choose a `Hardware MFA` device.\n8. In the `Manage MFA Device wizard`, in the `MFA code 1` box, enter the six-digit number that's currently displayed on the MFA device. Wait up to 30 seconds for the device to generate a new number, and then enter that number in the `MFA code 2` box. Choose `Assign MFA`.\n   \n## Conclusion \n\nBy ensuring hardware MFA is enabled for the root user, you can effectively manage access to resources in the AWS Cloud. This adds an extra layer of protection and enhances the overall security of your AWS resources."
      ],
      "x-kaytu-noncompliance-cost": [
        "It's critical to manage access to activities and resources in AWS by enabling Multi-Factor Authentication (MFA) for root users, and specifically, hardware MFA where possible. Non-compliance to this control can lead to several potential negative outcomes, including:\n\n1. **Security Vulnerabilities:** Without MFA, access to root accounts and high-level privileges is less secure, making your environment more susceptible to unauthorized access, data breaches, or loss of sensitive information.\n\n2. **Financial Impact:** If unauthorized access occurs, there could be unwanted use of Amazon Web Services, leading to unexpected and potentially significant financial costs.\n\n3. **Reputational Damage:** Breaches associated with poor security practices can lead to reputational harm, undermining customer trust. This could also apply to potential business partners or investors, who might become more reluctant to invest in a company seen as not prioritizing security.\n\n4. **Non-Compliance Penalties:** Non-compliance with data protection regulations and standards, such as GDPR, could result in heavy financial penalties.\n\n5. **Operational Disruptions:** Unauthorized access to the root user could lead to disruption of your AWS services, impacting business continuity and causing potential delays and setbacks. \n\n6. **Inability to Recover Data or Services:** If an attacker gains access to your root user without MFA, they could delete services or data. This could result in permanently lost data or critical services, as well as potential recovery costs if possible to recover. \n\nBy ensuring that hardware MFA is enabled for the root user, these risks can be mitigated."
      ],
      "x-kaytu-usefulness-example": [
        "This AWS control emphasizes the security of an AWS account. By enabling hardware MFA (Multi-Factor Authentication) for the root user, access to resources in the AWS Cloud becomes highly secure. It reduces the chances of unauthorized access even if the root user credentials get compromised. \n\nExample: \n\nImagine an organization managing an online retail platform with customer data stored on the AWS Cloud. The root user, for this AWS account, has the highest privileges and can access all resources, including sensitive customer data. \n\nIf a person with malicious intent gains the root user password, they can potentially cause havoc by manipulating or stealing data. A hardware MFA device configured for the root user adds an extra layer of security. Even if they obtain the password, without the MFA device, unauthorized individuals cannot access the critical data. This control thereby greatly reduces the risk of data breaches and illegal activities."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_user_console_access_mfa_enabled",
    "Title": "IAM users with console access should have MFA enabled",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that MFA is enabled for all AWS Identity and Access Management (IAM) users that have a console password.",
    "QueryID": "aws_iam_user_console_access_mfa_enabled",
    "DocumentURI": "policies/aws_iam_user_console_access_mfa_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Markup version:\n\n# AWS Control: Managing Access to Resources\n\nEnsure that **Multi-Factor Authentication (MFA)** is enabled for all **AWS Identity and Access Management (IAM)** users who have a console password. This management setup significantly contributes to the safe and secure use of AWS cloud resources.\n\n## MFA for IAM Users\n\nMulti-Factor Authentication adds an extra layer of protection on your AWS resources. Besides the standard username and password, it requires users to provide a second piece of information (authentication code) to confirm their identity before granting access to the online resources.\n\n## How to enable MFA?\n\n1. Sign in to the **AWS Management Console** as the **IAM user**.\n2. Navigate to your **IAM dashboard**.\n3. In the navigation pane, choose **Users**.\n4. Select the name of the desired **IAM user**.\n5. Under the **User Security Credentials** section, next to **Assigned MFA device**, choose **Manage**.\n6. Follow the prompts to set up the MFA device.\n\nThis control helps maintain secure access to your AWS cloud resources, ensuring that only authorized users have access.\n\n**NB:** The console password should be strong enough. A strong password includes a mixture of uppercase and lowercase letters, numbers, and special characters."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-Compliance to this AWS Control can result in several high-risk cost implications:\n\n1. **Security Breaches** - If MFA (Multi-Factor Authentication) is not enabled, it makes it easier for unauthorized users to gain access to your AWS Cloud resources if they obtain an IAM user's password. This can lead to data breaches, theft of sensitive information, and unauthorized changes to your environment.\n\n2. **Financial Losses** - Unauthorized access could also result in financial losses. An attacker who gains control of your resources could misuse services and run up expensive bills on your cloud account.\n\n3. **Regulatory Fines** - Many industry regulations and standards, such as GDPR, PCI DSS, require the implementation of strong access controls, including MFA. Non-Compliance can result in financial fines.\n\n4. **Reputation Damage** - Data breaches and security incidents as a result of lack of MFA could damage your company's reputation, potentially resulting in loss of customers or business partnerships.\n\n5. **Operational Downtime** - If an intrusion occurs, you may need to halt operations until the breach is controlled, which leads to operational downtime, reduced productivity, and potential financial losses.\n\nIn conclusion, the cost of non-compliance with the AWS control mandating MFA for AWS IAM users can be extremely high, potentially involving security breaches, financial losses, regulatory fines, and even damage to the company's reputation."
      ],
      "x-kaytu-usefulness-example": [
        "The Multi-Factor Authentication (MFA) feature in AWS Identity and Access Management (IAM) is a vital control tool that strengthens the security of your AWS environment, especially when users are provided access to sensitive resources. \n\nFor example, consider a scenario where a company's AWS environment is primarily used for storing sensitive customer data which is accessed and managed by various IAM users. In such cases, it's critically important to protect these resources from unauthorized access and potential breaches. \n\nBy enabling MFA for all IAM users with console password, each user will be required to enter a unique authentication code from their AWS MFA device, in addition to their standard AWS credentials. Here is an example in the markup format:\n\n```\n```yaml\nresource \"aws_iam_user\" \"lb\" {\n  name = \"loadbalancer\"\n  path = \"/system/\"\n\n  tags = {\n    tag-key = \"MFAEnabled\"\n  }\n}\n\nresource \"aws_iam_user_login_profile\" \"lb\" {\n  user    = aws_iam_user.lb.name\n  pgp_key = \"keybase:madeupkey\"\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\nresource \"aws_iam_user_mfa\" \"lb\" {\n  user   = aws_iam_user.lb.name\n  serial = aws_iam_virtual_mfa_device.lb_mfa.arn\n}\n\nresource \"aws_iam_virtual_mfa_device\" \"lb_mfa\" {\n  name = \"EnableMFAFor${aws_iam_user.lb.name}\"\n}\n\n```\n```\n\nIn the above AWS configuration in HashiCorp Configuration Language (HCL), a new IAM user named 'loadbalancer' is created along with a login profile. A virtual Multi-Factor Authentication (MFA) device is then assigned to this user, thereby mandating the need for a uniquely generated code from the MFA device for every login attempt. This method helps in providing an additional layer of protection to the company's critical customer data."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_managed_policy_attached_to_role",
    "Title": "IAM AWS managed policies should be attached to IAM role",
    "Description": "This control checks if all AWS managed policies specified in the list of managed policies are attached to the AWS Identity and Access Management (IAM) role. The rule is non compliant if an AWS managed policy is not attached to the IAM role.",
    "QueryID": "aws_iam_managed_policy_attached_to_role",
    "DocumentURI": "policies/aws_iam_managed_policy_attached_to_role.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control Explanation\n\nThis control is used to oversee and manage access to your resources in AWS. The control is related to AWS Identity and Access Management (IAM) roles and managed policies. Here is what it does:\n\n- **AWS IAM roles** are a secure way to grant permissions to entities (users or applications) that you trust. Instead of creating individual IAM users, you can create a role and define permissions for it, then attach these permissions to multiple entities.\n\n- **AWS managed policies** are standalone policies that you can attach to multiple users, groups, and roles in your AWS account. They are predefined by AWS and cover common use cases.\n\nTherefore, this control performs an audit operation to check whether all AWS managed policies that you specified in a certain list are actually attached to your AWS IAM role.\n\nIf this is not the case, then your setup is not compliant with this control. This means there are identity and access management policies that should be attached to your IAM roles but are currently not attached.\n\nThe primary purpose of this control is to help you ensure that IAM roles in your account have required permissions via attached managed policies, providing a measure of security, auditability, and compliance."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control can have several cost implications:\n\n1. **Security Vulnerabilities:** If appropriate managed policies aren't attached to an IAM role, then it's likely that the entity assuming the role doesn't have the necessary permissions to perform its intended operations. This could open your cloud environment up to potential security hazards and privacy concerns. Incidences like these could result in substantial fines and penalties according to regulations like GDPR, HIPAA, SOC, CCPA, etc.\n\n2. **Operational Disruption:** Lack of necessary permissions may disrupt regular operations and workflows causing delays and negatively affecting productivity. Depending on the severity of the interruption, this can translate into significant financial loss.\n\n3. **Increased Audit and Remediation Cost:** Non-compliance to IAM policies can increase the time, effort and cost required for auditing and remediation. The effort to investigate and fix non-compliance issues can be substantial and might require additional resources.\n\n4. **Reputational Damage:** Cases of security breaches or non-compliance can harm an organization's reputation, resulting in loss of customers, partners, or decreased business opportunities.\n\n5. **Legal Ramifications:** Depending on the nature of your services, non-compliance could also lead to legal actions, which will certainly result in additional costs, including potential sanctions or compensations.\n\nIn summary, ensuring that AWS managed policies are appropriately attached to IAM roles is necessary for maintaining secure and efficient operations, avoiding unnecessary costs associated with non-compliance."
      ],
      "x-kaytu-usefulness-example": [
        "AWS managed policies are versions of IAM policies that are controlled by AWS. These policies allow you to manage permissions and can help you follow best practices for securing your AWS resources. The usefulness of this control can be demonstrated through an example. \n\nFor example, let's say your organization operates a large number of AWS services such as EC2, S3, DynamoDB, etc. Managing and controlling their access at user level can become tiresome and might lead to security issues. By using managed policies, you can standardize the required permissions into policies and attach them to roles. This way, whoever assumes the role will have the necessary permissions without the need for manual assignment.\n\nIf you have a Data Science team that requires read-only access to S3 buckets, you would create an IAM Role named 'DataScienceS3ReadOnly' and attach the 'AmazonS3ReadOnlyAccess' AWS managed policy to it. When a team member assumes this role, the AWS Control verifies if the 'AmazonS3ReadOnlyAccess' managed policy is attached to it. If not, the rule would be non compliant, prompting a review and the necessary amendment, thus assuring that users have the required permissions and preventing unauthorized access. This automated check greatly simplifies security management on AWS."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_all_policy_no_service_wild_card",
    "Title": "Ensure IAM policy should not grant full access to service",
    "Description": "Checks if AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. The rule is non compliant if the managed IAM policy allows full access to at least 1 AWS service.",
    "QueryID": "aws_iam_policy_custom_no_service_wildcard",
    "DocumentURI": "policies/aws_iam_all_policy_no_service_wild_card.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/IAM"
      ],
      "x-kaytu-explanation": [
        "AWS IAM (Identity and Access Management) allows you to manage access to AWS services and resources securely. One way to control access to your AWS resources is through IAM policies which are essentially documents that define permissions.\n\nThis AWS Control checks if IAM policies grant full permissions to all actions on an individual AWS resource, which could potentially be a security risk.\n\nTo elaborate, when a managed IAM policy allows full access to at least one AWS service, the rule becomes non-compliant. Full access means the policy has the 'Action' element set to '*', which may allow the policy holder unrestricted access to perform any operation on the specified AWS resources.\n\n```markdown\n## AWS Control: Check IAM Policy Permissions\n\n**Purpose:** \n\nThe control checks whether AWS Identity and Access Management (IAM) policies grant permissions to all actions on individual AWS resources. \n\n**Rule:** \n\nThe rule is non-compliant if the managed IAM policy allows full access to at least one AWS service.\n\n**Non-Compliance:**\n\nA non-compliant policy is one that grants full access ('Action' set to '*') to an AWS service, meaning it has permissions to perform any operation on the specified AWS resources. \n\n**Why It Matters:**\n\nGranting full access to an IAM user could potentially lead to unintended or malicious actions, causing data loss or service disruption, among other risks. \n\n**How to Comply:**\n\nTo comply with this rule and ensure that IAM policies are configured securely, carefully limit the permissions granted by each policy to fit the specific needs of its holder.\n```\nRemember, this is aimed at improving security by ensuring IAM policies are appropriately scoped, operating under the principle of least privilege where users have just enough access to perform their tasks.\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control could lead to significant costs, both financial and operational, for organizations. Here are a few potential costs:\n\n1. **Security breaches**: If an IAM policy allows full access to at least one AWS service to unauthorized users, it could result in data breaches, leading to both financial losses and regulatory penalties.\n\n2. **Loss of data integrity**: Unauthorized or inappropriate access can lead to data corruption or loss, which may require costly recovery procedures.\n\n3. **Regulatory fines**: Organizations under regulatory requirements like GDPR, HIPAA etc. could face heavy penalties for noncompliance with data protection and privacy laws which may be the result of poor access controls.\n\n4. **Reputation damage**: A security breach or loss of data can harm an organization's reputation, resulting in loss of business or customers.\n\n5. **Operational disruption**: Non-compliance could result in a disruption of critical services, impacting the organization's ability to conduct business operations.\n\nHence, it is crucial that IAM policies be configured correctly to grant only necessary permissions to the relevant services or users, thus maintaining the principle of least privilege.\n\n```markdown\n## Cost of Non-Compliance to AWS IAM Control\n\n- **Security Breaches**: Unauthorized full access can lead to potential security breaches causing financial and regulatory implications.\n- **Loss Of Data Integrity**: Unrestricted access can result in corruption or loss of data, incurring costs for data recovery and service restoration.\n- **Regulatory Fines**: Non-compliance with data protection and privacy laws such as GDPR or HIPAA could result in heavy penalties.\n- **Reputation Damage**: Security breaches or data loss can severely harm an organization's reputation, resulting in potential loss of business or customers.\n- **Operational Disruption**: Poorly managed access controls could disrupt critical services, affecting business operations and requiring resources for restoration.\n```"
      ],
      "x-kaytu-usefulness-example": [
        "AWS IAM policies grant permissions to control access to AWS services and resources. This control check is essential in preventing security breaches due to unauthorized access to AWS services.\n\nFor instance, a company is using various AWS services like Amazon S3, EC2 instances, Lambda functions, and more. Every service demands certain permissions and roles. Having all-access roles could pose a threat to the system's integrity as it becomes a single point of failure. In other words, if a user or role with full access permissions is compromised, the malicious actor could potentially have control over all AWS services, leading to potential damage.\n\nThus, this control that checks if IAM policies allow full access to any service is crucial for maintaining security standards. When this control is found to be non-compliant, the administrators can quickly act to modify the IAM policy to limit access and safeguard the system integrity and security. Example corrective actions could be segmenting roles and policies related to specific services, implementing least privilege access model, etc. \n\n```\nA sample policy that would be marked noncompliant by this control could look like:\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"*\",\n            \"Resource\": \"*\"\n        }\n    ]\n}\n\nThis policy allows all actions (\"Action\": \"*\") on all resources (\"Resource\": \"*\"), which is a potential security risk.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudtrail_trail_validation_enabled",
    "Title": "CloudTrail trail log file validation should be enabled",
    "Description": "Utilize AWS CloudTrail log file validation to check the integrity of CloudTrail logs. Log file validation helps determine if a log file was modified or deleted or unchanged after CloudTrail delivered it. This feature is built using industry standard algorithms: SHA-256 for hashing and SHA-256 with RSA for digital signing. This makes it computationally infeasible to modify, delete or forge CloudTrail log files without detection.",
    "QueryID": "aws_cloudtrail_trail_validation_enabled",
    "DocumentURI": "policies/aws_cloudtrail_trail_validation_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CloudTrail"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "## AWS CloudTrail Log File Validation\n\nThe AWS CloudTrail log file validation feature provides a mechanism for checking the integrity of CloudTrail log files. This feature offers a way to verify whether a log file was altered, deleted or remained unchanged after CloudTrail delivered it.\n\n### How it Works\n\nLog file validation employs SHA-256 for creating a hash representation of the log file and SHA-256 with RSA for the digital signature. These are industry standard algorithms known for their robust security. These digital fingerprints make it extremely challenging to modify, delete or fabricate CloudTrail log files without triggering detection. \n\n```markdown\n**Benefits of Using CloudTrail Log File Validation:**\n- **Integrity:** Validates the integrity of the logs, ensuring they have not been tampered with\n- **Security:** Uses industry standard SHA-256 and RSA algorithms for high security\n- **Audit-friendly:** Supports compliance and auditing requirements by providing a reliable history of the AWS environment activity\n- **Unchangeability:** Makes it impossible to rewrite or erase activities logged\n```\n\n### Usage\n\nTo utilize AWS CloudTrail log file validation, you need to turn on CloudTrail in your AWS account. After doing so, every action taken in your AWS environment will automatically be logged and delivered to an S3 bucket. Upon delivery, CloudTrail employs SHA-256 hashing and digital signing to create a unique digital fingerprint for each log. \n\nYou can then use CloudTrail to fetch the fingerprints and compare them with the logs present in your S3 bucket. If the fingerprints match, it indicates that the logs have remained untouched.\n\nConclusively, this AWS control provides an additional layer of security, ensuring the accountability, and the immutability of your CloudTrail logs."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS Control of utilizing CloudTrail log file validation can result in several potential costs:\n\n1. **Loss of Data Integrity**: If the integrity of log files is not maintained, unauthorized changes to data may go unnoticed. This can result in decision-making based on false data, potentially causing business disruptions, inaccurate forecasts, and poor strategic planning.\n\n2. **Security Breaches**: Without log file validation, it becomes easier for malicious entities to alter or delete logs to cover their tracks after a data breach. This not only increases the risk of breaches occurring but also makes them harder to detect, investigate, and remediate.\n\n3. **Regulatory Compliance Penalties**: Many industries must comply with specific regulations regarding the handling and protection of data, including log file integrity. In such cases, non-compliance could lead to financial penalties, legal repercussions, and damage to the organization's reputation.\n\n4. **Increased Risk of Downtime**: In a case where logs are manipulated or deleted, critical systems could be unknowingly operating under harmful conditions leading to potential unexpected crashes or downtimes which could cause financial losses.\n\n5. **Forensic Investigation Complications**: CloudTrail logs are integral in performing forensic investigations in case of any suspicious activity or security incident. If these logs are tampered with, it can compromise the investigation and lead to incorrect outcomes.\n\n6. **Loss of Customer Trust**: Failure to properly protect and validate data can lead to a loss of trust from customers and partners, with associated reputational damages and potentially loss of business. \n\nIn order to avoid these costs, it is crucial to comply with AWS Control and enable CloudTrail log file validation to ensure the integrity and security of log files."
      ],
      "x-kaytu-usefulness-example": [
        "An Example Instance:\n\nImagine an organization named XYZ Corp, which constantly tracks their user activity and API usage in their AWS environment for security auditing and incident response purposes. They use AWS CloudTrail to record these events and log files in an organized manner.\n\nHowever, they suspect that someone might be attempting to manipulate their CloudTrail logs to hide malicious activities. If these logs were tampered with, it could lead to undetected security breaches, allowing the hacker to gain further access and compromising the organization's security structure.\n\nIn this scenario, the functionality of AWS CloudTrail log file validation can show its usefulness. XYZ Corp enables log file validation in CloudTrail settings at the organization level. With this feature activated, they can now confirm whether a log file was modified, deleted or remained unchanged after CloudTrail delivered it.\n\nIf a log file was indeed tampered with (modified or deleted), the validation process would fail, alerting XYZ Corp of the unexpected change. This early detection allows XYZ Corp to quickly discover potential security breaches, enabling them to take corrective and preventative actions in a timely manner. The SHA-256 and SHA-256 with RSA encryption make sure that the logs' integrity cannot be compromised without detection.\n\nTherefore, in this way, AWS CloudTrail log file validation proves extremely useful in maintaining the integrity of log files and alerting the organization of any tampered logs, thereby protecting its AWS environment."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_instance_not_publicly_accessible",
    "Title": "EC2 instances should not have a public IP address",
    "Description": "Manage access to the AWS Cloud by ensuring Amazon Elastic Compute Cloud (Amazon EC2) instances cannot be publicly accessed.",
    "QueryID": "aws_ec2_instance_not_publicly_accessible",
    "DocumentURI": "policies/aws_ec2_instance_not_publicly_accessible.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EC2"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "This AWS control implies restricting public access to Amazon EC2 instances, which are essentially virtual servers in Amazon's Elastic Compute Cloud (EC2) for running applications on the AWS infrastructure.   \n\nThis can be explained in a more defined way in the markup format like this:\n\n```markdown\n# AWS Control: Managing Access to Amazon EC2 Instances\n\nThis control measure ensures all Amazon EC2 instances are not publicly accessible, enhancing security and privacy of data and applications running on these instances.\n\n## Implementation:\n\n1. **Restrict Security Group Rules:** Use security group rules that only allow needed traffic from trusted IP addresses.\n   \n2. **Implement Network Access Control Lists (NACLs):** NACLs provide a rule-based tool for controlling network traffic ingress and egress at the protocol and subnet level.\n\n3. **AWS Identity and Access Management (IAM):** Use IAM roles and policies to manage access.\n\n4. **Disable SSH/RDP Access:** By default, AWS allows SSH for Linux instances and RDP for Windows. Disable these settings in a production environment to prevent public access.\n\n5. **Utilize AWS PrivateLink**: AWS PrivateLink provides private connectivity between VPCs, AWS services, and on-premises applications, securely on the Amazon network.\n```\nThe key objective of this control is to minimize the threats that your EC2 instances could come under by considerably reducing their exposure to public access. This, in turn, escalates the overall security of your instances, preserving integrity and confidentiality."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control can lead to several potential costs:\n\n1. `Security Breaches and Data Leaks:` If the EC2 instances are publicly accessible, it increases the probability of unauthorized access, potentially leading to data breaches. This could result in legal penalties, loss of customer trust, and negative brand impact.\n\n2. `Cloud Resource Misuse:` Unauthorized access could lead to misuse of resources, causing unplanned expenses. For instance, the intruder can use the EC2 instances to run large applications, leading to high costs.\n\n3. `Compliance Penalties:` If your organization is subject to regulations like GDPR, HIPAA, PCI-DSS etc., non-compliance with this control may result in hefty fines and penalties. \n\n4. `Operational Disruption:` Unauthorized access can lead to manipulation or deletion of vital data, causing operational disruptions.\n\n5. `Privacy Violations:` If the exposed EC2 instances contain personally identifiable information (PII), it could result in privacy rights violations, attracting legal actions and reputation damage.\n\nRemember that the specific costs will depend upon the nature of data exposed, volume of the data, jurisdiction and the type of industry."
      ],
      "x-kaytu-usefulness-example": [
        "Managing access to the AWS Cloud by ensuring Amazon Elastic Compute Cloud (Amazon EC2) instances cannot be publicly accessed helps to enhance security. \n\nFor example, consider a company working on a proprietary machine learning algorithm. This company uses EC2 instances to perform computations and simulations related to this algorithm. If these instances were publicly accessible, it could potentially expose sensitive data or allow unauthorized modification of their algorithm. By restricting public access to these instances, AWS helps to protect this company's intellectual property and maintain the integrity of their computations.\n\nAdditionally, the risk associated with malicious actors such as hackers or other cyber threats is significantly reduced. In case the security credentials gets compromised, the restriction on public access will ensure that the EC2 instances are not accessed in an unauthorized manner, thereby preventing potential data breaches or unauthorized modifications to the system. \n\n```markdown\nExample:\nA finance company A makes use of EC2 instances to run complex simulations and store sensitive data related to their clients investment patterns. If these EC2 instances were publicly accessible, sensitive financial information could be exposed to bad actors that could lead to data breaches and loss of trust from the clients. With AWS Control, company A can manage access to the AWS Cloud by ensuring that their EC2 instances cannot be publicly accessed thereby protecting their sensitive data and maintaining client trust.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_default_encryption_enabled",
    "Title": "S3 bucket default encryption should be enabled",
    "Description": "To help protect data at rest, ensure encryption is enabled for your Amazon Simple Storage Service (Amazon S3) buckets.",
    "QueryID": "aws_s3_bucket_default_encryption_enabled",
    "DocumentURI": "policies/aws_s3_bucket_default_encryption_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "The encryption of Amazon S3 buckets is an essential security practice to safeguard your data at rest stored within the S3 bucket in Amazon AWS. It helps to prevent unauthorized access and meet certain compliance requirements.\n\nHere's this control in markup format:\n\n```markdown\n# Amazon S3 Bucket Encryption\n\nTo secure your data at rest stored in Amazon S3 buckets, enable encryption.\n\n## Why is it important?\n\n1. **Data protection**: Encryption converts your data into a code that requires a key to be accessed. It is essential in preventing unauthorized access.\n2. **Regulatory compliance**: Certain regulations and industry standards such as GDPR, HIPAA, and others may require data to be encrypted at rest.\n\n## How to enable S3 bucket encryption?\n\nYou can enable encryption for S3 buckets while creating a new bucket or for an existing one. Here are the general steps:\n\n1. Sign in to the AWS Management Console and open the Amazon S3 console.\n2. In the Buckets list, choose the name of the bucket that you want to enable encryption for.\n3. Choose the **Properties** tab.\n4. Choose **Default encryption**.\n5. In the dialog box, you can choose **Amazon S3 key (SSE-S3)**, **AWS KMS key (SSE-KMS)**, or **Customer-provided key (SSE-C)**.\n6. If you chose **AWS KMS key**, then in the **KMS master key** list, choose the key that you want to use to encrypt the objects.\n7. Choose **Save**.\n\n## Monitor and maintain\n\nRegularly monitor and audit your Amazon S3 buckets to ensure that encryption is enabled. You can use AWS CloudTrail for this purpose.\n\n**Note: Once encryption is enabled for an S3 bucket, it applies to all objects stored in the bucket. All new objects that are uploaded to the bucket are encrypted by default.**\n\n```\nThis markup format provides an easy-to-follow guide on how to enable encryption for your Amazon S3 buckets."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the above AWS Control, which insists on enabling encryption for Amazon S3 buckets, can have serious implications. Not meeting this control can lead to potential costs coming in the following forms:\n\n1. **Financial Loss:** If unauthorized individuals, either external hackers or internal employees with bad intentions, gain access to unsecured S3 buckets, they might misuse sensitive information for financial gain or demand ransom by encrypting your files.\n\n2. **Reputational Damage:** A data breach can lead to significant damage to an organization's reputation. Clients and customers entrust their data with a company in the belief that it will be securely maintained. If that trust is shattered due to non-compliance, it may take time to regain their full confidence.\n\n3. **Regulatory Fines:** Several industries are regulated by authorities that mandate strict cybersecurity practices. If your organization handles sensitive information such as credit card info, healthcare data, or personal identification details, non-compliance with encryption mandates can result in hefty fines.\n\n4. **Lost Business Opportunities:** If an organization is known for its lax security practices, especially when it comes to data storage and protection, it could lose out on potential business opportunities. Businesses and customers want to be assured that their data is in safe hands. If that assurance is uncertain, they're likely to take their business elsewhere.\n\n5. **Data Recovery Costs:** If access to your data is lost due to no encryption, you may need to spend quite a bit on data recovery services.\n\nNon-compliance to this control could potentially cost a company in various ways, from monetary to reputational, making it essential to ensure encryption is enabled for Amazon S3 buckets."
      ],
      "x-kaytu-usefulness-example": [
        "```\nAs an example, consider ABC company that stores sensitive financial information of their clients in Amazon S3. By enabling the encryption feature, they ensure this data is protected and only accessible to authorized personnel. \n\nIn a scenario where a hacker gains access to ABC’s Amazon S3 buckets, they would not be able to decrypt the sensitive financial data without the necessary encryption keys. This encryption feature provides an additional layer of security, limiting the damage that can be potentially caused by data breaches. Furthermore, encryption helps ABC company meet regulatory requirements related to data protection and privacy. This level of security assurance can also strengthen the company's reputation by demonstrating a commitment to protecting client data.\n```\n"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_user_no_inline_attached_policies",
    "Title": "IAM user should not have any inline or attached policies",
    "Description": "This rule ensures AWS Identity and Access Management (IAM) policies are attached only to groups or roles to control access to systems and assets.",
    "QueryID": "aws_iam_user_no_inline_attached_policies",
    "DocumentURI": "policies/aws_iam_user_no_inline_attached_policies.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control Rule: Attach IAM Policies Only to Groups or Roles\n\nThis rule is designed to ensure better security and manageability in your AWS environment. AWS Identity and Access Management (IAM) allows you to manage access to AWS services and resources. Violating this rule could lead to unauthorized access or privilege escalation.\n\n## Principle\n\nIAM policies outline permissions that determine what actions are allowed or denied for the specific AWS resources. Attaching these policies directly to individual IAM users rather than to groups or roles can make configuration and access management more complicated. To uphold the principle of least privilege and streamline access control, it is recommended to attach policies to IAM groups or roles.\n\n## How It Works\n\n1. **IAM Group:** Administrators can create an IAM group, grant the necessary permissions to this group via a policy, and then add users to this group. This way, all the users in the group inherit the permissions from the policy.\n\n2. **IAM Role:** Roles can be assumed by trusted entities, such as IAM users, applications, or an AWS service like EC2. Policies attached to IAM roles apply to any entity that assumes the role.\n\n## Benefits\n\n- **Security:** Reduces the risk of unauthorized access and privilege escalation.\n- **Manageability:** Eases user management by grouping users with similar access requirements.\n- **Consistency:** Ensures that permissions are uniformly applied to a group of users.\n- **Flexibility:** Roles can be assumed by people or AWS services, which is useful for temporary access or cross-account access.\n\n## Compliance \n\nAdherence to this control rule is critical for aligning with best practices in IAM permissions management and can be integral to meeting certain regulatory and compliance requirements. \n\n---\n\nPlease note, this control rule does not replace a comprehensive approach to your AWS security and compliance needs. Always review and understand the implications of configuration changes in your environment."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control can lead to several potential costs and risks:\n\n1. **Security Risks**: If policies are attached directly to users and not groups or roles, it can lead to inconsistent and incorrect permissions being granted. This can expose your organization to various security threats like unauthorized access, data breaches, and loss of confidential data.\n\n2. **Management Overhead**: Managing individual IAM policies for each user can be very time-consuming and can result in practical difficulties. It is easier and more efficient to manage access at a group or role level.\n\n3. **Increased Operational Costs**: Time spent on managing individual IAM policies leads to increased operational costs. It can also slow down processes and reduce efficiency, thus indirectly impacting the overall performance of your organization.\n\n4. **Compliance Violations \u0026 Fines**: If your organization works in a regulated industry or handles sensitive data (like healthcare or financial data), non-compliance can result in heavy fines and penalties from regulatory bodies.\n\n5. **Reputation Damages**: Any data leak or security compromise resulting from improper access control can lead to serious reputational damage. This could ultimately result in lost business opportunities and lower customer trust.\n\nIn summary, the cost of non-compliance to this AWS control can be quite high, impacting not just the organization's operational efficiency and costs, but also its reputation and business continuity."
      ],
      "x-kaytu-usefulness-example": [
        "For example:\n``\nA software development company is using AWS for all its server needs. There are various teams like development, testing, and operations working on AWS infrastructure. The company decides to follow the best security practices and limit the access to its AWS resources.\n\nThe development team only needs access to EC2 instances, S3 buckets and RDS instances. Similarly, the testing team needs read access to EC2 instances and full access to S3 buckets. The operations team needs full access to all resources. \n\nThe company uses this AWS Control and creates IAM groups for development, testing, and operations team. They attach policies to these groups which give necessary permissions.\n\nBy doing this, the company ensures that everyone just has the access to resources which they need, providing a secure environment and preventing potential threats due to unwanted access.``"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_restrict_public_read_access",
    "Title": "S3 buckets should prohibit public read access",
    "Description": "Manage access to resources in the AWS Cloud by only allowing authorized users, processes, and devices access to Amazon Simple Storage Service (Amazon S3) buckets.",
    "QueryID": "aws_s3_bucket_restrict_public_read_access",
    "DocumentURI": "policies/aws_s3_bucket_restrict_public_read_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS provides the ability to manage and control access to resources in the AWS Cloud including Amazon Simple Storage Service (Amazon S3) buckets. This can help ensure that only authorized users, processes, and devices can gain access.\n\nThis access control is in place to help prevent unauthorized viewing or modification of resources and can be fine-tuned to allow specific types of access (e.g. read-only, write, etc) to specific resources. It can also prevent certain types of access completely.\n\nIn addition to managing access, AWS also provides the ability to track who is accessing which resources and when. This can be helpful for a range of tasks, from auditing to identifying potential security threats.\n\nHere is an example of how you can represent this control in markup format:\n\n```markdown\n# AWS Control: Manage Access to Resources \n\nAmazon Web Services (AWS) allows you to control access to resources in the cloud, like Amazon Simple Storage Service (S3) buckets. Here's what you need to know:\n\n1. **Access Control**: You can manage who has access to specific resources. This helps to prevent unauthorized viewing or alteration of your resources.\n\n2. **Permissions**: Access can be customized to allow specific actions, such as reading or writing. Certain types of access can be blocked entirely.\n\n3. **Audit Trail**: AWS tracks who accesses which resources and when, making it easier for you to perform tasks like auditing or identifying potential security threats.\n```\n\nThis markup format allows you to highlight the key points about managing access to resources in AWS, in a clear and easy-to-read manner."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS Control, which strictly advises only allowing authorized users, processes, and devices access to Amazon Simple Storage Service (Amazon S3) buckets, can have severe consequences. \n\n1. **Data Breaches**: Unauthorized access to your S3 buckets can lead to data breaches. Hackers may gain access to sensitive data, modify it, or even delete it. If your company stores confidential data, a breach could result in millions of dollars in damage.\n\n2. **Legal and Regulatory Penalties**: If you are in a regulated industry or handle personally identifiable information (PII), non-compliance could lead to substantial legal penalties. These can come in the form of fines or lawsuits from individuals whose data has been compromised.\n\n3. **Loss of Business**: If you suffer from a significant data breach due to non-compliance, you risk losing the trust of your customers or clients. They may choose to do business with your competitors instead, leading to a loss in revenue.\n\n4. **Damage to Reputation**: A data breach can significantly harm a company's reputation. It could take years to rebuild trust with customers and regain a positive public perception.\n\n5. **Costly Investigation and Remediation**: Non-compliance that leads to a breach sometimes requires a security audit, digital forensics investigation, and the deployment of remediation measures, all of which can be costly.\n\n6. **Potential Increase in Insurance Premiums**: Organizations with a history of non-compliance and resultant data breaches may face increased premiums when renewing professional indemnity and cyber risk insurance policies.\n\nIn conclusion, ensuring compliance with this AWS control is not just a matter of following best practices; it is crucial for the overall security and integrity of a business. It's essential to implement strong access control measures to protect your critical and sensitive data stored on Amazon S3."
      ],
      "x-kaytu-usefulness-example": [
        "Managing access to resources is crucial for data protection and privacy. For instance, let's assume you own a company that stores sensitive customer data like personal identification documents, tax information, etc., in Amazon S3 buckets.\n\nBy using this AWS control, you can ensure that only select authenticated employees (like system administrators or data analysts) have access to this sensitive data stored in your S3 buckets.\n\nMoreover, restrictive access controls can also prevent accidental leakage of data by users or processes that shouldn't have particular permissions. For instance, you could prevent a data engineer, who needs to only read data for analysis purposes, from accidentally deleting vital information.\n\n```\n*Maintaining authorized access helps:*\n- Preserving data privacy by enabling `Access Control List (ACL)` and `bucket policies` to permit or deny specified operations from users or systems.\n- Enabling `AWS Identity and Access Management (IAM)` to provide secure access to your AWS services and resources for the users.\n- Using `AWS Organizations Service Control Policies (SCPs)` to ensure authorized account level actions across the organization.\n```\n\nConsequently, managing access can protect your company's vital data from unauthorized access, accidental deletion or modification, and remain compliant with data protection regulations."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_security_group_associated_to_eni",
    "Title": "VPC security groups should be associated with at least one ENI",
    "Description": "This rule ensures the security groups are attached to an Amazon Elastic Compute Cloud (Amazon EC2) instance or to an ENI. This rule helps monitoring unused security groups in the inventory and the management of your environment.",
    "QueryID": "aws_vpc_security_group_associated_to_eni",
    "DocumentURI": "policies/aws_vpc_security_group_associated_to_eni.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/VPC"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS control refers to a specific set of security and compliance protocols in AWS. In this case, the AWS control in question is a rule or policy that checks whether security groups are attached to instances of Amazon Elastic Compute Cloud (Amazon EC2) or an Elastic Network Interface (ENI).\n\nIn AWS, security groups work as firewalls for your instances; they control inbound and outbound traffic. If a security group is not attached to any EC2 instances or ENIs, it means the security group is not managing any traffic, and it is considered unused.\n\nBy continuously monitoring and managing these unused security groups, you can optimize security group management and improve the security posture of your AWS environment. Below is the description in markup format for the rule:\n\n---\n```\n\u003e **AWS Control Rule:**\n\u003e \n\u003e This rule ensures that:\n\u003e \n\u003e - All security groups are attached to an Amazon Elastic Compute Cloud (Amazon EC2) instance or an Elastic Network Interface (ENI).\n\u003e - Helps in identifying and managing unused security groups in the inventory.\n\u003e\n\u003e Purpose: \n\u003e\n\u003e - To efficiently manage the security groups in use.\n\u003e - To improve the overall security of the AWS environment by eliminating unused or unnecessary security groups.\n```\n---"
      ],
      "x-kaytu-noncompliance-cost": [
        "Cost of non-compliance to this AWS control can be severe and multi-faceted:\n\n1. **Security Risks**: Unused security groups pose huge security risks as hackers can exploit any loose ends left while managing them. This might lead to unauthorized access to your EC2 instances and compromise the integrity and confidentiality of your data.\n\n2. **Inefficient Resource Management**: Unused security groups consume computing resources, adding to your operational expenses without any necessary business outcomes. The clutter introduced by such unused resources also slows down management tasks and hampers overall system performance.\n\n3. **Regulatory Non-Compliance**: If your business operates in a regulated industry, you may need to comply with certain mandates that require minimal resource wastage and optimal security management. Failing to do this can result in hefty fines and penalties.\n\n4. **Compromised System Performance**: As mentioned before, if system resources are being unnecessarily utilized by unused security groups, then it could drop the performance of those EC2 instances, considering that AWS would be using resources to manage these unused security groups.\n\n5. **Increased Costs**: You're charged for every security group rule that you add to your AWS environment. Therefore, leaving unused security groups in your inventory may lead to a significant increase in your AWS costs."
      ],
      "x-kaytu-usefulness-example": [
        "Example:\n\nAmazon Web Services (AWS) uses security groups as virtual firewalls to control inbound and outbound traffic for resources like an Amazon Elastic Compute Cloud (EC2) instance. Imagine a scenario where a company hosts its website on an EC2 instance. They have different security groups defining access at different levels – for example, one for the web server, one for the database server, and perhaps one for the development team.\n\nIf the company creates a new security group but forgets to attach it to an instance, this could result in potential security breaches. By using the AWS Control, they could effectively monitor and manage such unassigned security groups.\n\nOn the flip side, they may have security groups that were created and used in the past but are no longer necessary. These unused security groups can clutter the system and could potentially pose a security risk if they are not properly managed. Thus, having the AWS Control rule to monitor unused security groups further enhances their control over their environment, promoting better security, clean management, and efficient use of resources.\n\nThe AWS Control thus provides better inventory management, security administration, and resource management for the company.\n\n```\nExample in markup:\n\n# AWS Control For Security Group Attachment Monitoring\n\nThe following AWS Control rule is useful for monitoring and managing security groups in your AWS environment.\n\n```aws\ncontrol \"aws_security_group_attachment\" do\n  impact 1.0\n  title \"Check if security groups are attached to EC2 instances or ENIs\"\n\n  describe aws_security_group(group_id: 'sg-0123456789fghex46') do\n    it { should be_in_use }\n  end\nend\n```\n\nThis rule will check if a security group with the provided 'group_id' is actually being used by any EC2 instance or network interface. If it isn't, then the rule will fail, indicating an unused security group in your inventory.\n\nThis can help in monitoring unused security groups and ensuring proper management of your AWS environment.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ebs_snapshot_not_publicly_restorable",
    "Title": "EBS snapshots should not be publicly restorable",
    "Description": "Manage access to the AWS Cloud by ensuring EBS snapshots are not publicly restorable.",
    "QueryID": "aws_ebs_snapshot_not_publicly_restorable",
    "DocumentURI": "policies/aws_ebs_snapshot_not_publicly_restorable.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EBS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS (Amazon Web Services) offers an access control mechanism known as EBS (Elastic Block Store) snapshots. These snapshots are backups of your EBS volumes (i.e., your data), and you can store them for use in case of an emergency.\n\nHowever, security is critical when dealing with these snapshots - if they are not configured correctly, they might be publicly accessible, meaning anyone on the internet can access your data.\n\nThe provided control implies that you should control access to these EBS snapshots and make sure they are not publicly restorable. Practically, it means:\n\nLimit who can restore these snapshots to certain AWS accounts only. \nDo not permit snapshots to be shared publicly. \nSet permissions explicitly, and secure them following the least-privilege principle, i.e., giving just enough permissions to carry out required tasks.\n\nIn Markup format (for AWS documentation):\n\n```\n# Control: Manage Access to EBS Snapshots\n\nEnsure that your EBS snapshots are not publicly restorable.\n\nThis control implies that you:\n* Limit restore permissions to certain AWS accounts only.\n* Do not share snapshots publicly.\n* Grant explicit permissions following the least-privilege principle.\n\nIf snapshots are publicly accessible, anyone on the internet may access your data. Proper configuration of snapshot access is crucial for data security.\n```\n\nRemember, the rules for managing access to AWS resources, like EBS snapshots, are set in policies in IAM (AWS Identity \u0026 Access Management). Always review these policies regularly for any potential security breaches."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control can have serious cost implications:\n\n1. **Financial Loss**: If an EBS snapshot is publicly restorable, anyone can restore that snapshot and access the data. If the data is sensitive or critical, it may provide competitive advantage to competitors, causing financial loss. Instances may also be launched from the snapshot to initiate attacks, and your organization will pay for it.\n\n2. **Regulatory Fines**: If your organization falls under the purview of data protection laws (like GDPR, HIPAA, CCPA), a leak of personal identifiable information (PII) can result in substantial fines and penalties.\n\n3. **Legal Actions**: The individual whose data has been leaked may initiate legal action against the engaging organization for breaching their privacy rights.\n\n4. **Brand Reputation**: After a data breach, trust from customers is lost, which might impact the brand image and its value in the market negatively. This might deter new customers and lead to loss of existing ones.\n\n5. **Data Loss**: In a worst-case scenario, the snapshots might contain critical data backup. Malicious actors could potentially restore and then delete the data.\n\n6. **Resource Misuse**: Publicly available snapshots could be restored and used for unauthorized activities. This would use your company's resources and you would have to bear its cost.\n   \nRemember, the exact cost of non-compliance could vary depending on the nature and volume of the data compromised."
      ],
      "x-kaytu-usefulness-example": [
        "AWS makes it easy for users to manage resources and data stored in the cloud. EBS snapshots, in particular, are a convenient way to save and restore data on EBS volumes. However, exposing such snapshots to the public could potentially provide unwanted users with access to confidential data.\n\nA good example would be a company keeping all of its customer data on an EBS volume. If a snapshot is made publicly restorable, anyone can restore that snapshot to their own EBS volume and access all of the company's confidential customer data. This could involve leaking of personal information and potential for misuse of the customer's individual data, violating privacy and resulting in legal implications for the company. Also, it can compromise the competitive advantage of the company as its data might be accessible to its competitors.\n\nTo avoid such situations, AWS provides the \"Manage access to the AWS Cloud by ensuring EBS snapshots are not publicly restorable\" control. By using this, the company can ensure their EBS snapshots are only restorable by authorized users within their organization. Hence, it secures the customer's sensitive data and protects it from being mishandled or misused."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudtrail_multi_region_trail_enabled",
    "Title": "At least one multi-region AWS CloudTrail should be present in an account",
    "Description": "AWS CloudTrail records AWS Management Console actions and API calls. You can identify which users and accounts called AWS, the source IP address from where the calls were made, and when the calls occurred. CloudTrail will deliver log files from all AWS Regions to your S3 bucket if MULTI_REGION_CLOUD_TRAIL_ENABLED is enabled.",
    "QueryID": "aws_cloudtrail_multi_region_trail_enabled",
    "DocumentURI": "policies/aws_cloudtrail_multi_region_trail_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/CloudTrail"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS CloudTrail is a service offered by Amazon Web Services (AWS) that provides logging of all activity within your AWS account. This includes both actions taken via the AWS Management Console and those performed via API calls. By creating a trail of these activities, CloudTrail allows for extensive monitoring, security analysis, and troubleshooting.\n\nOne of the key features of CloudTrail is the ability to record the details about the source of any API call or AWS Management Console action. This includes the user or account that initiated the call, the source IP address from which the call was made, and the time the call occurred. This level of detail provides valuable context when investigating unusual activity or attempting to resolve technical issues.\n\nMoreover, CloudTrail supports the ability to record and deliver log files from all AWS Regions to your Amazon S3 bucket, providing a centralized location for all your AWS activity logs. This feature can be enabled by turning on MULTI_REGION_CLOUD_TRAIL_ENABLED. When this setting is enabled, CloudTrail will automatically deliver logs from all regions rather than just the region in which the activity occurred. This can be especially useful if you have AWS resources spread across multiple regions and want to maintain a complete, centralized log. \n\nHere is the text in markup format:\n\n```markdown\n**AWS CloudTrail** is a service offered by Amazon Web Services (AWS) that provides logging of all activity within your AWS account. This includes actions taken via the **AWS Management Console** and those performed via **API calls**. \n\nCloudTrail records the details about the source of any API call or AWS Management Console action, including:\n* The user or account that initiated the call\n* The source IP address from which the call was made \n* The time the call occurred. \n\nMoreover, by enabling **MULTI_REGION_CLOUD_TRAIL_ENABLED**, CloudTrail can record and deliver log files from all **AWS Regions** to your Amazon S3 bucket. This provides a centralized location for all your AWS activity logs, which is particularly useful if you have AWS resources spread across multiple regions.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with the AWS Control `MULTI_REGION_CLOUD_TRAIL_ENABLED` comes with several potential costs:\n\n1. **Security Risks:** If CloudTrail is not enabled in all regions, malicious activities conducted in ‘non-tracked’ regions might remain unnoticed. Unauthorized changes in those regions would not be recorded, creating a blind spot for security audits and making it harder to hold any malicious actors accountable.\n\n2. **Forensic Investigation Complications:** If a security issue does occur, not having the CloudTrail logs from all regions could significantly hamper the forensic investigation. The investigative team would lack vital information like source IP, AWS accounts used, and timestamp of the suspicious activity. The cost of conducting an investigation without these important logs could be significantly higher, and the process longer.\n\n3. **Compliance Violations:** Depending on the specific regulations that a company needs to comply with for their industry, non-compliance to this control could result in potential legal and financial penalties. Regulations like HIPAA, GDPR, and others mandate comprehensive logging of all actions and a failure in presenting required logs could incur fines and disciplinary action.\n\n4. **Reputation Damage:** If a data breach occurs and it's discovered that not all security measures (like CloudTrail in all regions) were taken, it could lead to damaged customer trust and a stained company reputation.\n\n5. **Operational Disruptions:** Without complete visibility into the AWS operations across all regions, troubleshooting technical issues might be more challenging and time-consuming, thus leading to more prolonged operation disruptions.\n\nThe cost of non-compliance is multifaceted and extends beyond financial penalties to operational efficiency, security and reputation risk management. As such, following AWS Controls and implementing `MULTI_REGION_CLOUD_TRAIL_ENABLED` provides a vital layer of security and accountability for AWS operations."
      ],
      "x-kaytu-usefulness-example": [
        "For an example:\n\nSuppose you are the CEO of a tech company and you have a team of engineers working on several projects. One of the projects involves developing a web application on AWS. The application suddenly crashes and your team is having trouble figuring out what caused the issue.\n\nHere, you can use AWS CloudTrail's feature to track every single Management Console action and API call made in your AWS environment. This enables you to understand what operations were performed right before the system crash occurred. \n\nYou can identify which user or account made the call, find out the source IP address from where the call was made, and when this happened. This high level of scrutiny might help you find that, for instance, an API call was made that unintentionally deleted a critical part of your application's infrastructure, leading to its crash.\n\nAdditionally, if you have the MULTI_REGION_CLOUD_TRAIL_ENABLED feature enabled, AWS CloudTrail will deliver all the log files from all AWS regions to your S3 bucket. This is useful if your application operates in multiple AWS regions as it helps maintain a comprehensive log record.\n\nSo, in this way, AWS CloudTrail helps you diagnose and troubleshoot operational issues and allows you to keep close tabs on what actions are being performed in your AWS environment."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ebs_volume_encryption_at_rest_enabled",
    "Title": "EBS volume encryption at rest should be enabled",
    "Description": "Because sensitive data can exist and to help protect data at rest, ensure encryption is enabled for your Amazon Elastic Block Store (Amazon EBS) volumes.",
    "QueryID": "aws_ebs_volume_encryption_at_rest_enabled",
    "DocumentURI": "policies/aws_ebs_volume_encryption_at_rest_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EBS"
      ],
      "x-kaytu-explanation": [
        "# Control Name: Encryption for Amazon Elastic Block Store (Amazon EBS) Volumes\n\n## Description \n\nEncryption of data at rest is a critical aspect of data security. It ensures that stored data cannot be read without the proper decryption keys. This control ensures that Amazon Elastic Block Store (EBS) volumes are encrypted.\n\nAmazon EBS is a high-performance block storage service designed for use with Amazon EC2 for both throughput and transaction-intensive workloads at any scale. \n\n## Rationale\n\nWhen data at rest is encrypted, unauthorized individuals can't access your data without the decryption keys, providing an additional layer of security for sensitive data.\n\nEncrypting EBS volumes, which may contain sensitive information, can help to protect your data from unauthorized access and fulfill compliance requirements for data-at-rest encryption.\n\n## Remediation\n\nFollow these necessary steps to enable encryption for EBS volumes:\n\n- Log in to Amazon AWS Management Console.\n- Navigate to the EC2 Dashboard.\n- Select 'Volumes' under 'Elastic Block Store'.\n- For each unencrypted volume, create a new, encrypted volume.\n- Attach the encrypted volumes to your instances after stopping the instances.\n- Restart the instances.\n\n## Compliance\n\nThis control is necessary for compliance with various security standards and regulations, including:\n\n- General Data Protection Regulation (GDPR)\n- Payment Card Industry Data Security Standard (PCI DSS)\n- Health Insurance Portability and Accountability Act (HIPAA)\n- Federal Information Security Management Act (FISMA)\n\n## Audit\n\nRegular monitoring can ensure ongoing compliance with this control. Use the AWS Management Console or a monitoring automation tool to verify that all Amazon EBS volumes are encrypted.\n\n## References\n\n- [AWS: Amazon Elastic Block Store](https://aws.amazon.com/ebs/)\n- [AWS: Amazon EBS Encryption](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html)\n\n## Tags\n\n- Encryption\n- Data at Rest\n- Compliance\n- Amazon EBS\n- GDPR\n- PCI DSS\n- HIPAA\n- FISMA"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control can lead to several significant costs. \n\n1. **Data Breaches**: Unencrypted EBS volumes leave sensitive data vulnerable to unauthorized access and potential breaches. Data breaches can have a severe financial impact on businesses due to potential regulatory fines, loss of customers, and reputational damages. According to a 2020 report by IBM, the average total cost of a data breach is $3.86 million.\n\n2. **Non-compliance Fines**: Organizations that need to abide by certain compliance standards (like GDPR, HIPAA, PCI-DSS etc.) can be fined significantly for non-compliance. These fines can reach up to $1.5m in the case of HIPAA, or 4% of annual global turnover under GDPR.\n\n3. **Loss of Business Opportunities**: Non-compliance may lead to loss of business opportunities. For instance, some clients or business partners might require proof of adherence to certain security practices or certifications before engaging in business activities.\n\n4. **Operational Costs**: In the event of a security breach related to unencrypted EBS volumes, organizations would need to spend valuable resources to investigate the breach, recover the data and restore systems.\n\n5. **Legal Costs**: If a breach leads to the exposure of personally identifiable information (PII) or other sensitive data, businesses could potentially face lawsuits that result in substantial legal costs.\n\nEncrypting EBS volumes is a crucial security measure that can significantly reduce these risks and associated costs."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, imagine a scenario where a company is developing a healthcare application on AWS. This application collects, processes, and stores sensitive patient information such as health history, insurance details, etc. In this case, data security is paramount due to both ethical and regulatory reasons (like HIPAA compliance).\n\nIf the company is using Amazon Elastic Block Store (Amazon EBS) volumes for data storage, enabling encryption can provide an additional layer of security. By doing so,\n\n- It protects data at rest from threatening activities such as unauthorized access or data breaches.\n- It encrypts the data as it moves between EBS volumes and the instances to which they are attached, thus securing data during transmission.\n- It satisfies regulatory requirements for data encryption at-rest.\n\n```markdown\nExample:\nA healthcare application is using AWS for collecting and processing patient information. The developers enable encryption for their Amazon EBS volumes to ensure the security of sensitive data at rest. This helps them not only to stave off potential unauthorized access or breaches but also to comply with HIPAA regulations requiring the encryption of patient information.\n```\n\nBy enabling encryption on their EBS volumes, the company can continue its operations knowing its sensitive data is protected."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_emr_cluster_master_nodes_no_public_ip",
    "Title": "EMR cluster master nodes should not have public IP addresses",
    "Description": "Manage access to the AWS Cloud by ensuring Amazon EMR cluster master nodes cannot be publicly accessed.",
    "QueryID": "aws_emr_cluster_master_nodes_no_public_ip",
    "DocumentURI": "policies/aws_emr_cluster_master_nodes_no_public_ip.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EMR"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Restrict Public Access to Amazon EMR Cluster Master Nodes\n\nAmazon Elastic MapReduce (EMR) is a cloud-native big data platform, allowing processing of large amounts of data quickly and cost-effectively at scale using popular distributed frameworks such as Hadoop, Apache Spark, HBase and others.\n\n## Importance\n\nA fundamental security best practice is to restrict public access to your resources. This is especially important for resources like the Amazon EMR cluster master node, which plays a critical role in the management and operation of the cluster. \n\nIf unauthorized individuals gain access to the master node, they might be able to disrupt cluster operations or access potentially sensitive data. Therefore, your security plan should prevent EMR cluster master nodes from being publicly accessed.\n\n## Solution\n\nYou can manage access to the AWS Cloud and Amazon EMR cluster master nodes by using security groups within your Virtual Private Cloud (VPC). A security group acts like a firewall for your instance, controlling inbound and outbound traffic.\n\nIn the inbound rules of your security group, you should avoid rules that allow inbound traffic from `0.0.0.0/0` or `::/0` (which represent all IPv4 and IPv6 traffic, respectively). Instead, specify the IP ranges necessary for your operation.\n\nFor example, a valid rule might only allow SSH traffic (port 22) from the IP addresses of your organization's offices.\n\n```markdown\nType: SSH\nProtocol: TCP\nPort Range: 22\nSource: [Your organization's IP addresses]\n```\n\nBy effectively utilizing security groups and VPC features, you can ensure your Amazon EMR cluster master nodes are not publicly accessed. However, consider appropriate security measures for applications that need to access the master node. They may require configuration changes to ensure they can continue to access the master node."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control measure can lead to severe implications, including:\n\n1. **Security Breaches:** If EMR cluster master nodes are publicly accessible, there is an increased risk of potential security breaches. Unauthorized users might exploit vulnerabilities and gain unlawful access to sensitive data leading to data breaches. Addressing those breaches can be financially demanding, increasing the organization's expenses.\n\n2. **Regulatory Violations:** Many regulations demand businesses to ensure the security of their data, especially when it comes to personally identifiable information (PII). Non-compliance could result in heavy fines and penalties imposed by regulatory authorities. \n\n3. **Reputation Damage:** If security breaches result in data leaks, it can lead to significant harm to an organization's reputation. Customers might lose trust and refuse to do business with an organization that cannot protect its data.\n\n4. **Loss of data and IP**: Publicly accessible master nodes can result in unauthorized data access and loss. In some cases, critical business information or intellectual property might fall into the wrong hands, leading to competitive disadvantages.\n\nTo avoid these costs, organizations must ensure Amazon EMR cluster master nodes are not publicly accessible, and the proper security measures are in place."
      ],
      "x-kaytu-usefulness-example": [
        "Amazon EMR (Elastic MapReduce) provides a data-processing platform that can handle a large amount of data. One of the primary benefits is the ability to scale resources as per your requirement. An instance of its usefulness can be seen in the following scenario:\n\nFor a company involved in managing sensitive customer data for analysis, misuse or unauthorized access to this data can lead to severe consequences, not only financially due to potential fines, but also to the company's reputation. \n\n```\n    aws emr create-cluster \\\n    --applications Name=Hadoop Name=Hive Name=Pig \\\n    --ec2-attributes '{\"KeyName\":\"myKey\",\"InstanceProfile\":\"EMR_EC2_DefaultRole\",\"SubnetId\":\"subnet-abc123\",\"EmrManagedMasterSecurityGroup\":\"sg-master1\",\"EmrManagedSlaveSecurityGroup\":\"sg-slave1\"}' \\\n    --release-label emr-5.29.0 \\\n    --log-uri 's3n://aws-logs-123456789012-us-west-1/elasticmapreduce/' \\\n    --instance-type m5.xlarge \\\n    --instance-count 3 \n```\n\nIn this instance, you’ll notice “EmrManagedMasterSecurityGroup” which is used for firewall rules to control traffic for the instances, and it ensures the master node cannot be publicly accessed. This setup prevents unauthorized entities from potentially gaining access to and control over the data or altering the analysis processes; thus, it provides an added layer of security for managing sensitive data."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudtrail_trail_integrated_with_logs",
    "Title": "CloudTrail trails should be integrated with CloudWatch logs",
    "Description": "Use Amazon CloudWatch to centrally collect and manage log event activity. Inclusion of AWS CloudTrail data provides details of API call activity within your AWS account.",
    "QueryID": "aws_cloudtrail_trail_integrated_with_logs",
    "DocumentURI": "policies/aws_cloudtrail_trail_integrated_with_logs.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/CloudTrail"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# Amazon CloudWatch and AWS ControlTrail \n\nYou can use **Amazon CloudWatch**, a service of AWS (Amazon Web Services), to centrally collect and manage the log event activity of your applications, systems, and services. It's essentially a monitoring and observability service, providing you with data and actionable insights.\n\n\u003cdiv\u003e\n    \u003cul\u003e\n        \u003cli\u003eIt collects and track metrics from AWS resources and applications in real-time. \u003c/li\u003e\n        \u003cli\u003eIt collects and monitors log files from your systems, applications and AWS services.\u003c/li\u003e\n        \u003cli\u003eYou can set high-resolution alarms, visualize logs and metrics together, and take automated actions, understand and resolve operational issues, and uncover system bottlenecks quickly.\u003c/li\u003e\n        \u003cli\u003eIt also helps you discover new ways to optimize your application or service performance.\u003c/li\u003e\n     \u003c/ul\u003e\n\u003c/div\u003e\n\nIn addition, you can include **AWS CloudTrail** data in CloudWatch. AWS CloudTrail is a service that records AWS API calls for your AWS account and delivers log files to you. The information collected by CloudTrail gives you details about the API call activity in your AWS account, such as:\n\n\u003cdiv\u003e\n    \u003cul\u003e\n        \u003cli\u003eIdentity of the API caller.\u003c/li\u003e\n        \u003cli\u003eTimestamp of the API call.\u003c/li\u003e\n        \u003cli\u003eSource IP address of the API caller.\u003c/li\u003e\n        \u003cli\u003eRequest parameters made with the API call.\u003c/li\u003e\n        \u003cli\u003eResponse elements returned by the AWS service.\u003c/li\u003e\n     \u003c/ul\u003e\n\u003c/div\u003e\n\nLinking these two services together provides you with a comprehensive data set for monitoring, securing, optimizing, and auditing your AWS account.\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS Control of using Amazon CloudWatch to centrally collect and manage log event activity, with the inclusion of AWS CloudTrail data, could fall under several categories:\n\n1. **Financial Costs**: Without central logging and monitoring, it's challenging to identify, diagnose, and fix issues, resulting in extended downtime. This situation could lead to lost business and penalties in the event of a contractual SLA breach.\n\n2. **Security Costs**: Ignoring this control can mean you are less responsive to security-related incidents, being unaware of malicious activities until it's too late. This vulnerability could lead to data breaches, system compromises, unauthorized access, and negatively affect your business reputation.\n\n3. **Audit Costs**: Central log management is crucial for auditing purposes. Without it, audits take more time and money. Additionally, lack of compliance could result in non-compliance penalties from regulatory bodies, such as GDPR, HIPAA, or PCI DSS.\n\n4. **Operational Costs**: Without central management through CloudWatch, the operations team might spend more time troubleshooting issues, affecting productivity and operational efficiency.\n\n5. **Compliance Costs**: If a company is required to comply with certain regulatory standards, non-compliance with this control would mean a breach of those standards, potentially resulting in hefty fines.\n\nAll these potential costs reiterate the importance of central log management using Amazon CloudWatch, enabling effective debugging, secure and efficient operations, and maintaining regulatory compliance in AWS environments."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, you're running a large web application spread across multiple instances and services in Amazon Web Services. You realize that diagnosing issues or tracking user activity could be a complex task due to the dispersion of logs across different systems. \n\nBy using Amazon CloudWatch, you can store, view, and monitor your log files from Amazon EC2 instances, AWS CloudTrail, Route 53, and other sources in one centralized location. You could then easily access them for specific time period data, search for specific error messages, or analyze any patterns in your application data or system behavior.\n\nFurthermore, by including AWS CloudTrail data into your Amazon CloudWatch, you are able to keep track of all the API call activities within your AWS account. This data provides deeper visibility into who is making what kind of request, the services used, the actions performed, and parameters for the actions. This could be particularly useful, for example, when an unexpected action occurs like a sudden spike in delete requests or an unauthorized access attempt. \n\nThis combined approach helps you troubleshoot issues, understand user behavior and activity within your web application, and ensures a more secure, efficient, and effective management of your AWS environments."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_restrict_public_write_access",
    "Title": "S3 buckets should prohibit public write access",
    "Description": "Manage access to resources in the AWS Cloud by only allowing authorized users, processes, and devices access to Amazon Simple Storage Service (Amazon S3) buckets.",
    "QueryID": "aws_s3_bucket_restrict_public_write_access",
    "DocumentURI": "policies/aws_s3_bucket_restrict_public_write_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Control allows you to manage who can access your resources in the AWS Cloud, specifically your Amazon Simple Storage Service (Amazon S3) buckets. This control ensures that only the authorized users, processes, and devices can access the data stored in your S3 buckets. This is crucial for protecting sensitive data and maintaining data privacy. \n\nThis control is primarily achieved through the use of AWS Identity and Access Management (IAM) service, where you can create policies that determine who is allowed or denied access to your AWS resources. You can also use features like bucket policies and Access Control Lists (ACLs) on S3 to give more granular control on the buckets.\n\nMoreover, AWS Control also provides options to encrypt the data stored in your S3 buckets, adding an additional layer of protection to your data.\n\nHere it is in markup format:\n\n```markdown\n# AWS Control - Managing Access to Amazon S3 Resources\n\nAWS Control allows you to effectively manage access to your resources in the AWS Cloud, primarily your **Amazon Simple Storage Service (Amazon S3) buckets**. This control ensures that only authorized users, processes, and devices can access the data stored in these buckets, crucial for protecting sensitive data and maintaining data privacy.\n\n## Features\n- **AWS Identity and Access Management (IAM) service**: Create policies that determine who has permitted or denied access to your AWS resources.\n- **Bucket policies and Access Control Lists (ACLs) on S3**: Get granular control over each S3 bucket.\n- **Encryption**: AWS Control offers options to encrypt the data stored in your S3 buckets for an additional layer of data protection.\n```\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control can result in various costs which include:\n\n1. **Security Breach Costs**: Uncontrolled access to Amazon S3 buckets can lead to data breaches where unauthorized users may gain access to sensitive data, modify it, or even delete it. This can result in massive consequential costs for investigation and restoration processes, and potential fines in the event of violation of compliance regulations such as GDPR. \n\n2. **Loss of Business**: If unauthorized modification or deletion of data occurs, critical business processes might be affected leading to downtime or outage, which may translate into loss of business. Also, any leakage of customers' sensitive data can result in loss of customer trust and a resultant decrease in business.\n\n3. **Legal and Regulatory Penalties**: Depending on the type, scope, and severity of data accessed or breached, organizations can face significant legal and regulatory penalties. In extreme cases, it might lead to businesses being temporarily or permanently shut down either due to regulatory conditions or financial ruin.\n\n4. **Reputational Costs**: Incidents related to data security can lead to significant reputational damage. After a data breach, prospects, customers, and partners could lose trust in your organization, and recovering from reputational damage can be a lengthy and costly process.\n\nTo avoid these costly consequences, it is essential to appropriately manage access to resources in the AWS Cloud. This includes making sure only authorized users, processes, and devices are granted access to Amazon Simple Storage Service (Amazon S3) buckets. This can be achieved by effectively using AWS services and features such as AWS Identity and Access Management (IAM), bucket policies, and Access Control Lists (ACLs)."
      ],
      "x-kaytu-usefulness-example": [
        "In an e-commerce company where multiple teams are constantly working on different aspects of the business, it's crucial to manage and control access to resources in the AWS cloud effectively. For example, there might be an R\u0026D team that is developing new features, a Marketing team that needs access to customer analytics data, and a Sales team that requires access to their leads and opportunities database.\n\nImagine that the company's sensitive data such as customers' credit card details, personal information, transaction history, and so on, are all stored in Amazon S3 buckets. In this scenario, controlling who can access these buckets is critical. \n\nBy implementing this AWS control, the company can ensure that only authorized users, devices, or processes can access specific S3 buckets. For instance, they can ensure that the R\u0026D team can only access the buckets related to software development but not to customers' financial data or the Sales team's databases.\n\nThis would not just safeguard the company's sensitive data but also minimize the risk of any accidental changes or deletions by people who aren't supposed to have access. It also helps maintain an audit trail of who accessed what data and when, which can be extremely useful in the event of a security breach or for compliance purposes. \n\nHere's an example of a policy that would restrict access to an S3 bucket (replace `'your-bucket-name'` with your actual bucket name):\n\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AllowBucketReadAccess\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::your-bucket-name\"\n            ]\n        },\n        {\n            \"Sid\": \"AllowObjectReadAccess\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::your-bucket-name/*\"\n            ]\n        }\n    ]\n}\n```\nThis policy would allow a user, process, or device to list the contents of the bucket and read the objects in the bucket but does not provide any other permissions (like put, delete, etc.)."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_instance_prohibit_public_access",
    "Title": "RDS DB instances should prohibit public access",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that Amazon Relational Database Service (Amazon RDS) instances are not public.",
    "QueryID": "aws_rds_db_instance_prohibit_public_access",
    "DocumentURI": "policies/aws_rds_db_instance_prohibit_public_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Ensuring Non-Public Amazon RDS Instances \n\nAWS best practice suggests that resources in your AWS Cloud, like Amazon Relational Database Service (RDS) instances, should not be public in order to manage access to important data securely.\n\n## **Description:**\n\nWhen you configure your Amazon RDS instances to be public, these instances' data can be accessed from any IP address on the internet. This is a risk for sensitive data that may reside on these instances as it opens the possibility for unauthorized access or malicious attacks. \n\nTo properly manage data security risks, it is recommended that Amazon RDS instances are not set to be publicly available. Instead, it is best to limit access to trusted IP ranges or establish private connections using tools such as AWS Direct Connect or VPN.\n\n## **Risks:**\n\n- Unauthorized data access\n- Data breaches\n- Inadequate compliance posture\n\n## **Audit:**\n\nTo check if your Amazon RDS instances are publicly accessible:\n\n1. Open the Amazon RDS console.\n2. In the navigation pane, choose \"DB Instances\". \n3. Choose an instance and under the \"Details\" section, check the \"Publicly Accessible\" value.\n\n## **Remediation:**\n\nIf your Amazon RDS instance is publicly accessible, follow these steps to modify its accessibility:\n\n1. Open the Amazon RDS console \n2. In the navigation pane, select \"DB Instances\". \n3. Select the DB instance that is publicly accessible. \n4. Choose \"Modify\". \n5. Under the \"Network \u0026 Security\" heading, set \"Public Accessibility\" to \"No\". \n6. Choose \"Apply Immediately\", then choose \"Modify DB Instance\" to apply changes. \n\n**Note:** You must make this change during your maintenance window to avoid disruption. \n\n## **References:**\n\n- [Amazon RDS: Modify a DB Instance](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html)\n- [Amazon RDS: Security group rules](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.SecurityGroups.html)"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS Control can lead to several costs, both tangible and intangible. \n\n1. **Security Breach Costs:** The foremost cost of non-compliance is the potential for security breaches. If your Amazon RDS instances are public, they are potentially accessible to anyone on the internet. This might expose sensitive data to malicious actors leading to data leaks or breaches, which are costly to rectify. It might also lead to unauthorized modification, deletion, or theft of data.\n\n2. **Damage to Reputation:** Following any data breach, organizations often face a significant loss of trust from customers, partners, and the market. This can lead to a loss of business, making it an indirect but substantial cost of non-compliance.\n\n3. **Regulatory Fines:** Depending on the nature of your organization and the data you deal with, you could also be subjected to heavy fines from regulatory bodies for not following data security norms. Furthermore, you might face lawsuits from affected parties.\n\n4. **Potential System Disruption:** Unrestricted access might also lead to increased risk of Distributed Denial of Service (DDoS) attacks, causing potential system disruption and thus affecting business continuity.\n\n5. **Cost of Remediation:** If a breach happens, the organization would have to spend substantial resources for remediation which include investigation of breach, recovery of lost data, improving security infrastructure, potential legal fees etc.\n\nTo avoid these costs, it is essential to manage access effectively, ensuring that Amazon RDS instances are not public thereby limiting the access to specific, authenticated users."
      ],
      "x-kaytu-usefulness-example": [
        "***Example***\n\nHyperCorp operates a critical application for its business processes and stores sensitive data in an Amazon RDS Instance. To improve security, the firm's IT administrator configured the RDS instance to not be publicly accessible. This considerably reduced the likelihood of unauthorized access to the database. \n\nThe application servers, which require access to the database, are hosted within the organization's secure AWS VPC (Virtual Private Cloud). They connect to the RDS instance through the private endpoint within the VPC. This way, all the data remains secure within the AWS network, making it appropriately isolated from potential threats.\n\n```markup\nSpec:\n  VpcConfig:\n    SubnetIds: \n      - subnet-02827fbd8b1234567\n    SecurityGroupIds: \n      - sg-01234567\n  PubliclyAccessible: false\n...\n```\nThis AWS markup indicates that the RDS instance is not publicly accessible (`PubliclyAccessible: false`). It can only be accessed by authorized entities which are allowed by the specified security group (`SecurityGroupIds: - sg-01234567`) within the specified subnet (`SubnetIds: - subnet-02827fbd8b1234567`). \n\nBy managing access to their database on AWS, HyperCorp can ensure that only authorized entities can communicate with the database, thereby, strengthening its data security and guarding against potential cyber attacks."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_lambda_function_restrict_public_access",
    "Title": "Lambda functions should restrict public access",
    "Description": "Manage access to resources in the AWS Cloud by ensuring AWS Lambda functions cannot be publicly accessed.",
    "QueryID": "aws_lambda_function_restrict_public_access",
    "DocumentURI": "policies/aws_lambda_function_restrict_public_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/Lambda"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Lambda is a service that lets you run your code without provisioning or managing servers. However, allowing public access to your Lambda functions can lead to unauthorized actions, ranging from triggering functions unnecessarily (which may increase your AWS costs), to exploiting any vulnerabilities within the functions themselves.\n\nTo prevent public access, you can take the following steps:\n\n1. **Create a proper IAM policy that restricts access to your AWS Lambda functions.**\n\n   In AWS, IAM policies define what actions are allowed or denied on what AWS resources. For example, you can create an IAM policy that allows only certain IAM users or roles to invoke your Lambda functions.\n\n```markup\n{\n    \"Version\":\"2012-10-17\",\n    \"Statement\":[{\n    \"Effect\":\"Allow\",\n    \"Action\":\"lambda:InvokeFunction\",\n    \"Resource\":\"arn:aws:lambda:\u003cregion\u003e:\u003caccount-id\u003e:function:\u003cfunction-name\u003e\"\n    }]\n}\n```\n\n2. **Assign the IAM policy to users or roles.**\n\n   You can assign the IAM policy you created to IAM users or roles in your AWS account.\n\n3. **Do not create API Gateway method with ANY method and ANY AllowMethod.**\n\n   API Gateway methods can be publicly accessible, allowing anyone to invoke your Lambda functions. Avoid creating an API Gateway method with '*' (ANY) method and '*' (ANY) AllowMethod which permits any HTTP method (GET, POST, PUT, DELETE, etc.) from any source to be invoked.\n\n4. **Secure your AWS Lambda functions using AWS WAF (Web Application Firewall).**\n\n   You can use AWS WAF to allow or block HTTP(S) requests to your AWS Lambda functions based on conditions such as IP addresses, HTTP headers, HTTP body, or URI strings. \n\nBy managing the access to your AWS Lambda functions appropriately, you ensure that only authorized users, roles, or services can trigger them, enhancing the security of your AWS resources."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this control could result in a variety of costs, both financial and otherwise. Here are some potential consequences:\n\n1. **Data Breaches:** If AWS Lambda functions can be publicly accessed, they can be exploited to extract sensitive data causing loss of data privacy and integrity. This can lead to identity theft, fraud, and other forms of cybercrime. \n\n2. **Monetary Losses:** Data breaches often lead to financial losses, starting from regulatory fines, penalties, legal fees, and even paying ransom to cybercriminals. It can also lead to business disruption, which can be quite costly.\n\n3. **Reputation Damage:** An organization that suffers a data breach will likely experience damage to its reputation which can result in loss of customers and future business.\n\n4. **Non-compliance Penalties:** Companies operating in certain sectors, such as finance or health, must comply with specific regulations concerning data security. Non-compliance due to poorly configured Lambda functions can lead to steep penalties or even loss of license to operate.\n\n5. **Remediation Costs:** In case of a security incident, the organisation will need to employ significant resources to restore affected systems or data, which can be an additional significant expense.\n\nTo mitigate these risks, access to AWS Lambda functions should be appropriately managed and monitored, ensuring that public access is disallowed wherever it is not necessary."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a company is developing a serverless application on AWS using Lambda functions to process sensitive customer data. They have multiple Lambda functions in place to handle different aspects like processing customer's personal data, payment details, order details etc.\n\nHowever, if these Lambda functions could be publicly accessed, it introduces a potential vulnerability as unauthorized users could potentially access or invoke these functions. Unauthorized access could lead to data leakage, potentially revealing and compromising sensitive data like credit card information or personal identification data. \n\nHence, by managing access to AWS resources and ensuring AWS Lambda functions cannot be publicly accessed, the company can effectively protect the sensitive customer information processed by its Lambda functions which would otherwise lead to a security breach causing severe damage to reputation and financial loss."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_snapshot_prohibit_public_access",
    "Title": "RDS snapshots should prohibit public access",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that Amazon Relational Database Service (Amazon RDS) instances are not public.",
    "QueryID": "aws_rds_db_snapshot_prohibit_public_access",
    "DocumentURI": "policies/aws_rds_db_snapshot_prohibit_public_access.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Amazon RDS Instances Should Not Be Public \n\nAmazon Web Services (AWS) provides numerous services and resources that users can utilize to build robust and scalable architectures. One important aspect of utilizing AWS resources is to properly manage and control access to these resources. \n\n## **Control Description**\nOne crucial AWS control stipulates that Amazon Relational Database Service (Amazon RDS) instances should not be made public. This means that these instances should not be accessible directly from the internet. This control is of paramount importance to prevent unauthorized access, data leakage, and other potential security threats. \n\n## **Access Control**\nTo manage resource access in AWS, one commonly used method is to configure Security Groups. A Security Group acts like a firewall; it controls inbound and outbound traffic to resources, in this case, Amazon RDS instances. \n\nBy default, AWS Security Groups allow outbound traffic but block all inbound traffic. \n\n## **How to Implement the Control**\nTo ensure that RDS instances are not public, it is recommended to deny all inbound traffic rules in Security Groups that are associated with the RDS instances. \n\n```markdown\n- Select the relevant RDS instance on AWS Console.\n- Under the 'Security Group Rules' tab, review the inbound and outbound rules.\n- If there are any rules allowing traffic from `0.0.0.0/0` (the entire internet), remove or modify these rules.\n- Save the security group settings.\n```\n\nIt is also imperative to regularly monitor and audit resource access controls for any changes and ensure adherence to defined policies. \n\nThis control reduces the attack surface by ensuring databases are not exposed to the internet and remain only accessible to authorized network sources. \n\n## **Conclusion**\nWhile developing in the Cloud, it's crucial to implement stringent security controls such as this. AWS service Amazon RDS instances should not be public, thereby ensuring they are secure from unauthorized access and potential data breaches."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS control, which mandates that Amazon Relational Database Service (Amazon RDS) instances are not public, can lead to the following consequences: \n\n1. **Data Breaches**: If your Amazon RDS instances are public, there is a high risk of unauthorized third parties gaining access to your sensitive data. This leakage of data can lead to significant financial damage for a company in terms of fines for non-compliance to data regulations and loss of proprietary data.\n\n2. **Loss of consumer trust**: Incidents of data breaches can erode public trust in a company. If sensitive consumer data is stolen, it can cause users to abandon your service.\n\n3. **Regulatory Sanctions**: Companies operating in certain sectors are required by law to comply with specific regulations pertaining to data privacy and security. If an AWS RDS instance is public and leads to a data breach, the company can be fined or sanctioned for non-compliance.\n\n4. **Manipulation of data**: Unauthorized access to RDS instances can lead to not just theft of data, but also manipulation of the data. A rogue agent can manipulate data to cause chaos or for their advantage, which can have varied negative impacts on the business. \n\n5. **Cost of Remediation**: Post a data breach or unauthorized access, a big chunk of the budget has to be spent on identifying the breach, fixing it, and taking measures to prevent such incidents in the future. This cost of remediation can be significantly high. \n\nIt is therefore very important to manage access to resources in AWS Cloud and ensure Amazon RDS instances are not public, to avoid the potential for these damaging and costly issues."
      ],
      "x-kaytu-usefulness-example": [
        "```markdown\nExample:\n\nA healthcare data analysis company is using Amazon RDS to store and manage their patients' data. This information is highly sensitive and should not be accessible to anyone outside their organization for privacy and legal reasons (HIPAA compliance).\n\nEnsuring that their Amazon RDS instances are not public would be of immense value. By keeping their instances private, they significantly reduce the risk of unauthorized access and potential data breaches. This way, only the employees and applications that are granted explicit permissions will have the potential to access this information.\n\nWith Amazon RDS not public, they can encourage strong access management policies within their organization, boosting their overall security posture and upholding their commitment to protecting sensitive patient data.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_group_user_role_no_inline_policies",
    "Title": "IAM groups, users, and roles should not have any inline policies",
    "Description": "Ensure an AWS Identity and Access Management (IAM) user, IAM role or IAM group does not have an inline policy to control access to systems and assets.",
    "QueryID": "aws_iam_group_user_role_no_inline_policies",
    "DocumentURI": "policies/aws_iam_group_user_role_no_inline_policies.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Identity and Access Management (IAM) offers ways to define who is authenticated (signed in) and authorized (has permissions) to perform resources operations within your AWS account. Policies are like the legal documents for AWS, they determine who has what type of permission.\n\nThere are two types of policies in IAM: Managed Policies and Inline Policies. Managed policies are standalone policies that you could attach to multiple users, groups, and roles in your AWS environment. Whereas, inline policies are those that you can embed directly into a single user, group, or role.\n\nA control to \"Ensure an AWS Identity and Access Management (IAM) user, IAM role or IAM group does not have an inline policy to control access to systems and assets\" would mean to have a policy in place that prevents an IAM user, IAM role or IAM group from having an inline policy that can control access to systems and assets. The goal of this control is to prevent unauthorized and potentially harmful access to your AWS resources.\n\nIn AWS, it is generally recommended to use Managed Policies instead of Inline Policies for easier management, greater flexibility and better control.\n\nIn the markup format, this control can't be represented because markup languages like HTML, Markdown, etc. are designed to structure and present text, they don't have capabilities to implement or represent policies or controls related to an IAM service of AWS (or any other cloud service's control specification)."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control can be quite significant. Here are some potential consequences:\n\n1. **Poor Security:** Inline policies are policies that you manage on an individual IAM user, group, or role basis. If IAM users, roles, or groups have inline policies, it could lead to access control issues. This could result in unauthorized access to your resources, data breaches, or loss of sensitive information.\n\n2. **Lack of Centralized Control:** AWS recommends managed policies for most purposes because they are easier to manage, scalable and re-usable. Using inline polices can make it difficult to manage permissions as it bypasses centralized control. This could lead to inconsistencies in policies and can cause problems with permissions management.\n\n3. **Increased Overhead:** Inline policies have to be managed individually for each IAM user, group or role. If you have many IAM entities, this could significantly increase your overhead in terms of management and maintenance.\n\n4. **Difficulty in Auditing and Compliance:** This practice may lead to difficulty in auditing and ensuring compliance. With inline policies, you would need to examine each IAM user, group or role individually, which would be a tedious process. Also, it will be difficult to ensure compliance with any security standards that your organization or regulators might require."
      ],
      "x-kaytu-usefulness-example": [
        "AWS Identity and Access Management (IAM) provides the ability to manage access to AWS services and resources securely. However, using inline policies might lead to fine-grained permissions, increasing complexity, and leading to potential misconfigurations or exposure of resources.\n\nAn example instance where this policy can be useful is a company that has a substantial number of users, roles, and groups that interact with its AWS environment. By avoiding inline policies and using managed policies instead, they can easily reuse policies and apply them to multiple entities. Additionally, it helps maintain a central control point for permissions since managed policies aren't embedded within a single user, role, or group.\n\nBy ensuring that users, roles, or groups do not have inline policies, it minimizes the risk of accidentally granting excessive permissions to an entity, enhancing the security posture of the environment. It also simplifies the management and auditing of the permissions since administrators only need to review and manage a single entity instead of multiple scattered policies. \n\nThis control is also useful in large organizations where many teams need similar access to resources. Instead of creating an inline policy for each entity, a managed policy can be created and attached to entities as per the requirement, enabling more efficient access management."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_redshift_cluster_prohibit_public_access",
    "Title": "Redshift clusters should prohibit public access",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that Amazon Redshift clusters are not public.",
    "QueryID": "aws_redshift_cluster_prohibit_public_access",
    "DocumentURI": "policies/aws_redshift_cluster_prohibit_public_access.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/Redshift"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control - Managing Access to Amazon Redshift Clusters\n\nAmazon Redshift is a fast, scalable, and secure data warehouse that makes it simple and cost-effective to analyze all your data using standard SQL. It is extremely important to ensure that these clusters are not public to safeguard your sensitive information.\n\n## How to Manage Access to Redshift Clusters\n\nHere are the steps to manage access to Amazon Redshift clusters:\n\n### Step 1: Verify Cluster's Public Accessibility\n- Sign in to the Amazon Redshift console.\n- In the navigation pane, click on `Clusters`.\n- In the list of clusters, click on your cluster.\n- Under `Cluster Properties`, check `Network and Security settings`.\n- Ensure the `Publicly accessible` setting is marked as `No`.\n\n### Step 2: Modify Public Accessibility\n\nIf the cluster is publicly accessible, here's how to modify it:\n\n- Select your cluster and click `Modify`.\n- In the `Cluster Configuration` section, uncheck the `Publicly accessible` option.\n- Click `Modify` to apply the changes. \n\nPlease note, these changes will not take effect until you reboot your cluster. Ensure you plan this during a maintenance window or a time when the disruption will have the least impact on your users.\n\n## Additional security measures\n\nFurthermore, ensure you:\n- Restrict access to IP addresses that require access by utilising security groups.\n- Implement least privilege principle i.e., grant least possible permissions required to run tasks.\n- Enable `AWS CloudTrail` to log, monitor and retain database events for additional security and troubleshooting.\n\nBy ensuring Amazon Redshift clusters are not publicly accessible, you are adding an additional layer of security to your AWS Cloud environment."
      ],
      "x-kaytu-noncompliance-cost": [
        "Managing access to resources effectively in AWS Cloud is crucial to maintaining the integrity and confidentiality of the data stored within a system. If Amazon Redshift clusters are made public, it can lead to potential security breaches and data loss.\n\nThe cost of non-compliance to the control (i.e., making Amazon Redshift clusters public) can be several-fold:\n\n1. **Security Breaches**: Unrestricted public access to Redshift clusters can potentially lead to intrusion attempts into your data resources. This can further lead to data breaches causing serious harm to the business.\n\n2. **Data Loss/Manipulation**: Unauthorized access to clusters can potentially lead to data loss or manipulation, causing significant disruption to business operations and decision making.\n\n3. **Legal \u0026 Regulatory Fines**: If the data stored in Redshift clusters is under any regulatory framework (like PI, HIPAA, etc.), the organization might face severe legal penalties for non-compliance resulting in finance loses.\n\n4. **Reputation Damage**: A breach in data security can significantly damage the reputation of a company leading to loss of customer trust and potentially reducing market share.\n\n5. **Lost Business Opportunities**: Apart from direct financial losses, businesses may lose potential future business opportunities as a result of the reputational damage suffered due to the data breach.\n\n6. **Costs Associated with Remediation**: The company might have to incur significant costs in identifying the security loopholes, fixing them and restoring the data.\n\nIn order to avoid these costs, businesses must ensure that their Amazon Redshift clusters are not public and that appropriate security measures are in place to protect their data resources."
      ],
      "x-kaytu-usefulness-example": [
        "AWS provides useful controls like the ability to manage access to resources in the cloud. For instance, ensuring that Amazon Redshift clusters are not public can be useful in several scenarios. \n\nConsider a retail company that uses Amazon Redshift for its data warehousing needs. The company stores sensitive data such as customer information, sales data, and even some internal metrics. If these Redshift clusters are public, anyone on the internet can potentially access this data, leading to serious privacy and security risks.\n\nBy ensuring that Redshift clusters are not public and only accessible to authorized personnel within the company, sensitive data remains secure. Network traffic is controlled, making sure that only legitimate requests are processed, and data breaches are prevented, all contributing to preserving the integrity and privacy of the retail company's data.\n\nThis is an example of how the AWS control to manage access to resources helps businesses protect their data and maintain compliance with security regulations. \n\n```markdown\nExample:\n\nA retail company uses Amazon Redshift to manage and analyze their vast amounts of data. To maximize their data's security, they use the following AWS control:\n\n- **Not Making Redshift Clusters Public:** By ensuring their Amazon Redshift clusters aren't public, the company effectively prevents unauthorized access to their sensitive data. This control enables them to restrict access to a select few, therefore reducing the risk of data breaches and potential misuse of their customer and sales data.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudfront_distribution_logging_enabled",
    "Title": "CloudFront distributions access logs should be enabled",
    "Description": "This control checks if Amazon CloudFront distributions are configured to capture information from Amazon Simple Storage Service (Amazon S3) server access logs. This rule is non compliant if a CloudFront distribution does not have logging configured.",
    "QueryID": "aws_cloudfront_distribution_logging_enabled",
    "DocumentURI": "policies/aws_cloudfront_distribution_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CloudFront"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Amazon CloudFront Distributions Logging Configuration\n\n## Description\n\nThis AWS control concerns the logging configurations of Amazon CloudFront distributions, specifically if they're set up to capture Amazon S3 server access logs.\n\nAmazon CloudFront is a fast content delivery network (CDN) provided by Amazon Web Services. It securely delivers data, videos, applications, and APIs with low latency and high transfer speeds. It also integrates with other AWS services to give developers and businesses an easy way to distribute content to users with low latency, high data transfer speeds, and no minimum usage commitments.\n\nAmazon Simple Storage Service (Amazon S3) is an object storage service that offers scalability, data availability, security, and performance. \n\nServer access logging provides detailed records for the requests that are made to an Amazon S3 bucket. This feature is useful for security audit purposes as it provides the requester's identity, the time of the request, the request action, the response status, and error codes, among others.\n\nThis control checks if CloudFront distributions are capturing Amazon S3 server access logs. In other words, it audits if the logging feature to record access requests made to your S3 buckets through CloudFront distributions is enabled.\n\n---\n\n## Non-Compliance\n\nThis control measures compliance by checking the logging configuration of each CloudFront distribution.\n\nIf the control finds a CloudFront distribution that is not configured to capture access logs from Amazon S3 servers, that distribution is considered non-compliant.\n\nOn the other hand, if all CloudFront distributions in the AWS environment have logging configured appropriately, the control is compliant.\n\nIt's necessary to ensure this logging is enabled for security and audit purposes, to support identifying potential unauthorized activities or system vulnerabilities.\n\n---\n\n## Remediation\n\nTo ensure compliance with this rule, review and modify the configurations of your Amazon CloudFront distributions as necessary. Ensure that server access logging is enabled, and logs are being captured consistently from Amazon S3 servers.\n\nFor more instructions on how to enable server access logging, please refer to AWS' official documentation. \n\n---\n\nThis control supports efforts to avoid data breaches, fulfill compliance requirements, and maintain overall operational security and performance within the AWS environment."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control can escalate widely depending on the severity and the magnitude of the uncontrolled situation. Here are some potential costs that might be associated with not adhering to this rule:\n\n1. **Loss of valuable data**: CloudFront access logs contain valuable information about user activities like IP addresses, user agents, HTTP statuses etc. If these are not captured, this vital information would be lost which might be required for audit and analysis purposes.\n\n2. **Difficulty in debugging issues**: These logs play a crucial role in debugging issues and incidents. Investigating and resolving issues could be a daunting task without these logs.\n\n3. **Increased security risk**: Without these logs, unauthorized access or security threats might go unnoticed resulting in potential breaches and loss of data.\n\n4. **Increased operational costs**: Investigating issues without proper logs can lead to increased operational costs. More resources might be required to troubleshoot and fix issues without logs.\n\n5. **Potential non-compliance penalties**: Depending on the industry and organization policies, regulatory authorities might impose fines if logs are not maintained, which is often necessary to comply with various security standards and certifications.\n\n6. **Damage to reputation**: If a data breach happens and customer's data is compromised, this could severely tarnish the image of the company and lead to loss of customer trust.\n\nHence, it is essential to comply with this control and ensure that Amazon CloudFront distributions are configured to capture server access logs from Amazon S3."
      ],
      "x-kaytu-usefulness-example": [
        "For large organizations with multiple websites and applications, it is crucial to monitor and analyze web traffic data and track access logs for security concerns such as unauthorized access attempts or unusual activities. By configuring Amazon CloudFront to capture information from Amazon Simple Storage Service (Amazon S3) server access logs, the organization can get detailed records of every single request made to their S3 resource. This can be helpful in subsequent security audits or incident investigations. \n\nIf there's a security breach or an attempt to access sensitive data, the logs can be scrutinized to understand the vector of the attack. These logs can also assist in compliance reporting for various regulations like GDPR where detailed access record is a mandate. Mitigate future attacks by putting in place proactive measures derived from patterns exhibited in these logs. \n\nFor instance, a media service company uses Cloudfront to deliver its content globally. Configuring Cloudfront to capture server access logs helps them identify any unauthorized attempt to access their S3 buckets. The logs provide details about request type, resource accessed, request initiator's IP, error code etc. Therefore, server access logs are an important part of security best practices and compliance efforts. \n\nThis rule, checking whether Amazon CloudFront distributions are configured to capture logs, will be a handy tool in system health check and ensuring regulatory compliance. The rule alerts the system administrators when logging is not properly configured, ensuring that organization's data security measures are not compromised."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudwatch_log_group_retention_period_365",
    "Title": "Log group retention period should be at least 365 days",
    "Description": "Ensure a minimum duration of event log data is retained for your log groups to help with troubleshooting and forensics investigations.",
    "QueryID": "aws_cloudwatch_log_group_retention_period_365",
    "DocumentURI": "policies/aws_cloudwatch_log_group_retention_period_365.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/CloudWatch"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "## AWS Control: Retain and Manage Log Data\n\n### Description\nYour AWS resources generate valuable log data that can be used to troubleshoot issues and conduct forensic and security investigations. It's important to ensure that this data is retained for a sufficient amount of time according to your organization's policies or regulatory requirements.\n\n### Code Implementation\n```markdown\n1. Sign in to the AWS Management Console.\n2. Open the CloudWatch console.\n3. In the navigation pane, click `Log groups`.\n4. Select a log group.\n5. Under the `Actions` dropdown, select `Edit retention`.\n6. Set the desired retention duration and save changes.\n```\n### Compliance\nBy retaining logs for an appropriate duration, organizations can ensure they have enough historical data to troubleshoot problems or investigate security incidents. This could help to meet compliance objectives related to data preservation and monitoring.\n\n### Associated Costs\nWhile retaining logs for longer periods of time can provide benefits in terms of troubleshooting and compliance, it also comes with increased storage costs. It's important to balance the value of extended log retention with these costs.\n\n### Best Practices\n- Determine appropriate log retention durations according to your specific use case and legal requirements.\n- Monitor and regularly review your log files to identify potential issues or security incidents.\n- Use AWS services such as AWS CloudTrail and Amazon CloudWatch Logs to automatically collect, store, and analyze log data.\n- Set up automated alerts for specific types of log activities to ensure quick awareness and response to potential security threats. \n\n### Related AWS Services\nAWS CloudTrail, Amazon CloudWatch Logs.\n\nPlease note that you may incur additional costs for using these AWS services. Check the service pricing details on the official AWS website.\n\nRemember to adhere to any data retention policies or regulatory requirements your organization may be subject to. This could mandate a specific duration for log data retention.\n\n-------\n_Disclaimer: The code implementation is a generalized snippet on how to set the log data retention period in AWS Management Console. The actual steps to follow could vary depending on the AWS Services you are using._"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control can result in numerous costly consequences. \n\n1. **Loss of valuable data**: If event log data isn't retained for an adequate duration, potentially critical pieces of information about your system's operation and security could be lost. If you need to look back to a certain period to investigate an issue or a breach, the necessary data may no longer be available. \n\n2. **Difficulty in bug and issue resolution**: Logs are crucial in troubleshooting and resolving application issues. Without enough historical data, it becomes harder and takes longer to identify patterns and causes of bugs or malfunctions. This delay can negatively impact system performance and user experience, leading to financial losses.\n\n3. **Hindrance in forensic investigations**: In the case of a security incident, logs are usually the first place investigators look to understand what happened. If log data isn't sufficiently retained, the investigation might hit a dead-end, leaving the security breach unresolved and your system vulnerable to repeated attacks.\n\n4. **Potential non-compliance penalties**: Depending on the industry, certain regulations (like HIPAA for healthcare or PCI DSS for payment cards) require log retention for a specified time period. Failure to comply may result in hefty penalties and a loss of customer/industry trust.\n\n5. **Complication in incident response**: Lack of previous log data can also hinder incident response activities, making it difficult to figure out the sequence of events, perform damage control, and prevent future incidents.\n\nTo avoid financial and reputational damage, it's crucial to comply with the AWS control on retaining event log data for a minimum duration."
      ],
      "x-kaytu-usefulness-example": [
        "The following is an example instance where retaining a minimum duration of event log data can prove to be useful:\n\nDevOps engineer Alex works for a software company that develops applications served via AWS infrastructure. One day, he receives complaints about frequent application crashes experienced by users in the past week. With no known changes in the application code and infrastructure setup, Alex is uncertain about the cause.\n\nTo investigate this, he looks at the AWS event logs for the past week. However, Alex had set the log retention period to only three days because the company was trying to save costs on log data storage.\n\nDue to this misstep, Alex is unable to access logs from the time when the application crashes started. As a result, he struggles to diagnose and resolve the issue, causing prolonged application downtime and a frustrating experience for users.  \n\nIf a minimum retention period was in place, Alex could have access to the crucial log data needed to quickly identify and solve the problem. Hence, implementing a minimum duration of event log data retention is a useful practice in AWS."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_account_password_policy_min_length_14",
    "Title": "Ensure IAM password policy requires a minimum length of 14 or greater",
    "Description": "Password policies, in part, enforce password complexity requirements. Use IAM password policies to ensure that passwords are at least a given length. Security Hub recommends that the password policy require a minimum password length of 14 characters.",
    "QueryID": "aws_iam_account_password_policy_min_length_14",
    "DocumentURI": "policies/aws_iam_account_password_policy_min_length_14.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "x-kaytu-explanation": [
        "```markdown\n# AWS Control: Password Policies \n\nPassword policies are security tools used to enforce password complexity requirements in order to enhance the security of your AWS resources. They are a part of Identity and Access Management (IAM) that makes sure the passwords being used meet a certain set of criteria.\n\n**Minimum Password Length Requirement:**\nAmazon's Security Hub suggests that the password policy should require a minimum password length of 14 characters. This recommendation ensures enhanced safety as long passwords are usually hard to break.\n\nTo set this requirement on AWS, follow the steps below:\n\n1. Open the IAM console in the AWS Management Console.\n2. In the navigation pane, select __Account Settings__.\n3. In the __Password Policy__ section, check the box for __Apply password policy__.\n4. Next, indicate the minimum password length as 14 in the __Allowable Password Length__ section.\n5. Click __Apply__ to finish setting up the policy.\n\nFollowing these steps will ensure that all the IAM users in your AWS environment are required to set a password of at least 14 characters in length when they create or update their password.\n```\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control can result in several costs:\n\n1. **Security breaches**: Passwords that do not meet the recommended length requirement are more at risk of being guessed, cracked, or hacked. This can lead to unauthorized access to your AWS environment, resulting in misuse or theft of sensitive data, customer trust damage, or even a shutdown of services.\n\n2. **Regulatory penalties**: Many industries have regulations requiring companies to implement certain security measures, including robust password policies. Failing to comply could result in fines, sanctions, or the loss of certain business rights.\n\n3. **Loss of customer trust and business reputation**: If a breach happens due to weak passwords, the company's reputation can be damaged and customers could lose their trust in the company's ability to safeguard their data.\n\n4. **Financial loss**: The cost of remediation following a security breach can be significant. This includes the cost to investigate the breach, implement stronger security measures, potential legal fees, and loss of business during the remediation process. \n\n5. **Operational disruption**: In the event of a breach, normal business operations may be halted to investigate and remedy the situation, leading to further financial losses and possibly missed opportunities.\n   \nIn conclusion, non-compliance to AWS password policy control can cause serious harm to your AWS environment, company reputation, and financial stability."
      ],
      "x-kaytu-usefulness-example": [
        "The following example demonstrates the instance of setting up password policy on AWS IAM with minimum password length of 14 characters.\n\n```markdown\nSet Up Password Policy in AWS IAM\nThe following steps show how to set a password policy for IAM users:\n\n1. Open the AWS Management Console and sign in with your AWS account.\n2. Navigate to 'Services' and then select 'IAM' under Security, Identity \u0026 Compliance.\n3. In the navigation pane, select 'Account Settings'.\n4. Under 'Password Policy', click 'Change'.\n5. Under 'Set password policy', do the following:\n    - Check the box for 'Require at least one uppercase letter from Latin alphabet (A-Z)'.\n    - Check the box for 'Require at least one lowercase letter from Latin alphabet (a-z)'.\n    - Check the box for 'Require at least one number'.\n    - Check the box for 'Require at least one non-alphanumeric character (!@#$%^\u0026*())'.\n    - Set 'Minimum password length' to '14'.\n6. After you've checked the boxes and set the password length, click 'Save Changes'.\n\nThis password policy ensures that all IAM users must create a password with at least 14 characters, an uppercase letter, a lowercase letter, a number and a non-alphanumeric character. This is a recommended policy by AWS to ensure password complexity and security.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_subnet_auto_assign_public_ip_disabled",
    "Title": "VPC subnet auto assign public IP should be disabled",
    "Description": "Ensure if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address. The control is compliant if Amazon VPC does not have subnets that are assigned a public IP address. The control is non compliant if Amazon VPC has subnets that are assigned a public IP address.",
    "QueryID": "aws_vpc_subnet_auto_assign_public_ip_disabled",
    "DocumentURI": "policies/aws_vpc_subnet_auto_assign_public_ip_disabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/VPC"
      ],
      "x-kaytu-explanation": [
        "This AWS (Amazon Web Services) Control involves the configuration of Amazon Virtual Private Cloud (VPC). VPC is a cloud service which allows users to generate and control their virtual networking environment which includes IP address ranges, subnets, and configuration of route tables and network gateways.\n\nThe control checks if the VPC subnets are assigned a public IP address. \n\n```markdown\nCompliance:\n- The control is said to be *compliant* if the VPC does not have any subnets that are assigned a public IP address. \n\nNon-Compliance:\n- The control is deemed *non-compliant* if the VPC has any subnets that are assigned a public IP address.\n```\n\nAssigning a public IP address to a VPC subnet can have security implications, as it can potentially expose your VPC to the internet, thereby becoming a target for malicious activities over the internet. To ensure the safety of your VPC, it's generally advised to not assign a public IP address to the VPC subnets."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control can have several consequences and potential costs: \n\n1. **Increased Security Risk**: Exposing VPC subnets directly to the internet by assigning them public IP addresses increases the attack surface for malicious actors. This could lead to security breaches, data loss or corruption, and could compromise the integrity of your infrastructure.\n\n2. **Data Breaches and Associated Penalties**: If sensitive data gets exposed because of an insecure configuration, organizations can face severe penalties, especially if they are under regulations such as GDPR, HIPAA, etc. These penalties can be monetary, but they can also include reputational costs.\n\n3. **Unexpected Costs**: Publicly exposed resources may handle more traffic than intended, leading to an increase in data transfer costs. If services exposed to the internet are misused or attacked (for example in a DDoS attack), this could also lead to additional unexpected costs.\n\n4. **Regulatory Compliance Issues**: Non-Compliance with this control could also mean non-compliance with industry-specific regulations and standards, potentially causing penalties and/or the need for costly rectification activities.\n\n5. **Operational Issues**: If unauthorized changes or access occurs due to the public exposure of your resources, this could cause service disruptions, leading to potential downtime and associated operational costs. \n\nNote: While it's sometimes necessary to have subnets with a public IP, it's best practice to minimize this as much as possible, and to secure those subnets using appropriate security measures. These can include security groups, network access control lists (NACLs), and AWS services like GuardDuty and Shield."
      ],
      "x-kaytu-usefulness-example": [
        "As a web company deploying a new online service, you choose to use Amazon Web Services (AWS) for your cloud infrastructure. For maximum security, you decide to divide your network into multiple subnets via Amazon Virtual Private Cloud (VPC). You have one subnet dedicated to the front-end services, which need to interact with internet traffic, and another subnet for critical back-end services containing sensitive customer data.\n\nTo prevent any accidental exposure of your back-end services, you apply the AWS control - \"Ensure if Amazon VPC subnets are assigned a public IP address.\" By ensuring only the required front-end subnet is public-facing and the back-end subnet is not assigned any public IP address, you prevent any direct access from the internet to the sensitive customer data, thus achieving a strict security level.\n\nIn this case, this AWS control ensures compliance by providing an additional security layer, as the subnets containing sensitive data will not be exposed to the internet just by mistake or misconfiguration, protecting the data from potential threats. \n\nOn the other hand, if the control finds VPC subnets with assigned public IP address(es) that shouldn't have, it flags them as non-compliant, prompting an investigation into why that's the case, consequently increasing the organization's overall security posture."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_elb_application_classic_lb_logging_enabled",
    "Title": "ELB application and classic load balancer logging should be enabled",
    "Description": "Elastic Load Balancing activity is a central point of communication within an environment.",
    "QueryID": "aws_elb_application_classic_lb_logging_enabled",
    "DocumentURI": "policies/aws_elb_application_classic_lb_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/ELB"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "**Elastic Load Balancing activity in AWS**\n\nElastic Load Balancing is a fully managed service offered by Amazon Web Services (AWS) that makes it easy to distribute incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, virtual appliances, and IP addresses.\n\n```\n## Key Features\n```\n* **High Availability**: Elastic Load Balancing (ELB) automatically distributes incoming application traffic across multiple targets, such as EC2 instances. It ensures that only healthy targets receive traffic by detecting unhealthy ones and rerouting traffic appropriately.\n\n* **Flexibility \u0026 Scalability**: ELB can automatically scale its capacity according to traffic patterns. It can handle the varying load of your application traffic in a single Availability Zone or across multiple availability zones.\n\n* **Security**: ELB provides robust security features, including integrated certificate management, user-authentication, and SSL/TLS decryption. \n\n* **Improved Performance**: ELB offers robust request and connection handling capabilities. It can handle traffic peaks and connect users to the least busy instance to minimize response time.\n\n```\n## How ELB Works\n```\n1. Once a load balancer is created, it has a DNS name that can be used to route the traffic.\n2. When clients open a connection with the load balancer, they send a request to it.\n3. The load balancer distributes incoming application traffic across multiple targets, such as EC2 instances, in multiple Availability Zones. This increases the fault tolerance of your applications.\n4. The load balancer continues to monitor the health of its registered instances and does not send requests to instances that are not healthy.\n\n```\n## Types of Elastic Load Balancing\n```\nAWS provides three types of load balancers, each suited to different types of applications or needs.\n\n* **Application Load Balancer (ALB)**: Best suited for HTTP and HTTPS traffic. It operates at layer 7 and offers advanced routing features, native HTTP/2, and WebSocket support.\n\n* **Network Load Balancer (NLB)**: Ideal for load balancing of TCP, UDP, and TLS traffic where extreme performance is necessary. \n\n* **Classic Load Balancer (CLB)**: Provides basic load balancing across multiple Amazon EC2 instances and operates at both the request level and connection level.\n\nELB is a crucial component of any AWS environment as it optimizes the distribution of workloads, ensuring that no single resource becomes a bottleneck, and improves overall system responsiveness and availability. It forms a central point of communication within the AWS environment as all client requests are routed through it."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS control of \"Elastic Load Balancing activity is a central point of communication within an environment\" can be significant on multiple fronts: technical, operational, financial, reputational, and regulatory. \n\n1. **Technical Cost:**\n   - It could lead to poor load balancing of network traffic, causing some servers to be overwhelmed while others are underused.\n   - The potential for service interruption or degradation can increase significantly.\n   - It can lead to inadequate fault tolerance in the AWS environment, causing a single point of failure.\n\n2. **Operational Cost:**\n   - Non-compliance can lead to increased administrative and troubleshooting time.\n   - It may require more resources to manage and monitor the infrastructure, increasing operational costs.\n\n3. **Financial Cost:**\n   - A non-balanced load can lead to inefficient use of resources, which can inflate costs.\n   - Non-compliance may invoke penalties or additional costs due to violation of service level agreements (SLAs).\n\n4. **Reputational Cost:**\n   - Service disruptions can lead to customer dissatisfaction and damage the company's reputation.\n   - A difference in performance across different services due to poor load balancing can lead to a poor user experience.\n\n5. **Regulatory Cost:**\n   - In specific industries, failure to comply with certain controls such as load balancing may result in regulatory fines or penalties.\n   - Non-compliance with industry standards can lead to audit failures.\n\nBy ensuring compliance with this control, companies can maintain a balanced and high-performing AWS environment that is efficient, reliable, and consistent in delivering results. It helps in enhancing the customer experience, operations, security as well as maintaining regulatory standards.\n"
      ],
      "x-kaytu-usefulness-example": [
        "Elastic Load Balancing ensures that incoming traffic to your AWS environment is distributed evenly across multiple targets. This can be across multiple EC2 instances, containers, IP addresses, and Lambda functions.\n\nSuppose you're running a large e-commerce store in AWS, with a front-end web application, a back-end order processing service, and numerous databases. During peak time (e.g., during a holiday sale), there's a massive influx of users accessing your site and making purchases. This causes a high load on your front-end web application and the back-end order processing service.\n\n```markup\n\u003cexample\u003e\n  To handle this influx without affecting user experience or crashing servers, Elastic Load Balancing would be useful. It would distribute the incoming user traffic across multiple instances of your web application and order processing service. Therefore, instead of all requests 'hitting' one server and potentially overloading it, the traffic is spread evenly, thus ensuring server health and application responsiveness.\n\n  1. Amazon EC2: You might have multiple instances for your web app to handle high traffic. But it's not efficient to direct all traffic to a single EC2 instance when others are idle. ELB can distribute incoming traffic evenly among all instances.\n\n  2. Auto Scaling: With Elastic Load Balancing, you can pair it with EC2 Auto Scaling to ensure that you have enough instances to handle the load at any given time.\n\n  3. High Availability: ELB automatically distributes incoming application traffic across multiple targets, such as EC2 instances, which increases the availability of your application.\n\n  4. Containerized Application: If you have an application running on a Docker container and use services like ECS or EKS, ELB ensures that the traffic is evenly distributed among all containers.\n\n  5. Serverless Architecture: When used with Lambda functions, ELB can efficiently distribute user requests to different Lambda functions for better performance.\n\u003c/example\u003e\n```\nIn this scenario, Elastic Load Balancing ensures the high availability and fault tolerance of your applications, despite high user traffic."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_cross_region_replication_enabled",
    "Title": "S3 bucket cross-region replication should be enabled",
    "Description": "Amazon Simple Storage Service (Amazon S3) Cross-Region Replication (CRR) supports maintaining adequate capacity and availability.",
    "QueryID": "aws_s3_bucket_cross_region_replication_enabled",
    "DocumentURI": "policies/aws_s3_bucket_cross_region_replication_enabled.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Cross-Region Replication (CRR) is a feature of Amazon Simple Storage Service (Amazon S3) that enables automatic and asynchronous copying of objects across buckets in different AWS Regions. This feature is used to maintain data redundancy and high availability by protecting your data against unexpected events such as deletion, corruption, or disasters in a specific region.\n\nHere's a markup example that explains the usage of Amazon S3 CRR:\n\n```\n## Amazon S3 Cross-Region Replication\n\nAmazon S3 provides a feature called Cross-Region Replication (CRR) that helps to maintain \ncapacity and availability of your data. It involves automatic and asynchronous copying of\nobjects across different AWS Regions.\n\n### Benefits\n\n- **Higher availability**: In case of a region-wide service disruption, your data \n  remains available in a different region.\n\n- **Data redundancy**: CRR copies all data including all versions of an object \n  (including all writes and deletes) across regions, offering stronger data \n  replication.\n\n- **Compliance needs**: For data residency and compliance needs, Cross-Region \n  Replication allows automatic replication of data to another region.\n\n### How it Works\n\n1. When an object in the source bucket is modified, Amazon S3 makes a new copy \n   of the object in the target bucket.\n   \n2. Amazon S3 uses the same key name for the object in the source and target buckets.\n\n3. If the event includes a `DELETE` for either a versioned or non-versioned object, \n   Amazon S3 doesn’t replicate the delete marker at the target bucket.\n   \n4. If the capacity of the source bucket is changed, it does not affect the capacity \n   of the target bucket.\n   \nPlease note that Cross-region replication requires versioning to be enabled on both \nthe source and destination buckets.\n```\nThis markup explains AWS S3's CRR feature, its benefits, and how it works."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the Amazon Simple Storage Service (Amazon S3) Cross-Region Replication (CRR) control could potentially incur several costs, which are outlined below:\n\n1. **Data Loss**: One of the main purposes of CRR is to provide a backup of your data in another region. Non-compliance to this control could result in significant data loss if a disaster disables the primary region where your data is stored. The cost here would be trying to recreate this lost data, which may prove to be very costly and, in some cases, impossible.\n\n2. **Downtime Costs**: Without a backup in another region, your services could go offline in case of a region-wide issue. This could lead to financial losses because users might not be able to access your application or service.\n\n3. **Legal and Compliance Costs**: For industries that are under regulations requiring disaster recovery and business continuity measures, non-compliance could result in legal penalties, audit issues, and a negative impact on corporate reputation.\n\n4. **Increased Recovery Time**: If you experience a failure in one region and don’t have CRR set up, the time it takes to recover your data and restart operations may increase significantly.\n\n5. **Loss of Business Reputation and Customer Trust**: If a disaster impacts application availability or results in data loss, you risk damaging your business reputation and loss of customer trust. This can result in loss of customers and decreased revenue.\n\n    ```markdown\n    - Data Loss: Significant data loss if a disaster disables the primary region.\n    - Downtime Costs: Financial losses due to inaccessible application or service.\n    - Legal and Compliance Costs: Penalties for not complying with disaster recovery and business continuity regulations.\n    - Increased Recovery Time: Larger delays in recovering data and restarting operations.\n    - Loss of Business Reputation and Customer Trust: Potential loss of customers and decreased revenue.\n    ```"
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a global retail company has its primary operations in North America with their data stored in the Amazon S3 bucket in the US East region. As the company extends its operations to Europe, there is a need for quicker access to data in this region. Making use of Amazon cross-region replication, the company can automatically replicate data from a source bucket in the US East region to a destination bucket in the EU (Ireland) region. This can immensely reduce the latency in data access for the European customers, improving their user experience and ensuring business continuity even during regional failures."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_instance_encryption_at_rest_enabled",
    "Title": "RDS DB instance encryption at rest should be enabled",
    "Description": "To help protect data at rest, ensure that encryption is enabled for your Amazon Relational Database Service (Amazon RDS) instances.",
    "QueryID": "aws_rds_db_instance_encryption_at_rest_enabled",
    "DocumentURI": "policies/aws_rds_db_instance_encryption_at_rest_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "```\n# AWS Control: Encryption for Amazon RDS Instances\n\nData security is paramount to maintain trust and reliability with customers. One way of ensuring the security of your data in AWS is to use encryption. \n\n## **What is Amazon RDS?**\n\nAmazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale relational databases in the cloud. It provides cost-effective and resizable capacity while managing time-consuming database administration tasks, freeing you up to focus on your applications and business.\n\n## **Importance of Encryption**\n\nEncryption transforms data from a readable form to an encoded version that can only be decoded by another entity if they have the decryption key. \n\nWhen you enable encryption for your RDS instances, all the data stored at rest in the underlying storage is encrypted, as are its automated backups, read replicas, and snapshots.\n\n## **AWS's support for Encryption**\n\nAWS supports encryption at rest for RDS instances. This simply means it encrypts your data before it writes them to the storage layer and it decrypts them when you access them. The encryption and its operations have minimal impact on the performance of your database. \n\nThe keys used for this encryption and decryption process are managed by AWS Key Management Service (KMS). With AWS KMS, you are the master of your keys. You have the control to establish and manage the keys used to encrypt and decrypt your data.\n\n## **How to Enable Encryption?**\n\nWhen creating a new Amazon RDS instance, simply check the `Enable Encryption` option under the `Database Options` step. Select your master key from the list or create a new one if necessary. Note that all DB instances in a DB cluster must be encrypted.\n\nRemember, once your RDS instance is created, you cannot modify whether it uses encryption or not. Make sure to enable encryption when setting up new RDS instances to ensure the security of your data at rest.\n```\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS Control of enabling encryption for your Amazon RDS instances can be both financial and reputational, depending on the nature of any potential data leak or breach.\n\n- **Potential Fines:** Many regions and industries have laws and regulations that prescribe penalties for not properly protecting sensitive customer data. For example, under the General Data Protection Regulation (GDPR) in the European Union, companies can be fined up to 4% of annual global turnover or €20 Million (whichever is greater) for breaching its requirements.\n\n- **Data Breaches:** If data stored within unencrypted RDS instances is accessed or stolen, it could potentially be used for malicious purposes leading to a serious data breach. The cost of a data breach can be immense; an IBM study in 2020 estimated that the average total cost of a data breach is $3.86 million.\n\n- **Loss of Trust:** If customers or clients find out that their data is not being properly encrypted and protected, they may lose trust in your business, potentially leading to loss of clients and sales.\n\n- **IP Loss:** For organizations that store intellectual property or sensitive business data in an RDS instance, the lack of encryption could lead to loss or theft of this data.\n\n- **Remediation Costs:** If you are found to be non-compliant, you may need to expend additional resources to bring your systems into compliance, including potential modifications to your database, applications, and possibly even business processes.\n\nTo prevent these possible costs, it's critical to adhere to best practices and ensure encryption is enabled for all sensitive data at rest within your Amazon RDS instances."
      ],
      "x-kaytu-usefulness-example": [
        "Consider a large pharmaceutical company, named XYZ Pharmaceuticals, that handles very sensitive information about clinical trials, patients, drug formulation etc. This data is critical to their operation and of high interest to hackers. They use Amazon Relial Database Service (RDS) to store and manage this data.\n\nAs per the regulatory requirements, the company has to comply with HIPAA rules which require them to implement a mechanism to protect sensitive patient data. If someone with malicious intent can access this data, they could reveal the secret formula for a top-selling drug, or sell the private patient information on the dark web. \n\nFor this, ensuring that encryption is enabled in Amazon RDS instances is crucial. With encryption enabled, the data will be unreadable without the encryption key, even if someone is able to access it. Thus, this protection method ensures that the company can keep the data secure, help to address the regulatory requirements, and keep their business running smoothly while protecting the privacy of patients and the confidentiality of the drug development process."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_autoscaling_group_with_lb_use_health_check",
    "Title": "Auto Scaling groups with a load balancer should use health checks",
    "Description": "The Elastic Load Balancer (ELB) health checks for Amazon Elastic Compute Cloud (Amazon EC2) Auto Scaling groups support maintenance of adequate capacity and availability.",
    "QueryID": "aws_autoscaling_group_with_lb_use_health_check",
    "DocumentURI": "policies/aws_autoscaling_group_with_lb_use_health_check.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/AutoScaling"
      ],
      "x-kaytu-explanation": [
        "The AWS Elastic Load Balancer (ELB) is a cloud-based service provided by Amazon Web Services that monitors incoming network traffic and automatically distributes it across multiple Amazon EC2 (Elastic Compute Cloud) instances. This capability allows a high level of fault tolerance, managing the network traffic in a way that if an EC2 instance becomes unhealthy or unresponsive, the ELB redirects the traffic to the remaining healthy instances.\n\nHealth checks are a core ELB function and are crucial for maintaining system integrity and performance in AWS. These checks are used to monitor the status and availability of the EC2 instances within Auto Scaling groups.\n\nAmazon EC2 Auto Scaling groups are used to maintain the desired number of EC2 instances and adjust as per the demands of the system load. Auto Scaling ensures that Amazon EC2 instances are effectively utilized and increases or decreases instance capacity in response to varying demand, enabling greater fault tolerance, availability, and network scalability.\n\nThe interaction between ELB and Auto Scaling health checks ensures that AWS maintains enough capacity and availability to efficiently distribute network traffic and maintain system performance and integrity. If a health check determines that an instance is unhealthy, the Auto Scaling group can automatically replace the instance, ensuring optimal performance and availability.\n\nAll of these features allow AWS to support large-scale and highly variable network environments, providing a robust and reliable cloud computing platform.\n\nIn markup format:\n\n```\n- **Elastic Load Balancer (ELB):** A service from AWS that automatically distributes incoming network traffic across multiple Amazon Elastic Compute Cloud (Amazon EC2) instances.\n- **Health checks:** A part of ELB that monitors the health and availability of EC2 instances.\n- **Amazon EC2 Auto Scaling groups:** A feature that maintains a desired number of EC2 instances and scales it based on system load. Interacts with ELB health checks to ensure optimal performance and availability by replacing unhealthy instances.\n```\n**Main Benefit:** This control supports in maintaining high-level system integrity and performance, offering a robust cloud computing platform by ensuring enough capacity, proper distribution of network traffic, and high availability."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control can have significant consequences which include:\n\n1. **Increased Downtime**: If the Elastic Load Balancer (ELB) health checks are not carried out properly, you risk having components of your application unavailable. This could cause increased downtime and a poor user experience.\n\n2. **Uneven Load Distribution**: EC2 instances which are not healthy might still continue to receive requests leading to their over-utilization while other instances are underutilized. This will cause an uneven distribution of load, inefficient utilization of resources and could lead to overworked instances failing, causing application errors and performance issues.\n\n3. **Capacity Management Issues**: Without proper health checks, you may not be able to scale your resources efficiently. This could result in either wastage of resources (if over-provisioned) or inability to meet demand (if under-provisioned), both of which have cost implications.\n\n4. **Impacted Business Continuity**: Insufficient capacity and availability of the critical applications due to non-compliance can significantly impact business operations. This could lead to loss of business opportunities, adverse customer experiences, and targeted SLAs being missed.\n\n5. **Higher Costs**: Instances that are not healthy but still functioning may cause more traffic, causing you to incur more bandwidth costs. Also, if your unhealthy instances are causing your application to perform badly, you may need to invest more in debugging and fixing the issue.\n\nIn essence, failure to comply with this control can lead to serious application performance issues, financial losses, and a potential hit to your organization's reputation. Therefore, it is of utmost importance to ensure that ELB health checks are appropriately configured for Amazon EC2 Auto Scaling groups."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, say you manage a medium-sized e-commerce site that experiences fluctuations in traffic at various times throughout the day or year. To ensure that your site is always up and running well, regardless of surges in usage, you leverage AWS Control such as Amazon Elastic Compute Cloud (EC2) and Auto Scaling groups. \n\nHere's where Elastic Load Balancer (ELB) health checks could be very useful. With ELB health checks configured for your EC2 Auto Scaling groups, AWS can monitor the health status of these instances. When demand rises and traffic to your site increases, EC2 Auto Scaling can automatically increase the number of Amazon EC2 instances to maintain the performance. \n\nSimilarly, If ELB health checks detect an unhealthy instance, the Auto Scaling group replaces the instance ensuring high availability and load balancing of incoming traffic across the healthy instances. \n\nTherefore, through ELB health checks, you could efficiently maintain the robustness of your service without manually monitoring and managing the capacity of your site. This could significantly improve user experience on your e-commerce platform and potentially boost sales by reducing downtime."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_redshift_cluster_maintenance_settings_check",
    "Title": "Amazon Redshift should have required maintenance settings",
    "Description": "Ensure whether Amazon Redshift clusters have the specified maintenance settings. Redshift clusters `allowVersionUpgrade` should be set to `true` and `automatedSnapshotRetentionPeriod` should be greater than 7.",
    "QueryID": "aws_redshift_cluster_maintenance_settings_check",
    "DocumentURI": "policies/aws_redshift_cluster_maintenance_settings_check.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/Redshift"
      ],
      "x-kaytu-explanation": [
        "This AWS (Amazon Web Services) control is related to the maintenance settings of Amazon Redshift clusters. Amazon Redshift is a cloud-based data warehousing solution that allows companies to process large datasets for business intelligence tasks.\n\nHere is the control broken down:\n\n- **`allowVersionUpgrade`**: This is a parameter for Amazon Redshift clusters. If it's set to `true`, AWS can update the Redshift software version whenever new versions are available. It's recommended to always enable this option to benefit from the latest patches, features, and enhancements provided by AWS.\n\n- **`automatedSnapshotRetentionPeriod`**: This parameter specifies the number of days to retain automated snapshots in Amazon Redshift. It's recommended for this value to be set greater than 7, meaning that AWS will keep your automated snapshots for at least a week. This enables you to recover your database from a backup if something goes wrong.\n\nHere is this in markdown:\n\n```markdown\n# Amazon Redshift Maintenance Controls\n\nEnsure in your AWS environment, Amazon Redshift clusters have specified maintenance settings:\n\n- **Allow Version Upgrade**: The Redshift clusters should have `allowVersionUpgrade` set to `true`. Enabling this allows AWS to update to the newest versions when available.\n\n- **Automated Snapshot Retention Period**: The `automatedSnapshotRetentionPeriod` should be set to more than 7 days. By doing this, AWS will retain your automated snapshots for at least a week, providing you a backup to recover your database if necessary.\n```\n\nFollow these controls to make sure your Amazon Redshift clusters are maintained properly and securely."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the mentioned AWS control can have multiple impacts on your AWS operations and overall system:\n\n1. **Potential System Vulnerabilities:**\n  By setting `allowVersionUpgrade` to `false`, you prevent Amazon Redshift from upgrading clusters to the most recent version. This could leave your system exposed to potential vulnerabilities that have been fixed in newer versions, thereby increasing the risk of security breaches. \n\n2. **Data Loss Risk**\n   Having `automatedSnapshotRetentionPeriod` set less than 7 risks losing data because snapshots provide a backup mechanism for your data. If the retention period is too short, you may not have enough time to recognize and react to any data corruption, data loss or similar issue which might have occurred.\n\n3. **Inflexibility in Infra Management**\n   Not allowing automated upgrades or implementing longer snapshot retention periods means potentially more manual management of your infrastructure, which could lead to inefficiency and lack of optimization.\n\n4. **Non-compliance to Industry Standards**\n   Depending on the standards or regulations your industry should adhere to, non-compliance with these AWS guidelines might result in legal or compliance issues, and potentially heavy fines.\n\n5. **Potential Business Disruption**\n  Should an issue occur, like a severe bug in the current Redshift version or data corruption without a backup, it may lead to disruption of your business processes, which could result in financial loss and harm to reputation.\n\nIn conclusion, these settings are in place to ensure the resiliency, uptime, efficiency and security of your AWS Redshift clusters. Non-adherence can lead to increased operational risks, inefficiencies and potential financial losses. Costs can be difficult to estimate due to variable factors, but they could be substantial depending on the severity of an incident that could have been prevented by following the control."
      ],
      "x-kaytu-usefulness-example": [
        "The following AWS control ensures that the Redshift clusters have specific maintenance settings:\n\n- `allowVersionUpgrade` is set to `true`: This allows Amazon Redshift to conduct automatic updates of the clusters to newer versions. This is beneficial as it helps ensure your databases are always running on the most updated, efficient, and secure software.\n\n```markdown\nFor Instance, a tech firm using Redshift clusters to manage its large data workflows would want to make sure the clusters run smoothly and securely. They need to upkeep the performance, security, and compatibility of their database systems. If 'allowVersionUpgrade' is not set to true, they risk running an outdated version of Redshift, potentially vulnerable to security threats or missing key feature upgrades.\n```\n\n- `automatedSnapshotRetentionPeriod` should be greater than 7: This ensures that the automated snapshots that Amazon Redshift creates for recovery purposes are retained for more than a week. In case of any disaster or data loss, the snapshots could be used to restore the data, mitigating the potential impact of any data loss.\n\n```markdown\nAs an example, an e-commerce company handling thousands of transactions daily cannot afford the loss of any data as it could significantly impact their business operations and reputation. If 'automatedSnapshotRetentionPeriod' is not set to a value greater than 7, the company would only be able to recover a week's worth of data in the event of a disaster, potentially losing valuable data and revenue in the process.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_redshift_cluster_encryption_logging_enabled",
    "Title": "Redshift cluster audit logging and encryption should be enabled",
    "Description": "To protect data at rest, ensure that encryption is enabled for your Amazon Redshift clusters. You must also ensure that required configurations are deployed on Amazon Redshift clusters. The audit logging should be enabled to provide information about connections and user activities in the database.",
    "QueryID": "aws_redshift_cluster_encryption_logging_enabled",
    "DocumentURI": "policies/aws_redshift_cluster_encryption_logging_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/Redshift"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Amazon Redshift Cluster Encryption and Configurations\n\n## Why is it important?\n\nProtecting data at rest is a crucial aspect of data security. Enabling encryption for your Amazon Redshift clusters ensures that your stored data is protected against unwanted access or visibility. Additionally, ensuring the necessary configurations on your Redshift clusters is important in maintaining standards compliant with AWS best practices. Implementing audit logging will facilitate tracking user activities and connections in the database, which can be valuable in traceability and incident response scenarios.\n\n## How to Implement this Control?\n\n### 1. Enable Encryption\n\nEnable encryption for each Amazon Redshift Cluster. AWS provides different methods for managing keys used for encryption - AWS Key Management Service, a hardware security module or a customer-provided key. You can set this up when creating a cluster or can modify existing one.\n\n```sh\naws redshift modify-cluster --cluster-identifier your-cluster-id --encrypted\n```\n\n### 2. Ensure Required Configurations\n\nSet up necessary configurations such as VPC setup, cluster parameter group settings, database user creation, security group configurations etc.\n\n### 3. Enable Audit Logging\n\nAudit logging should be enabled to capture database events such as session establishment and command execution. Amazon Redshift logs these events to CloudWatch Logs.\n\n```sh\naws redshift describe-logging-status --cluster-name your-cluster-id\naws redshift enable-logging --cluster-name your-cluster-id --bucket-name your-bucket-name \n```\n\n## Compliance\n\nThis control aids in meeting compliance requirements for data protection and privacy such as GDPR, CCPA, and HIPAA.\n\n## References\n\n- [AWS Redshift - Managing Clusters](https://docs.aws.amazon.com/redshift/latest/mgmt/managing-clusters.html)\n- [AWS Redshift - Enabling audit logging](https://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html)"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control could result in several significant costs, not just financial but also operational and reputational for a business. Here are a few potential costs:\n\n1. **Data Breach**: Non-encrypted data at rest is a potential gold mine for hackers. In case of a security breach, sensitive data could be exposed leading to unauthorized access to proprietary business or to highly sensitive customer information. This could lead to severe financial penalties depending on data protection regulations applicable to your business.\n\n2. **Regulatory fines**: Depending on the jurisdiction and the nature of the data involved, there are various regulatory bodies that enforce data protection laws such as GDPR, HIPAA, SOX, etc. Non-compliance with these could result in hefty fines.\n\n3. **Loss of Trust and Reputation**: In the event customer data is compromised, besides attracting legal penalties, it could also lead to erosion of trust among your customer base leading to loss of business.\n\n4. **Audit Failures**: If audit logging is not enabled, it would be difficult to pass audits from regulatory agencies, leading to potential penalties, or loss of certifications or licences, affecting credibility among clients and customers.\n\n5. **Difficulty in Issue Detection and Resolution**: In case of an event where issues are noticed in the database, lack of proper log can make the process of identifying and resolving those issues longer and more complex, causing operational inefficiency and increased costs. \n\n6. **Legal Costs**: In case of data breaches, you could get sued by your clients or users. This can result in large legal costs, added to the reputation damage."
      ],
      "x-kaytu-usefulness-example": [
        "A multinational corporation using AWS services for processing and storing a large volume of data can greatly benefit from the mentioned AWS control. Let's consider they use Amazon Redshift clusters for storing company-wide data, including sensitive information like client data, proprietary research, employee details, etc.\n\nTo safeguard this data from potential breaches, implementing encryption becomes a necessity. By enabling encryption for Redshift, they can protect data at rest, rendering it unreadable even if an unauthorized entity bypasses other security controls.\n\nThe configurations necessary for Redshift actively contribute to the overall security. It dictates who gets access, when and from where, effectively avoiding any unauthorized access.\n\nThe audit logging feature allows the organization to monitor all connections to and user activities within the database. If any suspicious activities are detected, it could provide critical information to identify the source and nature of the threat.\n\nExample: \n\n```\n{\n  \"Effect\": \"Allow\",\n  \"Action\": [\"redshift:CreateCluster\"],\n  \"Resource\": \"*\",\n  \"Condition\": {\n     \"Bool\": {\n       \"redshift:Encrypted\": \"true\"\n     }\n  }\n}\n```\n\nIn this IAM policy example, the CreateCluster action is only allowed if encryption is enabled on the Redshift clusters. This ensures that any new data placed in the clusters will be encrypted at rest automatically."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_eks_cluster_endpoint_restrict_public_access",
    "Title": "EKS clusters endpoint should restrict public access",
    "Description": "Ensure whether Amazon Elastic Kubernetes Service (Amazon EKS) endpoint is not publicly accessible. The rule is compliant if the endpoint is publicly accessible.",
    "QueryID": "aws_eks_cluster_endpoint_restrict_public_access",
    "DocumentURI": "policies/aws_eks_cluster_endpoint_restrict_public_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EKS"
      ],
      "x-kaytu-explanation": [
        "This AWS Control describes a security measure for Amazon Elastic Kubernetes Service (EKS). It highlights the importance of ensuring that your EKS endpoint is not publicly accessible, as this presents a potential vulnerability.\n\nHowever, it seems like there is a contradiction between the description and the compliance criteria. The description suggests setting the EKS endpoint to not publicly accessible while the compliance criteria suggest the exact opposite.\n\nThe more logical interpretation should be: The rule is compliant if the endpoint is NOT publicly accessible.\n\nHere's an example of how you might write this AWS Control in markup format:\n```\n**AWS Control: Amazon EKS Endpoint Accessibility**\n\n- **Description**: This control measures the accessibility of the Amazon Elastic Kubernetes Service (Amazon EKS) endpoint. \n\n  To ensure maximum security, your EKS endpoint should not be publicly accessible, thus helping to prevent unauthorized access.\n\n- **Compliance Criterion**: The rule is compliant if the EKS endpoint is _not_ publicly accessible. \n\n  This can be achieved by following the Amazon EKS best practice of restricting IP access to trusted IPs or VPCs only.\n\n```\n\nPlease note that you would need to replace the sections written in italic with the actual procedure or instructions."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control can result in several potential costs:\n\n1. **Security Risks:** If EKS endpoints are publicly accessible, they are exposed to the internet and therefore more susceptible to potential cyber threats including data breaches, DDoS attacks, and other malicious activities. This can lead to loss or corruption of data, unplanned downtime, security breaches or leak of sensitive information, all of which may severely impact the operational efficiency and reputation of the business.\n\n2. **Financial Implications:** A security breach can lead to significant financial losses. Costs can be associated with incident response, system remediation, potential fines for data breaches, and sometimes even with customer compensations. \n\n3. **Regulatory Violations:** Depending on the industry, keeping endpoints publicly accessible might also lead to non-compliance with certain regulations (for instance GDPR, HIPAA), which can result in hefty fines and penalties. \n\n4. **Reputational Damage:** Data breaches can harm a company's reputation, leading to loss of customers and potential business in the future.\n\n5. **Potential Loss of Intellectual Property:** If EKS endpoints are publicly accessible, malicious actors can potentially gain unauthorized access to sensitive company information or intellectual property. \n\nIt is essential to ensure that EKS endpoints are not publicly accessible to mitigate these risks, comply with all relevant regulations, protect sensitive data, and ensure the overall security of a business."
      ],
      "x-kaytu-usefulness-example": [
        "Amazon EKS provides the flexibility to start, run, and scale Kubernetes applications in the AWS cloud or on-premises. It helps in deploying these applications in a secure environment which aligns with security standards. \n\nFor example, a multinational organization, XYZ Corp., uses Amazon EKS to run their Kubernetes applications. This organization has sensitive data, which requires strong access control to prevent unauthorized access. By ensuring that the Amazon EKS endpoint is not publicly accessible, XYZ Corp. can prevent potential security breaches. This would comply with data privacy regulations and prevent unauthorized data leaks.\n\nThis rule configured in AWS control allows an organization to detect any public accessibility of their EKS endpoint and promptly address it. It ensures that only authorized entities have access to their services, thus enhancing the overall security posture of their cloud presence.\n\nHere's a sample code written in CloudFormation, that enforces this control:\n\n```markup\nEKSClusterEndpointPublicAccess:\n   Type: 'AWS::EKS::Cluster'\n   Properties:\n     Name: 'my-eks-cluster'\n     ResourcesVpcConfig:\n       EndpointPublicAccess: False\n```\nThis code snippet enforces the AWS Control of ensuring that an Amazon EKS endpoint is not publicly accessible. Therefore, the EKS endpoint is only accessible via the specified VPC bundled within the `ResourcesVpcConfig` property. This is a way to enforce this useful control in the AWS infrastructure. \n\nPlease note that the rule states that it's compliant if the endpoint is publicly accessible. This seems contradictory given the context, so please check the exact requirements for your system's compliance."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_autoscaling_launch_config_public_ip_disabled",
    "Title": "Auto Scaling launch config public IP should be disabled",
    "Description": "Ensure if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations. This rule is non compliant if the Launch Configuration for an Auto Scaling group has AssociatePublicIpAddress set to 'true'.",
    "QueryID": "aws_autoscaling_launch_config_public_ip_disabled",
    "DocumentURI": "policies/aws_autoscaling_launch_config_public_ip_disabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/AutoScaling"
      ],
      "x-kaytu-explanation": [
        "This is an Amazon Web Services (AWS) security control or policy that serves to ensure that Amazon Elastic Compute Cloud (EC2) Auto Scaling groups don't have public Internet Protocol (IP) addresses enabled through their Launch Configurations.\n\nAWS EC2 Auto Scaling enables automatic scaling of resources to meet the demands of your applications. It uses \"Launch Configurations\" to determine the settings for instances that it launches. Among these settings is the \"AssociatePublicIpAddress\" attribute.\n\nWhen the \"AssociatePublicIpAddress\" attribute in a Launch Configuration is set to 'true', the instances launched by these configurations will be directly accessible from the public internet. This can potentially expose these resources to security threats.\n\nThe security control in question checks this attribute for all Launch Configurations of Auto Scaling groups. It considers the rule to be non-compliant if it finds a Launch Configuration with the \"AssociatePublicIpAddress\" set to 'true', which means it is allowing its instances to have public IP addresses. This control helps to enforce best practices for maintaining the security and privacy of the resources on your network."
      ],
      "x-kaytu-noncompliance-cost": [
        "Cost of Non-Compliance:\n\nNon-compliance to this control can lead to multiple cost implications:\n\n1. **Security Risk:** Allowing public IP addresses through Launch Configurations increases the attack surface for malicious actors. If these Auto Scaling groups get compromised, it can lead to unauthorized access, data breaches and other security incidents that could end up costing the organization significant financial damages, include penalties and fines.\n\n2. **Data Loss:** In case of a security breach, there might be a loss of sensitive data which incurs a great cost to an organization. This attack could also damage the company's reputation leading to loss of business.\n\n3. **Increased Operational Costs:** Non-compliance could mean more time and resources spent on managing IT risks, responding to security incidents, and in some serious cases, it can also result in loss of business continuity.\n\n4. **Regulatory Fines:** If the data involved is subject to regulatory compliance (such as GDPR, HIPAA, etc.), non-compliance can result in hefty fines and penalties.\n\n5. **Reputational Damage:** Non-compliance to such controls can damage an organization's reputation which can indirectly lead to costs in terms of lost business opportunities. \n\nTherefore, it is crucial for organizations to adhere to AWS controls to prevent any adverse effects on their services and maintain trust with the customers."
      ],
      "x-kaytu-usefulness-example": [
        "AWS Control \"Ensure if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations\" is particularly useful in scenarios where it is necessary to maintain security and privacy of your data and applications in the cloud.\n\n## Example\n\nLet's say you have an e-commerce web application that automates the scaling of its instances using Amazon EC2 Auto Scaling groups. The app contains sensitive data like credit card information and user details which should not be exposed to potential threats.\n\nHere, this AWS Control acts as an extra layer of security. It checks if the Launch Configuration for your Auto Scaling group allows public IP addresses. If the 'AssociatePublicIpAddress' is set to 'true', it flags the rule as non-compliant.\n\n```\n    {\n        \"AutoScalingGroups\": [\n            {\n                \"AutoScalingGroupName\": \"my-auto-scaling-group\",\n                \"LaunchConfigurationName\": \"my-launch-configuration\",\n                \"DesiredCapacity\": 4,\n                \"MinCapacity\": 1,\n                \"MaxCapacity\": 6\n            }\n        ],\n        \"LaunchConfigurations\": [\n            {\n                \"LaunchConfigurationName\": \"my-launch-configuration\",\n                \"InstanceType\": \"m5.large\",\n                \"AssociatePublicIpAddress\": true\n            }\n        ]\n    }\n ```\n\nIn the above JSON example, the 'AssociatePublicIpAddress' is set to 'true', which means instances in this auto-scaling group can be accessed from the internet directly. This triggers a non-compliance issue.\n\nBy monitoring and complying with this rule, it ensures that no public IP is assigned to your EC2 instances. Not having a public IP enhances security by restricting direct access to your instances from the internet, reducing the exposure to potential security threats."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ecs_task_definition_user_for_host_mode_check",
    "Title": "ECS task definition container definitions should be checked for host mode",
    "Description": "Check if Amazon Elastic Container Service (Amazon ECS) task definition with host networking mode has 'privileged' or 'user' container definitions.The rule is non compliant for task definitions with host network mode and container definitions of privileged=false or empty and user=root or empty.",
    "QueryID": "aws_ecs_task_definition_user_for_host_mode_check",
    "DocumentURI": "policies/aws_ecs_task_definition_user_for_host_mode_check.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/ECS"
      ],
      "x-kaytu-explanation": [
        "The control is triggered to check the security settings related to host networking mode of a task definition in Amazon Elastic Container Service (ECS). \n\nA task definition is a blueprint for your application. It specifies the container information for your application, like the Docker image to use, the memory and CPU requirements, the port mappings, and the network mode.\n\nIn Amazon ECS, there are three types of network modes: `none`, `bridge`, and `host`. When `host` mode is chosen, the task skips container-level networking and directly uses the host's network. \n\nIn this context, the control is designed to check for two specific parameters in the task definition: `privileged` and `user`. \n\n1. `privileged`: A `privileged` container has more access to the host's system. It's a potential security vulnerability because if a container is running in `privileged` mode, it would be able to access resources that are usually inaccessible.   \n\n2. `user`: This parameter deals with authorization. The `user` parameter defines the linux user identity used in the container. When `user=root`, the user has root privileges in the container, which means they have unrestricted access to execute any command.\n\nAccording to the rule, the control will flag the task definition as non-compliant if it is using the `host` networking mode and either: \n\n - The `privileged` flag is set to `false` or it is not set; or\n - The `user` parameter is set to `root` or it is not set.\n\nNon-compliance would indicate that the task definition allows unrestricted access, being potentially insecure. The rule encourages setting appropriate and limited privileges for task definitions to avoid security risks, such as privilege escalation or unauthorized access."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS Control can be both financial and reputational. If your Amazon ECS task definitions with host networking mode have 'privileged' or 'user' container definitions that are non-compliant, it means that your tasks could potentially have unrestricted access to all system resources on the container instance, leading to potential security risks. Here's how:\n\n- **Security risks**: Misconfigured or unprotected container definitions can pose serious security risks. If an attacker gains access to a container that is 'privileged' or is running as 'root', they could potentially have access to all system resources. They could then perform malicious activities, which could include stealing sensitive data, launching attacks on other systems, or causing disruptions to the service. \n\n- **Financial implications**: In the event of a security breach, there could be significant financial implications. This could include loss of revenue due to service disruptions, potential fines for non-compliance to regulations (like GDPR or HIPAA), and costs associated with investigating the incident, remediation activities, and implementing measures to prevent future incidents. \n\n- **Reputational damage**: Besides financial loss, a major security breach can severely damage a company's reputation, resulting in loss of customer trust and potential business.\n\nTo avoid these risks, AWS recommends ensuring that all task definitions for ECS with host network mode are compliant with this rule, i.e., they should not be 'privileged' and should not run as 'root' unless necessary, and any such exceptions should be tightly controlled and monitored."
      ],
      "x-kaytu-usefulness-example": [
        "Below is an instance of usage scenario for Amazon ECS task with host networking mode applying to the non-compliant rule:\n\nA company is operating a microservice-based application in AWS environment using the Amazon Elastic Container Service (ECS) to manage their containers. They typically use task definitions to specify the Docker container parameters for their applications.\n\nThe company wants to align its security practices with best practices for a more reliable and secure system. One of the security recommendations is to prevent the system from any potential security breach by checking whether a task definition with host networking mode has 'privileged' or 'user' container definitions. \n\n```yaml\n{\n  \"family\": \"web_service\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"web\",\n      \"image\": \"httpd\",\n      \"cpu\": 10,\n      \"memory\": 500,\n      \"networkMode\": \"host\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 80,\n          \"hostPort\": 8080\n        }\n      ],\n      \"essential\": true,\n      \"privileged\": false,   # This should be checked\n      \"user\": \"\"\n\n   ],\n\n  \"requiresCompatibilities\": [\n    \"EC2\"\n  ],\n  \"networkMode\": \"host\"\n}\n```\n\nIn this YAML, a task definition is created for a web service (httpd image). The application is hosted on EC2, and the networking mode is set to 'host'. \n\nHowever, as per the inputs above, this setup is non-compliant because the container definition has 'privileged' set as false and the 'user' field is empty. To comply with the AWS best practices, 'privileged' should be set to true when 'user' is root or empty to ensure restricted access to Docker features and enhanced security.\n\nTherefore, checking for these configurations is useful in maintaining good AWS security posture."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_security_group_restrict_ingress_ssh_all",
    "Title": "VPC security groups should restrict ingress SSH access from 0.0.0.0/0",
    "Description": "Amazon Elastic Compute Cloud (Amazon EC2) Security Groups can help manage network access by providing stateful filtering of ingress and egress network traffic to AWS resources.",
    "QueryID": "aws_vpc_security_group_restrict_ingress_ssh_all",
    "DocumentURI": "policies/aws_vpc_security_group_restrict_ingress_ssh_all.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/VPC"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# Amazon Elastic Compute Cloud (EC2) Security Groups\n\nAmazon Elastic Compute Cloud (EC2) Security Groups play a critical role in managing network access to AWS resources. They provide stateful filtering of both ingress (incoming) and egress (outgoing) network traffic.\n\n## **Stateful Filtering**\n\nStateful filtering allows the security group to track the state of traffic, meaning it automatically permits return traffic from an entry (ingress) to exit (egress) without an explicit rule. \n\nFor example, if you send a request from your instance, the response traffic for that request is allowed to flow in regardless of inbound security group rules. Conversely, if you allow inbound traffic from a specific IP address range, then all traffic to that IP address range is allowed to flow out, regardless of outbound security group rules.\n\n## **Ingress and Egress Filtering**\n\n- **Ingress filtering**: This relates to controlling the incoming network traffic to your AWS resources. You can specify the protocols, ports, and source IP ranges that are allowed to reach your instances.\n\n- **Egress filtering**: This relates to controlling the outgoing network traffic from your AWS resources. You can specify the protocols, ports, and destination IP ranges that are permitted to leave your instances.\n\n## **Management of Network Access**\n\nBy defining the rules in your security groups, you can manage access to your AWS resources, allowing only the necessary and secure traffic. This helps to increase the security of your AWS resources, reducing the risk of inadvertent exposure or breaches."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the Amazon EC2 Security Groups control can be significant and multi-faceted, potentially leading to financial, reputational, and operational consequences.\n\n1. Financial Cost:\n\n   - **Data Breaches**: Failing to properly configure and use Amazon EC2 Security Groups may leave your AWS resources vulnerable to cyber attacks. This may result in data breaches which are not only costly to rectify but might also lead to penalties if it is found that the data was not adequately protected.\n\n   - **Resource Misuse**: If unauthorized users gain access to EC2 instances due to lax security group configurations, they may exploit the resources for malicious activities, leading to unexpected financial costs.\n\n2. Reputational Cost:\n\n   - **Customer Trust**: In the event of a data breach resulting from poor management of security groups, the news may lead to a loss of customer trust. Regaining this trust is often costly, requiring significant investments in public relations, communications, and enhanced security measures.\n\n   - **Regulatory Compliance**: A company's reputation within its industry or with regulatory bodies can also be impacted. If it's found to be lacking in compliance with expected standards, it can lose reputation points and find it more difficult to work with key partners or pass future audits.\n\n3. Operational Cost:\n\n   - **Downtime**: Inappropriate or lax security configuration can lead to successful attacks that cause downtime. Downtime for critical applications can lead to significant losses in productivity and sales.\n\n   - **Incident Response**: Mitigating a security incident can lead to additional costs in terms of operations. These include the cost of forensic investigation, system recovery, and strengthening security measures.\n\nBy ensuring compliance with EC2 Security Groups control, you lower these risks and associated costs. It will provide stateful filtering of both ingress and egress network traffic to AWS resources, enabling protection from malicious activities."
      ],
      "x-kaytu-usefulness-example": [
        "For example, you are running a web application on an Amazon EC2 instance. This web application must allow outside traffic to access it on specific ports to function properly. However, for security purposes, it is paramount to restrict access to SSH (port 22) or any other unnecessary ports to a limited set of trusted IP addresses.\n\nBy using Amazon EC2 Security Groups, you can create a security group that allows HTTP and HTTPS traffic (port 80 and 443) from anywhere, but limits SSH to only your company's IP address. This set-up helps to restrict network access to your application, thus improving its security from potential threats that could compromise your EC2 instance.\n\n```\n{\n\"SecurityGroups\": [\n    {\n        \"IpPermissions\": [\n            {\n                \"IpProtocol\": \"tcp\",\n                \"FromPort\": 80,\n                \"ToPort\": 80,\n                \"IpRanges\": [{\"CidrIp\": \"0.0.0.0/0\"}]\n            },\n            {\n                \"IpProtocol\": \"tcp\",\n                \"FromPort\": 443,\n                \"ToPort\": 443,\n                \"IpRanges\": [{\"CidrIp\": \"0.0.0.0/0\"}]\n            },\n            {\n                \"IpProtocol\": \"tcp\",\n                \"FromPort\": 22,\n                \"ToPort\": 22,\n                \"IpRanges\": [{\"CidrIp\": \"203.0.113.0/24\"}] \n            }  \n        ]\n    }\n]\n}\n```\n\nIn this JSON security group rule, HTTP and HTTPS traffic are allowed from all sources (`0.0.0.0/0`), while SSH traffic is only allowed from the range of IP addresses corresponding to your company (`203.0.113.0/24`). This security group can be associated with your EC2 instance, enforcing these rules and enhancing the security of your web application."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_cloudtrail_trail_logs_encrypted_with_kms_cmk",
    "Title": "CloudTrail trail logs should be encrypted with KMS CMK",
    "Description": "To help protect sensitive data at rest, ensure encryption is enabled for your Amazon CloudWatch Log Groups.",
    "QueryID": "aws_cloudtrail_trail_logs_encrypted_with_kms_cmk",
    "DocumentURI": "policies/aws_cloudtrail_trail_logs_encrypted_with_kms_cmk.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/CloudTrail"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS CloudWatch is a service provided by Amazon Web Services (AWS) which monitors your applications, systems, and services running on AWS. It collects and tracks key metrics, collects and monitors log files, sets alarms, and automatically reacts to changes in your AWS resources.\n\nCloudWatch Log Groups are used to define groups of log streams that share the same properties, combined under a single unique name.\n\nEncryption is a process of encoding information so that only authorized parties can access it. When encryption is enabled for your Amazon CloudWatch Log Groups, it adds an extra layer of security to protect your data from unauthorized access and potential attackers. This is especially important when your logs contain sensitive data.\n\nHere's how you can represent this control in markup format (specifically in XML):\n\n```xml\n\u003ccontrol\u003e\n  \u003cdescription\u003eTo help protect sensitive data at rest, ensure encryption is enabled for your Amazon CloudWatch Log Groups.\u003c/description\u003e\n  \u003cfamily\u003eEncryption\u003c/family\u003e\n  \u003clevel\u003eMedium\u003c/level\u003e\n  \u003caws_service\u003eCloudWatch\u003c/aws_service\u003e\n  \u003ccontrol_activities\u003e\n    \u003ccontrol_activity\u003eEnable encryption for CloudWatch Log Groups\u003c/control_activity\u003e\n  \u003c/control_activities\u003e\n  \u003creference\u003eAWS CloudWatch Documentation\u003c/reference\u003e\n\u003c/control\u003e\n```\n\nThis XML format includes some imaginary tags (like `\u003cfamily\u003e`, `\u003clevel\u003e`, and `\u003caws_service\u003e`) for organizing controls, adding a risk level and linking them to a specific AWS service, which are not usually used in Markdown but rather in XML or YAML.\n\nIf you need a simpler markdown format, it might look something like this:\n\n```markdown\n- **Control**: Ensure encryption is enabled for your Amazon CloudWatch Log Groups.\n- **Description**: To help protect sensitive data at rest. \n- **Family**: Encryption\n- **AWS Service**: CloudWatch\n- **Risk Level**: Medium\n- **Reference**: AWS CloudWatch Documentation\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control, which is the encryption of your Amazon CloudWatch Log Groups, could potentially lead to several major costs:\n\n1. **Security Breach**: If your log data is not encrypted, it means sensitive information could be read by unauthorized individuals. In the event of a security breach, threat actors can exploit this vulnerability to gain valuable insights about your system or customer data. This can lead to the loss of important data, or worse, breaches of customer's personal data.\n\n2. **Financial loss**: A data breach resulting from non-encrypted CloudWatch Log Groups might result to significant financial losses. This can come from regulatory fines, legal fees, or loss of business due to reputational damage. Businesses may also need to spend significantly on damage control, identifying the cause of the breach, enhancing security measures or compensating affected customers or partners.\n\n3. **Regulatory Fines**: Depending on the jurisdiction of your business, non-compliance with data protection regulations (like GDPR in Europe, or CPPA in California) may result to regulatory fines. These regulations typically require businesses to put appropriate security measures in place to protect sensitive data, such as enabling encryption.\n\n4. **Reputational Damage**: Non-compliance and subsequent data breach could result in reputational damage which can harm customer trust and loyalty. Rebuilding reputation post breach can be a time-consuming and costly affair. \n\n5. **Business Disruption**: Dealing with a security breach could cause substantial disruption to your business operations. This could further escalate costs, particularly if the breach impacts your ability to deliver services to your customers or clients. \n\nHere's a simple demonstration to emphasize these points.\n\n```markdown\n**Cost of Non-Compliance with Amazon CloudWatch Logs Encryption:**\n\n- **Security Breach**: Non-encrypted log data can be accessed by unauthorized individuals, which can lead to loss of sensitive data and potential exploitation.\n- **Financial loss**: Costs can be incurred from remediation of a data breach, regulatory fines, legal fees, loss of business, and spending on enhanced security measures.\n- **Regulatory fines**: Non-compliance with data protection regulations such as GDPR or CPPA can lead to substantial fines.\n- **Reputational damage**: A data breach can severely impact the trust of customers and partners, resulting in loss of business and reduced customer loyalty.\n- **Business disruption**: The operational impact of dealing with a security breach can further escalate costs, particularly if service delivery to customers is affected.\n```\n"
      ],
      "x-kaytu-usefulness-example": [
        "Consider a scenario where you're running an e-commerce business that processes numerous transactions daily. Each of these transactions generates logs containing sensitive customer information such as their names, addresses, and purchase history. \n\nHaving these logs unencrypted would mean that if a hacker breaches your security measures, they can easily access your customers' sensitive data. This could lead to several issues such as identity theft, fraudulent transactions, and reputational damage to your business.\n\nBy enabling encryption for your Amazon CloudWatch Log Groups, you add an extra layer of security that helps protect your customers' data. Even if an unauthorized user manages to access your logs, they won't be able to read them without the encryption key. This significantly reduces the chances of your sensitive data being compromised.\n\nFurthermore, complying with data protection regulations often requires businesses to encrypt sensitive data. Therefore, utilizing encryption on your Amazon CloudWatch Log Groups can also help your business comply with these rules. \n\nHere is how you can enable encryption for your CloudWatch Log Group in AWS:\n\n```markdown\n1. Sign in to the AWS Management Console and open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.\n2. In the navigation pane, choose 'Log groups'.\n3. Choose the name of the log group that you want to encrypt.\n4. For 'Encrypted', choose 'Edit'.\n5. Choose 'Enable Encryption'.\n6. For 'CMS key', choose the AWS Key Management Service (AWS KMS) key to use.\n7. Choose 'Save'.\n```\n\nWith these steps, all the new data ingested to this Log Group will be encrypted and you're adding an essential security control to protect your sensitive information."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_dynamodb_table_point_in_time_recovery_enabled",
    "Title": "DynamoDB table point-in-time recovery should be enabled",
    "Description": "Enable this rule to check that information has been backed up. It also maintains the backups by ensuring that point-in-time recovery is enabled in Amazon DynamoDB.",
    "QueryID": "aws_dynamodb_table_point_in_time_recovery_enabled",
    "DocumentURI": "policies/aws_dynamodb_table_point_in_time_recovery_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/DynamoDB"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS offers various controls to enhance security and ensure data consistency across its services. One of these controls is a rule that checks if the information has been backed up in Amazon DynamoDB, a scalable NoSQL database service for all applications that need consistent, single-digit millisecond latency at any scale. \n\nThis rule, when enabled, performs regular checks to confirm whether a backup operation has been performed. If no backup is found, it triggers an alert for the user to perform necessary backup operations. \n\nApart from this, the rule also ensures enabling of point-in-time recovery (PITR). PITR helps protect your Amazon DynamoDB tables from accidental write or delete operations. With point-in-time recovery, you don't have to worry about creating, maintaining, or scheduling on-demand backups. \n\nBelow is an example of how this control can be written in a markup format such as Markdown.\n\n```markdown\n---\n\n#### Backup and Point-In-Time Recovery Rule in Amazon DynamoDB\n\n- **Rule Description**: This rule checks if the information has been backed up and maintains the backups by ensuring that point-in-time recovery is enabled in Amazon DynamoDB.\n\n- **What to Enable**: To implement this control, enable the following features:\n  1. **Data Backup**: Regularly create and maintain backups of your data in Amazon DynamoDB.\n  2. **Point-In-Time Recovery (PITR)**: Enable PITR to protect your tables from accidental write or delete operations. \n\n- **How to Enable**:\n  1. Sign into the AWS Management Console and open the DynamoDB console at https://console.aws.amazon.com/dynamodb/.\n  2. In the navigation pane, choose `Tables`, and then select your table.\n  3. Choose the `Backups` tab.\n  4. In the `Point-in-time recovery` section, choose `Enable`.\n  5. Choose `Enable` again when prompted for confirmation.\n\n- **Benefits**:\n  - Helps in maintaining data consistency and recoverability.\n  - Reduces worries about creating, maintaining, or scheduling on-demand backups.\n  - Enhances the overall data management strategy.\n\n---\n```\n\nRemember to replace the placeholder `\u003cyour-table\u003e` with the actual name of your DynamoDB table."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS Control could result in the following costs:\n\n- **Data Loss**: If data is not regularly backed up, there is an increased risk of loss of data. In cases where data is lost, whether because of human error, system malfunction, or a security incident like a cyberattack, having a current backup could be the difference between minor inconvenience and major disaster. The cost associated with data loss can be enormous depending on the significance of the data.\n\n- **Downtime**: If a critical error or failure happens and there are no backup data available, your operations could experience prolonged downtime while trying to rectify the issue or recreate the lost data. Downtime could mean loss of productivity, poor customer experience, opportunity costs, and more.\n\n- **Reputation Damage**: If the lost data includes customer data, or the data loss results in disruption to customer services, it could also damage your brand reputation leading to loss of customers or harm to business relationships. This could also lead to loss of future business prospects.\n\n- **Non-compliance Penalties**: Depending on the industry you operate in, non-compliance to certain backup and recovery policies can lead to legal penalties, fines, and sanctions. For examples, businesses dealing with healthcare or financial data are subject to strict laws and regulations around data protection.\n\n- **Recovery Costs**: Without proper backups, the cost to recover or restore lost data can be much more expensive. You may need to invest in external data recovery services, which can be costly and are not always successful.\n\nTherefore, it is important to ensure you comply with this AWS Control to mitigate these potential costs."
      ],
      "x-kaytu-usefulness-example": [
        "# Example\n\nCompany XYZ is a popular e-commerce platform that has a large user base. They store their customer data and transaction records in DynamoDB. \n\nOn a day when their website experiences massive traffic due to a flash sale, an unexpected error occurred. This error leads to the corruption of some data. \n\nAs Company XYZ had proactively enabled the AWS control rule that checks if point-in-time recovery is enabled on their DynamoDB, they were able to recover the corrupted data to its state before the error. \n\nThis helped the company recover from the potential huge setback quickly, proving the immense usefulness of this AWS control rule."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_codebuild_project_artifact_encryption_enabled",
    "Title": "CodeBuild project artifact encryption should be enabled",
    "Description": "This control checks if a CodeBuild project has encryption enabled for all of its artifacts. The rule is non compliant if 'encryptionDisabled' is set to 'true' for any primary or secondary (if present) artifact configurations.",
    "QueryID": "aws_codebuild_project_artifact_encryption_enabled",
    "DocumentURI": "policies/aws_codebuild_project_artifact_encryption_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CodeBuild"
      ],
      "x-kaytu-explanation": [
        "CodeBuild is a service offered by AWS for compiling source code, running tests, and producing software packages. One of the features of CodeBuild is the ability to produce artifacts - these are the outputs from the build process, such as compiled code or test results. \n\nIn some contexts, it's extremely important that these artifacts are kept secure. Encrypting the artifacts is one way to help ensure their security. If encryption is disabled, anyone who can access the artifact storage location could potentially read or modify the artifacts.\n\nThis control checks if a CodeBuild project has encryption enabled for all of its artifacts. This is done by checking the `encryptionDisabled` property. If this property is set to `true`, it means that encryption is disabled and the artifacts are potentially at risk. \n\nThe control checks both the primary artifact configuration and, if they exist, any secondary artifact configurations. If any of these have `encryptionDisabled` set to true, the rule is marked as non compliant.\n\nHere is how this control can be described in markup format:\n\n```markdown\n# AWS CodeBuild Projects Encryption Check\n\nThis control checks if all artifacts produced by an AWS CodeBuild project are encrypted. If encryption is disabled for any artifact configuration, the project is considered non-compliant.\n\n## Non-Compliant Resources\n- **AWS::CodeBuild::Project**  \n  Any CodeBuild project that has the 'encryptionDisabled' property set to 'true' for either its primary or any secondary artifact configurations.\n```\n\nThis document is written in Markdown, a lightweight markup language for creating formatted text. The text is broken up into sections using headings, which are indicated by the `#` symbol. The `**` symbols are used to make text bold, indicating important terms."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS Control indicates that you are not using encryption for the artifacts of the CodeBuild project. \n\nHere's the potential cost of non-compliance:\n\n1. **Security Risks**: The absence of encryption could expose your data to security threats such as unauthorized access to sensitive information, data breaches, or leakage. Such exposure might result in compromise of your system's integrity and confidentiality.\n\n2. **Non-compliance violation costs**: Non-compliance with data protection regulations, such as GDPR, HIPAA etc., could lead to hefty fines. It could also lead to penalties under international, national, or local laws and regulations depending on the jurisdiction your business operates in.  \n\n3. **Reputation damage**: In the event of a data breach or leak, your business reputation could be damaged. It could also affect your customer trust and result in potential loss of business.\n\n4. **Loss of Intellectual Property**: CodeBuild artifacts may contain trade secrets or intellectual property relevant to your business. If 'encryptionDisabled' is set to 'true', such data is exposed and could be exploited or stolen.\n\n5. **Data Recovery**: If artifacts are compromised due to encryption being disabled, you may incur costs related to data recovery and systems reinforcement.\n\nIn summary, not enforcing encryption on AWS CodeBuild project artifacts could migrate potential risks towards your data security and integrity, resulting in financial, operational, and reputational costs."
      ],
      "x-kaytu-usefulness-example": [
        "For example, consider a software development company that uses AWS CodeBuild for creating and testing their applications. The application source code could include sensitive information such as API keys, client data, or proprietary algorithms. Also, the built artifacts may include critical data or sensitive settings.\n\nIf any artifact data is unencrypted, it could get exposed in case of a security breach, leading to both financial loss and reputation damage to the company. To ensure the safety of the artifacts, the company enables encryption for all CodeBuild projects.\n\nHowever, with multiple teams working on different projects and deploying new CodeBuild Projects regularly, there can be cases when a project gets created with 'encryptionDisabled' set to 'true', either mistakenly or because the person creating the project isn't aware of the policy.\n\nTherefore, the company uses the specified AWS control to continuously monitor the CodeBuild projects. If a project is discovered that has not enabled encryption, it will be flagged as non-compliant, bringing the issue to the attention of the responsible team and allowing them to correct it immediately. This way, the control helps maintain the security of the company’s assets."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_codebuild_project_source_repo_oauth_configured",
    "Title": "CodeBuild GitHub or Bitbucket source repository URLs should use OAuth",
    "Description": "Ensure the GitHub or Bitbucket source repository URL does not contain personal access tokens, user name and password within AWS Codebuild project environments.",
    "QueryID": "aws_codebuild_project_source_repo_oauth_configured",
    "DocumentURI": "policies/aws_codebuild_project_source_repo_oauth_configured.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CodeBuild"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Securing Source Repository in AWS Codebuild\n\n## Description:\n\nAmazon Web Services (AWS) recommends that the GitHub or Bitbucket source repository URL in your AWS CodeBuild project environments should not contain any personal access tokens, user names, or passwords. \n\n## Rationale: \n\nIncluding personal access tokens, usernames, and passwords in your source repository URL can expose these sensitive credentials to unauthorized users. This can lead to unauthorized access and manipulation of your source code and data, consequently leading to a serious breach of data privacy and security. \n\n## Corrective Action:\n\nYou need to revise the configuration of your AWS Codebuild project environments. If you currently have any personal access tokens, user names, or passwords within your GitHub or Bitbucket source repository URL, they should be removed immediately. Instead, you should authenticate access to your source repository using OAuth connections or SSH keys, which don't require embedding sensitive information directly into URLs.\n\n## Example:\n\nBefore: `https://\u003cusername\u003e:\u003cpassword\u003e@github.com/org/repo.git`\n\nAfter: `https://github.com/org/repo.git`\n\nAlways ensure that you are managing and storing any sensitive information in a secure manner.\n\n## Monitoring:\n\nMonitor access to your AWS CodeBuild project environments regularly. Use AWS CloudTrail, AWS Config, or a similar service to detect any attempts to include personal access tokens, usernames, or passwords in your source repository URLs. \n\n## Plan:\n\nIdentify all AWS CodeBuild project environments and ensure that they do not contain personal tokens, usernames, or passwords. Implement a process to review and update configurations periodically to maintain security standards over time. \n\n## Best Practice:\n\nImplement a regular rotation of access keys and make sure all secret and access keys are properly secured. Use the principle of least privilege, i.e., granting only the necessary access for users to perform their duties.\n"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control has potentially severe implications. The repository URL should not contain any sensitive data, such as personal access tokens, usernames, or passwords. If any such information is included, it is susceptible to exposure and misuse:\n\n1. **Data Breach:** A rogue actor could gain access to the repository and access all of its data. This may include proprietary code, personal data, or other sensitive information. A data breach could result in severe financial and reputational damages.\n\n2. **Unauthorized Changes in Codebase:** With unauthorized access to the repository, malicious changes to the codebase, such as the inclusion of backdoors or other harmful code, could be made. This could lead to further security compromises.\n\n3. **Compliance Violations:** It could result in a violation of the compliance standards such as GDPR, HIPAA, or others depending on the nature of the data stored in the repository. The violations could lead to hefty fines and penalties.\n\n4. **Loss of Trust:** A breach could significantly impact the level of trust that customers, partners, and stakeholders place in the organization which can have long-term implications on business operations and revenue.\n\nTherefore, to avoid these severe issues, it is highly important to comply with the recommended AWS controls. Always ensure personal access tokens, usernames, passwords, or any other sensitive information, is never included in the repository URL within the AWS Codebuild project environments."
      ],
      "x-kaytu-usefulness-example": [
        "The effectiveness of this AWS Control can be illustrated in an organization utilizing AWS CodeBuild for their development lifecycle. \n\nLet's say the organization has a large development team that uses GitHub for source control. They've configured AWS CodeBuild to pull the latest code from GitHub and build it. Now, one of the developers inadvertently includes a personal access token, username, or password in the repository URL within the CodeBuild project environment. \n\nThis could be a major security risk as any member with access to the CodeBuild configuration could potentially see and misuse these sensitive details. For instance, this could lead to unauthorized changes to the code repository or even data breaches if the compromised credentials have enough privileges.\n\nBy enforcing the AWS control to ensure GitHub or Bitbucket source repository URL does not contain personal access tokens, user name, and password, they avoid these risks. Any attempt to save the CodeBuild project settings with such sensitive details in the repository URL would be prevented, enhancing the security of their development workflow.\n\nTherefore, in this instance, the AWS Control proves to be useful in protecting sensitive information and reducing potential vulnerabilities in the AWS CodeBuild project environment."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ssm_managed_instance_compliance_patch_compliant",
    "Title": "SSM managed instance patching should be compliant",
    "Description": "Enable this rule to help with identification and documentation of Amazon Elastic Compute Cloud (Amazon EC2) vulnerabilities.",
    "QueryID": "aws_ssm_managed_instance_compliance_patch_compliant",
    "DocumentURI": "policies/aws_ssm_managed_instance_compliance_patch_compliant.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/SSM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: EC2 Vulnerability Identification and Documentation\n\nThis rule is crucial for maintaining your system's security. It helps in identifying potential security threats in your Amazon Elastic Compute Cloud (EC2) instances and provides complete documentation of these threats for future reference. \n\n## What it means\n\nAmazon EC2 instances are vulnerable to various forms of cyber threats like any other online system. If not identified, these vulnerabilities can make your systems susceptible to external attacks. This AWS Control enables a rule that automatically scans for these vulnerabilities and documents them.\n\n## How it works\n\nOnce the rule is enabled, the system then regularly examines the EC2 instances to identify any potential vulnerabilities that may exist. In case it detects any, the system documents them, enabling you to take the necessary security measures against these threats.\n\n## The Importance \n\nThis control function helps:\n- Maintain the security of your Amazon EC2 instances by routinely checking for vulnerabilities.\n- Offers thorough documentation of these vulnerabilities, which could be vital in implementing preventative measures.\n- Helps your team to take immediate actions when any vulnerability is identified. \n\nTo ensure the security of your EC2 instances, it is recommended to enable this rule in your AWS Control.\n\n```markdown\n**Remember:** Security should always be the *top* priority in any online-based system. Keep your Amazon EC2 instances secure by enabling this rule, which helps in detecting and documenting vulnerabilities.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control - the rule that facilitates the tracking and documentation of Amazon EC2 vulnerabilities could potentially result in significant costs, both direct and indirect. \n\n1. **Financial Costs**: Non-compliance can lead to financial loss through data breaches. An undetected vulnerability could be exploited, causing potentially huge financial damages. Depending on its severity, a single vulnerability could cost hundreds of thousands of dollars in response efforts, lost business, remediation, and potential fines for failing to adhere to data protection regulations.\n\n2. **Operational Interruption**: A successful attack could interrupt your services' normal operation, leading to downtime and affecting business continuity. Recovery time and potential loss of operational efficiency could translate into significant costs.\n\n3. **Reputational Damage**: Besides immediate financial loss, an unaddressed vulnerability that leads to a privacy breach also can severely harm the reputation of a business, causing long-term business loss.\n\n4. **Legal and Regulatory Penalties**: If vulnerabilities lead to a data breach, the organization may face potential legal penalties and regulatory fines, especially if the vulnerabilities are a result of non-compliance with industry standards or data protection regulations.\n\n5. **Remediation Costs**: Detecting and patching vulnerabilities after a breach has happened is often much more expensive than following a preventive approach. \n\n6. **Loss of Customer Trust**: If customer data is compromised due to these vulnerabilities, it can lead to a loss of customer trust which could impact the business significantly.\n\nSo, it's crucial to enable this control rule to identify and document the Amazon EC2 vulnerabilities to prevent security risks. This will not only improve security but also save costs in the long run."
      ],
      "x-kaytu-usefulness-example": [
        "- **Use Case:** You are a system administrator for a large organization that utilizes Amazon Web Services (AWS) as part of your company's infrastructure. Your company runs many servers and applications on Amazon Elastic Compute Cloud (Amazon EC2) instances.\n\n    One day, as you're doing a security audit, you notice suspicious activity on one of your EC2 instances. You need to quickly and efficiently identify potential vulnerabilities on this instance and document them for further investigation.\n\n    You decide to enable the AWS Control rule for identifying and documenting EC2 vulnerabilities. This rule will systematically scan your EC2 instances for common vulnerabilities and generate a report detailing the findings. \n\n    After enabling this rule, you can now easily identify the vulnerabilities present in your EC2 instance, allowing you to take swift corrective action to rectify these issues. Additionally, the documentation generated by this rule assists you in keeping organized records of your security audits.\n\n    This AWS Control rule thus proves to be extremely useful in ensuring the security and integrity of your company's AWS infrastructure."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_redshift_cluster_automatic_snapshots_min_7_days",
    "Title": "Amazon Redshift clusters should have automatic snapshots enabled",
    "Description": "This control checks whether Amazon Redshift clusters have automated snapshots enabled. It also checks whether the snapshot retention period is greater than or equal to seven.",
    "QueryID": "aws_redshift_cluster_automatic_snapshots_min_7_days",
    "DocumentURI": "policies/aws_redshift_cluster_automatic_snapshots_min_7_days.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/Redshift"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "This control is related to Amazon Web Services (AWS) which hosts some of the most important and sensitive data collected by organizations, and helps ensure the durability and security of your backups in Amazon Redshift – a fully managed data warehousing service in the cloud. \n\n```\n## Control: Automated Snapshots and Retention Period\n\nThis control is intended to check the status of automated snapshots for Amazon Redshift clusters and the snapshot retention period. Automated snapshots are an essential part of data recovery strategy as they are automatically generated within a defined period of time.\n\nSnapshot retention period is the duration for which Amazon Redshift retains automatic snapshots in the backup storage. It's a good data protection practice to retain snapshots for a minimum of seven days.\n\n### Why is it important?\n\n- **Automated Snapshots:** Enabling automated snapshots ensures that you will have regular, point-in-time backups of your data. These snapshots are stored in Amazon S3, a secure and durable storage service.\n\n- **Retention Period:** Ensuring the retention period is at least seven days provides a week of recovery points, protecting your data and enabling you to restore data from any of these points if necessary.\n\n### How to Implement\n\nUnder the settings of your Redshift cluster configurations, enable `Automated Snapshots` and set the `Retention period` to a minimum of seven days.\n\n### Potential Impact\n\nImplementing this control can protect against data loss and provide recovery options in the event of a failure or issue, reducing downtime and potential loss of productivity.\n```\nThis simple explanation of the control helps clarify the requirements of enabling automated snapshots and having a retention period of at least seven days. These features add an extra layer of data protection and can help recover lost data."
      ],
      "x-kaytu-noncompliance-cost": [
        "The control mentioned monitors the following aspects on Amazon Redshift clusters:\n\n1. Whether automated snapshots are enabled.\n2. Whether the snapshot retention period is set to a minimum of seven days.\n\nThe cost of non-compliance to this control can be in different forms such as:\n\n**Data Loss:**\n\nIf automated snapshots are not enabled, the database may lose important data in case of an outage or error. Snapshots provide a means to backup your data and restore from it in case of any accidental deletes, application bugs, or hardware failures.\n\n**Non-Recovery:**\n\nWithout snapshots, and especially if the retention period is not at least seven days, you may not be able to restore the database to a previous state. In scenarios like a major data corruption, this can be critical to business recovery.\n\n**Non-Compliance to Regulations:**\n\nIf your business operates in a regulated industry, then failing to maintain snapshots could lead to penalties or fines for non-compliance to data protection regulations.\n\n**Monetary Loss:**\n\nThe combination of lost data and downtime can lead to significant financial costs for the business.\n\nIn markup format, the costs can be presented as follows:\n\n- **Data Loss:** Not having automated snapshots enabled can lead to significant data losses in case of errors or outages and this is critical to avoid in any business.\n- **Non-Recovery:** Without snapshots and a retention period of at least seven days, you may not be able to restore the database to a previous state, which can be a serious problem in case of major data corruption.\n- **Non-Compliance to Regulations:** Failure to maintain snapshots could result in penalties or fines for non-compliance to data protection regulations.\n- **Monetary Loss:** The combination of lost data and downtime can lead to significant financial losses."
      ],
      "x-kaytu-usefulness-example": [
        "```markdown\nUse Case: A financial services company uses Amazon Redshift to manage large volumes of financial and customer data. Regular backup of this data is crucial for the company to meet regulatory requirements and to restore systems in case of any data loss or failure.\n\nExample: AWS Control is enabled to monitor the Redshift clusters, specifically checking if automated snapshots are enabled. This provides an extra layer of data protection by ensuring automated, regular backups of the cluster. Additionally, AWS Control ensures the snapshot retention period is set for seven days or more, meeting the company's policy for data retention and disaster recovery.\n\nWithout this robust, automated AWS Control in place, the company may risk non-compliance with regulatory requirements, potential business interruption due to data loss, and greater exposure to cyber threats. AWS Control helps the company mitigate these risks while saving unnecessary costs and resource commitments for manual monitoring and enforcement of backup policies.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_dms_replication_instance_not_publicly_accessible",
    "Title": "DMS replication instances should not be publicly accessible",
    "Description": "Manage access to the AWS Cloud by ensuring DMS replication instances cannot be publicly accessed.",
    "QueryID": "aws_dms_replication_instance_not_publicly_accessible",
    "DocumentURI": "policies/aws_dms_replication_instance_not_publicly_accessible.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/DMS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Control such as managing access to the AWS Cloud by ensuring DMS replication instances cannot be publicly accessed essentially implies controlling and limiting the access to the Data Migration Service (DMS) in AWS. \n\nThis control prevents DMS replication instances from being exposed to the public, protecting it from potential malicious activities. It is a crucial aspect of security and compliance management.\n\nIn the official AWS management console, you can configure the specific DMS instances to limit their offer for public access.\n\nHere is a simple demonstration of such control in AWS Management Console in markup format:\n\n```markdown\n- Open the AWS Management Console\n- Navigate to the DMS dashboard\n- For each DMS instance:\n  - Choose the instance that you want to modify\n  - Choose 'Modify'\n  - In the 'Public accessibility' settings, choose 'No'\n  - Choose 'Continue'\n  - On the summary page, choose 'Modify instance'\n- Repeat for each DMS instance\n\nWith these steps, DMS replication instances cannot be publicly accessed, thereby ensuring tightened security in the AWS Cloud.\n```\n\nRemember, by limiting public access, you prevent unauthorised access or changes to your DMS instances, enforcing strict control over who and what can interact with these key data migration resources."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS Control can lead to several potential costs:\n\n1. **Security breaches:** If your DMS replication instances are publicly accessible, they can be vulnerable to security attacks. This can potentially lead to unauthorized access to your sensitive data. Such a breach could result in the theft, corruption, or complete loss of data.\n\n2. **Financial penalties:** Depending on the nature of your business and the data you're managing, security breaches might lead to hefty financial penalties. This is particularly true if you're subject to regulations like GDPR, HIPAA, or PCI-DSS. For example, under GDPR, fines can go up to 4% of annual global turnover or €20 Million (whichever is greater) for non-compliance.\n\n3. **Reputation damage:** Data breaches can lead to a loss of trust among your customers and partners; this can negatively impact your business reputation. Restoring that trust can be costly and time-consuming.\n\n4. **Resources for incident response:** In the event of a breach, your company will need to dedicate resources to respond to the incident. This includes identifying the source of the breach, securing your systems, and potentially restoring or recovering lost or compromised data. This process can be both time and cost-intensive. \n\n5. **Potential downtime:** If a security breach is serious enough, it might cause a disruption to your services, leading to potential downtime. This could impact not only your company's reputation but also your revenues.\n\nTo avoid these potential costs, it's crucial to manage access to the AWS Cloud accurately and ensure DMS replication instances cannot be publicly accessed."
      ],
      "x-kaytu-usefulness-example": [
        "For example, an eCommerce company that hosts its website on the AWS cloud might use the Database Migration Service (DMS) to facilitate data transfers between different kinds of databases. However, the company's databases contain sensitive customer and transaction information that could be exploited if accessed by an unauthorized party.\n\nBy implementing the \"Manage access to the AWS Cloud by ensuring DMS replication instances cannot be publicly accessed\" control, the company could limit the exposure of its databases to only authorised personnel. This could involve setting up a secure virtual private cloud (VPC) and ensuring all DMS replication instances are situated within this VPC.\n\nBy ensuring DMS replication instances are inaccessible to the public, the company can add an extra layer of security to its AWS usage. This can help protect their confidential data and prevent unauthorized individuals from manipulating or stealing their data. This can therefore help the company maintain customer trust and avoid the reputational and financial damage of a data breach."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_default_security_group_restricts_all_traffic",
    "Title": "VPC default security group should not allow inbound and outbound traffic",
    "Description": "Amazon Elastic Compute Cloud (Amazon EC2) security groups can help in the management of network access by providing stateful filtering of ingress and egress network traffic to AWS resources.",
    "QueryID": "aws_vpc_default_security_group_restricts_all_traffic",
    "DocumentURI": "policies/aws_vpc_default_security_group_restricts_all_traffic.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/VPC"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon Elastic Compute Cloud (Amazon EC2) security groups are a significant aspect of network security in the AWS environment. They offer the ability to manage network access by providing stateful inspection of ingress (incoming) and egress (outgoing) network traffic to Amazon Web Services (AWS) resources.\n\nHere's the explanation in the form of a markup format:\n\n# Amazon EC2 Security Groups\n\n## Overview\nAmazon Elastic Compute Cloud (Amazon EC2) security groups are virtual firewalls for your EC2 instances to control incoming and outgoing traffic.\n\n## Purpose\nSecurity groups help in the management of network access. They provide **stateful filtering** of both ingress (inbound) and egress (outbound) network traffic to AWS resources.\n\n## Key Features\n\n- **Stateful Filtering:** This means changes made to the security group affects both inbound and outbound in response to user-defined rules. \n\n- **Traffic Control:** Security groups enable control of inbound traffic (from other systems to EC2 instances) as well as outbound traffic (from EC2 instances to other systems).\n\n- **Access Management:** They help to manage authorized network paths, allowing you to specify which traffic can reach your EC2 instances.\n\nRemember, every EC2 instance is associated with a security group, and the group plays a pivotal role in controlling access to AWS applications. User-defined rules within the security groups determine the traffic flow to the associated instance."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control could result in several major potential costs:\n\n1. **Loss of Data:** Without appropriate security measures, malicious actors could potentially access sensitive data. This could result in direct financial loss, a damaged business reputation, or legal penalties, especially if the data in question is regulated by laws or standards such as GDPR or HIPAA.\n\n2. **System Downtime:** If your EC2 instances and other AWS resources are not properly secured, they may be more vulnerable to denial-of-service attacks. These can make your system unavailable, resulting in dissatisfaction among your customers or users, and potentially leading to lost business.\n\n3. **Increased Threat of Breach:** If there is non-compliance to the AWS EC2 security group control, it can potentially increase the risk of security breaches. Breaches due to non-compliance can have financial implications in terms of penalties, ransomware payments, and settlements with affected parties.\n\n4. **Non-Compliance costs:** If your industry is subject to specific compliance standards, non-compliance with security best practices could result in hefty fines or sanctions.\n\n5. **Remediation Costs:** If a breach does occur, there will obviously be associated costs with investigating the problem, fixing the security flaw that allowed it to happen, and recovering any lost data.\n\nTherefore, it is highly recommended to ensure compliance with AWS controls like EC2 security groups. Doing so can help you avoid these potential pitfalls and protect your business."
      ],
      "x-kaytu-usefulness-example": [
        "Example:\n\n```markdown\nIn an e-commerce website scenario, the company's server could be hosted using Amazon EC2. There will be multiple parts of the system, each with a different purpose - one might store customer information, another might manage orders, and a third might handle payment processing. \n\nTo secure their system, the company could create different EC2 security groups for each of these parts. For instance, they could have a 'CustomerInfo' security group where only certain IP addresses (maybe those of the company's administrators or customer support team) are allowed to access the part of the system that handles customer information. \n\nSimilarly, they could have an 'Orders' security group where only systems from the 'CustomerInfo' and 'PaymentProcessing' groups can make requests. This means if an unauthorized source tries to directly access the 'Orders' systems, it would be denied.\n\nBy using Amazon EC2 security groups in this manner, they can control the network access to their AWS resources, providing secure, stateful filtering of both inbound and outbound network traffic. This method of filtration exhibits context sensitivity as it keeps track of active connections and their states, making the system both secure and efficient.\n```\n"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ssm_managed_instance_compliance_association_compliant",
    "Title": "SSM managed instance associations should be compliant",
    "Description": "Use AWS Systems Manager Associations to help with inventory of software platforms and applications within an organization.",
    "QueryID": "aws_ssm_managed_instance_compliance_association_compliant",
    "DocumentURI": "policies/aws_ssm_managed_instance_compliance_association_compliant.md",
    "ManualVerification": false,
    "Severity": "Medium",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/SSM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS Systems Manager Associations is a feature of AWS Systems Manager, a service designed to assist you in managing your AWS and on-premises systems at large scale. \n\nAssociations is a state management capability that helps you consistently apply a specific configuration to your infrastructure. It defines a steady state by associating certain AWS resources and specifying a desired state for those resources. You can associate Amazon Machine Images (AMIs), scripts, documents (including Systems Manager documents (SSM documents) and AWS CloudFormation templates), and parameters with a targeted set of resources.\n\nUtilizing AWS Systems Manager Associations can significantly assist in the management of software platforms and applications inventory within an organization. This is because it periodically applies a Systems Manager SSM document, allowing you to automate tasks such as collection of instance metadata, software inventories, and performing patch operations.\n\n```markup\nHere's an example of how an Association can be set in CloudFormation YAML format:\n\n```YAML\nResources:\n  BasicExample:\n    Type: 'AWS::SSM::Association'\n    Properties:\n      Name: AWS-GatherSoftwareInventory\n      Targets:\n        - Key: \"tag:Env\"\n          Values: \n            - Test\n```\n\nIn this example, a new association is created with the AWS-GatherSoftwareInventory SSM document. The association will be applied to the resources tagged with \"Env: Test\". This means that the AWS Systems Manager will gather software inventory from all instances with this tag.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS Control of using AWS Systems Manager Associations for inventorying software platforms and applications within an organization can be both financial, operational and security-related.\n\n1. **Disorganization and Inefficiency**: AWS Systems Manager allows businesses to manage their resources using a systematic and organized approach. Failure to do so will result in disorganization, making it difficult to locate, manage, and monitor software applications and platforms. This inefficiency can lead to loss of productivity and unnecessary delays.\n\n2. **Security Vulnerabilities and Compliance Risks**: Not having a clear inventory of software applications could expose the organization to several security threats as unrecognized or unchecked software can become the target of hackers. Similarly, failure to systematically track these applications could lead to non-compliance with regulations such as SOX, HIPAA, or GDPR, resulting in financial penalties and reputational damage.\n\n3. **Over-provisioned Resources**: Without a proper inventory, an organization may end up paying for resources they are not using or don't need, wasting financial resources. \n\n4. **Resource Mismanagement**: If there is a lack of inventory, it is challenging to manage resources effectively. This could mean overuse of certain resources and underuse of others, leading to inefficient cost and resource management.\n\n5. **Lack of Optimization**: AWS Systems Manager helps in automation and optimization of tasks. Non-compliance to this control means the organization is missing on these optimizations, leading to wastage of resources and increased costs.\n\n6. **Increased MTTR**: When issues occur, if the inventory is not organized, it takes longer time to locate the issue and resolve it, leading to increased Mean-Time-To-Resolve(MTTR). This can lead to longer periods of service outages and have financial implications.\n\nTherefore, non-compliance to this control will lead to disorganization, increased security risks and decreased efficiency, which ends up increasing both operational and financial costs for the organization."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a big organization, say ABC Corp, has multiple ongoing software projects across various departments. They need a system to streamline and maintain an inventory of all the software platforms and applications used in their projects. With AWS Systems Manager Associations, it not only aids in keeping a running inventory, but it also helps in applying updates and managing these software systems from a single location.\n\nUsing this service, ABC Corp's IT department can keep a detailed record of all software resources, which reduces redundancy, ensure standardization \u0026 increases efficiency. The IT team can also make sure security protocols \u0026 updates are implemented across the board uniformly and promptly.\n\n```markdown\nABC Corp's use of AWS Systems Manager Associations:\n    \n1. **Inventory Management:** AWS Systems Manager helps ABC Corp in managing and recording all software applications, their versions, and platforms used across various departments.\n2. **Update Management:** The IT team can use this service to apply updates or patches on the software applications or resources, making sure that all the systems stay up to date.\n3. **Standardization:** AWS Systems Manager can help the company ensure that a standard set of applications are being used across all projects and branches, avoiding the chaos of having multiple versions of the same service.\n4. **Security**: By managing and applying patches from a central location, ABC Corp can ensure that critical security protocols are applied universally, reducing potential risks of breaches.\n```\n\nAWS Systems Manager Associations proves highly useful for ABC Corp in the comprehensive management of their software resources and maintaining security standards."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_codebuild_project_environment_privileged_mode_disabled",
    "Title": "CodeBuild project environments should not have privileged mode enabled",
    "Description": "This control checks if an AWS CodeBuild project environment has privileged mode enabled. This control fails when an AWS CodeBuild project environment has privileged mode enabled.",
    "QueryID": "aws_codebuild_project_environment_privileged_mode_disabled",
    "DocumentURI": "policies/aws_codebuild_project_environment_privileged_mode_disabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CodeBuild"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Check for Privileged Mode in AWS CodeBuild Project Environment\n\nThis control is designed to check if the environment in an AWS CodeBuild project has enabled the `Privileged mode`. In essence, this control is a security measure that ensures that the project environment adheres to best practices regarding access and permissions.\n\n## What is Privileged Mode?\n\n`Privileged mode` in AWS CodeBuild allows the Docker daemon to have extended privileges which can inadvertently provide root level access to a host on which the Docker daemon is running. This can pose a significant security risk if misused or mishandled, hence the need for a control to check its status.\n\n## When does the Control Fail?\n\nThe control fails if it finds out that the `privileged mode` is enabled for a CodeBuild project environment. This implies that potentially insecure Docker daemon privileges are in use, which might be at odds with an organization's security policies or standards. In such cases, the control would trigger a failure alert to prompt necessary action.\n\n## Example in AWS CLI\n\nUsing AWS CLI, this check can be performed with the following command:\n\n```\naws codebuild batch-get-projects --names \"project-name\"\n```\n\nThe output will contain 'environment' section where 'privilegedMode' can be checked:\n\n```json\n\"environment\": {\n  ...\n  \"privilegedMode\": false,\n  ...\n}\n```\n\nIn this case, 'privilegedMode' is `false` which means it is not enabled. If it were `true`, the control would fail."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS control may result in the following costs:\n\n* **Security Risk**: Enabling privileged mode in AWS CodeBuild project environment provides the docker container access to all devices from the hosting system. This could potentially present a significant security risk as it may expose sensitive system details or permissions, paving the way for possible unauthorized access, data leakage, or cyberattacks.\n\n* **Regulatory Compliance Violations**: If your organization falls under regulations such as GDPR, HIPAA, PCI DSS, or others, non-compliance could lead to hefty fines or sanctions due to failure to adequately safeguard sensitive data. \n\n* **Potential System Damage or Disruption**: Unauthorized access because of privileged access could potentially lead to system damage or disruption of services which can be costly to fix and lead to downtime for your services.\n\n* **Reputation Damage**: Breaches of sensitive data especially in organizations that handle customer data can lead to a loss of trust from customers, potentially damaging the reputation of the company. \n\nIn conclusion, it's a good security practice to always operate with least privileged access principle, which means giving enough permissions to do the job and no more. Non-compliance with AWS controls related to privileged access could be a costly mistake."
      ],
      "x-kaytu-usefulness-example": [
        "This AWS Control is particularly useful in maintaining security for AWS environments that run CodeBuild projects. \n\nFor example, assume you have an organization that frequently uses AWS CodeBuild for automating software build processes. When a developer mistakenly enables privileged mode, it might expose the environment to unnecessary security risks, such as the execution of arbitrary code due to exploited vulnerabilities.\n\nThis AWS Control can automatically identify this configuration error and alert the relevant teams or personnel. They can then take immediate corrective measures to disable the privileged mode, thereby significantly reducing the potential risk of security breach. \n\nMoreover, continual oversight of privileged mode can also help meet compliance requirements that demand strict control over who can perform sensitive operations in the system.\n\nHere is a demonstration in a markup:\n\n```markdown\nRepository: `project-xyz`\nBuild Project: `build-001`\nStatus: `Privileged Mode Enabled`\nAction Needed: `Disable the privileged mode for build environment`\n\nDetails: \nThe `build-001` project in the `project-xyz` repository has been identified as currently running in Privileged Mode. This configuration poses security risks such as potential arbitrary code execution. \n\nRecommendation:\nPlease disable Privileged Mode ASAP to ensure the security of the AWS environment. Check the AWS CodeBuild documentation for instructions to [modify project settings](https://docs.aws.amazon.com/codebuild/latest/userguide/change-project.html#change-project-console).\n```\nWithout this AWS Control, such security risk could go unnoticed, possibly leading to severe consequences if exploited by malicious actors."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_sagemaker_notebook_instance_direct_internet_access_disabled",
    "Title": "SageMaker notebook instances should not have direct internet access",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that Amazon SageMaker notebooks do not allow direct internet access.",
    "QueryID": "aws_sagemaker_notebook_instance_direct_internet_access_disabled",
    "DocumentURI": "policies/aws_sagemaker_notebook_instance_direct_internet_access_disabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/SageMaker"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Managing access to resources in the AWS Cloud effectively demands control over the networking capabilities of your Amazon SageMaker notebooks. These cloud-based Jupyter notebooks are used for machine learning and the analysis of information. \n\nHowever, allowing these notebooks unrestricted internet access could potentially expose sensitive data or open the system up to external threats. \n\nHere's a sample markup format that describes this control:\n\n```markdown\n# AWS Control: Manage Internet Access in Amazon SageMaker Notebooks \n\n## Overview\n\nThis control is designed to ensure secure management of cloud resources by preventing Amazon SageMaker notebooks from having direct internet access.\n\n## Implementing the Control\n\nImplementation of this control is essential to mitigate against potential data breaches or unwanted intrusion. This is done by:\n\n1. **Creating a VPC without internet access**: A Virtual Private Cloud (VPC) lets you host AWS resources in your own virtual network. You'll need to create one without internet gateway attached.\n2. **Attach the correct Security groups and Network Access Control Lists (NACLs)**: You can use these to impose inbound and outbound rules which dictate the traffic to and from your VPC.\n3. **Place the SageMaker notebook in the VPC**: This ensures it inherits the networking properties of the VPC, thereby blocking direct internet access.\n\n**Note:** Scripts running on the SageMaker notebooks which require internet access will no longer work. You may need to modify your data ingestion/preparation methods accordingly.\n\n## Benefits\n\n- **Enhanced Security**: This setup prevents unauthorized access to your SageMaker notebooks, which may contain sensitive data.\n- **Improved Control**: It gives you full control over who and what can communicate with your notebook instances in the VPC.\n```\nIt's recommended to review AWS's own material on these topics for a deeper understanding and practical steps to implement these controls."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS control which states \"Manage access to resources in the AWS Cloud by ensuring that Amazon SageMaker notebooks do not allow direct internet access\" can manifest in various forms, namely security risks, potential data loss or exposure, financial costs, and legal implications.\n\n**1. Security Risk:**\nIf Amazon SageMaker notebooks have direct internet access, it increases the potential for security vulnerabilities, as this potentially exposes the data to external threats. Unauthorized personnel might gain access and tamper with, or steal sensitive data.\n\n**2. Data Loss or Exposure:**\nSince having direct internet access exposes the SageMaker notebooks to the public, it can lead to data leaks. The data can be accessed, manipulated, or deleted by malicious actors which results in a potential data breach.\n\n**3. Financial Costs and Legal Implications:**\nResulting from a data breach, organisations can face massive financial losses due to fines, penalties, and costs involved in resolving the breach. The General Data Protection Regulation (GDPR) and other privacy laws apply strict penalties for breaches of sensitive user data. Businesses may also face legal action from parties affected by the breach. Moreover, they may need to invest in security services to repair the damage and prevent future compromises.\n\n**4. Reputation Damage:**\nNon-compliance can result in a damaged reputation when consumers lose trust in an organization's ability to protect their data. This can lead to a loss of customer base and difficulty in attracting new customers. \n\nHence, it's critical to comply with AWS controls to ensure secure and efficient utilization of AWS resources. Regular checks and audits must be performed to ensure that necessary AWS controls are in place and up to standards."
      ],
      "x-kaytu-usefulness-example": [
        "This AWS control is useful in situations where there is a need to preserve the integrity and security of data being used in SageMaker notebooks. For instance, a company performing sensitive data analysis using Amazon SageMaker would benefit from this control. By ensuring that the SageMaker notebooks do not allow direct internet access, the company reduces the risk of unwanted data exposure or potential cyber attacks. This can be particularly beneficial for companies dealing with financial data, personal data, or any other sensitive information. In such cases, this control allows the company to make use of the powerful machine learning capabilities of SageMaker, without compromising the security of their data."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_elasticache_redis_cluster_automatic_backup_retention_15_days",
    "Title": "ElastiCache Redis cluster automatic backup should be enabled with retention period of 15 days or greater",
    "Description": "When automatic backups are enabled, Amazon ElastiCache creates a backup of the cluster on a daily basis. The backup can be retained for a number of days as specified by your organization. Automatic backups can help guard against data loss.",
    "QueryID": "aws_elasticache_redis_cluster_automatic_backup_retention_15_days",
    "DocumentURI": "policies/aws_elasticache_redis_cluster_automatic_backup_retention_15_days.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/ElastiCache"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon ElastiCache provides an automatic backup feature for enhancing data protection and facilitating disaster recovery. Here is a breakdown of its details:\n\n- **Automatic Backups**: This refers to a functionality where the system automatically creates a backup of all data stored within an Amazon ElastiCache cluster.\n- **Daily Backups**: Amazon ElastiCache carries out this backup process on a daily basis, which means that at the end of each day, you'll have a backup copy of your whole database.\n- **Backup Retention**: Backups are not kept indefinitely. The duration for which they are stored can be customized as per the organization's preferences. This ensures you have access to data from the past few days/weeks/months, in accordance to your defined retention period.\n- **Data Loss Prevention**: Automatic backups serve as a protective measure against data loss. In case of a system failure or data corruption, you can restore your database from the latest backup.\n- **Amazon ElastiCache Cluster**: A cluster refers to a collection of one or more cache nodes, each of which run an engine software (Memcached or Redis). The automatic backup feature captures the state of the entire cluster.\n\nIn a markup format:\n\n```markdown\n# Amazon ElastiCache - Automatic Backup Feature\n\nAmazon ElastiCache facilitates **automatic backups** of the **cluster** on a **daily** basis to prevent data loss. The backup retention period can be defined as per your organization's preferences. This built-in feature ensures a higher level of data protection and accelerates disaster recovery process.\n```"
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance with this AWS Control - automatic backups in Amazon ElastiCache could result in three primary cost areas:\n\n1. **Operational Costs**: If data loss occurs due to a system failure or human error, and no backup is available, your team’s time and resources will need to be devoted to data recovery. In some cases, data may be permanently lost, which could involve costs associated with re-creation or replacement.\n\n2. **Business Costs**: Having no available backup could mean significant downtime for your services or applications. This may lead to lost revenue if your services are inaccessible or not fully operational. There are also implications for customer trust and reputation to consider which could result in longer-term business loss.\n\n3. **Compliance Costs**: If your organization has to comply with certain regulations that require data preservation and you're not complying, you could face fines or penalties. This would also apply if data is lost and it contains information that is legally required to be retained.\n\nThe exact cost will greatly depend on the type and amount of data lost, the operational importance of that data, and of course the specifics of any legal or regulatory compliance requirements. It's clear that the cost (both financial and in terms of operational disruption) can be significant, and as such, automatic backups should be considered essential for all business-critical data stored in Amazon ElastiCache.\n\nNote: Any cost saving achieved by not performing automatic backups is likely to be insignificant in relation to the potential costs in the event of data loss."
      ],
      "x-kaytu-usefulness-example": [
        "For an e-commerce website that handles thousands of transactions in a day, maintaining all these records is crucial. If a data loss occurs due to system failure or an unforeseen issue, it can result in considerable losses - both financially and in terms of user trust. \n\nThe automatic backup feature in Amazon ElastiCache can be a useful control in this situation, as it creates backups of the entire cluster on a daily basis. This means, if data is lost or the system falls victim to an unforeseen error, the backup copy would be available for restoration of service.\n\nFor instance, if the company's policy is to retain 7 days of backup, the daily backup facility will maintain 7 past days of data, replacing the oldest one with the new backup every day. In case of any data loss, the organization can revert to any of the preserved daily backups ensuring minimal loss of data logged within the last 7 days.\n\nTherefore, through this feature, Amazon ElastiCache provides a protective barrier against data loss and helps facilitate continuity for the organization's operations."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_policy_restricts_cross_account_permission_changes",
    "Title": "Amazon S3 permissions granted to other AWS accounts in bucket policies should be restricted",
    "Description": "This control checks whether the S3 bucket policy prevents principals from other AWS accounts from performing denied actions on resources in the S3 bucket.",
    "QueryID": "aws_s3_bucket_policy_restricts_cross_account_permission_changes",
    "DocumentURI": "policies/aws_s3_bucket_policy_restricts_cross_account_permission_changes.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/S3"
      ],
      "x-kaytu-explanation": [
        "This control is a security measure provided by AWS to ensure that your S3 buckets are properly configured to prevent unauthorized access or actions. It verifies that the policy attached to your S3 bucket is set to deny actions for any principals (users, roles, or services) from other AWS accounts. \n\nHere is a breakdown of the control with a markup format:\n\n- `This control`: This refers to a mechanism or policy put in place to ensure a certain level of security or compliance.\n- `Checks whether`: This control essentially verifies if a certain condition (mentioned next) is fulfilled.\n- `The S3 bucket policy`: The rules and settings attached to an S3 bucket that dictate which principals have what kind of access to that bucket.\n- `Prevents principals from other AWS accounts`: It ensures that an unauthorized user, role, or service cannot access your resource.\n- `from performing denied actions`: Any action set under the `Deny` policy in AWS.\n- `on resources in the S3 bucket`: This control relates to accessing resources like objects present in the S3 bucket, and not the bucket itself.\n\nHere's a sample outline of how such a policy in JSON format may look:\n```json\n{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n     {\n        \"Sid\":\"DenyOtherAccounts\",\n        \"Effect\":\"Deny\",\n        \"Principal\": \"*\",\n        \"Action\":[\n           \"s3:*\"\n        ],\n        \"Resource\":[\n           \"arn:aws:s3:::BucketName/*\"\n        ],\n        \"Condition\": {\n            \"StringNotEquals\": {\n                \"aws:PrincipalAccountId\": [\"your-aws-account-id\"]\n            }\n        }\n     }\n  ]\n}\n```\nIn this policy, the \"Effect\" is set to \"Deny\", and the \"Principal\" is set to \"*\", denying all AWS identities. But then the \"Condition\" key with \"StringNotEquals\" is used to exclude your own AWS account from this denial, essentially allowing only your account to perform actions on the S3 bucket resources."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control can be multi-faceted and significant. Below are some potential costs that may occur:\n\n1. **Data Breach**: If your S3 bucket policy does not prevent principals from other AWS accounts from performing denied actions, it can cause serious security vulnerabilities. Unauthorized access from other AWS accounts could lead to a data breach. The cost of a data breach can be quite high, due to customer compensation, regulatory fines, and loss of brand reputation.\n\n2. **Loss of Data**: Without proper security controls like this, there is a risk of data getting deleted or modified without your knowledge. This can cause serious disruption to your business and the cost to recover from such an incident can be significant.\n\n3. **Compliance Penalties**: If your business is subject to any data protection regulation (like GDPR, HIPAA, etc,), non-compliance to such controls could invite penalties and fines from regulatory bodies.\n\n4. **Unwanted Charges**: If other users can gain access, they may perform actions which result in unexpected costs - for example, they could add objects to the bucket or make numerous requests leading to large AWS bills. \n\n    ```\n    Note: Non-compliance to this control could be accidental too. Maybe another AWS account user within your own organization, not aware of the cost implications, could perform unwanted operations on your S3 bucket.\n    ```\n\n5. **Loss of Trust**: An organization's inability to secure its data could lead to customers losing trust in the organization's abilities to securely manage their data, causing the loss of potential or existing customers. \n\nTo summarize, the cost of non-compliance to this AWS control is not just limited to financial aspects but also extends to operational, reputation and legal costs."
      ],
      "x-kaytu-usefulness-example": [
        "For example, consider a company called XYZ Corp that uses AWS S3 for storing sensitive customer data. Their AWS account has multiple S3 buckets, one of which stores this sensitive data. For performance reasons and cost savings, they frequently share some non-sensitive data buckets with external vendors and partners from other AWS accounts. \n\nHowever, they need to ensure that their sensitive customer data stored in a specific S3 bucket remain private and is not accidentally or intentionally accessed by these external entities. \n\nHere, the AWS Control that checks whether the S3 bucket policy prevents principals from other AWS accounts from performing denied actions on resources in the S3 bucket would be extremely useful. This control would continuously monitor the bucket access policies, and alert or take actions if any external access is detected, thus significantly reducing XYZ Corp's data security risks. \n\nAWS Control Code Example:\n\n```markdown\n    {\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Sid\": \"ExamplePolicy\",\n          \"Effect\": \"Deny\",\n          \"Principal\": \"*\",\n          \"Action\": \"s3:*\",\n          \"Resource\": \"arn:aws:s3:::examplebucket/*\",\n          \"Condition\": {\n            \"StringNotEquals\": {\n              \"aws:userId\": \"${aws:userId}\"\n            }\n          }\n        }\n      ]\n    }\n```\n\nIn this code, the policy denies all S3 actions (`s3:*`) performed by all users (`\"Principal\": \"*\"`) on all objects in the bucket (`\"Resource\": \"arn:aws:s3:::examplebucket/*\"`) except the user who owns the bucket. Therefore, no external user from other AWS accounts can perform actions on this bucket."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_codebuild_project_plaintext_env_variables_no_sensitive_aws_values",
    "Title": "CodeBuild project plaintext environment variables should not contain sensitive AWS values",
    "Description": "Ensure authentication credentials AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY do not exist within AWS CodeBuild project environments. Do not store these variables in clear text. Storing these variables in clear text leads to unintended data exposure and unauthorized access.",
    "QueryID": "aws_codebuild_project_plaintext_env_variables_no_sensitive_aws_values",
    "DocumentURI": "policies/aws_codebuild_project_plaintext_env_variables_no_sensitive_aws_values.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/CodeBuild"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "This control is suggesting that sensitive AWS credentials, specifically `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, should not be stored or used in AWS CodeBuild project environments. These are access keys for your AWS account, and keeping them within a CodeBuild project can lead to security issues if they are improperly exposed or unauthorized access is obtained, as they could potentially be used to perform any AWS API function.\n\nInstead, it is recommended to use IAM roles for tasks, where the rights and permissions can be explicitly managed, limiting potential exposure and risks. This AWS security best practice helps to prevent unintended data exposure and unauthorized access. \n\nIn addition, these credentials should not be stored in clear text. This would make them easily readable if someone gained access to wherever they're stored. Instead, they should always be stored securely, such as in encrypted format.\n\n```markup\n\u003crule id=\"aws-code-build-project-keys\"\u003e\n    \u003cdescription\u003e\n        Ensure AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY do not exist within AWS CodeBuild project environments. \n    \u003c/description\u003e\n    \u003cremediation\u003e\n        Do not store these variables in clear text. Storing these variables in clear text may lead to unintended data exposure and unauthorized access.\n    \u003c/remediation\u003e\n    \u003ccompliance\u003e\n        AWS best practices\n    \u003c/compliance\u003e\n    \u003cseverity\u003ewarning\u003c/severity\u003e\n    \u003ctype\u003emandatory\u003c/type\u003e\n\u003c/rule\u003e\n```\n\nThe above markup describes the rule. It gives a description of the rule, the remediation steps if the rule is not being followed, what compliance framework it is part of, the severity of not following the rule, and that this rule is mandatory to follow."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the mentioned AWS control can lead to numerous setbacks with potential legal, financial and reputational risks. If you violate this control and store `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` in plain text within AWS CodeBuild project environments, it can result in the following costs:\n\n1. **Data Breaches**: If these credentials are exposed, attackers could potentially gain unauthorized access to your AWS resources. This could lead to data breaches, where your organization's sensitive information or user data could be leaked, manipulated or erased. The cost of a data breach can be enormous, both financially (due to penalties, remediation costs, etc.) and in terms of reputation.\n\n2. **Unauthorized Activities**: The attacker could use these credentials to perform unauthorized activities, such as starting up new instances, altering databases etc., which could disrupt your services or result in unexpected costs.\n\n3. **Non-Compliance Fines**: Depending on the laws and regulations in your industry or region (like GDPR, CCPA, HIPAA etc.), non-compliance could result in heavy fines.\n\n4. **Loss of Business**: In the aftermath of a data breach, customer trust is greatly impacted. This could lead to lost business, both from existing customers who choose to take their business elsewhere, and potential future customers who are dissuaded by the security incident.\n\nRemember, it is recommended to use AWS Secrets Manager or AWS Systems Manager Parameter Store to keep secrets like these. Avoid hard coding sensitive information including authentication credentials into your code."
      ],
      "x-kaytu-usefulness-example": [
        "The secure management of access keys is crucial for maintaining the integrity and safety of applications and services in AWS environments. \n\nFor example, consider a company \"X\" which has a SaaS based application developed in an AWS infrastructure that uses CodeBuild for continuous integration and continuous delivery (CI/CD). CodeBuild uses a build specification file which is a collection of build commands and related settings, stored in the project source code as a text file named `buildspec.yml`.\n\nIf the company stores plain text AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY in the `buildspec.yml` file, they expose themselves to significant risks. Any employee with access to the source code would be able to view these credentials and potentially misuse the permissions associated with these keys. Furthermore, if an outsider were to gain access to the source code - for example, if it is accidentally pushed to a public repository - they would be able to gain unauthorized access to the AWS environment. This would allow them to potentially compromise sensitive data or inject malicious code into the company's applications and infrastructure.\n\nAssuming a worst case scenario, if the keys provide administrator level access, unauthorized personnel or malicious actors could cause a significant amount of damage - affecting both the company's operations and its reputation. Monetary loss can occur from fraud, data theft, recovery operations, or potential regulatory fines.\n\nHence, it is important to ensure that the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are not stored in plain text within the AWS CodeBuild project environments and appropriate key management practices are put in place. Critical credentials should be stored securely and processes should be implemented for regular key rotation."
      ]
    },
    "Managed": true
  }
]