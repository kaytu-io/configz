[
  {
    "ID": "aws_iam_user_mfa_enabled",
    "Title": "IAM user MFA should be enabled",
    "Description": "Enable this rule to restrict access to resources in the AWS Cloud.",
    "QueryID": "aws_iam_user_mfa_enabled",
    "DocumentURI": "policies/aws_iam_user_mfa_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Restrict Access to Cloud Resources\n\nThis control rule is essential for managing the security of your resources in the AWS Cloud. AWS provides several services and features to enhance your resource permissions management, maintain control over your resources, and detect any unusual activity.\n\n## What does this control do?\n\nWhen this control rule is enabled, it restricts access to the resources available in your AWS Cloud. This means that only approved entities (users, roles, services, etc.) would have access to specified resources. \n\n## How does it Work?\n\nThe control makes use of AWS Identity and Access Management (IAM) policies to manage permissions and regulate access to your AWS resources. \n\nIAM policies define what actions are allowed or denied on what resources at what time. You can attach these policies to IAM identities (users, groups of users, or roles) and AWS resources. \n\nFor example, you could create an IAM policy that allows read-only access to objects in an S3 bucket, and attach the policy to a group of users. Then, only the users in that group could read objects in the specified bucket.\n\n## Why is it Important?\n\nThis rule is beneficial to maintain control over your resources and protect them from unwanted modifications or exposures. \n\nMoreover, it helps in keeping track of the actions performed on the AWS resources, analyzing trends, and detecting irregularities. \n\nIt's also pertinent in ensuring that people in your organization have the least access necessary to perform their work, thereby implementing least privilege best practices.\n\n## Conclusion\n\nTo sum up, by enabling this AWS control, you can significantly advance the security of your resources, reinforce your access control, and maintain a high level of security for your AWS cloud environment."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to access restriction control in AWS has numerous cost implications. Here are a few of them:\n\n1. **Loss due to data breaches and security incidents:** Not properly restricting access can lead to unauthorized individuals obtaining sensitive data. This may result in losses related to customer trust, legal penalties, and direct financial loss if the data includes financial information.\n\n2. **Increased operational costs:** Administrative tasks such as troubleshooting and rectifying inappropriate access privileges require time and effort from your technical staff. There are direct costs associated with the increased workload and potential overtime pay.\n\n3. **Regulatory fines and penalties:** If a company is subject to data regulation (like GDPR, HIPAA, PCI-DSS), non-compliance could result in significant legal penalties.\n\n4. **Reputational damage:** Non-compliance leading to a security incident can vastly damage the reputation of your organization. This can have a lasting impact on your brand and customer loyalty. Lost customers and reduced sales could be a significant indirect cost.\n\n5. **System downtime:** If misconfigured permissions lead to accidental disruption of vital systems, this could lead to system downtime. There are costs associated with lost productivity, potential sales loss, and customer dissatisfaction.\n\nThus, customers must adhere to AWS compliance and restrict access to vital resources in the cloud accordingly."
      ],
      "x-kaytu-usefulness-example": [
        "AWS offers an \"Access Control Rule\" which is effectively utilized in multiple scenarios, one of them is explained below:\n\nFor instance, a multinational corporation with several teams around the world. AWS Control allows them to properly manage and restrict access. They can establish a rule to strictly limit access to important resources, such as databases containing sensitive business information, source codes, etc.\n\nDifferent departments or positions in the corporation may have different access rights. For instance, the IT department may need full permission to manage cloud resources, while the marketing department may only require access to specific data analysis tools or storage repositories pertaining to marketing data. By enabling this rule, it ensures that every department or staff member can access only the resources that they are designated to use, thus maintaining the organization's security and privacy. \n\nHere's an example of how you could use markup to apply this rule:\n\n```JSON\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AccessControlRule\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\"AWS\": \"arn:aws:iam::AccountB-ID:root\"},\n            \"Action\": \"s3:GetObject\",\n            \"Resource\": \"arn:aws:s3:::mybucket/*\",\n            \"Condition\": {\"StringEquals\": {\"aws:SourceVpce\": \"vpce-1a2b3c4d\"}}\n        }\n    ]\n}\n```\n\nThis JSON IAM policy ensures that only the specific VPC endpoint (vpce-1a2b3c4d) from account B will have \"s3:GetObject\" permissions for all objects in your bucket, effectively restricting access to your cloud-based resources to enhance your application's security."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_root_user_mfa_enabled",
    "Title": "IAM root user MFA should be enabled",
    "Description": "Manage access to resources in the AWS Cloud by ensuring MFA is enabled for the root user.",
    "QueryID": "aws_iam_root_user_mfa_enabled",
    "DocumentURI": "policies/aws_iam_root_user_mfa_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "`## AWS Control: Enable MFA for Root User\n\n### Overview\n\nOne of the critical controls for managing access to resources in the AWS Cloud is ensuring that Multi-Factor Authentication (MFA) is enabled for the root user. The root user is a high privilege account with unrestricted access to all resources within the AWS account. \n\n### Importance of enabling MFA\n\nBy enabling MFA, an additional layer of security is added on top of username and password, making it significantly more difficult for unauthorized users to access your cloud data and resources. Whenever the root user tries to log in, they will be required to provide two or more credentials or \"factors\" â€” something they know (password), something they have (a trusted device), and something they are (biometrics, not used in AWS).\n\n### How to enable MFA\n\nHere is a simplified step-by-step guide on how to enable MFA:\n\n1. Sign in to the AWS Management Console using your root user credentials.\n2. Navigate to the IAM Dashboard.\n3. In the left navigation pane, click on \"Dashboard\" and look for \"Root user sign-in\" details.\n4. Under \"Security Status\", Click on \"Activate MFA on your root account\".\n5. In the Manage MFA page, click on \"Multi-factor Authentication (MFA)\".\n6. Click \"Activate MFA\".\n7. Choose a device type (virtual or hardware), follow the on-screen instructions to set it up, and then click \"Enable MFA\".\n\nRemember to regularly check the MFA activation in your root account to mitigate any potential risks associated with unauthorized access to your AWS resources.`"
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to the AWS control of managing access to resources in the AWS Cloud by ensuring Multi-Factor Authentication (MFA) is enabled for the root user can manifest in various ways:\n\n1. **Security Breaches:** If MFA is not enabled, the system is more vulnerable to unauthorized access. If attackers guess, steal, or crack the root user's password, they could gain full access to the AWS account. This could lead to data theft, modification, or deletion.\n\n2. **Financial Losses:** Unauthorized access could lead to the misuse of AWS services, causing financial losses. An attacker could spin up large and costly instances, leading to substantial increases in your AWS bill.\n\n3. **Compliance Issues:** If your organization falls under regulations that require MFA (like GDPR, HIPAA, etc.), noncompliance could include fines \u0026 penalties. \n\n4. **Reputation Damage:** Data breaches often lead to reputation damage. Customers may lose trust in your organization's ability to protect their data, causing them to take their business elsewhere.\n\n5. **Resource and Time Consumption:** Breaches often necessitate extensive investigation \u0026 response activities, audits, and security improvements, consuming significant resources and time that could have been used productively.\n\n6. **Business Disruption:** In the worst-case scenario, attackers could disrupt or completely halt your business operations.\n\nHence, it is critically essential to enable and enforce MFA for the root user account in the AWS environment. MFA adds an extra layer of protection on top of the username and password, further securing access to the account."
      ],
      "x-kaytu-usefulness-example": [
        "Consider the following scenario to understand the usefulness of having Multi-Factor Authentication (MFA) enabled for the root user in an AWS environment:\n\nA company, ABC Corporation, has its entire infrastructure hosted on the AWS Cloud. They rely upon various AWS services like EC2 for hosting applications, RDS for the database needs, and S3 for storing data. \n\nRecently, the IT team at ABC Corp noticed unusual activity in their AWS account. Upon investigation, they found out that their root credentials have been compromised and are being used to perform non-compliant operations resulting in potential data loss and financial implications.\n\nHad MFA been enabled for the root user, this could have been avoided. Here's why:\n\n```markdown\n- MFA adds an extra layer of protection on top of the username and password. Even if someone somehow gets hold of the root user credentials, they won't be able to access the account without getting through the MFA challenge.\n\n- It acts like an early warning system. When an unauthorized person tries to log in and faces an MFA challenge, it triggers notifications/alerts. A timely alert can help in preventing wider data exposure.\n\n- Besides, AWS offers multiple options for MFA like virtual MFA, U2F security keys, or hardware key fobs, providing a choice to choose the desired MFA method.\n```\n\nHence, managing access to AWS resources with MFA for root user plays a key role in maintaining the security of an AWS account and thus, the overall organizational data and infrastructure. This is vital especially from the perspective of compliance and audits, as well."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ec2_instance_ebs_optimized",
    "Title": "EC2 instance should have EBS optimization enabled",
    "Description": "An optimized instance in Amazon Elastic Block Store (Amazon EBS) provides additional, dedicated capacity for Amazon EBS I/O operations.",
    "QueryID": "aws_ec2_instance_ebs_optimized",
    "DocumentURI": "policies/aws_ec2_instance_ebs_optimized.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EC2"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "An **optimized instance in Amazon Elastic Block Store (Amazon EBS)** is an additional service provided by AWS to give your applications more reliable and robust access to data storage. This specific feature allows you to dedicate additional capacity for EBS input/output operations, improving the overall performance of your data transfer process.\n\nOnce an instance is EBS-optimized, it delivers dedicated bandwidth for both input and output operations with Amazon EBS. This dedicated bandwidth does not share with other services in the same instance, thereby reducing any potential performance inconsistency that can be caused by other network traffic.\n\nEBS-optimized instances can be useful if you have workloads with high I/O requirements, or where consistent and high-speed data transfer rates are critical.\n\nKey Benefits:\n- Dedicated bandwidth gives more access to storage with less contention from other services.\n- Better and consistent performance in data transfer.\n- Ideal for high I/O workloads for robust data access.\n\nHow to Use:\n- During the launching of an instance, you can enable EBS optimization in the \"Configure Instance\" section, under \"Add Storage\".\n- You can also modify an existing instance to become EBS-optimized.\n\nPricing:\n- There is an additional hourly charge for your EBS-optimized instances, which differs based on the instance type.\n- For the latest pricing information, you can refer to the Amazon EC2 pricing page.\n\nIn conclusion, using an EBS-optimized instance can significantly improve the performance of your applications by providing dedicated capacity for EBS I/O operations."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to using optimized instances in Amazon Elastic Block Store (Amazon EBS) can result in several costs, including but not limited to:\n\n1. **Increased latency**: EBS optimized instances deliver dedicated network capacity for EBS I/O. Without it, there could be competition for network bandwidth between your EBS volumes and other data transfers (like your EC2 instance's outbound internet traffic). This could cause increased latency which can affect your application's performance.\n\n2. **Increased costs**: EBS volumes that frequently deliver their peak performance, like Provisioned IOPS SSD (io1 and io2) volumes, may consume more instance bandwidth than can be provided by an instance that is not EBS-optimized. You may have to upgrade to a larger, more costly instance or add more instances to meet demand, thus increasing costs. \n\n3. **Decreased reliability**: If your EC2 instance does not provide the recommended bandwidth, it can affect data consistency and reliability causing intermittent application and data failures. Reactive measures to these issues lead to additional diagnostic and fix costs.\n\n4. **Customer satisfaction**: The performance of your applications could be negatively impacted, leading to a decrease in user satisfaction. This could translate to losing potential and existing customers to competitors with more reliable services.\n\nIn conclusion, it's critical to adhere to this AWS control to ensure the smooth and reliable operation of your applications. Despite the possible higher initial costs, it may save you from later dealing with unexpected performance issues, greater costs and potentially lost customers."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, consider a scenario of a financial organization that processes large volumes of transaction data daily. This data is stored in databases that need frequent reading and writing operations. \n\nIn such cases, using an optimized instance in Amazon Elastic Block Store (EBS) can be highly beneficial. It can improve performance for I/O intensive workloads as well as the throughput of the databases, enabling faster processing of transactions. The organization can utilize the dedicated capacity to handle the high rate of I/O operations, ensuring smooth, efficient, and uninterrupted data transaction processing without any lag or delay. \n\nMoreover, Amazon EBS-optimized instances can deliver consistent performance that is crucial for the organization's mission-critical applications, which deal with sensitive financial data. They can also prevent the interference between I/O associated with the Amazon EBS volume and other traffic to and from the instance.\n\n```markup\nUse Case: \nA financial organization uses optimized instance in Amazon EBS for their transaction databases that require high rate of read/write operations. The organization can leverage the additional, dedicated capacity for Amazon EBS I/O operations to make sure that data transactions are processed efficiently and consistently, enhancing overall system performance and customer experience.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_versioning_enabled",
    "Title": "S3 bucket versioning should be enabled",
    "Description": "Amazon Simple Storage Service (Amazon S3) bucket versioning helps keep multiple variants of an object in the same Amazon S3 bucket.",
    "QueryID": "aws_s3_bucket_versioning_enabled",
    "DocumentURI": "policies/aws_s3_bucket_versioning_enabled.md",
    "ManualVerification": false,
    "Severity": "Low",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon Simple Storage Service (S3) introduces the feature called \"Bucket Versioning\". This feature allows you to keep and retrieve multiple versions of an object in the same bucket. When you enable bucket versioning, it protects your data from both unintended deletes and overwrites.\n\nHere's how you could explain this AWS Control in markup format:\n\n```markdown\n# Amazon S3 Bucket Versioning\n\n**Amazon Simple Storage Service (S3)** introduces a service named **Bucket Versioning**. This service allows users to **preserve, retrieve, and restore** every version of every object in their Amazon S3 bucket. With this feature enabled, you can easily recover from both unintended user actions and application failures.\n\n## Features:\n\n- **Prevent Data Loss**: Safeguards against accidental deletions or modifications.\n- **Data Retrieval**: Quickly retrieve previous versions of your data.\n- **Backup and Version Control**: Maintain all versions of an object (including all writes and deletes) in the bucket.\n\n## How to enable?\n\nBucket versioning can be enabled by following the below steps:\n\n1. In the Amazon S3 console, select your bucket.\n2. Go to bucket settings and choose **Properties**.\n3. From properties, scroll to the **Bucket Versioning** section and choose the **Enable** option.\n\n*Remember: Once the bucket versioning is turned on, you can't suspend it, you can only enable \"MFA Delete\".*\n```\nThis explanation describes the control, its features, and a step-by-step guide on how to enable versioning in a user-friendly markup format."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS control of enabling Amazon S3 bucket versioning could potentially result in numerous risks and costs:\n\n1. **Data Loss:** Without versioning, if an object is accidentally deleted or overwritten, you may not be able to easily recover the original version. This could result in permanent loss of vital data, causing operational disruption and potential financial losses.\n\n2. **Backup \u0026 Recovery Costs:** If versioning isn't enabled and data is lost, you would have to rely on complex backup and recovery solutions which can be time-consuming and expensive.\n\n3. **Risk of Non-compliance:** If your industry has strict compliance regulations regarding data preservation and recoverability, failing to enable versioning could put you in non-compliance, resulting in fines and other penalties. \n\n4. **Business Continuity Threats:** In case of incidents like ransomware attacks or human errors, data recovery is required. Not having versioning could risk business continuity, as critical data may take longer or may not be recoverable at all. \n\n5. **Reputation Damage:** Losing customer data can lead to lost trust and damage to your business's reputation. \n\nIn conclusion, compliance with AWS controls, specifically using Amazon S3 bucket versioning, is crucial for data integrity, regulatory compliance, and business continuity. Allowing non-compliance could lead to significant operational, financial, and reputational risks."
      ],
      "x-kaytu-usefulness-example": [
        "Suppose a cloud engineer working for a software company is managing an AWS S3 bucket that stores critical system configuration files. Their team frequently changes these configurations for different deployments of the company's product, so they need to have past website configurations readily available in case they need to revert any changes quickly.\n\nBy leveraging AWS S3 bucket versioning, they can keep all variants of the object (in this case, the system configuration files) within the same S3 bucket. For every edit or deletion, a new version of the object is automatically stored. \n\nSuch a setup makes it easy for the team to track changes or quickly restore an old version if something goes wrong with the new configuration. They could even run an A/B test with two versions of the same page, which is exceptionally useful in testing new features or changes.\n\nHere is a potential example in MarkDown:\n\n```markdown\n# Use Case: Using AWS S3 Bucket Versioning for System Configuration Files\n\n1. A cloud engineer uploads a version of the system configuration file onto the S3 bucket. The bucket versioning feature is enabled.\n2. She makes changes to the configuration file and uploads the new variant.\n3. S3 automatically stores this as a new version of the same file. The older version continues to exist in the bucket.\n4. If any problems occur, the engineer can quickly revert to the previous configuration file using the version stored in the S3 bucket.\n5. The company can effectively track changes, test new features, and ensure the smooth deployment of various configurations. \n```\n\nIn this instance, S3 bucket versioning has made the work of managing different versions of crucial files much easier and less error-prone for the team."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_snapshot_encrypted_at_rest",
    "Title": "RDS DB snapshots should be encrypted at rest",
    "Description": "Ensure that encryption is enabled for your Amazon Relational Database Service (Amazon RDS) snapshots.",
    "QueryID": "aws_rds_db_snapshot_encrypted_at_rest",
    "DocumentURI": "policies/aws_rds_db_snapshot_encrypted_at_rest.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Enable Encryption for Amazon RDS Snapshots\n\nWhen dealing with data security in the cloud, it is always important to ensure that your data backups are properly protected using strong encryption mechanisms. Amazon Web Services (AWS) provides a built-in feature to encrypt your data at rest in the backup snapshots of your Amazon Relational Database Service (RDS) instances.\n\n## Why encrypt RDS snapshots?\n\nEncryption of RDS snapshots adds an additional layer of security to your data by rendering it unreadable to unauthorized individuals. Encrypted snapshots can only be accessed by individuals or services with the necessary decryption keys, making your data more secure.\n\n## How to enable encryption?\n\nTo enable encryption for your Amazon RDS snapshots:\n\n1. Open the Amazon RDS console.\n\n2. Choose **Snapshots** in the navigation pane.\n\n3. Choose the DB snapshot that you want to encrypt.\n\n4. Choose **Actions**, then choose **Copy Snapshot**.\n\n5. In the **Encryption** section, choose **Enable encryption**.\n\n6. Choose the KMS key that you want to use to encrypt the snapshot. If you don't have a KMS key, you can choose **Default Key** to use the AWS managed key for Amazon RDS.\n\n7. Choose **Copy Snapshot**.\n\nPlease note that encryption can't be disabled once it has been enabled on a snapshot.\n\nIn addition to enabling encryption, you should also restrict access to your snapshots by implementing proper AWS Identity and Access management (IAM) policies.\n\n---\n\nRemember, the security of your data is of utmost importance. Enabling encryption for your Amazon RDS snapshots is a simple way to enhance the security posture of your environment."
      ],
      "x-kaytu-noncompliance-cost": [
        "If an organization does not comply with the specified AWS control which states that encryption needs to be enabled for Amazon RDS Snapshots, it may face several potential costs:\n\n1. **Data Breach Risks**: Unencrypted RDS snapshots are vulnerable to unauthorized access. If a data breach happens, it could lead to exposure of sensitive data which could harm the company's reputation and customer trust.\n\n2. **Non-compliance Fines**: The organization could face severe fines and legal penalties if it fails to comply with legal regulations around data protection, such as GDPR, HIPAA, or PCI DSS. \n\n3. **Forensic Costs**: In the case of a breach, the organization may need to hire a security team for forensic analysis which can be quite expensive.\n\n4. **Loss of Business**: If your company operates in a regulated industry, not enabling encryption might prevent you from doing business with certain customers or in certain markets.\n\n5. **Remediation Costs**: If it is found that the snapshots are not encrypted, the company might need to consider hiring experts to ensure that the infrastructure is compliant with the necessary principles of data security.\n\nThus, complying with this AWS control and thus ensuring encryption for RDS snapshots not only secures your data but also saves significant cost related to potential data breaches and non-compliance penalties."
      ],
      "x-kaytu-usefulness-example": [
        "Example:\n\nProject ABC currently involves using AWS RDS for managing a database that contains sensitive user data. Protection and security of this data are critical. We have a policy to regularly take snapshots of our database for backup and disaster recovery purposes.\n\nHere, enabling encryption for our Amazon RDS snapshots proves to be useful. \n\n- Firstly, it provides an additional layer of security. With snapshots encrypted, even in the unlikely case where unauthorized individuals gain access, they won't be able to decrypt and comprehend the data without the right decryption keys. \n\n```\nresource \"aws_db_snapshot\" \"example\" {\n  db_instance_identifier = aws_db_instance.example.id\n  db_snapshot_identifier = \"testsnapshot12345\"\n  snapshot_type          = \"manual\"\n  storage_encrypted      = true\n}\n```\n\n- Secondly, enabling encryption allows us to meet compliances and regulatory requirements for handling sensitive data, providing reassurances to our stakeholders and customers regarding data safety.\n\nTherefore, this particular AWS control serves a significant role in enhancing the security of our database backups and safeguarding confidential user data."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_iam_user_console_access_mfa_enabled",
    "Title": "IAM users with console access should have MFA enabled",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that MFA is enabled for all AWS Identity and Access Management (IAM) users that have a console password.",
    "QueryID": "aws_iam_user_console_access_mfa_enabled",
    "DocumentURI": "policies/aws_iam_user_console_access_mfa_enabled.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/IAM"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Manage MFA Access for IAM Users\n\n## Overview\nIn Amazon Web Services (AWS), it's crucial to manage access to resources within the AWS Cloud. This control emphasizes the importance of enabling Multi-Factor Authentication (MFA) for all AWS Identity and Access Management (IAM) users who have a console password.\n\n## What is MFA?\nMulti-factor Authentication (MFA) is a method of confirming a user's claimed identity by utilizing something they know (password or PIN), something they have (smart card, mobile device), and sometimes, something they are (Biometric verification). \n\n## Why Enable MFA for IAM Users?\nMFA adds an extra layer of protection on top of username and password. With MFA, even if a password is compromised, the account is not accessible without the second verification step which generally is a dynamic code generated by a device the user possesses. \n\nIAM users with console access could have high privileges, and by enforcing MFA you reduce the risk of unauthorized access.\n\n## How to Enable MFA?\nTo require MFA for IAM users, follow these steps:\n\n1. Open the IAM console.\n2. In the navigation pane, choose Users, and then choose the IAM user that you want to manage.\n3. In the IAM user's settings, navigate to \"Security Credentials\" tab.\n4. Under Assigned MFA device, click on Manage.\n5. Choose a MFA device type, and follow the steps in the wizard to set up a MFA device.\n\nOnce MFA is enabled, the user will be prompted for a second factor of authentication when they sign in.\n\n## Conclusion\nBy managing your IAM users' access with MFA-enabled, you strengthen the security of your AWS resources. This process is particularly beneficial for IAM users who have console passwords, enhancing their access security."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the mentioned AWS control could result in severe financial and operational implications. \n\n1. **Security Breaches**: Not enabling Multi-Factor Authentication (MFA) significantly increases the likelihood of security breaches. If an attacker can gain access to an IAM user's password, they can potentially access, alter, or delete data, leading to information loss, operational downtime, and potentially financial damage. \n\n2. **Non-compliance Penalties**: Many industries have regulations that require businesses to protect their systems and data. Failure to comply with these regulations (like GDPR, HIPPA, and others) can lead to severe fines. \n\n3. **Reputational Damage**: A data breach due to inadequate security measures can damage the reputation of the business. \n\n4. **Loss of Business**: Breach of sensitive customer data could result in loss of customers, affecting the profitability of the company.\n\n5. **Recovery Costs**: There will be significant costs related to recovering lost data, restoring systems, and improving security measures after a breach.\n\n6. **Legal Liabilities**: If the data breach includes sensitive information like personal or financial data, the company might face legal liabilities. \n\n7. **Increased Audit Costs:** Non-compliance might lead to more frequent and rigorous audits, resulting in increased costs.\n\nTherefore, ensuring MFA for all IAM users with a console password is an important control to mitigate risks associated with unauthorized access and potential data loss. It also helps in maintaining compliance with privacy regulations."
      ],
      "x-kaytu-usefulness-example": [
        "---\nExample:\n \nConsider an organization that holds vital and confidential data about its clients. In order to protect this data, they are using AWS Cloud services. The Administrator has created multiple AWS IAM users who can access the AWS Management Console with their passwords.\n\nEven though IAM provides robust policies to manage access to AWS resources, there can still be potential risks if an IAM user's console password falls into the wrong hands. To prevent unauthorized access to the resources, the Administrator ensures that Multi-Factor Authentication (MFA) is enabled for all IAM users that have console passwords.\n\nWith MFA enabled, users now need to provide two forms of identification (password and a unique MFA code) every time they log into the AWS Management Console. This increases the security level, making sure that even if a password is compromised, the unauthorized user would still need to breach the second layer of security.\n\nIn such a case, using MFA provides an extra layer of security to the AWS resources, ensuring that sensitive information is not compromised due to unauthorized access. It proves the usefulness of this AWS control in an organizational setup where data security is a top priority. This MFA control coupled with robust IAM policies significantly reduces security risks associated with unauthorized access."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_restrict_public_read_access",
    "Title": "S3 buckets should prohibit public read access",
    "Description": "Manage access to resources in the AWS Cloud by only allowing authorized users, processes, and devices access to Amazon Simple Storage Service (Amazon S3) buckets.",
    "QueryID": "aws_s3_bucket_restrict_public_read_access",
    "DocumentURI": "policies/aws_s3_bucket_restrict_public_read_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "Amazon Web Services (AWS) provides a feature that enables you to manage and control access to your resources on the AWS Cloud. This is particularly useful when it comes to Amazon Simple Storage Service (S3) buckets, which can be used to store and retrieve data.\n\nThis control works by only allowing authorized users, processes, and devices to access your Amazon S3 buckets. This means you can effectively manage who has access to the data stored in your S3 buckets, as well as monitor and manage any potential security threats.\n\nHere is an outline of this control:\n\n```markdown\n1. **Manage Access to AWS Resources**\n    - This feature allows you to manage and control who has access to your AWS resources.\n\n2. **Authorization**\n    - Only authorized users, processes, and devices are allowed to access your Amazon S3 buckets.\n\n3. **Resource - Amazon S3 Buckets**\n    - Store and retrieve data in S3 buckets.\n\n4. **Security**\n    - Through managing access, you can monitor and manage any potential security threats.\n```\n\nBy implementing this control, you are enhancing the security of your data stored in AWS Cloud, which in turn helps maintain data integrity and confidentiality."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control can result in severe consequences including both financial and strategic impacts. Here are some potential costs:\n\n1. **Unauthorized Data Access**: Unauthorized users can access confidential data stored in S3 buckets. This may comprise sensitive customer data or critical business data, potentially leading to data breaches.\n\n2. **Data loss**: Unauthorized users can potentially alter or delete key data resulting in the loss of valuable business information. The cost of data recovery or the impact of losing that data permanently could be substantial.\n\n3. **Fines \u0026 Legal Action**: If the data stored on the S3 buckets has any Personal Identifiable Information (PII) or other regulated data, non-compliance to this control could cause companies to violate data privacy laws such as GDPR, HIPAA etc. This could lead to hefty fines and legal actions.\n\n4. **Reputation Damage**: Data breaches often lead to negative publicity which could tarnish the reputation of a company. This may result in loss of customers and business opportunities.\n\n5. **Loss of Customer Trust**: If a data breach occurs due to this non-compliance, not only can the company suffer financial losses, but it can also lead to a significant drop in customer trust, which can have long-term impacts on the business.\n\n6. **Incurred cost in Incident response**: Non-compliance may result in the need for urgent incident response procedures and mechanisms, including investigation and clean-up efforts, which can be costly."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a company XYZ, Inc. uses Amazon S3 to store confidential business data and application data. This encompasses sensitive information like financial records, employee details, customer database, proprietary software codes and more. The company might thus use AWS's access management control to setup different access levels. \n\nFor example, they could permit only specific employees, like their Database Manager, direct access to the S3 bucket containing the company's main customer database. Similarly, another S3 bucket containing logs might only be accessible by the IT team for troubleshooting and maintenance purposes. \n\nIn addition, XYZ could incorporate AWS's control to only allow an automated, company-approved process to put data into the S3 bucket that contains proprietary software source code. In this way, they can ensure the source code does not get manipulated unknowingly.\n\nThis highlighting the importance of AWS control in ensuring that only authorized users, devices, and processes can access system-critical information. This not only aids with the organization's data security strategy, but also with compliance with various data handling and privacy regulations."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_s3_bucket_restrict_public_write_access",
    "Title": "S3 buckets should prohibit public write access",
    "Description": "Manage access to resources in the AWS Cloud by only allowing authorized users, processes, and devices access to Amazon Simple Storage Service (Amazon S3) buckets.",
    "QueryID": "aws_s3_bucket_restrict_public_write_access",
    "DocumentURI": "policies/aws_s3_bucket_restrict_public_write_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/S3"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Manage Access To Resources\n\nThis control management involves limiting access to resources in the AWS cloud to only authorized users, processes, and devices. It mainly focuses on providing access to [Amazon Simple Storage Service (Amazon S3) buckets](https://aws.amazon.com/s3/).\n\n## How it Works?\n\n1. **Authorized users**: Only users who have been granted access can interact with the resources. This includes both AWS IAM (Identity and Access Management) users and root users associated with the AWS account.\n\n2. **Authorized processes**: Certain automated processes that require access to AWS resources will also need to be given explicit permission to do so.\n\n3. **Authorized devices**: Access can also be limited by device. This is typically achieved through device-based policies.\n\n## Importance\n\nManaging access to resources in the AWS Cloud is crucial for maintaining the security and integrity of your data. By controlling who or what can access your resources, you can prevent unauthorized use, protect sensitive information, and meet regulatory compliance requirements.\n\n## Amazon S3 Buckets\n\nAmazon S3 Buckets are essentially public cloud storage resources available in AWS's S3 service. They are highly scalable and designed to store and retrieve any amount of data, at any time, from anywhere on the web. This control management ensures your S3 buckets are not exposed to potential security risks.\n\n## In Practice\n\nTo implement this control, AWS provides services such as [AWS Identity and Access Management (IAM)](https://aws.amazon.com/iam/) and [AWS Organizations](https://aws.amazon.com/organizations/) which offer advanced features for controlling access at a granular level.\n\nHere is an example on how to achieve this using AWS IAM:\n\n```markdown\n  1. Go to the AWS IAM console.\n  2. Choose **Roles**, then choose **Create role**.\n  3. Under **Select type of trusted entity**, choose **AWS service**.\n  4. Choose the service that will use this role, then choose **Next: Permissions**.\n  5. Under **Attach permissions policies**, search for and check the appropriate policy.\n  6. Follow the prompts to name and describe the new role, then choose **Create role**.\n```\n\nBy using these services and features, you can ensure that your AWS resources are only accessible by authorized users, processes, and devices."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the stated AWS control can have several direct and indirect costs:\n\n1. **Monetary Loss:** If unauthorized users, processes, or devices access Amazon S3 buckets, it could lead to data theft. This unauthorized access can lead to a data breach, and sensitive customer data leak can cost companies heavily in terms of regulatory fines, litigation costs, stock price impact, and potential customer loss.\n\n2. **Reputation Damage:** A data breach can severely harm a company's reputation. Once the trust of customers is compromised, it's difficult to regain their trust back. This could lead to long-term business loss. \n\n3. **Business Disruption:** Unauthorized access can potentially have effects like data corruption, deletion, or holding data hostage. This can disrupt the normal functioning of the company causing a significant business loss.\n\n4. **Regulatory Fines:** Non-compliance to data protection regulations (such as GDPR, HIPAA, etc.) and guidelines can lead to heavy regulatory fines.\n\n5. **Remediation Cost:** Once a breach happens, a forensic investigation into the breach, removal of the unauthorized access, and fixing the vulnerabilities can be an expensive affair.\n\n6. **Loss due to malicious activities:** If an attacker gains unauthorized access and uses the compromised access for activities like crypto-mining, spamming, DDoS, etc., the company might end up with a hefty AWS bill.\n\nHence, managing access to resources in the AWS cloud by only allowing authorized users, processes, and devices access to Amazon S3 buckets is an extremely crucial control to keep the associated costs at bay."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a financial services firm requires a secure storage solution for storing sensitive customer data. They are using Amazon S3 buckets to store this information in the AWS cloud. However, to ensure that this data is accessible only by authorized personnel and to maintain compliance with regulations, they need to manage access to these resources.\n\nBy implementing AWS access control, the firm can set up policies and permissions that restrict access to these Amazon S3 buckets. They might allow access to only certain employees within the firm based on their roles, such as data analysts and database administrators. They might set up processes where these specified roles need to input unique credentials to gain access. The firm could also authorize certain devices for access to prevent hackers from reaching the data from unrecognized devices.\n\nFurthermore, they could set up alerts to inform them of any unauthorized or suspicious attempts to access the data. Leveraging these access control measures, the firm can substantially reduce the chances of a data breach, protect their business credibility and ensure they are adhering to regulatory norms."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_instance_prohibit_public_access",
    "Title": "RDS DB instances should prohibit public access",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that Amazon Relational Database Service (Amazon RDS) instances are not public.",
    "QueryID": "aws_rds_db_instance_prohibit_public_access",
    "DocumentURI": "policies/aws_rds_db_instance_prohibit_public_access.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control - Manage Amazon RDS Instance Accessibility\n\nThis control is aimed at managing the accessibility and security of AWS resources, particularly Amazon Relational Database Service (RDS) instances. The primary objective is to ensure that the RDS instances are not publicly accessible, thereby preventing any unauthorized access or potential threats.\n\nAmazon RDS instances, by default, are created in a Virtual Private Cloud (VPC), providing segregation and security from the public internet. Always reassure these instances are protected from being public, which means that they are not accessible from the internet and can only be accessed within the VPC.\n\nIf an RDS instance is public, it might pose a security risk because it can be accessed from any IP address on the internet.\n\nBelow are best practices to implement this control:\n\n## Best Practices\n\n### 1. Prevent Public Accessibility\nOn creating an RDS instance, ensure to specify its accessibility level. AWS provides two options for `Public Accessibility` - `Yes` and `No`. Always choose `No` to make the instance private.\n\n```markup\n\"PubliclyAccessible\": false\n```\n\n### 2. Use Security Groups\nSecurity groups act as virtual firewalls for your RDS instance. Configure the security groups to restrict the inbound and outbound traffic, allowing only necessary connections.\n\n### 3. Enable Network Access Control Lists (NACLs)\nNACLs provide an additional layer of security for your VPC by controlling the traffic to your RDS instance.\n\n### 4. Implement IAM Policies\nApply IAM policies for the RDS instances to ensure that only authorized users and applications can access or modify the instances.\n\nBy effectively managing the accessibility of your Amazon RDS instances, you can minimize the risk of unauthorized access and protect your valuable data in the AWS Cloud."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the Amazon Web Services (AWS) control of ensuring that Amazon Relational Database Service (RDS) instances are not public can have significant costs. These can be grouped into financial, reputational, and operational costs. \n\n1. **Financial Cost**: If Amazon RDS instances are public, it increases the risk of cyber-attacks. A successful data breach can result in substantial fines especially if the breached data violates various privacy laws like GDPR, HIPAA, CCPA, etc. Additionally, the cost of remediation, investing in more robust security measures post-breach, possible compensation to affected users, as well as potential legal fees can spike up financial costs.\n\n2. **Reputational Cost**: Data breaches harm the reputation of businesses. In an era where data privacy is a matter of significant concern, suffering a data breach due to lack of proper resource access management can decrease user trust in your services. This could result in loss of customers which would affect revenue.\n\n3. **Operational Cost**: Following a successful attack, the organization may have to spend a lot on recovery activities. These can include investigations into what went wrong, the process of fixing the vulnerability, data recovery, and potential system downtimes that affect the business's normal functioning.\n\nAll these costs can potentially dwarf the financial, time, and resource investment into maintaining compliance with the AWS control of managing access to resources in the AWS cloud. Consequently, non-compliance to this AWS control can have significant costs and should be taken seriously."
      ],
      "x-kaytu-usefulness-example": [
        "AWS provides users the ability to manage the visibility of their Amazon RDS instances for security reasons. A common use case of this can be as follows:\n\n**Scenario: E-Commerce Platform**\n\nConsider an e-commerce platform that utilizes an Amazon RDS instance to manage and store all its customer data, including sensitive information like credit card details and personal data. It is important for this business to ensure that their RDS instance is not public and hence, prevent unauthorized entities from accessing this sensitive data.\n\nThe AWS Control to manage access to resources allow engineers at the e-commerce platform to ensure the RDS instance is not publicly accessible. They can check and modify the security groups associated with the database, the network Access control lists (ACLs), and the database's subnet's route table to prevent direct accessibility over the internet. \n\nWithout this AWS Control, the business could be at risk of data breaches, which could have serious legal and reputational consequences. Therefore, the control of managing access is integral to the safe operation of this business and its commitment to customer data protection."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ebs_attached_volume_encryption_enabled",
    "Title": "Attached EBS volumes should have encryption enabled",
    "Description": "Because sensitive data can exist and to help protect data at rest, ensure encryption is enabled for your Amazon Elastic Block Store (Amazon EBS) volumes.",
    "QueryID": "aws_ebs_attached_volume_encryption_enabled",
    "DocumentURI": "policies/aws_ebs_attached_volume_encryption_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gdpr": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "gxp_eu_annex_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/EBS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Encrypt Amazon EBS Volumes \n\nAmazon Web Services (AWS) allows users to protect sensitive data by enabling encryption for your Amazon Elastic Block Store (EBS) volumes. It is critical to implement this security measure to safeguard your data while at rest.\n\n## What is Amazon EBS?\n\nAmazon EBS offers persistent block-level storage volumes for use with EC2 instances in the AWS Cloud. It is mainly used for applications that require a database, a file system, or access to raw block-level storage.\n\n## The Importance of Encrypting EBS Volumes\n\nEncryption plays a crucial role in the protection and compliance of your company data. It converts the original representation of the information into an encoded version, making it unreadable by unauthorized users.\n\nSensitive data can exist in all types of businesses across various industries. Many of these sectors must adhere to strict regulations that mandate the proper protection of sensitive information to prevent unauthorized access and potential data breach incidents.\n\nWhen you enable encryption in Amazon EBS volumes, this ensures that both data at rest within the volume and data moving between the volume and the instance are secured.\n\n## Steps to Enable Encryption for Amazon EBS volumes\n\n1. Open the Amazon EC2 console.\n2. In the navigation pane, choose `Volumes` under `ELASTIC BLOCK STORE`.\n3. Select the volume to encrypt, then choose `Actions`.\n4. In the actions list, choose `Modify Volume`.\n5. In the dialog box, select `Yes` for `Encryption`.\n6. Choose or create a master key in the Key Management Service (KMS) which will be used to encrypt the volume.\n\nBy following these steps, you can ensure your sensitive data resides in encrypted Amazon EBS volumes, bolstering your data security strategy and meeting compliance requirements."
      ],
      "x-kaytu-noncompliance-cost": [
        "## Non-compliance costs to AWS EBS encryption\n\nNon-compliance with the control of ensuring encryption for Amazon Elastic Block Store (EBS) volumes can expose organizations to several potential risks and costs, including but not limited to:\n\n1. **Data Breaches**: If encryption is not enabled, sensitive data stored on Amazon EBS volumes is vulnerable to breaches. This can result in significant financial loss through fines, incident response, and customer compensation. Besides, organizations may face reputational damage, which can impact the customer trust and future business opportunities.\n\n2. **Non-compliance Penalties**: Many industries have privacy regulations that mandate the encryption of sensitive data at rest. Non-compliance with these regulations (GDPR, HIPAA, PCI DSS, etc.) can lead to hefty financial penalties or legal implications.\n\n3. **Loss of Intellectual Property**: Without encryption, an attacker may gain unauthorized access to IP stored as data. This could result in business losses, competitive disadvantage, and damage to the organization's market position.\n\n4. **Operational Disruption**: A security incident caused by encryption non-compliance can disrupt regular business operations, reducing productivity or causing downtime.\n\n5. **Loss of Customer Trust**: If customer data is involved in a breach due to non-compliance, this can lead to a loss of customer trust which could have long-term implications for customer retention and acquisition.\n\nIn conclusion, ensuring encryption is enabled for your Amazon EBS volumes is vital for protecting sensitive data, upholding compliance with data protection regulations, and avoiding potential costly consequences."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, an e-commerce company that uses Amazon Elastic Block Store (Amazon EBS) to store sensitive customer data such as credit card information, personal details etc. would find enabling encryption extremely useful. \n\nIf a malicious attacker gains unauthorized access to the company's server and attempts to steal the data from the EBS volumes, they won't be able to use or read the data if it's encrypted. Thus, the sensitive data would remain secure despite the breach. \n\nMoreover, if the EBS volumes are mistakenly configured to be publicly accessible, the encryption would still prevent any unauthorized individuals from reading the data. \n\nHere's a markup example that can help illustrate the usage: \n\n```\n{\n  \"Resources\": {\n    \"MyVolume\": {\n      \"Type\": \"AWS::EC2::Volume\",\n      \"Properties\": {\n        \"AvailabilityZone\": \"us-west-2b\",\n        \"Size\": \"100\",\n        \"VolumeType\": \"gp2\",\n        \"Encrypted\": \"true\",\n        \"KmsKeyId\": \"arn:aws:kms:us-west-2:012345678912:key/abcd1234-a123-456a-a12b-a123b4cd56ef\"\n      }\n    }\n  }\n}\n```\n\nIn this JSON formatted AWS CloudFormation template example, an encrypted EBS volume (`\"Encrypted\": \"true\"`) is being created with a specified KMS key (`\"KmsKeyId\"`), representing a secure way to ensure any stored data would be unreadable if accessed improperly."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_rds_db_snapshot_prohibit_public_access",
    "Title": "RDS snapshots should prohibit public access",
    "Description": "Manage access to resources in the AWS Cloud by ensuring that Amazon Relational Database Service (Amazon RDS) instances are not public.",
    "QueryID": "aws_rds_db_snapshot_prohibit_public_access",
    "DocumentURI": "policies/aws_rds_db_snapshot_prohibit_public_access.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/RDS"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "AWS provides several mechanisms to secure your Amazon RDS databases. One important control to manage access is ensuring that your Amazon RDS instances are not publicly accessible. This improves the security of your data by preventing unwanted access from uncontrolled sources. \n\nIn Markup format, you can explain this AWS control as follows:\n\n# Manage Access to Resources in the AWS Cloud\nOne critical aspect of managing access to resources in the AWS cloud is controlling access to Amazon RDS instances.\n\n## Amazon RDS Instances\nAmazon RDS provides a scalable and secure database solution. However, you should ensure that these database instances are not publicly accessible. This security measure is essential to prevent any unwanted access and protect your data from unauthorized exploitation.\n\n### Ensuring Private RDS Instances\nTo ensure private RDS instances: \n1. Set the 'Publicly Accessible' option to 'No' when creating or modifying an RDS instance.\n2. Set up Security Groups and NACLs to allow only specific, trusted IP ranges to access your Amazon RDS instances.\n3. Regularly audit your instances to ensure they remain private.\n\nBy following these steps, you can effectively manage access to resources in the AWS cloud, protecting your data from unnecessary exposure."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to this AWS control can result in several serious financial, security, and reputational costs:\n\n1. **Security breaches and data theft**: If your Amazon RDS instances are public, it significantly increases the risk of unauthorized access, data breaches, and theft. You could potentially lose valuable and sensitive data, which could cost your company in compensatory damages.\n\n2. **Regulatory fines and penalties**: Non-compliance can lead to fines, penalties, or even legal action by regulatory bodies, especially if you deal with sensitive data such as personal identifying information (PII) or credit card data.\n\n3. **Loss of customer trust**: If the data breach becomes public knowledge, it can lead to loss of customer trust, impacting your company's image and possibly leading to loss of business. This can have long-term financial implications, as regaining customer trust can be time-consuming and costly.\n\n4. **Compliance costs**: If your systems are found to be non-compliant, you may need to undertake extensive remedial action to ensure compliance, leading to additional cost.\n\n5. **Business disruption**: In the event of a security breach, your business activities might be disrupted, leading to loss of revenue and added costs to restore services. \n\nTo avoid these costs, it is important to ensure that your Amazon RDS instances are not public. Manage and restrict access to your Amazon RDS instances by using mechanisms like Security Groups, Network Access Control Lists (NACLs), and Identity and Access Management (IAM) policies."
      ],
      "x-kaytu-usefulness-example": [
        "For example, consider a business which carries out its operations online on a website. This business keeps all its user-related data, transactional data and other important information in Amazon RDS instances.\n\nIn spite of this, if this Amazon RDS instance is made public, it can lead to potential data breaches. Attackers can exploit this vulnerability to gain unauthorized access to sensitive data, resulting in unlawful activities such as data theft, data loss, or even making the database unavailable by inflicting a Denial-of-Service attack.\n\nWith AWS Control, the business can ensure that their Amazon RDS instances are not public, protecting their sensitive data from unauthorized access. This helps ensure data privacy, maintain business continuity, fulfill compliance requirements, and protect the company's reputation."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_security_group_restrict_ingress_ssh_all",
    "Title": "VPC security groups should restrict ingress SSH access from 0.0.0.0/0",
    "Description": "Amazon Elastic Compute Cloud (Amazon EC2) Security Groups can help manage network access by providing stateful filtering of ingress and egress network traffic to AWS resources.",
    "QueryID": "aws_vpc_security_group_restrict_ingress_ssh_all",
    "DocumentURI": "policies/aws_vpc_security_group_restrict_ingress_ssh_all.md",
    "ManualVerification": false,
    "Severity": "Critical",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cis_controls_v8_ig1": [
        "true"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "pci_dss_v321": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/VPC"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# Amazon Elastic Compute Cloud (EC2) Security Groups \n\nAmazon EC2 Security Groups serve as a virtual firewall for your Elastic Compute Cloud (EC2) instances, helping to control both inbound (ingress) and outbound (egress) network traffic.\n\n## **Stateful Filtering**\n\nSecurity Groups in AWS are stateful, which means changes are dynamically updated and any change in inbound rules might automatically apply to outbound rules as well.\n\nFor example, if you allow incoming HTTP requests from IP 1.2.3.4, then all outbound responses to IP 1.2.3.4 are also allowed. \n\nIn other words, if you send a request from your EC2 instance, the response to that request, regardless of the outbound rules, are allowed to flow back in.\n\n## **How do they work?**\n\nWhen you create a new Security Group, it starts out without any permissions. You then add rules to each security group to allow traffic to or from its associated Amazon EC2 instances. You can modify the rules for a security group at any time; the new rules are automatically applied to all instances that are associated with the security group.\n\n## **Managing Access**\n\nThrough careful rule configuration in your security groups, you can manage access to your instances in the VPC effectively. For instance, you can set rules that allow only web traffic (HTTP and HTTPS) from the internet to reach your Web Servers, or only allow database traffic between your web servers and your database servers."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the AWS Control, which suggests the use of Amazon Elastic Compute Cloud (Amazon EC2) Security Groups, could lead to several costs. \n\n1. **Enhanced Risk of Data Breaches**: Without properly set up security groups, your AWS resources are at a significantly higher risk of malicious attacks. Cybersecurity breaches can lead to unauthorized access of sensitive data that could have serious reputational, legal, and monetary implications.\n\n2. **Inefficient Resource Management**: Not utilizing Amazon EC2 Security Groups leads to poor network access management. It results in the inefficient allocation and use of network traffic, causing poor performance and higher operational costs.\n\n3. **Non-Adherence to Compliance Requirements**: Many industries have stringent regulatory requirements related to data security. Non-compliance to these controls could lead to heavy penalties and legal issues.\n\n4. **Potential System Downtime**: Without appropriate measures to manage network access, systems could be vulnerable to DoS (Denial of Service) attacks. This could lead to system downtime, causing a significant interruption to business operations and potential associated revenue loss.\n\nIn summary, non-compliance with the specified AWS Control can lead to significant costs concerning compromised data security, inefficient operations, possible legal penalties, and potential system downtime. It's essential to use Amazon EC2 Security Groups to manage network access for ensuring optimized, secure, and compliant operations."
      ],
      "x-kaytu-usefulness-example": [
        "For example, imagine you are deploying a web application on AWS using Amazon EC2 instances. The app consists of a public-facing web server and a backend database server. \n\nIn such a scenario, you can set up separate security groups for the web server (WebSG) and the database server (DbSG).\n\nWebSG might be configured to allow ingress traffic on port 80 (HTTP) and port 443 (HTTPS) from anywhere (0.0.0.0/0) and allow all outbound traffic. This way, users globally can access your web server.\n\nThe DbSG might be configured to only allow ingress traffic on the database port (say port 3306 for MySQL) only from the WebSG. This means that only your web server can communicate with your database server, adding an extra layer of security.\n\nThus, using Amazon EC2 Security Groups in this scenario allows you to control the access to your instances, ensuring that they are reachable only as intended, thereby helping to reduce the potential for malicious activity. \n\nHere's how you could define these security groups in markup using AWS CloudFormation YAML format:\n\n```yaml\n  WebSG:\n    Type: 'AWS::EC2::SecurityGroup'\n    Properties:\n      GroupDescription: Web Server SG\n      SecurityGroupIngress:\n        - IpProtocol: tcp\n          FromPort: 80\n          ToPort: 80\n          CidrIp: 0.0.0.0/0\n        - IpProtocol: tcp\n          FromPort: 443\n          ToPort: 443\n          CidrIp: 0.0.0.0/0\n\n  DbSG:\n    Type: 'AWS::EC2::SecurityGroup'\n    Properties:\n      GroupDescription: Database Server SG\n      SecurityGroupIngress:\n        - IpProtocol: tcp\n          FromPort: 3306\n          ToPort: 3306\n          SourceSecurityGroupName: !Ref 'WebSG'\n```\n\nThis is just one example of how Amazon EC2 Security Groups can be useful for managing network access to your AWS resources."
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_ebs_attached_volume_delete_on_termination_enabled",
    "Title": "Attached EBS volumes should have delete on termination enabled",
    "Description": "This rule ensures that Amazon Elastic Block Store volumes that are attached to Amazon Elastic Compute Cloud (Amazon EC2) instances are marked for deletion when an instance is terminated.",
    "QueryID": "aws_ebs_attached_volume_delete_on_termination_enabled",
    "DocumentURI": "policies/aws_ebs_attached_volume_delete_on_termination_enabled.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "service": [
        "AWS/EBS"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Auto-delete EBS Volumes on Termination \n## Rationale\nThis control ensures that any Amazon Elastic Block Store (EBS) volumes that are attached to Amazon Elastic Compute Cloud (EC2) instances are marked for deletion when the instance is terminated. \n\nInternet-facing applications and services running on Amazon EC2 instances can accumulate a large number of EBS volumes over their lifecycle. AWS charges for EBS volumes whether they are in use or not, leading to unnecessary costs if unused volumes are not deleted.\n\nThe aim is to prevent the accumulation of unnecessary Amazon EBS volumes, which will create unnecessary costs. It also helps in maintaining a cleaner and more efficient infrastructure.\n\n## Description\n\nWhen an Amazon EC2 instance is set to terminate, it's important to ensure that the Amazon EBS volumes attached to it are cleaned up as well. With this control, the deletion of EBS volumes is automated when an EC2 instance is terminated, greatly reducing the opportunity for human error and oversight.  \n\n```markdown\n- **Control Key:** EC2-006\n- **Control Name:** Auto-delete EBS Volumes on Termination\n- **Control Description:** Amazon Elastic Block Store volumes attached to Amazon Elastic Compute Cloud instances should be deleted when the instance is terminated.\n- **Rationale:** Minimizing unnecessary EBS volumes reduces costs and promotes more efficient resource utilization within the AWS environment.\n```\n\n## Remediation\n\nTo achieve this control, instance property `DeleteOnTermination` for EBS volumes can be set to `true`. This can be done when launching the instance or modifying an existing one.\n\n```shell\naws ec2 modify-instance-attribute --instance-id i-1234567890abcdef0 --block-device-mappings DeviceName=/dev/sda1,Ebs={DeleteOnTermination=true}\n```\n\nThe above command changes the `DeleteOnTermination` attribute to `true` for the Amazon EBS volume (`/dev/sda1`) attached to the specified instance (`i-1234567890abcdef0`).\n\n## Best Practices\n\nWhile auto-deletion of EBS volumes can help reduce costs, consider the following to prevent data loss:\n\n- Always create and maintain backups of your EBS volumes.\n- Perform regular data audits and clean-ups. \n\nPlease review the official AWS documentation for more information on managing EBS volumes."
      ],
      "x-kaytu-noncompliance-cost": [
        "The cost of non-compliance to this AWS control could be significant in terms of both data security and financial impact. This cost could arise depending on how unreachable data or unanticipated costs have affected a business.\n\nHere are some potential costs in the case of non-compliance:\n\n- **Unused EBS volume Costs**: If EBS volumes are not deleted when their associated EC2 instances are terminated, they continue to exist in the cloud and incur cost, even if they are not in active use. These unused resources could lead to significant unnecessary expenditure over time. \n\n- **Data Privacy and Security Risks**: The data in the unattached volumes could become the target of malicious activities. Not deleting the EBS volumes when an instance is terminated means the data stored in those volumes is still accessible. If adequate security measures are not in place, this could potentially lead to a data breach which could be extremely costly including regulatory penalties, brand damage, and loss of customer trust.\n\n- **Regulatory Non-Compliance**: In some industries, companies may be required to ensure data is deleted once it is no longer required, for compliance purposes with regulations like GDPR, CCPA, PCI DSS, HIPAA, etc. Not adhering to this control could mean breaching these regulations leading to hefty fines and legal consequences.\n\n- **Cleanup Costs**: If there are a large number of unattached EBS volumes, significant time and resources may be required to clean up these volumes, especially if it has to be done manually. \n\nThus, adhering to this rule not only helps to optimize costs by ensuring you're not paying for resources you're not actively using, but also enhance data security by minimizing potential risks and threats."
      ],
      "x-kaytu-usefulness-example": [
        "Example:\n\nYou are managing a range of EC2 instances for a seasonal online store. These instances have associated EBS volumes containing temporary data utilized for the storefront. Once the season ends, you decide to terminate these EC2 instances. \n\nBy having this AWS Control in place, all associated EBS volumes will be automatically marked for deletion when the instances are terminated. This control not only saves you the manual work of deleting each volume individually but also reduces the chance of incurring unnecessary costs from maintaining unused EBS volumes. \n\nMarkup:\n\n```\nExample:\n\nYou are managing a range of EC2 instances for a seasonal online store. These instances have associated EBS volumes containing temporary data utilized for the storefront. Once the season ends, you decide to terminate these EC2 instances. \n\nBy having this AWS Control in place, all associated EBS volumes will be automatically marked for deletion when the instances are terminated. This control not only saves you the manual work of deleting each volume individually but also reduces the chance of incurring unnecessary costs from maintaining unused EBS volumes.\n```"
      ]
    },
    "Managed": true
  },
  {
    "ID": "aws_vpc_security_group_restrict_ingress_common_ports_all",
    "Title": "VPC security groups should restrict ingress access on ports 20, 21, 22, 3306, 3389, 4333 from 0.0.0.0/0",
    "Description": "Manage access to resources in the AWS Cloud by ensuring common ports are restricted on Amazon Elastic Compute Cloud (Amazon EC2) security groups.",
    "QueryID": "aws_vpc_security_group_restrict_ingress_common_ports_all",
    "DocumentURI": "policies/aws_vpc_security_group_restrict_ingress_common_ports_all.md",
    "ManualVerification": false,
    "Severity": "High",
    "Tags": {
      "audit_manager_control_tower": [
        "true"
      ],
      "category": [
        "Compliance"
      ],
      "cisa_cyber_essentials": [
        "true"
      ],
      "fedramp_low_rev_4": [
        "true"
      ],
      "fedramp_moderate_rev_4": [
        "true"
      ],
      "ffiec": [
        "true"
      ],
      "gxp_21_cfr_part_11": [
        "true"
      ],
      "hipaa_final_omnibus_security_rule_2013": [
        "true"
      ],
      "hipaa_security_rule_2003": [
        "true"
      ],
      "nist_800_171_rev_2": [
        "true"
      ],
      "nist_800_53_rev_4": [
        "true"
      ],
      "nist_800_53_rev_5": [
        "true"
      ],
      "nist_csf": [
        "true"
      ],
      "plugin": [
        "aws"
      ],
      "rbi_cyber_security": [
        "true"
      ],
      "service": [
        "AWS/VPC"
      ],
      "soc_2": [
        "true"
      ],
      "x-kaytu-explanation": [
        "# AWS Control: Managing Access to AWS Cloud Resources \n\nIn order to manage access to resources in the AWS Cloud, it is crucial to ensure that common ports are restricted on the Amazon Elastic Compute Cloud (EC2) security groups. Through this control, unauthorized access can be prevented, thereby enhancing the security of your AWS environment. \n\n## Importance of Restricting Ports \n\nBy restricting the common ports on your EC2 security group, you essentially limit the data communication over the network. Remember, each port number represents a different service or application, and by restricting access to them, you can prevent potential exposure of sensitive data or vulnerabilities to external threats. \n\n## Implementation \n\nTo manage this, you can set up your security groups in such a way that it only allows inbound traffic from trusted IP ranges or specific Amazon EC2 instances. Similarly, by allowing outgoing traffic only to specific IP addresses, ports, or both, you can protect your resources. The less access you provide, the less attractive your infrastructure becomes for potential attackers. \n\n---\nRemember, to edit a security group, you need to log in to your Amazon EC2 console, select 'Security Groupsâ€™ from the navigation pane, select the security group, choose the 'Inbound Rules' or 'Outbound Rules' tab, and update the rules as necessary. \n\nTake note however, these changes can impact applications and services running on your instances, so a thorough understanding of the network requirements of your applications and services is essential. \n\nAlways remember, implementing a 'least privilege' principle in managing access to your AWS resources is a best practice for enhancing your cloud security."
      ],
      "x-kaytu-noncompliance-cost": [
        "Non-compliance to the \"Manage access to resources in the AWS Cloud\" control by not ensuring that common ports are restricted on Amazon EC2 security groups can result in various costs. Here are some possible implications and associated costs:\n\n1. **Security Risks \u0026 Data Breach:** If common ports are left open, it increases chances of unauthorised access and data breach. This can lead to financial losses due to potential regulatory penalties and business reputation damage.\n\n2. **Data Theft:** Potential data theft resulting from unauthorized access can lead to significant financial loss depending on the value of the stolen data.\n\n3. **Service Disruption:** An intruder could potentially damage or disrupt the service, leading to service downtime and impact business continuity. This would negatively impact the business financially, as the cost to restore service can be substantial.\n\n4. **Potential Regulatory Penalties:** Non-compliance could result in regulatory penalties, especially if the breach involves sensitive or personal data, and the business failed to meet compliance requirements.\n\n5. **Increased Audit \u0026 Investigation Cost:** In case of a data breach, businesses might need to conduct an extensive audit and investigation to identify the breach source, which can be costly.\n\n6. **Additional Remediation Cost:** Depending on the extent and impact of a breach, the business could incur significant remediation costs.\n\n7. **Operational Inefficiencies:** Unauthorized access could lead to operational inefficiencies that can have a negative impact on productivity and therefore lead to financial costs.\n\nTherefore, it's important to ensure common ports are restricted on Amazon EC2 security groups to mitigate these risks and associated costs."
      ],
      "x-kaytu-usefulness-example": [
        "For instance, a company has several Amazon EC2 instances running different web applications and servers. The company is concerned about the potential security risks from unauthorized access or attacks to these applications.\n\nProperly managing access to resources would involve restricting common ports on Amazon EC2 security groups to mitigate these risks. For example, the company could restrict SSH access (port 22), which is commonly targeted by brute force attacks, to only their specific IP ranges. In addition, unused ports can also be closed off to eliminate any potential vulnerabilities.\n\nManaging access in this way protects the companyâ€™s EC2 instances from unauthorized access, ensures that only the necessary ports are open to reduce potential attack surfaces, and greatly increases the security of their AWS Cloud environment. This can not only prevent potential data breaches but can also enhance the performance of the servers by preventing unnecessary traffic."
      ]
    },
    "Managed": true
  }
]